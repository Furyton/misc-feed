<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-10-14T23:14:03.025Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Arnak Dalalyan at the RSS Journal Webinar]]></title>
        <id>http://xianblog.wordpress.com/?p=54209</id>
        <link href="https://xianblog.wordpress.com/2023/10/15/arnak-dalalyan-at-the-rss-journal-webinar/"/>
        <updated>2023-10-14T22:23:37.000Z</updated>
        <summary type="html"><![CDATA[My friend and CREST colleague Arnak Dalalyan will (re)present [online] a Read Paper at the RSS on 31 October with my friends Hani Doss and Alain Durmus as discussants: ‘Theoretical Guarantees for Approximate Sampling and Log-Concave Densities’ Arnak Dalalyan ENSAE Paris, France Sampling from various kinds of distributions is an issue of paramount importance in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Socks, a matching game based on an additive combinatorics problem]]></title>
        <id>https://jeremykun.com/?p=120042</id>
        <link href="https://jeremykun.com/2023/10/14/socks-a-matching-game-based-on-an-additive-combinatorics-problem/"/>
        <updated>2023-10-14T13:00:00.000Z</updated>
        <summary type="html"><![CDATA[Can you find a set of cards among these six, such that the socks on the chosen cards can be grouped into matching pairs? (Duplicate pairs of the same sock are OK) This is the objective of the game Socks, a card game originally designed by Anna Varvak, a math professor at Soka University of […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SwinCross: Cross-modal Swin Transformer for Head-and-Neck Tumor
  Segmentation in PET/CT Images]]></title>
        <id>http://arxiv.org/abs/2302.03861</id>
        <link href="http://arxiv.org/abs/2302.03861"/>
        <updated>2023-10-14T02:18:49.684Z</updated>
        <summary type="html"><![CDATA[Gary Y. Li, Junyu Chen, Se-In Jang, Kuang Gong, Quanzheng Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hubert Reeves (1932-2023)]]></title>
        <id>http://xianblog.wordpress.com/?p=54253</id>
        <link href="https://xianblog.wordpress.com/2023/10/14/hubert-reeves-1932-2023/"/>
        <updated>2023-10-13T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Batch calibration: Rethinking calibration for in-context learning and prompt engineering]]></title>
        <id>http://blog.research.google/2023/10/batch-calibration-rethinking.html</id>
        <link href="http://blog.research.google/2023/10/batch-calibration-rethinking.html"/>
        <updated>2023-10-13T18:01:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Han Zhou, Student Researcher, and Subhrajit Roy, Senior Research Scientist, Google Research





Prompting large language models (LLMs) has become an efficient learning paradigm for adapting LLMs to a new task by conditioning on human-designed instructions. The remarkable in-context learning (ICL) ability of LLMs also leads to efficient few-shot learners that can generalize from few-shot input-label pairs. However, the predictions of LLMs are highly sensitive and even biased to the choice of templates, label spaces (such as yes/no, true/false, correct/incorrect), and demonstration examples, resulting in unexpected performance degradation and barriers for pursuing robust LLM applications. To address this problem, calibration methods have been developed to mitigate the effects of t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Emmanuel Abbe - Logic Reasoning and Generalization on the Unseen]]></title>
        <id>https://mlfoundations.org/talk/abbe/</id>
        <link href="https://mlfoundations.org/talk/abbe/"/>
        <updated>2023-10-13T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Transformers have become the dominant neural network architecture in deep learning. While they are state of the art in language and vision tasks, their performance is less convincing in so-called “reasoning” tasks. In this talk, we consider the “generalization on the unseen (GOTU)" objective to test the reasoning capabilities of neural networks, primarily Transformers on Boolean/logic tasks. We first give experimental results showing that such networks have a strong “minimal degree bias" - they tend to find specific interpolators having low degree, in agreement with the “leap complexity” picture derived for classic generalization. Using basic concepts from Boolean Fourier analysis and algebraic geometry, we then characterize such minimal degree profile interpolators and prove two theorems about the convergence of (S)GD to such interpolators on basic architectures. Since the minimal degree profile is not desirable in many reasoning tasks, we discuss various methods to correct this bias and improve consequently the reasoning capabilities. Based primarily on joint works with S. Bengio, A. Lotfi, K. Rizk and E. Adsera-Boix, T. Misiakiewicz.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Autoarticulation]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60917</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60917&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=autoarticulation"/>
        <updated>2023-10-13T11:43:35.000Z</updated>
        <summary type="html"><![CDATA[As Language Log readers are undoubtedly aware, I am prey to mondegreens, earworms, and other imaginary auditory oddities.  Lately, the last half year or so, I've been occasionally subject to what, faute de mieux, I've taken to calling "autoarticulation", modeled after "autosuggestion". It doesn't last very long, doesn't repeat on an endless loop, and is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EMO：基于最优传输思想设计的分类损失函数]]></title>
        <id>https://kexue.fm/archives/9797</id>
        <link href="https://kexue.fm/archives/9797"/>
        <updated>2023-10-13T09:06:00.000Z</updated>
        <summary type="html"><![CDATA[众所周知，分类任务的标准损失是交叉熵（Cross Entropy，等价于最大似然MLE，即Maximum Likelihood Estimation），它有着简单高效的特点，但在某些场景下也暴露...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flash-Decoding for long-context inference]]></title>
        <id>https://pytorch.org/blog/flash-decoding/</id>
        <link href="https://pytorch.org/blog/flash-decoding/"/>
        <updated>2023-10-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially Private Non-convex Learning for Multi-layer Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2310.08425</id>
        <link href="http://arxiv.org/abs/2310.08425"/>
        <updated>2023-10-13T02:24:56.147Z</updated>
        <summary type="html"><![CDATA[Hanpu Shen, Cheng-Long Wang, Zihang Xiang, Yiming Ying, Di
  Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement]]></title>
        <id>http://arxiv.org/abs/2310.07831</id>
        <link href="http://arxiv.org/abs/2310.07831"/>
        <updated>2023-10-13T02:24:56.142Z</updated>
        <summary type="html"><![CDATA[Aaron Defazio, Ashok Cutkosky, Harsh Mehta, Konstantin
  Mishchenko]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Theory of Non-Linear Feature Learning with One Gradient Step in
  Two-Layer Neural Networks]]></title>
        <id>http://arxiv.org/abs/2310.07891</id>
        <link href="http://arxiv.org/abs/2310.07891"/>
        <updated>2023-10-13T02:24:56.138Z</updated>
        <summary type="html"><![CDATA[Behrad Moniri, Donghwan Lee, Hamed Hassani, Edgar Dobriban]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Feature Learning and Generalization in Deep Networks with Orthogonal
  Weights]]></title>
        <id>http://arxiv.org/abs/2310.07765</id>
        <link href="http://arxiv.org/abs/2310.07765"/>
        <updated>2023-10-13T02:24:56.133Z</updated>
        <summary type="html"><![CDATA[Hannah Day, Yonatan Kahn, Daniel A. Roberts]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformers as Decision Makers: Provable In-Context Reinforcement
  Learning via Supervised Pretraining]]></title>
        <id>http://arxiv.org/abs/2310.08566</id>
        <link href="http://arxiv.org/abs/2310.08566"/>
        <updated>2023-10-13T02:24:53.412Z</updated>
        <summary type="html"><![CDATA[Licong Lin, Yu Bai, Song Mei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[preserving civilian lives is essential [reposted Guardian editorial]]]></title>
        <id>http://xianblog.wordpress.com/?p=54238</id>
        <link href="https://xianblog.wordpress.com/2023/10/13/preserving-civilian-lives-is-essential-reposted-guardian-editorial/"/>
        <updated>2023-10-12T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Developing industrial use cases for physical simulation on future error-corrected quantum computers]]></title>
        <id>http://blog.research.google/2023/10/developing-industrial-use-cases-for.html</id>
        <link href="http://blog.research.google/2023/10/developing-industrial-use-cases-for.html"/>
        <updated>2023-10-12T20:56:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Nicholas Rubin, Senior Research Scientist, and Ryan Babbush, Head of Quantum Algorithms, Quantum AI Team





If you’ve paid attention to the quantum computing space, you’ve heard the claim that in the future, quantum computers will solve certain problems exponentially more efficiently than classical computers can. They have the potential to transform many industries, from pharmaceuticals to energy.



For the most part, these claims have rested on arguments about the asymptotic scaling of algorithms as the problem size approaches infinity, but this tells us very little about the practical performance of quantum computers for finite-sized problems. We want to be more concrete: Exactly which problems are quantum computers more suited to tackle than their classical counterparts, an…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ox Demolition]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60911</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60911&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ox-demolition"/>
        <updated>2023-10-12T12:47:04.000Z</updated>
        <summary type="html"><![CDATA[From AntC: The black Chinese writing on a yellow background says: tuòhuāng niú jiànzhù qīngchāi gōnsī 拓荒牛建筑清拆公司 "bull / ox /bovine for opening up / reclaiming (waste)land for agriculture construction and demolition company" AntC, who sent this photograph to me, also included the following remarks: In my neighbourhood there’s a straggling cluster of Chinese/Asian businesses […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Machine Learning Approach for Modelling Parking Duration in Urban
  Land-use]]></title>
        <id>http://arxiv.org/abs/2008.01674</id>
        <link href="http://arxiv.org/abs/2008.01674"/>
        <updated>2023-10-12T02:19:40.575Z</updated>
        <summary type="html"><![CDATA[Janak Parmar, Pritikana Das, Sanjaykumar Dave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Change-Point Detection in Time Series via Deep Learning]]></title>
        <id>http://arxiv.org/abs/2211.03860</id>
        <link href="http://arxiv.org/abs/2211.03860"/>
        <updated>2023-10-12T02:19:40.545Z</updated>
        <summary type="html"><![CDATA[Jie Li, Paul Fearnhead, Piotr Fryzlewicz, Tengyao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Equivariant Transfer Learning from Pretrained Models]]></title>
        <id>http://arxiv.org/abs/2305.09900</id>
        <link href="http://arxiv.org/abs/2305.09900"/>
        <updated>2023-10-12T02:19:40.521Z</updated>
        <summary type="html"><![CDATA[Sourya Basu, Pulkit Katdare, Prasanna Sattigeri, Vijil
  Chenthamarakshan, Katherine Driggs-Campbell, Payel Das, Lav R. Varshney]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge Rumination for Pre-trained Language Models]]></title>
        <id>http://arxiv.org/abs/2305.08732</id>
        <link href="http://arxiv.org/abs/2305.08732"/>
        <updated>2023-10-12T02:19:40.468Z</updated>
        <summary type="html"><![CDATA[Yunzhi Yao, Peng Wang, Shengyu Mao, Chuanqi Tan, Fei Huang, Huajun
  Chen, Ningyu Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Double-Descent in Reinforcement Learning with LSTD and Random
  Features]]></title>
        <id>http://arxiv.org/abs/2310.05518</id>
        <link href="http://arxiv.org/abs/2310.05518"/>
        <updated>2023-10-12T02:19:40.400Z</updated>
        <summary type="html"><![CDATA[David Brellmann, Elo\"ise Berthier, David Filliat, Goran Frehse]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[learning ABC summaries with autoencoders [webinar]]]></title>
        <id>http://xianblog.wordpress.com/?p=54081</id>
        <link href="https://xianblog.wordpress.com/2023/10/12/learning-abc-summaries-with-autoencoders-webinar/"/>
        <updated>2023-10-11T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[The next One World ABC seminar will take place this Thursday, September 28, at 9am UK time and on-line. Speaker: Carlo Albert, Swiss Federal Institute of Aquatic Science and Technology Title: Learning summary statistics for Bayesian inference with Autoencoders Abstract: In order for ABC to give accurate results and be efficient, we need summary statistics […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What and How does In-Context Learning Learn? Bayesian Model Averaging,
  Parameterization, and Generalization]]></title>
        <id>http://arxiv.org/abs/2305.19420</id>
        <link href="http://arxiv.org/abs/2305.19420"/>
        <updated>2023-10-11T14:14:40.172Z</updated>
        <summary type="html"><![CDATA[Yufeng Zhang, Fengzhuo Zhang, Zhuoran Yang, Zhaoran Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Language Models Streamline Automated Machine Learning for Clinical
  Studies]]></title>
        <id>http://arxiv.org/abs/2308.14120</id>
        <link href="http://arxiv.org/abs/2308.14120"/>
        <updated>2023-10-11T14:14:40.156Z</updated>
        <summary type="html"><![CDATA[Soroosh Tayebi Arasteh, Tianyu Han, Mahshad Lotfinia, Christiane Kuhl,
  Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Transfer Learning and Gradient-Based Meta-Learning
  Techniques]]></title>
        <id>http://arxiv.org/abs/2310.06148</id>
        <link href="http://arxiv.org/abs/2310.06148"/>
        <updated>2023-10-11T14:14:40.149Z</updated>
        <summary type="html"><![CDATA[Mike Huisman, Aske Plaat, Jan N. van Rijn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Layer-wise Equivariances Automatically using Gradients]]></title>
        <id>http://arxiv.org/abs/2310.06131</id>
        <link href="http://arxiv.org/abs/2310.06131"/>
        <updated>2023-10-11T14:14:40.144Z</updated>
        <summary type="html"><![CDATA[Tycho F.A. van der Ouderaa, Alexander Immer, Mark van der Wilk]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mitigating Simplicity Bias in Deep Learning for Improved OOD
  Generalization and Robustness]]></title>
        <id>http://arxiv.org/abs/2310.06161</id>
        <link href="http://arxiv.org/abs/2310.06161"/>
        <updated>2023-10-11T14:14:40.074Z</updated>
        <summary type="html"><![CDATA[Bhavya Vasudeva, Kameron Shahabi, Vatsal Sharan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open letter to the Harvard community]]></title>
        <id>http://windowsontheory.org/?p=8694</id>
        <link href="https://windowsontheory.org/2023/10/11/open-letter-to-the-harvard-community/"/>
        <updated>2023-10-11T13:15:42.000Z</updated>
        <summary type="html"><![CDATA[This is a copy of the open letter that has been signed by well over 100 faculty at the time I am posting this. The full letter and list of signatories can be found on https://bit.ly/harvard-against-terrorism We are faculty at Harvard who are deeply concerned about the events in the Middle East, as well as … Continue reading Open letter to the Harvard community]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open letter to the Harvard community]]></title>
        <id>http://windowsontheory.org/?p=8694</id>
        <link href="https://windowsontheory.org/2023/10/11/open-letter-to-the-harvard-community/"/>
        <updated>2023-10-11T13:15:42.000Z</updated>
        <summary type="html"><![CDATA[This is a copy of the open letter that has been signed by well over 100 faculty at the time I am posting this. The full letter and list of signatories can be found on https://bit.ly/harvard-against-terrorism We are faculty at Harvard who are deeply concerned about the events in the Middle East, as well as … Continue reading Open letter to the Harvard community]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ML Model Server Resource Saving - Transition From High-Cost GPUs to Intel CPUs and oneAPI powered Software with performance]]></title>
        <id>https://pytorch.org/blog/ml-model-server-resource-saving/</id>
        <link href="https://pytorch.org/blog/ml-model-server-resource-saving/"/>
        <updated>2023-10-11T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Reviewers: Yunsang Ju(Naver GplaceAI Leader), Min Jean Cho(Intel), Jing Xu(Intel), Mark Saroufim(Meta)]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Men's Treaming]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60883</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60883&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mens-treaming"/>
        <updated>2023-10-11T04:36:45.000Z</updated>
        <summary type="html"><![CDATA[From Nick Tursi in Qatar: The sign says: ḥilāqat al-rijāl = “men’s shaving” For "Men's Trimming". That elongation of the short "i" is common among non-native speakers. Mauritians ask "where do you leave" (for "live"). Selected readings "A new way to resolve paradoxes" (10 /8/22) "Ockham's broom" (10/17/09) [Thanks to Devin Stewart, Joe Lowry, and […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[European particles matter]]></title>
        <id>http://xianblog.wordpress.com/?p=54075</id>
        <link href="https://xianblog.wordpress.com/2023/10/11/european-particles-matter/"/>
        <updated>2023-10-10T22:23:29.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Standardizing a random vector and applications]]></title>
        <id>https://parsiad.ca/blog/2023/standardizing_a_random_vector_and_applications/</id>
        <link href="https://parsiad.ca/blog/2023/standardizing_a_random_vector_and_applications/"/>
        <updated>2023-10-10T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Standardizing a random vector and applications to sampling a multivariate random normal distribution]]></title>
        <id>https://parsiad.ca/blog/2023/uncorrelating_correlated_random_normal_variables/</id>
        <link href="https://parsiad.ca/blog/2023/uncorrelating_correlated_random_normal_variables/"/>
        <updated>2023-10-10T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Real-time Audio-visual Speech Recognition]]></title>
        <id>https://pytorch.org/blog/real-time-speech-rec/</id>
        <link href="https://pytorch.org/blog/real-time-speech-rec/"/>
        <updated>2023-10-10T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Audio-Visual Speech Recognition (AV-ASR, or AVSR) is the task of transcribing text from audio and visual streams, which has recently attracted a lot of research attention due to its robustness to noise. The vast majority of work to date has focused on developing AV-ASR models for non-streaming recognition; studies on streaming AV-ASR are very limited.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Happy Hangul Day!]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60891</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60891&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=happy-hangul-day"/>
        <updated>2023-10-09T22:42:43.000Z</updated>
        <summary type="html"><![CDATA[Language wars, the Korean edition "Foreign words dominate signboards, restaurant menus in Korea", omonatheydidn't, LiveJournal (10/8/23; page loaded 10/9/23); source: The Korea Times Trendy use of foreign languages apparently sparks outrage in Korea as well. A Seoul-based office worker surnamed Kim, 35, was perplexed at being unable to locate the Japanese restaurant he had reserved […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian inference and conformal prediction]]></title>
        <id>http://xianblog.wordpress.com/?p=54191</id>
        <link href="https://xianblog.wordpress.com/2023/10/10/bayesian-inference-and-conformal-prediction/"/>
        <updated>2023-10-09T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Letter to Harvard President Claudine Gay]]></title>
        <id>http://windowsontheory.org/?p=8687</id>
        <link href="https://windowsontheory.org/2023/10/09/letter-to-harvard-president-claudine-gay/"/>
        <updated>2023-10-09T20:45:27.000Z</updated>
        <summary type="html"><![CDATA[Dear President Gay, Recent days have been harrowing for both me and every other Israeli or Jewish person on the Harvard campus. On October 7th, Hamas launched a premeditated attack on the Israeli population. Hundreds of terrorists infiltrated Israeli towns and houses. Children were killed in front of their parents; entire families were executed. Grandmothers, … Continue reading Letter to Harvard President Claudine Gay]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Letter to Harvard President Claudine Gay]]></title>
        <id>http://windowsontheory.org/?p=8687</id>
        <link href="https://windowsontheory.org/2023/10/09/letter-to-harvard-president-claudine-gay/"/>
        <updated>2023-10-09T20:45:27.000Z</updated>
        <summary type="html"><![CDATA[Dear President Gay, Recent days have been harrowing for both me and every other Israeli or Jewish person on the Harvard campus. On October 7th, Hamas launched a premeditated attack on the Israeli population. Hundreds of terrorists infiltrated Israeli towns and houses. Children were killed in front of their parents; entire families were executed. Grandmothers, … Continue reading Letter to Harvard President Claudine Gay]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SANPO: A Scene understanding, Accessibility, Navigation, Pathfinding, & Obstacle avoidance dataset]]></title>
        <id>http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html</id>
        <link href="http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html"/>
        <updated>2023-10-09T19:17:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Sagar M. Waghmare, Senior Software Engineer, and Kimberly Wilber, Software Engineer, Google Research, Perception Team




As most people navigate their everyday world, they process visual input from the environment using an eye-level perspective. Unlike robots and self-driving cars, people don't have any "out-of-body" sensors to help guide them. Instead, a person’s sensory input is completely "egocentric", or "from the self." This also applies to new technologies that understand the world around us from a human-like perspective, e.g., robots navigating through unknown buildings, AR glasses that highlight objects, or assistive technology to help people run independently.





In computer vision, scene understanding is the subfield that studies how visible objects relate to the sce…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How cats purr]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60886</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60886&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-cats-purr"/>
        <updated>2023-10-09T10:22:17.000Z</updated>
        <summary type="html"><![CDATA[The sound of a cat's purr is a familiar one: Your browser does not support the audio element. But this familiar sound raises at least two interesting biophysical questions. In the first place, cats purr both while breathing out and breathing in, while most people can only produce voiced sounds (= laryngeal oscillations) while breathing […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Occitan and Oenology]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60878</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60878&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=occitan-and-oenology"/>
        <updated>2023-10-09T01:29:55.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by François Lang] Picpoul (AKA Piquepoul, or Picapoll) is a white wine grape best known in the south of France.  The grape is known for its intense acidity, and many wine references claim that its name derives from the Occitan for "lip stinger". But I can't find any justification for […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[sweet 60’s]]></title>
        <id>http://xianblog.wordpress.com/?p=54064</id>
        <link href="https://xianblog.wordpress.com/2023/10/09/sweet-60s/"/>
        <updated>2023-10-08T22:23:26.000Z</updated>
        <summary type="html"><![CDATA[The traditional group picture at the end of Eric Moulines’ 60th anniversary celebration, at IHP, Paris. Some of the participants had already left (and I am carefully hidding in the background). Among the celebrating talks reflecting the huge thematic diversity of EM’s carreer, Patrick Flandrin gave a great historical account of a certain Édouard-Léon Scott […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[预训练一下，Transformer的长序列成绩还能涨不少！]]></title>
        <id>https://kexue.fm/archives/9787</id>
        <link href="https://kexue.fm/archives/9787"/>
        <updated>2023-10-08T07:09:00.000Z</updated>
        <summary type="html"><![CDATA[作为LLM的主流模型架构，Transformer在各类任务上的总体表现都出色，大多数情况下，Transformer的槽点只是它的平方复杂度，而不是效果——除了一个名为Long Range Are...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[computational statistics position at U of Toronto]]></title>
        <id>http://xianblog.wordpress.com/?p=54184</id>
        <link href="https://xianblog.wordpress.com/2023/10/08/computational-statistics-position-at-u-of-toronto/"/>
        <updated>2023-10-07T22:23:38.000Z</updated>
        <summary type="html"><![CDATA[Another Canadian assistant professor opening in computational statistics, with a call for candidates from the University of Toronto, with deadline 20 November 2023: Candidates must have earned a PhD degree in Statistics or a related area by the time of appointment, or shortly thereafter, with a demonstrated record of excellence in research and teaching. Experience […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nobel Prize winner Jon Fosse writes in Nynorsk, a minority writing system]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60870</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60870&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=nobel-prize-winner-jon-fosse-writes-in-nynorsk-a-minority-writing-system"/>
        <updated>2023-10-07T11:38:06.000Z</updated>
        <summary type="html"><![CDATA["The Nobel literature prize goes to Norway’s Jon Fosse, who once wrote a novel in a single sentence" By DAVID KEYTON, MIKE CORDER and JILL LAWLESS, AP (10/5/23) … While Fosse is the fourth Norwegian writer to get the Nobel literature prize, he is the first in nearly a century and the first who writes in […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[un/a post/e à/at U de/of Montréal]]></title>
        <id>http://xianblog.wordpress.com/?p=54180</id>
        <link href="https://xianblog.wordpress.com/2023/10/07/un-a-post-e-a-at-u-de-of-montreal/"/>
        <updated>2023-10-06T22:23:48.000Z</updated>
        <summary type="html"><![CDATA[A new assistant professor position in Statistics/Machine learning is opening at UdeM, the University of Montréal, with deadline 11 November 2023: The Department of Mathematics and Statistics invites applications for a full-time, tenure-track position of Assistant Professor in Statistics and Machine Learning. The successful candidate, depending on his or her expertise and interest, could be […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noncommutative Poisson vertex algebras and Courant-Dorfman algebras]]></title>
        <id>http://arxiv.org/abs/2106.00270</id>
        <link href="http://arxiv.org/abs/2106.00270"/>
        <updated>2023-10-06T21:12:33.945Z</updated>
        <summary type="html"><![CDATA[Luis \'Alvarez-C\'onsul, David Fern\'andez, Reimundo Heluani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Constructing abelian varieties from rank 2 Galois representations]]></title>
        <id>http://arxiv.org/abs/2208.01999</id>
        <link href="http://arxiv.org/abs/2208.01999"/>
        <updated>2023-10-06T21:12:33.918Z</updated>
        <summary type="html"><![CDATA[Raju Krishnamoorthy, Jinbang Yang, Kang Zuo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Twisted conjugacy in soluble arithmetic groups]]></title>
        <id>http://arxiv.org/abs/2007.02988</id>
        <link href="http://arxiv.org/abs/2007.02988"/>
        <updated>2023-10-06T21:12:33.895Z</updated>
        <summary type="html"><![CDATA[Paula Macedo Lins de Araujo, Yuri Santos Rego]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New reducible configurations for graph multicoloring with application to
  the experimental resolution of McDiarmid-Reed's Conjecture (extended version)]]></title>
        <id>http://arxiv.org/abs/1812.01911</id>
        <link href="http://arxiv.org/abs/1812.01911"/>
        <updated>2023-10-06T21:12:33.875Z</updated>
        <summary type="html"><![CDATA[Jean-Christophe Godin, Olivier Togni]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Principles of modern physics imply basic model of the universe]]></title>
        <id>http://arxiv.org/abs/physics/0107050</id>
        <link href="http://arxiv.org/abs/physics/0107050"/>
        <updated>2023-10-06T21:12:33.849Z</updated>
        <summary type="html"><![CDATA[Craig Philpot]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Keereezmy"; "Kill his mind"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60856</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60856&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=keereezmy-kill-his-mind"/>
        <updated>2023-10-06T11:32:28.000Z</updated>
        <summary type="html"><![CDATA[As I explained here in February of this year: One time on an expedition around the western part of the Taklamakan Desert in the center of Asia more than a decade ago, the Chinese driver played Lady Gaga's "Poker Face" scores of times.  He had other discs, but he only played that song, and he […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Inferential Reproducibility of Machine Learning Research]]></title>
        <id>http://arxiv.org/abs/2302.04054</id>
        <link href="http://arxiv.org/abs/2302.04054"/>
        <updated>2023-10-06T02:21:46.667Z</updated>
        <summary type="html"><![CDATA[Michael Hagmann, Philipp Meier, Stefan Riezler]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantitative CLTs in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2307.06092</id>
        <link href="http://arxiv.org/abs/2307.06092"/>
        <updated>2023-10-06T02:21:46.631Z</updated>
        <summary type="html"><![CDATA[Stefano Favaro, Boris Hanin, Domenico Marinucci, Ivan Nourdin,
  Giovanni Peccati]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explaining Emergent In-Context Learning as Kernel Regression]]></title>
        <id>http://arxiv.org/abs/2305.12766</id>
        <link href="http://arxiv.org/abs/2305.12766"/>
        <updated>2023-10-06T02:21:43.656Z</updated>
        <summary type="html"><![CDATA[Chi Han, Ziqi Wang, Han Zhao, Heng Ji]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse Deep Learning for Time Series Data: Theory and Applications]]></title>
        <id>http://arxiv.org/abs/2310.03243</id>
        <link href="http://arxiv.org/abs/2310.03243"/>
        <updated>2023-10-06T02:21:43.478Z</updated>
        <summary type="html"><![CDATA[Mingxuan Zhang, Yan Sun, Faming Liang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Energy-Based Prior Model with Diffusion-Amortized MCMC]]></title>
        <id>http://arxiv.org/abs/2310.03218</id>
        <link href="http://arxiv.org/abs/2310.03218"/>
        <updated>2023-10-06T02:21:43.472Z</updated>
        <summary type="html"><![CDATA[Peiyu Yu, Yaxuan Zhu, Sirui Xie, Xiaojian Ma, Ruiqi Gao, Song-Chun
  Zhu, Ying Nian Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mostly Monte Carlo Se[a]minar]]></title>
        <id>http://xianblog.wordpress.com/?p=54204</id>
        <link href="https://xianblog.wordpress.com/2023/10/06/mostly-monte-carlo-seaminar/"/>
        <updated>2023-10-05T22:23:38.000Z</updated>
        <summary type="html"><![CDATA[A brand new monthly series of Parisian seminars on the theory and practice of Monte Carlo in statistics and data science, in conjunction with our ERC OCEAN project. To kick start the series the organisers, Joshua Bon and Andrea Bertazzi, first postdocs in the project, will present some of their work on Friday 13 October, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computational Complexity of Learning Neural Networks: Smoothness and
  Degeneracy]]></title>
        <id>http://arxiv.org/abs/2302.07426</id>
        <link href="http://arxiv.org/abs/2302.07426"/>
        <updated>2023-10-05T02:23:40.316Z</updated>
        <summary type="html"><![CDATA[Amit Daniely, Nathan Srebro, Gal Vardi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computing high-dimensional optimal transport by flow neural networks]]></title>
        <id>http://arxiv.org/abs/2305.11857</id>
        <link href="http://arxiv.org/abs/2305.11857"/>
        <updated>2023-10-05T02:23:39.939Z</updated>
        <summary type="html"><![CDATA[Chen Xu, Xiuyuan Cheng, Yao Xie]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PersA-FL: Personalized Asynchronous Federated Learning]]></title>
        <id>http://arxiv.org/abs/2210.01176</id>
        <link href="http://arxiv.org/abs/2210.01176"/>
        <updated>2023-10-05T02:23:39.824Z</updated>
        <summary type="html"><![CDATA[Mohammad Taha Toghani, Soomin Lee, C\'esar A. Uribe]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified Transfer Learning Models for High-Dimensional Linear Regression]]></title>
        <id>http://arxiv.org/abs/2307.00238</id>
        <link href="http://arxiv.org/abs/2307.00238"/>
        <updated>2023-10-05T02:23:39.572Z</updated>
        <summary type="html"><![CDATA[Shuo Shuo Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No(t/n)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60825</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60825&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=not-n"/>
        <updated>2023-10-05T01:12:47.000Z</updated>
        <summary type="html"><![CDATA[That's bù 不, plus = a-, il-, im-, in-, ir-, un-, non- prefixes in English. It can enter into Mandarin contractions, such as bù 不 ("not") + yòng 用 ("use") = béng ("needn't), and the two Sinoglyphs used to write the constituent morphosyllables can fuse to become béng 甭 ("needn't). Here's a whole slew of such […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trajectory balance: Improved credit assignment in GFlowNets]]></title>
        <id>http://arxiv.org/abs/2201.13259</id>
        <link href="http://arxiv.org/abs/2201.13259"/>
        <updated>2023-10-05T01:04:49.684Z</updated>
        <summary type="html"><![CDATA[Nikolay Malkin, Moksh Jain, Emmanuel Bengio, Chen Sun, Yoshua Bengio]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2110.14053</id>
        <link href="http://arxiv.org/abs/2110.14053"/>
        <updated>2023-10-05T01:04:48.366Z</updated>
        <summary type="html"><![CDATA[Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth McMillan,
  Risto Miikkulainen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the efficiency of Stochastic Quasi-Newton Methods for Deep Learning]]></title>
        <id>http://arxiv.org/abs/2205.09121</id>
        <link href="http://arxiv.org/abs/2205.09121"/>
        <updated>2023-10-05T01:04:45.186Z</updated>
        <summary type="html"><![CDATA[Mahsa Yousefi, Angeles Martinez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Naive Exploration is Optimal for Online LQR]]></title>
        <id>http://arxiv.org/abs/2001.09576</id>
        <link href="http://arxiv.org/abs/2001.09576"/>
        <updated>2023-10-05T01:04:45.181Z</updated>
        <summary type="html"><![CDATA[Max Simchowitz, Dylan J. Foster]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Implicit Regularization of ReLU Neural Networks Characterizes the
  Learned Function -- Part I: the 1-D Case of Two Layers with Random First
  Layer]]></title>
        <id>http://arxiv.org/abs/1911.02903</id>
        <link href="http://arxiv.org/abs/1911.02903"/>
        <updated>2023-10-05T01:04:45.174Z</updated>
        <summary type="html"><![CDATA[Jakob Heiss, Josef Teichmann, Hanna Wutte]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Argentan half-marathon [1:30:55, 25/165, 2/9M5M, 23⁰]]]></title>
        <id>http://xianblog.wordpress.com/?p=54173</id>
        <link href="https://xianblog.wordpress.com/2023/10/05/argentan-half-marathon-13055-25-165-2-9m5m-23%e2%81%b0/"/>
        <updated>2023-10-04T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable spherical CNNs for scientific applications]]></title>
        <id>http://blog.research.google/2023/10/scalable-spherical-cnns-for-scientific.html</id>
        <link href="http://blog.research.google/2023/10/scalable-spherical-cnns-for-scientific.html"/>
        <updated>2023-10-04T17:26:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Carlos Esteves and Ameesh Makadia, Research Scientists, Google Research, Athena Team




Typical deep learning models for computer vision, like convolutional neural networks (CNNs) and vision transformers (ViT), process signals assuming planar (flat) spaces. For example, digital images are represented as a grid of pixels on a plane. However, this type of data makes up only a fraction of the data we encounter in scientific applications. Variables sampled from the Earth's atmosphere, like temperature and humidity, are naturally represented on the sphere. Some kinds of cosmological data and panoramic photos are also spherical signals, and are better treated as such. 



Using methods designed for planar images to process spherical signals is problematic for a couple of reasons. Firs…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hyper-inclusive we]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60828</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60828&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hyper-inclusive-we"/>
        <updated>2023-10-04T11:08:16.000Z</updated>
        <summary type="html"><![CDATA[Yesterday evening in a restaurant, our attentive server frequently asked us things like "Are we ready to order" and "How are we doing?". This use of we is common enough that I didn't notice it. But when they brought us a complimentary bit of sushi with the explanation "Here's some unagi for us", that caught […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New Library Updates in PyTorch 2.1]]></title>
        <id>https://pytorch.org/blog/new-library-updates/</id>
        <link href="https://pytorch.org/blog/new-library-updates/"/>
        <updated>2023-10-04T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Summary]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch 2.1: automatic dynamic shape compilation, distributed checkpointing]]></title>
        <id>https://pytorch.org/blog/pytorch-2-1/</id>
        <link href="https://pytorch.org/blog/pytorch-2-1/"/>
        <updated>2023-10-04T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to announce the release of PyTorch® 2.1 (release note)! PyTorch 2.1 offers automatic dynamic shape support in torch.compile, torch.distributed.checkpoint for saving/loading distributed training jobs on multiple ranks in parallel, and torch.compile support for the NumPy API.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High performance Llama 2 deployments with AWS Inferentia2 using TorchServe]]></title>
        <id>https://pytorch.org/blog/high-performance-llama/</id>
        <link href="https://pytorch.org/blog/high-performance-llama/"/>
        <updated>2023-10-04T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Recently, Llama 2 was released and has attracted a lot of interest from the machine learning community. Amazon EC2 Inf2 instances, powered by AWS Inferentia2, now support training and inference of Llama 2 models. In this post, we show low-latency and cost-effective inference of Llama-2 models on Amazon EC2 Inf2 instances using the latest AWS Neuron SDK release.  We first introduce how to create, compile and deploy the Llama-2 model and explain the optimization techniques introduced by AWS Neuron SDK to achieve high performance at low cost. We then present our benchmarking results. Lastly, we show how the Llama-2 model can be deployed through Amazon SageMaker using TorchServe on an Inf2 instance.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In-Context Learning Learns Label Relationships but Is Not Conventional
  Learning]]></title>
        <id>http://arxiv.org/abs/2307.12375</id>
        <link href="http://arxiv.org/abs/2307.12375"/>
        <updated>2023-10-04T02:22:27.694Z</updated>
        <summary type="html"><![CDATA[Jannik Kossen, Yarin Gal, Tom Rainforth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning k-Level Sparse Neural Networks Using a New Generalized Weighted
  Group Sparse Envelope Regularization]]></title>
        <id>http://arxiv.org/abs/2212.12921</id>
        <link href="http://arxiv.org/abs/2212.12921"/>
        <updated>2023-10-04T02:22:27.683Z</updated>
        <summary type="html"><![CDATA[Yehonathan Refael, Iftach Arbel, Wasim Huleihel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transferring Learning Trajectories of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.14122</id>
        <link href="http://arxiv.org/abs/2305.14122"/>
        <updated>2023-10-04T02:22:27.565Z</updated>
        <summary type="html"><![CDATA[Daiki Chijiwa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Relax: Setting Solver Parameters Across a Sequence of Linear
  System Instances]]></title>
        <id>http://arxiv.org/abs/2310.02246</id>
        <link href="http://arxiv.org/abs/2310.02246"/>
        <updated>2023-10-04T02:22:27.560Z</updated>
        <summary type="html"><![CDATA[Mikhail Khodak, Edmond Chow, Maria-Florina Balcan, Ameet Talwalkar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unifying supervised learning and VAEs -- coverage, systematics and
  goodness-of-fit in normalizing-flow based neural network models for
  astro-particle reconstructions]]></title>
        <id>http://arxiv.org/abs/2008.05825</id>
        <link href="http://arxiv.org/abs/2008.05825"/>
        <updated>2023-10-04T02:22:27.476Z</updated>
        <summary type="html"><![CDATA[Thorsten Gl\"usenkamp]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nobels away]]></title>
        <id>http://xianblog.wordpress.com/?p=54157</id>
        <link href="https://xianblog.wordpress.com/2023/10/04/nobels-away/"/>
        <updated>2023-10-03T22:23:55.000Z</updated>
        <summary type="html"><![CDATA[A self-administred poll in Nature about the respondents’ feeling about the prizes, with only 15% thinking it would be preferable to have none. As an absurd concept of singling out one scientist out the flock of top scientists, of comparing chalk and cheese, of idealising “great men” (since winners are predominantly men) with the ensuing […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Higher Criticism for Discriminating Word-Frequency Tables and Testing
  Authorship]]></title>
        <id>http://arxiv.org/abs/1911.01208</id>
        <link href="http://arxiv.org/abs/1911.01208"/>
        <updated>2023-10-03T22:13:31.118Z</updated>
        <summary type="html"><![CDATA[Alon Kipnis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Good News for Polynomial Root-finding]]></title>
        <id>http://arxiv.org/abs/1805.12042</id>
        <link href="http://arxiv.org/abs/1805.12042"/>
        <updated>2023-10-03T22:13:31.093Z</updated>
        <summary type="html"><![CDATA[Victor Y. Pan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Implicit Regularization and Momentum Algorithms in Nonlinearly
  Parameterized Adaptive Control and Prediction]]></title>
        <id>http://arxiv.org/abs/1912.13154</id>
        <link href="http://arxiv.org/abs/1912.13154"/>
        <updated>2023-10-03T22:13:31.075Z</updated>
        <summary type="html"><![CDATA[Nicholas M. Boffi, Jean-Jacques E. Slotine]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Horizon instability of extremal Reissner-Nordstr\"om black holes to
  charged perturbations]]></title>
        <id>http://arxiv.org/abs/1612.03172</id>
        <link href="http://arxiv.org/abs/1612.03172"/>
        <updated>2023-10-03T22:13:30.788Z</updated>
        <summary type="html"><![CDATA[Peter Zimmerman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Formal Embeddings Between $\mathcal{BSD}$-Models]]></title>
        <id>http://arxiv.org/abs/1708.00089</id>
        <link href="http://arxiv.org/abs/1708.00089"/>
        <updated>2023-10-03T22:13:30.640Z</updated>
        <summary type="html"><![CDATA[Valentin Burcea]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language, topolect, dialect, idiolect]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60820</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60820&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-topolect-dialect-idiolect"/>
        <updated>2023-10-03T18:12:52.000Z</updated>
        <summary type="html"><![CDATA[An educated person will have all four levels of speech. The more highly educated they are, the higher up the scale their language capacity will go, though they may not be familiar with some of the argot of the lower levels. Of course, all four levels are language, but that is possible because "language" has […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to Build an Interactive Chat-Generation Model using DialoGPT and PyTorch]]></title>
        <id>https://pytorch.org/blog/interactive-chat-gen-model/</id>
        <link href="https://pytorch.org/blog/interactive-chat-gen-model/"/>
        <updated>2023-10-03T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[The focus on interactive chat-generation (or conversational response-generation) models has greatly increased in the past several months. Conversational response-generation models such as ChatGPT and Google Bard have taken the AI world by storm. The purpose of interactive chat generation is to answer various questions posed by humans, and these AI based models use natural language processing (NLP) to generate conversations almost indistinguishable from those generated by humans.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zero-Shot Recommendations with Pre-Trained Large Language Models for
  Multimodal Nudging]]></title>
        <id>http://arxiv.org/abs/2309.01026</id>
        <link href="http://arxiv.org/abs/2309.01026"/>
        <updated>2023-10-03T03:15:24.414Z</updated>
        <summary type="html"><![CDATA[Rachel M. Harrison, Anton Dereventsov, Anton Bibin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Meets Sparse Regularization: A Signal Processing
  Perspective]]></title>
        <id>http://arxiv.org/abs/2301.09554</id>
        <link href="http://arxiv.org/abs/2301.09554"/>
        <updated>2023-10-03T03:15:24.376Z</updated>
        <summary type="html"><![CDATA[Rahul Parhi, Robert D. Nowak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WASA: WAtermark-based Source Attribution for Large Language
  Model-Generated Data]]></title>
        <id>http://arxiv.org/abs/2310.00646</id>
        <link href="http://arxiv.org/abs/2310.00646"/>
        <updated>2023-10-03T03:15:24.362Z</updated>
        <summary type="html"><![CDATA[Jingtan Wang, Xinyang Lu, Zitong Zhao, Zhongxiang Dai, Chuan-Sheng
  Foo, See-Kiong Ng, Bryan Kian Hsiang Low]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Reward-Agnostic Preference-Based Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2305.18505</id>
        <link href="http://arxiv.org/abs/2305.18505"/>
        <updated>2023-10-03T03:15:24.308Z</updated>
        <summary type="html"><![CDATA[Wenhao Zhan, Masatoshi Uehara, Wen Sun, Jason D. Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A review of ensemble learning and data augmentation models for class
  imbalanced problems: combination, implementation and evaluation]]></title>
        <id>http://arxiv.org/abs/2304.02858</id>
        <link href="http://arxiv.org/abs/2304.02858"/>
        <updated>2023-10-03T03:15:24.303Z</updated>
        <summary type="html"><![CDATA[Azal Ahmad Khan, Omkar Chaudhari, Rohitash Chandra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scaling up learning across many different robot types]]></title>
        <id>https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types</id>
        <link href="https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types"/>
        <updated>2023-10-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are launching a new set of resources for general-purpose robotics learning across different robot types, or embodiments. Together with partners from 34 academic labs we have pooled data from 22 different robot types to create the Open X-Embodiment dataset. We also release RT-1-X, a robotics transformer (RT) model derived from RT-1 and trained on our dataset, that shows skills transfer across many robot embodiments.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Familial inference]]></title>
        <id>http://xianblog.wordpress.com/?p=54136</id>
        <link href="https://xianblog.wordpress.com/2023/10/03/familial-inference/"/>
        <updated>2023-10-02T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[An ISBA-BNP webinar on Wednesday, 4 October, at 17:00 UTC by my friend Steve McEachern: Familial inference: Tests for hypotheses on a family of centers Many scientific disciplines face a replicability crisis. While these crises have many drivers, we focus on one. Statistical hypotheses are translations of scientific hypotheses into statements about one or more […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mental anguish from having too many English words in Japanese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60805</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60805&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mental-anguish-from-having-too-many-english-words-in-japanese"/>
        <updated>2023-10-02T12:47:25.000Z</updated>
        <summary type="html"><![CDATA[One thing I revel in about the English language is the huge number of loanwords it has:  French, Latin, Greek, Native American, Arabic, Persian, Turkish, Kurdish, Sanskrit, Hindi, Urdu, Bengali, Tamil, Russian, German, Spanish, Italian, Irish, Swedish, Dutch, Danish, Norwegian, Finnish, Japanese, Cantonese, Mandarin, Maori, Hebrew, Yiddish, Afrikaans, Zulu, Swahili, and so on and on […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pressure metrics for cusped Hitchin components]]></title>
        <id>http://arxiv.org/abs/2111.07493</id>
        <link href="http://arxiv.org/abs/2111.07493"/>
        <updated>2023-10-02T11:12:19.017Z</updated>
        <summary type="html"><![CDATA[Harrison Bray, Richard Canary, Lien-Yung Kao, Giuseppe Martone]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universality for Lozenge Tiling Local Statistics]]></title>
        <id>http://arxiv.org/abs/1907.09991</id>
        <link href="http://arxiv.org/abs/1907.09991"/>
        <updated>2023-10-02T11:12:19.012Z</updated>
        <summary type="html"><![CDATA[Amol Aggarwal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gromov's Oka principle for equivariant maps]]></title>
        <id>http://arxiv.org/abs/1912.07129</id>
        <link href="http://arxiv.org/abs/1912.07129"/>
        <updated>2023-10-02T11:12:18.987Z</updated>
        <summary type="html"><![CDATA[Frank Kutzschebauch, Finnur Larusson, Gerald W. Schwarz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tensor products of Bands and Ideals]]></title>
        <id>http://arxiv.org/abs/2207.13796</id>
        <link href="http://arxiv.org/abs/2207.13796"/>
        <updated>2023-10-02T11:12:18.792Z</updated>
        <summary type="html"><![CDATA[Mohamed Amine Ben Amor, Omer Gok, Damla Yaman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lessons Learned: How (Not) to Defend Against Property Inference Attacks]]></title>
        <id>http://arxiv.org/abs/2205.08821</id>
        <link href="http://arxiv.org/abs/2205.08821"/>
        <updated>2023-10-02T11:12:18.780Z</updated>
        <summary type="html"><![CDATA[Joshua Stock (1), Jens Wettlaufer, Daniel Demmler (1), Hannes
  Federrath (1) ((1) Universit\"at Hamburg)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at ICCV 2023]]></title>
        <id>http://blog.research.google/2023/10/google-at-iccv-2023.html</id>
        <link href="http://blog.research.google/2023/10/google-at-iccv-2023.html"/>
        <updated>2023-10-02T07:51:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Shaina Mehta, Program Manager, Google




Google is proud to be a Platinum Sponsor of the International Conference on Computer Vision (ICCV 2023), a premier annual conference, which is being held this week in Paris, France. As a leader in computer vision research, Google has a strong presence at this year’s conference with 60 accepted papers and active involvement in 27 workshops and tutorials. Google is also proud to be a Platinum Sponsor for the LatinX in CV workshop. We look forward to sharing some of our extensive computer vision research and expanding our partnership with the broader research community. 



Attending ICCV 2023? We hope you’ll visit the Google booth to chat with researchers who are actively pursuing the latest innovations in computer vision, and check out som…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing PyTorch Docathon H2 2023]]></title>
        <id>https://pytorch.org/blog/announcing-docathon-h2-2023/</id>
        <link href="https://pytorch.org/blog/announcing-docathon-h2-2023/"/>
        <updated>2023-10-02T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to announce that we will be holding a Docathon for PyTorch on November 1, 2023! This event is an opportunity for our community to come together and improve the quality of our documentation.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalized Balancing Weights via Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2211.07533</id>
        <link href="http://arxiv.org/abs/2211.07533"/>
        <updated>2023-10-02T03:15:24.494Z</updated>
        <summary type="html"><![CDATA[Yoshiaki Kitazawa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Characteristic Activation Value Analysis for Improved ReLU
  Network Feature Learning]]></title>
        <id>http://arxiv.org/abs/2305.15912</id>
        <link href="http://arxiv.org/abs/2305.15912"/>
        <updated>2023-10-02T03:15:24.452Z</updated>
        <summary type="html"><![CDATA[Wenlin Chen, Hong Ge]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Agnostic Learning with Average Smoothness]]></title>
        <id>http://arxiv.org/abs/2309.17016</id>
        <link href="http://arxiv.org/abs/2309.17016"/>
        <updated>2023-10-02T03:15:24.422Z</updated>
        <summary type="html"><![CDATA[Steve Hanneke, Aryeh Kontorovich, Guy Kornowski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization Guarantees of Gradient Descent for Multi-Layer Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.16891</id>
        <link href="http://arxiv.org/abs/2305.16891"/>
        <updated>2023-10-02T03:15:24.253Z</updated>
        <summary type="html"><![CDATA[Puyu Wang, Yunwen Lei, Di Wang, Yiming Ying, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Water quality prediction using machine learning and neural network
  approaches]]></title>
        <id>http://arxiv.org/abs/2309.16951</id>
        <link href="http://arxiv.org/abs/2309.16951"/>
        <updated>2023-10-02T03:15:24.231Z</updated>
        <summary type="html"><![CDATA[Yinpu Li, Siqi Mao, Yaping Yuan, Ziren Wang, Yixin Kang, Yuanxin Yao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ELLIS PhD Program]]></title>
        <id>http://xianblog.wordpress.com/?p=54113</id>
        <link href="https://xianblog.wordpress.com/2023/10/02/54113/"/>
        <updated>2023-10-01T22:23:12.000Z</updated>
        <summary type="html"><![CDATA[The ELLIS PhD Program is now accepting applications. ELLIS PhDs are co-supervised by one ELLIS fellow/scholar/unit faculty and one ELLIS fellow/scholar/member, both based in Europe. The ELLIS initiative has the goal to foster and educate the best talent in machine learning and related research areas by pairing outstanding students with leading academic and industrial researchers […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A dangerous degree of accidental intelligence]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60808</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60808&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-dangerous-degree-of-accidental-intelligence"/>
        <updated>2023-10-01T18:59:31.000Z</updated>
        <summary type="html"><![CDATA[Henry Farrell and Cosma Shalizi, "Behold the AI Shoggoth", The Economist 6/21/2023 ("The academics argue that large language models have much older cousins in markets and bureaucracies"): An internet meme keeps on turning up in debates about the large language models (LLMS) that power services such Openai’s ChatGPT and the newest version of Microsoft’s Bing […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[semi-marathon d’Argentan 2023]]></title>
        <id>http://xianblog.wordpress.com/?p=54037</id>
        <link href="https://xianblog.wordpress.com/2023/10/01/semi-marathon-dargentan-2023/"/>
        <updated>2023-09-30T22:23:06.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Share your language]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60800</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60800&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=share-your-language"/>
        <updated>2023-09-30T19:55:43.000Z</updated>
        <summary type="html"><![CDATA[If you can't make up your mind what to do about something, then in French you would say "je suis partagé":  I'm torn or divided over it.  You can't decide what to do about it.  You can't make up your mind whether to be pleased or angry with something.  But the verb "partager" means "to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Synge's dynamic problem for two isolated point charges. A new method to
  find global solutions for Functional Differential Equations System]]></title>
        <id>http://arxiv.org/abs/2308.11641</id>
        <link href="http://arxiv.org/abs/2308.11641"/>
        <updated>2023-09-30T02:18:51.265Z</updated>
        <summary type="html"><![CDATA[Rodrigo R. Silva, Annibal Figueiredo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[optimal formation for marathon records]]></title>
        <id>http://xianblog.wordpress.com/?p=53860</id>
        <link href="https://xianblog.wordpress.com/2023/09/30/optimal-formation-for-marathon-records/"/>
        <updated>2023-09-29T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[A fascinating experiment run (!) by researchers from Lyon and Torino, testing the impact of different pacer formations on the air drag of a specific runner, and leading to a predicted 4¼mn gain on a marathon for the optimal configuration. Inspired by (and in agreement with) the Nike Breaking2 and INEOS1:59 Challenge attempts. Of course, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Juridical tautology:  "illegal crime"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60774</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60774&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=juridical-tautology-illegal-crime"/>
        <updated>2023-09-29T20:12:34.000Z</updated>
        <summary type="html"><![CDATA[The news is flooded with stories about Hui Ka Yan 许家印 (MSM Xǔ Jiāyìn), one of China's wealthiest individuals, Chairman and Party Committee secretary of Evergrande Group, the mega real estate corporation that is currently going belly up, being arrested on suspicion of "illegal crimes".  That expression sounded so strange that I had to find […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Furious sleeping continues]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60778</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60778&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=furious-sleeping-continues"/>
        <updated>2023-09-29T13:31:36.000Z</updated>
        <summary type="html"><![CDATA[Several people have sent me pointers to the linguistically-themed 9/27/2023 NYT crossword puzzle. For some discussion by Sam Corbin, see "Talk, Talk, Talk", NYT 9/26/2023 ("Scott Koenig puts silly thoughts to bed with a clever crossword"), which includes a quotation from the puzzle's author: I first learned about Professor Chomsky as an undergraduate linguistics minor. […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11/03 1pm-2pm: Stats Seminar]]></title>
        <id>8a17841a8adb7b43018ae00188cd1221</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:15:11.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 11 Mar '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[26/02 1pm-2pm: Stats Seminar]]></title>
        <id>8a1785d88adb7b44018ae000e6e84f4b</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:14:30.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 26 Feb '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[12/02 1pm-2pm: Stats Seminar]]></title>
        <id>8a1785d78adb7884018ae000414f1360</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:13:47.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 12 Feb '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[29/01 1pm-2pm: Statistics Seminar]]></title>
        <id>8a1785d88adb7b44018adfff90924f47</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:13:02.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 29 Jan '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[15/01 1pm-2pm: Stats Seminar]]></title>
        <id>8a1785d78adb7884018adffec409135d</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:12:10.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 15 Jan '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[04/12 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841a8adb7b43018adfd7774d1148</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:29:14.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 04 Dec '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[20/11 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841b8adb7895018adfd6ce0c4ad1</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:28:31.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 20 Nov '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[06/11 1pm-2pm: Statistics Seminar]]></title>
        <id>8a1785d78adb7884018adfd618211321</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:27:44.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 06 Nov '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[23/10 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841b8adb7895018adfd54cfc4ace</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:26:52.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 23 Oct '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[09/10 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841b8adb7895018adfd46a884acb</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:25:54.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 09 Oct '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Selection in Algorithmic Decision-making]]></title>
        <id>http://arxiv.org/abs/2108.12547</id>
        <link href="http://arxiv.org/abs/2108.12547"/>
        <updated>2023-09-29T01:04:29.683Z</updated>
        <summary type="html"><![CDATA[Jin Li, Ye Luo, Xiaowei Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantum Self-Attention Neural Networks for Text Classification]]></title>
        <id>http://arxiv.org/abs/2205.05625</id>
        <link href="http://arxiv.org/abs/2205.05625"/>
        <updated>2023-09-29T01:04:29.678Z</updated>
        <summary type="html"><![CDATA[Guangxi Li, Xuanqiang Zhao, Xin Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Private Stochastic Optimization With Large Worst-Case Lipschitz
  Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to
  Non-Convex Losses]]></title>
        <id>http://arxiv.org/abs/2209.07403</id>
        <link href="http://arxiv.org/abs/2209.07403"/>
        <updated>2023-09-29T01:04:29.450Z</updated>
        <summary type="html"><![CDATA[Andrew Lowy, Meisam Razaviyayn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HyperBO+: Pre-training a universal prior for Bayesian optimization with
  hierarchical Gaussian processes]]></title>
        <id>http://arxiv.org/abs/2212.10538</id>
        <link href="http://arxiv.org/abs/2212.10538"/>
        <updated>2023-09-29T01:04:29.439Z</updated>
        <summary type="html"><![CDATA[Zhou Fan, Xinran Han, Zi Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Augmentation in the Underparameterized and Overparameterized
  Regimes]]></title>
        <id>http://arxiv.org/abs/2202.09134</id>
        <link href="http://arxiv.org/abs/2202.09134"/>
        <updated>2023-09-29T01:04:29.434Z</updated>
        <summary type="html"><![CDATA[Kevin Han Huang, Peter Orbanz, Morgane Austern]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bertrand’s paradox [re]solved?]]></title>
        <id>http://xianblog.wordpress.com/?p=53824</id>
        <link href="https://xianblog.wordpress.com/2023/09/29/bertrands-paradox-resolved/"/>
        <updated>2023-09-28T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[On the plane back from Vancouver, I read Bertrand’s Paradox Resolution and Its Implications for the Bing–Fisher Problem by Richard A. Chechile [who had pointed out his paper to me] In this paper, Chechile considers the Bayesian connections/sequences of Betrand’s paradox, as he sees it Bertrand’s different solutions/paradox to be “designed to illustrate his dissatisfaction […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DynIBaR: Space-time view synthesis from videos of dynamic scenes]]></title>
        <id>http://blog.research.google/2023/09/dynibar-space-time-view-synthesis-from.html</id>
        <link href="http://blog.research.google/2023/09/dynibar-space-time-view-synthesis-from.html"/>
        <updated>2023-09-28T20:01:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Zhengqi Li and Noah Snavely, Research Scientists, Google Research







A mobile phone’s camera is a powerful tool for capturing everyday moments. However, capturing a dynamic scene using a single camera is fundamentally limited. For instance, if we wanted to adjust the camera motion or timing of a recorded video (e.g., to freeze time while sweeping the camera around to highlight a dramatic moment), we would typically need an expensive Hollywood setup with a synchronized camera rig. Would it be possible to achieve similar effects solely from a video captured using a mobile phone’s camera, without a Hollywood budget?



In “DynIBaR: Neural Dynamic Image-Based Rendering”, a best paper honorable mention at CVPR 2023, we describe a new method that generates photorealistic free-viewp…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Re-weighted gradient descent via distributionally robust optimization]]></title>
        <id>http://blog.research.google/2023/09/re-weighted-gradient-descent-via.html</id>
        <link href="http://blog.research.google/2023/09/re-weighted-gradient-descent-via.html"/>
        <updated>2023-09-28T18:16:00.002Z</updated>
        <summary type="html"><![CDATA[Ramnath Kumar, Pre-Doctoral Researcher, and Arun Sai Suggala, Research Scientist, Google Research





Deep neural networks (DNNs) have become essential for solving a wide range of tasks, from standard supervised learning (image classification using ViT) to meta-learning. The most commonly-used paradigm for learning DNNs is empirical risk minimization (ERM), which aims to identify a network that minimizes the average loss on training data points. Several algorithms, including stochastic gradient descent (SGD), Adam, and Adagrad, have been proposed for solving ERM. However, a drawback of ERM is that it weights all the samples equally, often ignoring the rare and more difficult samples, and focusing on the easier and abundant samples. This leads to suboptimal performance on unseen data, espe…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[international safe abortion day]]></title>
        <id>http://xianblog.wordpress.com/?p=54140</id>
        <link href="https://xianblog.wordpress.com/2023/09/28/international-safe-abortion-day-2/"/>
        <updated>2023-09-28T10:23:12.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kimchee is Korean]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60759</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60759&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=kimchee-is-korean"/>
        <updated>2023-09-28T10:17:26.000Z</updated>
        <summary type="html"><![CDATA[Not Chinese.  Do you understand? This has long been a cabbage of contention, but make no mistake about it:  fermented kimchee / kimchi  (gimchi 김치 (IPA [kim.tɕʰi]) (lit., "soaked [in their own juices of fermentation] vegetables") is not the same thing as pickled paocai / pao tsai 泡菜 (lit., "soaked [in brine] vegetables"). Kimchee and […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantum-Noise-driven Generative Diffusion Models]]></title>
        <id>http://arxiv.org/abs/2308.12013</id>
        <link href="http://arxiv.org/abs/2308.12013"/>
        <updated>2023-09-28T03:15:19.646Z</updated>
        <summary type="html"><![CDATA[Marco Parigi, Stefano Martina, Filippo Caruso]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural network with optimal neuron activation functions based on
  additive Gaussian process regression]]></title>
        <id>http://arxiv.org/abs/2301.05567</id>
        <link href="http://arxiv.org/abs/2301.05567"/>
        <updated>2023-09-28T03:15:16.432Z</updated>
        <summary type="html"><![CDATA[Sergei Manzhos, Manabu Ihara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Neural Prompting with Large Language Models]]></title>
        <id>http://arxiv.org/abs/2309.15427</id>
        <link href="http://arxiv.org/abs/2309.15427"/>
        <updated>2023-09-28T03:15:16.311Z</updated>
        <summary type="html"><![CDATA[Yijun Tian, Huan Song, Zichen Wang, Haozhu Wang, Ziqing Hu, Fang Wang,
  Nitesh V. Chawla, Panpan Xu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Approximation of Zonoids and Uniform Approximation by Shallow
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2307.15285</id>
        <link href="http://arxiv.org/abs/2307.15285"/>
        <updated>2023-09-28T03:15:15.778Z</updated>
        <summary type="html"><![CDATA[Jonathan W. Siegel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GeONet: a neural operator for learning the Wasserstein geodesic]]></title>
        <id>http://arxiv.org/abs/2209.14440</id>
        <link href="http://arxiv.org/abs/2209.14440"/>
        <updated>2023-09-28T03:15:15.455Z</updated>
        <summary type="html"><![CDATA[Andrew Gracyk, Xiaohui Chen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representations having vectors fixed by a Levi subgroup]]></title>
        <id>http://arxiv.org/abs/2002.10928</id>
        <link href="http://arxiv.org/abs/2002.10928"/>
        <updated>2023-09-28T01:04:22.233Z</updated>
        <summary type="html"><![CDATA[Ilia Smilga]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Sparse Decision Trees]]></title>
        <id>http://arxiv.org/abs/1904.12847</id>
        <link href="http://arxiv.org/abs/1904.12847"/>
        <updated>2023-09-28T01:04:22.189Z</updated>
        <summary type="html"><![CDATA[Xiyang Hu, Cynthia Rudin, Margo Seltzer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding North Atlantic Climate Instabilities and Complex
  Interactions using Data Science]]></title>
        <id>http://arxiv.org/abs/2001.10171</id>
        <link href="http://arxiv.org/abs/2001.10171"/>
        <updated>2023-09-28T01:04:22.153Z</updated>
        <summary type="html"><![CDATA[Alka Yadav, Sourish Das, Anirban Chakraborti]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving the convergence of SGD through adaptive batch sizes]]></title>
        <id>http://arxiv.org/abs/1910.08222</id>
        <link href="http://arxiv.org/abs/1910.08222"/>
        <updated>2023-09-28T01:04:22.146Z</updated>
        <summary type="html"><![CDATA[Scott Sievert, Shrey Shah]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A differential model for B-type Landau-Ginzburg theories]]></title>
        <id>http://arxiv.org/abs/1709.00684</id>
        <link href="http://arxiv.org/abs/1709.00684"/>
        <updated>2023-09-28T01:04:21.912Z</updated>
        <summary type="html"><![CDATA[Elena Mirela Babalic, Dmitry Doryn, Calin Iuliu Lazaroiu, Mehdi
  Tavakol]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ISBA²⁴ [call for contributed talks]]]></title>
        <id>http://xianblog.wordpress.com/?p=54121</id>
        <link href="https://xianblog.wordpress.com/2023/09/28/isba%c2%b2%e2%81%b4-call-for-contributed-talks/"/>
        <updated>2023-09-27T22:24:52.000Z</updated>
        <summary type="html"><![CDATA[Now that the invited sessions have been selected by the scientific committee of ISBA²⁴ (with both sessions in which I am involved, Bayesian data privacy and The future of ISBA conferences, accepted), the call is open for contributed talks, with deadline 17 November. (If  this helps in making a proposal, childcare will be available during […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Reversal Curse]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60766</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60766&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-reversal-curse"/>
        <updated>2023-09-27T13:57:15.000Z</updated>
        <summary type="html"><![CDATA[An interesting recent paper — Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans,"The Reversal Curse: LLMs trained on 'A is B' fail to learn 'B is A'", arXiv.org 9/21/2023. The abstract: We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some snarks are worse than others]]></title>
        <id>http://arxiv.org/abs/2004.14049</id>
        <link href="http://arxiv.org/abs/2004.14049"/>
        <updated>2023-09-27T11:12:35.149Z</updated>
        <summary type="html"><![CDATA[Edita M\'a\v{c}ajov\'a, Giuseppe Mazzuoccolo, Vahan Mkrtchyan, Jean
  Paul Zerafa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Experimental Design for Staggered Rollouts]]></title>
        <id>http://arxiv.org/abs/1911.03764</id>
        <link href="http://arxiv.org/abs/1911.03764"/>
        <updated>2023-09-27T11:12:35.109Z</updated>
        <summary type="html"><![CDATA[Ruoxuan Xiong, Susan Athey, Mohsen Bayati, Guido Imbens]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computational aspects of orbifold equivalence]]></title>
        <id>http://arxiv.org/abs/1901.09019</id>
        <link href="http://arxiv.org/abs/1901.09019"/>
        <updated>2023-09-27T11:12:35.099Z</updated>
        <summary type="html"><![CDATA[Timo Kluck, Ana Ros Camacho]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The strategy of conflict and cooperation]]></title>
        <id>http://arxiv.org/abs/1808.06750</id>
        <link href="http://arxiv.org/abs/1808.06750"/>
        <updated>2023-09-27T11:12:35.035Z</updated>
        <summary type="html"><![CDATA[Mehmet S. Ismail]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NN2Poly: A polynomial representation for deep feed-forward artificial
  neural networks]]></title>
        <id>http://arxiv.org/abs/2112.11397</id>
        <link href="http://arxiv.org/abs/2112.11397"/>
        <updated>2023-09-27T02:21:28.251Z</updated>
        <summary type="html"><![CDATA[Pablo Morala (1, 2), Jenny Alexandra Cifuentes (3), Rosa E. Lillo
  (1, 2), I\~naki Ucar (1, 2) ((1) uc3m-Santander Big Data Institute,
  Universidad Carlos III de Madrid. Spain., (2) Department of Statistics,
  Universidad Carlos III de Madrid. Spain., (3) ICADE, Department of
  Quantitative Methods, Faculty of Economics, Business Administration,
  Universidad Pontificia Comillas. Spain.)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring Small Language Models with Prompt-Learning Paradigm for
  Efficient Domain-Specific Text Classification]]></title>
        <id>http://arxiv.org/abs/2309.14779</id>
        <link href="http://arxiv.org/abs/2309.14779"/>
        <updated>2023-09-27T02:21:26.121Z</updated>
        <summary type="html"><![CDATA[Hengyu Luo, Peng Liu, Stefan Esping]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Excess Risk Convergence Rates of Neural Network Classifiers]]></title>
        <id>http://arxiv.org/abs/2309.15075</id>
        <link href="http://arxiv.org/abs/2309.15075"/>
        <updated>2023-09-27T02:21:25.967Z</updated>
        <summary type="html"><![CDATA[Hyunouk Ko, Namjoon Suh, Xiaoming Huo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SGD Finds then Tunes Features in Two-Layer Neural Networks with
  near-Optimal Sample Complexity: A Case Study in the XOR problem]]></title>
        <id>http://arxiv.org/abs/2309.15111</id>
        <link href="http://arxiv.org/abs/2309.15111"/>
        <updated>2023-09-27T02:21:25.932Z</updated>
        <summary type="html"><![CDATA[Margalit Glasgow]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[congrats, friends!]]></title>
        <id>http://xianblog.wordpress.com/?p=53984</id>
        <link href="https://xianblog.wordpress.com/2023/09/27/congrats-friends/"/>
        <updated>2023-09-26T22:23:35.000Z</updated>
        <summary type="html"><![CDATA[Congrats to my friends who got academic recognition at JSM last month, among whom Bin Yu for her 2023 COPSS Distinguished Achievement Award and Lectureship, Veronika Rockova for her Emerging Leader Award, Nancy Reid for her David R. Cox Foundations of Statistics Award, Malay Ghosh for his Deming Lecture, Andrew Gelman for his Monroe G. […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Corporeal grammar]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60726</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60726&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=corporeal-grammar"/>
        <updated>2023-09-26T21:03:01.000Z</updated>
        <summary type="html"><![CDATA[Recent article in Scientific American: This Ancient Language Has the Only Grammar Based Entirely on the Human Body An endangered language family suggests that early humans used their bodies as a model for reality By Anvita Abbi on June 1, 2023 From just a small handful of Andaman Islanders, the last speakers of their languages, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google Research embarks on effort to map a mouse brain]]></title>
        <id>http://blog.research.google/2023/09/google-research-embarks-on-effort-to.html</id>
        <link href="http://blog.research.google/2023/09/google-research-embarks-on-effort-to.html"/>
        <updated>2023-09-26T14:10:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Michał Januszewski, Research Scientist, Google Research






The human brain is perhaps the most computationally complex machine in existence, consisting of networks of billions of cells. Researchers currently don’t understand the full picture of how glitches in its network machinery contribute to mental illnesses and other diseases, such as dementia. However, the emerging connectomics field, which aims to precisely map the connections between every cell in the brain, could help solve that problem. While maps have only been created for simpler organisms, technological advances for mapping even larger brains can enable us to understand how the human brain works, and how to treat brain diseases.



Today, we're excited to announce that the Connectomics team at Google Research and …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A new Indo-European language]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60750</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60750&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-new-indo-european-language"/>
        <updated>2023-09-26T08:47:29.000Z</updated>
        <summary type="html"><![CDATA[Many LL readers are familiar with the archeological site of Boğazköy-Hattusha in north-central Turkey, which was the capital of the Hittite Empire and the place where the Hittite Royal Archives (17th-13th c. BC) were discovered, making it the oldest historically attested Indo-European language (scattered Hittite words in Akkadian documents stretch back to the 20th c. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Utilizing Expert Features for Contrastive Learning of Time-Series
  Representations]]></title>
        <id>http://arxiv.org/abs/2206.11517</id>
        <link href="http://arxiv.org/abs/2206.11517"/>
        <updated>2023-09-26T02:21:19.953Z</updated>
        <summary type="html"><![CDATA[Manuel Nonnenmacher, Lukas Oldenburg, Ingo Steinwart, David Reeb]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring and Interacting with the Set of Good Sparse Generalized
  Additive Models]]></title>
        <id>http://arxiv.org/abs/2303.16047</id>
        <link href="http://arxiv.org/abs/2303.16047"/>
        <updated>2023-09-26T02:21:19.947Z</updated>
        <summary type="html"><![CDATA[Chudi Zhong, Zhi Chen, Margo Seltzer, Cynthia Rudin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Benefits of Being Distributional: Small-Loss Bounds for
  Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2305.15703</id>
        <link href="http://arxiv.org/abs/2305.15703"/>
        <updated>2023-09-26T02:21:18.545Z</updated>
        <summary type="html"><![CDATA[Kaiwen Wang, Kevin Zhou, Runzhe Wu, Nathan Kallus, Wen Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mode-Aware Continual Learning for Conditional Generative Adversarial
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.11400</id>
        <link href="http://arxiv.org/abs/2305.11400"/>
        <updated>2023-09-26T02:21:18.537Z</updated>
        <summary type="html"><![CDATA[Cat P. Le, Juncheng Dong, Ahmed Aloui, Vahid Tarokh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[脑洞大开：非线性RNN居然也可以并行计算？]]></title>
        <id>https://kexue.fm/archives/9783</id>
        <link href="https://kexue.fm/archives/9783"/>
        <updated>2023-09-26T02:03:00.000Z</updated>
        <summary type="html"><![CDATA[近年来，线性RNN由于其可并行训练以及常数推理成本等特性，吸引了一定研究人员的关注（例如笔者之前写的《Google新作试图“复活”RNN：RNN能否再次辉煌？》），这让RNN在Transform...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[course du souffle au Parc de Sceaux [42:06, 10k, 128m⁺, 43/663, 1/19M5M]]]></title>
        <id>http://xianblog.wordpress.com/?p=54100</id>
        <link href="https://xianblog.wordpress.com/2023/09/26/course-du-souffle-au-parc-de-sceaux-4206-10k-128m%e2%81%ba-43-663-1-19m5m/"/>
        <updated>2023-09-25T22:23:01.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A bad thing about social media is also good]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60735</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60735&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-bad-thing-about-social-media-is-also-good"/>
        <updated>2023-09-25T12:06:12.000Z</updated>
        <summary type="html"><![CDATA[Jill Lepore recently presented an illustrative example of how social media amplifies bad stuff ("The World According to Elon Musk's Grandfather", 9/19/2023): Walter Isaacson’s new biography of Musk […] only glancingly discusses Musk’s grandfather J. N. Haldeman, whom he presents as a risk-taking adventurer and whose politics he dismisses as “quirky.” In fact, Haldeman was […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond]]></title>
        <id>https://pytorch.org/blog/inside-the-matrix/</id>
        <link href="https://pytorch.org/blog/inside-the-matrix/"/>
        <updated>2023-09-25T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Use 3D to visualize matrix multiplication expressions, attention heads with real weights, and more.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Hybrid Deep Learning-based Approach for Optimal Genotype by
  Environment Selection]]></title>
        <id>http://arxiv.org/abs/2309.13021</id>
        <link href="http://arxiv.org/abs/2309.13021"/>
        <updated>2023-09-25T03:15:26.640Z</updated>
        <summary type="html"><![CDATA[Zahra Khalilzadeh, Motahareh Kashanian, Saeed Khaki, Lizhi Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multimodal Deep Learning for Scientific Imaging Interpretation]]></title>
        <id>http://arxiv.org/abs/2309.12460</id>
        <link href="http://arxiv.org/abs/2309.12460"/>
        <updated>2023-09-25T03:15:25.861Z</updated>
        <summary type="html"><![CDATA[Abdulelah S. Alshehri, Franklin L. Lee, Shihu Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring Transfer Learning in Medical Image Segmentation using
  Vision-Language Models]]></title>
        <id>http://arxiv.org/abs/2308.07706</id>
        <link href="http://arxiv.org/abs/2308.07706"/>
        <updated>2023-09-25T03:15:25.530Z</updated>
        <summary type="html"><![CDATA[Kanchan Poudel, Manish Dhakal, Prasiddha Bhandari, Rabin Adhikari,
  Safal Thapaliya, Bishesh Khanal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantitative Gaussian Approximation of Randomly Initialized Deep Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2203.07379</id>
        <link href="http://arxiv.org/abs/2203.07379"/>
        <updated>2023-09-25T03:15:25.483Z</updated>
        <summary type="html"><![CDATA[Andrea Basteri, Dario Trevisan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BayesDLL: Bayesian Deep Learning Library]]></title>
        <id>http://arxiv.org/abs/2309.12928</id>
        <link href="http://arxiv.org/abs/2309.12928"/>
        <updated>2023-09-25T03:15:25.385Z</updated>
        <summary type="html"><![CDATA[Minyoung Kim, Timothy Hospedales]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exact MCMC with differentially private moves]]></title>
        <id>http://xianblog.wordpress.com/?p=53975</id>
        <link href="https://xianblog.wordpress.com/2023/09/25/exact-mcmc-with-differentially-private-moves/"/>
        <updated>2023-09-24T22:23:27.000Z</updated>
        <summary type="html"><![CDATA[“The algorithm can be made differentially private while remaining exact in the sense that its target distribution is the true posterior distribution conditioned on the private data (…) The main contribution of this paper arises from the simple  observation that the penalty algorithm has a built-in noise in its calculations which is not desirable in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sweden's renewed emphasis on books and handwriting]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60683</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60683&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=swedens-renewed-emphasis-on-books-and-handwriting"/>
        <updated>2023-09-24T11:41:05.000Z</updated>
        <summary type="html"><![CDATA[Sweden brings more books and handwriting practice back to its tech-heavy schools Charlene Pele, AP (9/10/23) Accompanied by 10 photographs showing young children (3rd grade?) practicing handwriting. As young children went back to school across Sweden last month, many of their teachers were putting a new emphasis on printed books, quiet reading time and handwriting […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bad AI performance]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60690</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60690&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bad-ai-performance"/>
        <updated>2023-09-24T11:09:34.000Z</updated>
        <summary type="html"><![CDATA[It's clear that text-to-speech programs have gotten better and better over the past 60 years, technical details aside. The best current systems rarely make phrasing or letter-to-sound mistakes, and generally produce speech that sounds pretty natural on a phrase-by-phrase basis. (Though there's a lot of variation in quality, with some shockingly bad systems in common use.) […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian diﬀerential privacy for free?]]></title>
        <id>http://xianblog.wordpress.com/?p=53957</id>
        <link href="https://xianblog.wordpress.com/2023/09/24/bayesian-di%ef%ac%80erential-privacy-for-free/"/>
        <updated>2023-09-23T22:23:06.000Z</updated>
        <summary type="html"><![CDATA[“We are interested in the question of how we can build diﬀerentially-private algorithms within the Bayesian framework. More precisely, we examine when the choice of prior is suﬃcient to guarantee diﬀerential privacy for decisions that are derived from the posterior distribution (…) we show that the Bayesian statistician’s choice of prior distribution ensures a base […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Motivating the cross-entropy loss]]></title>
        <id>https://parsiad.ca/blog/2023/motivating_the_cross_entropy_loss/</id>
        <link href="https://parsiad.ca/blog/2023/motivating_the_cross_entropy_loss/"/>
        <updated>2023-09-23T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Introduction]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Hurting the feelings of the Chinese people", part 3]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60657</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60657&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hurting-the-feelings-of-the-chinese-people-part-3"/>
        <updated>2023-09-23T19:08:09.000Z</updated>
        <summary type="html"><![CDATA[Shared by John Rohsenow and David Cahill / Isham Cook: From Arthur Meursault (@emptymeursault) This is a trope with which we're intimately familiar. According to the Chinese government, of all peoples on earth, the Chinese people are unique in this regard, except that now, more and more, they are starting to hurt their own feelings, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of AI bias]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60695</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60695&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-ai-bias"/>
        <updated>2023-09-23T18:23:18.000Z</updated>
        <summary type="html"><![CDATA[The Large Language Model DistilBert is "a distilled version of BERT: smaller, faster, cheaper and lighter". A trained DistilBert model is available from Hugging Face, and recommended applications include "text classification", with the featured application being "sentiment analysis": And as with many similar applications, it's been noted that this version of "sentiment analysis" has picked […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Can We Reliably Improve the Robustness to Image Acquisition of Remote
  Sensing of PV Systems?]]></title>
        <id>http://arxiv.org/abs/2309.12214</id>
        <link href="http://arxiv.org/abs/2309.12214"/>
        <updated>2023-09-23T02:17:57.942Z</updated>
        <summary type="html"><![CDATA[Gabriel Kasmi, Laurent Dubus, Yves-Marie Saint-Drenan and
  Philippe Blanc]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[genius forgers]]></title>
        <id>http://xianblog.wordpress.com/?p=53932</id>
        <link href="https://xianblog.wordpress.com/2023/09/23/genius-forgers/"/>
        <updated>2023-09-22T22:23:24.000Z</updated>
        <summary type="html"><![CDATA[The other evening, I was listening to the French public radio (France Inter) while trying to micro-wave chutney out of green tomatoes and green crab apples found in my garden (I failed). The program was about a French art dealer, Giuliano Ruffini, who had sold several grand master paintings that later got resold at insane […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Heavily accented Mandarin]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60680</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60680&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=heavily-accented-mandarin"/>
        <updated>2023-09-22T10:49:45.000Z</updated>
        <summary type="html"><![CDATA[In "Voice-activated lights" (9/20/23), we saw how difficult it is even for native speakers of Modern Standard Mandarin to understand other varieties, and can be thankful to Zeyao Wu, who comes from the area where the topolect in the film is spoken, for kindly identifying and transcribing it for all of us. rit malors writes: […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dogged by an etymological shape]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60673</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60673&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dogged-by-an-etymological-shape"/>
        <updated>2023-09-22T04:21:22.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Martin Schwartz] The following is just an idle speculation for which I have no answer, but somehow I don't think mere coincidence is really a factor. A number of Old World languages of different groups show a word for 'dog' or a doglike beast of the type affricate/sibilant plus […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Online Self-Concordant and Relatively Smooth Minimization, With
  Applications to Online Portfolio Selection and Learning Quantum States]]></title>
        <id>http://arxiv.org/abs/2210.00997</id>
        <link href="http://arxiv.org/abs/2210.00997"/>
        <updated>2023-09-22T03:15:09.516Z</updated>
        <summary type="html"><![CDATA[Chung-En Tsai, Hao-Chung Cheng, Yen-Huan Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TrueLearn: A Python Library for Personalised Informational
  Recommendations with (Implicit) Feedback]]></title>
        <id>http://arxiv.org/abs/2309.11527</id>
        <link href="http://arxiv.org/abs/2309.11527"/>
        <updated>2023-09-22T03:15:09.427Z</updated>
        <summary type="html"><![CDATA[Yuxiang Qiu, Karim Djemili, Denis Elezi, Aaneel Shalman, Mar\'ia
  P\'erez-Ortiz, Sahan Bulathwela]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models]]></title>
        <id>http://arxiv.org/abs/2309.12307</id>
        <link href="http://arxiv.org/abs/2309.12307"/>
        <updated>2023-09-22T03:15:09.347Z</updated>
        <summary type="html"><![CDATA[Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, Song
  Han, Jiaya Jia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Activation Compression of Graph Neural Networks using Block-wise
  Quantization with Improved Variance Minimization]]></title>
        <id>http://arxiv.org/abs/2309.11856</id>
        <link href="http://arxiv.org/abs/2309.11856"/>
        <updated>2023-09-22T03:15:09.314Z</updated>
        <summary type="html"><![CDATA[Sebastian Eliassen, Raghavendra Selvan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian sparsification for deep neural networks with Bayesian model
  reduction]]></title>
        <id>http://arxiv.org/abs/2309.12095</id>
        <link href="http://arxiv.org/abs/2309.12095"/>
        <updated>2023-09-22T03:15:09.309Z</updated>
        <summary type="html"><![CDATA[Dimitrije Markovi\'c, Karl J. Friston, Stefan J. Kiebel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=53873</id>
        <link href="https://xianblog.wordpress.com/2023/09/22/a-journal-of-the-conquest-war-famine-and-death-year-4/"/>
        <updated>2023-09-21T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[Read [on the way back home (and during the following jet-lagged nights)] the Ninth Rain and its sequel the Bitter Twins, by Jen Williams, for which she won twice a British Fantasy Award. I am twice as surprised given that it is quite a poor series, with a simplistic approach to its world building, a […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes]]></title>
        <id>http://blog.research.google/2023/09/distilling-step-by-step-outperforming.html</id>
        <link href="http://blog.research.google/2023/09/distilling-step-by-step-outperforming.html"/>
        <updated>2023-09-21T21:25:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Cheng-Yu Hsieh, Student Researcher, and Chen-Yu Lee, Research Scientist, Cloud AI Team





Large language models (LLMs) have enabled a new data-efficient learning paradigm wherein they can be used to solve unseen new tasks via zero-shot or few-shot prompting. However, LLMs are challenging to deploy for real-world applications due to their sheer size. For instance, serving a single 175 billion LLM requires at least 350GB of GPU memory using specialized infrastructure, not to mention that today's state-of-the-art LLMs are composed of over 500 billion parameters. Such computational requirements are inaccessible for many research teams, especially for applications that require low latency performance.




To circumvent these deployment challenges, practitioners often choose to deplo…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Earwormitis]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60666</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60666&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=earwormitis"/>
        <updated>2023-09-21T18:56:32.000Z</updated>
        <summary type="html"><![CDATA[I'm not the first person to use that word, but I probably mean it in a distinctive way.  What I'm talking about is not the usual sort of earworm / öhrwurm that gets stuck in your brain and you just can't make it go away.  That's the usual kind, and I get it fairly often, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Networks as Denoising Algorithms: Sample-Efficient Learning of
  Diffusion Models in High-Dimensional Graphical Models]]></title>
        <id>http://arxiv.org/abs/2309.11420</id>
        <link href="http://arxiv.org/abs/2309.11420"/>
        <updated>2023-09-21T02:19:57.126Z</updated>
        <summary type="html"><![CDATA[Song Mei, Yuchen Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Prediction is Robust to Dispersive Label Noise]]></title>
        <id>http://arxiv.org/abs/2209.14295</id>
        <link href="http://arxiv.org/abs/2209.14295"/>
        <updated>2023-09-21T02:19:47.000Z</updated>
        <summary type="html"><![CDATA[Shai Feldman, Bat-Sheva Einbinder, Stephen Bates, Anastasios N.
  Angelopoulos, Asaf Gendler, Yaniv Romano]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classification Under Misspecification: Halfspaces, Generalized Linear
  Models, and Connections to Evolvability]]></title>
        <id>http://arxiv.org/abs/2006.04787</id>
        <link href="http://arxiv.org/abs/2006.04787"/>
        <updated>2023-09-21T02:19:46.993Z</updated>
        <summary type="html"><![CDATA[Sitan Chen, Frederic Koehler, Ankur Moitra, Morris Yau]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning]]></title>
        <id>http://arxiv.org/abs/2106.12059</id>
        <link href="http://arxiv.org/abs/2106.12059"/>
        <updated>2023-09-21T02:19:46.987Z</updated>
        <summary type="html"><![CDATA[Andreas Kirsch, Sebastian Farquhar, Parmida Atighehchian, Andrew
  Jesson, Frederic Branchaud-Charron, Yarin Gal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Pragmatic Look at Deep Imitation Learning]]></title>
        <id>http://arxiv.org/abs/2108.01867</id>
        <link href="http://arxiv.org/abs/2108.01867"/>
        <updated>2023-09-21T02:19:46.982Z</updated>
        <summary type="html"><![CDATA[Kai Arulkumaran, Dan Ogawa Lillrank]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Voice-activated lights]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60593</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60593&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=voice-activated-lights"/>
        <updated>2023-09-21T01:59:11.000Z</updated>
        <summary type="html"><![CDATA[I showed this mp4 video to a dozen native speakers of Sinitic languages (mostly Mandarin), but no one could identify, much less understand, what it was: https://i.imgur.com/MesyF9r.mp4   (from imgur) Chau Wu ruled out Taiwanese, Hakka, and Cantonese, but he said that he heard words that sounded like chú sī 廚司 ("chef") and chǎocài 炒菜 […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[All About that Bayes restart]]></title>
        <id>http://xianblog.wordpress.com/?p=54070</id>
        <link href="https://xianblog.wordpress.com/2023/09/21/all-about-that-bayes-restart/"/>
        <updated>2023-09-20T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[For all Bayesians and sympathisers in the Paris area, All about that Bayes seminars are restarting this semester with a talk by Kaniav Kamari (Centrale Supélec) on 10 October, 16h00, on Campus Pierre & Marie Curie, SCAI: Bayesian principal component analysis The technique of principal component analysis (PCA) has recently been expressed as the maximum […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arrowleaf pinot noir]]></title>
        <id>http://xianblog.wordpress.com/?p=53723</id>
        <link href="https://xianblog.wordpress.com/2023/09/20/arrowleaf-pinot-noir/"/>
        <updated>2023-09-20T18:20:21.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Buoyancy-driven exchange flows in inclined ducts]]></title>
        <id>http://arxiv.org/abs/1907.03502</id>
        <link href="http://arxiv.org/abs/1907.03502"/>
        <updated>2023-09-20T17:13:14.259Z</updated>
        <summary type="html"><![CDATA[Adrien Lefauve, P. F. Linden]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distinguished elements in semiring extensions]]></title>
        <id>http://arxiv.org/abs/1811.02142</id>
        <link href="http://arxiv.org/abs/1811.02142"/>
        <updated>2023-09-20T17:13:14.217Z</updated>
        <summary type="html"><![CDATA[Peyman Nasehpour]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approaches to analysis with infinitesimals following Robinson, Nelson,
  and others]]></title>
        <id>http://arxiv.org/abs/1703.00425</id>
        <link href="http://arxiv.org/abs/1703.00425"/>
        <updated>2023-09-20T17:13:14.204Z</updated>
        <summary type="html"><![CDATA[Peter Fletcher, Karel Hrbacek, Vladimir Kanovei, Mikhail G. Katz,
  Claude Lobry, Sam Sanders]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An extension of Calderon Transfer Principle]]></title>
        <id>http://arxiv.org/abs/2004.00462</id>
        <link href="http://arxiv.org/abs/2004.00462"/>
        <updated>2023-09-20T17:13:14.169Z</updated>
        <summary type="html"><![CDATA[Sakin Demir]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Canonicalizers and Declarative Rewrite Patterns]]></title>
        <id>https://jeremykun.com/?p=120004</id>
        <link href="https://jeremykun.com/2023/09/20/mlir-canonicalizers-and-declarative-rewrite-patterns/"/>
        <updated>2023-09-20T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents In a previous article we defined folding functions, and used them to enable some canonicalization and the sccp constant propagation pass for the poly dialect. This time we’ll see how to add more general canonicalization patterns. The code for this article is in this pull request, and as usual the commits are organized to be […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[自然数域中 N = ab + c 时 a + b + c 的最小值]]></title>
        <id>https://kexue.fm/archives/9775</id>
        <link href="https://kexue.fm/archives/9775"/>
        <updated>2023-09-20T06:16:00.000Z</updated>
        <summary type="html"><![CDATA[前天晚上微信群里有群友提出了一个问题：对于一个任意整数$N > 100$，求一个近似算法，使得$N=a\times b+c$（其中$a,b,c$都是非负整数），并且令$a+b+c$尽量地小。初看...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometric structure of shallow neural networks and constructive
  ${\mathcal L}^2$ cost minimization]]></title>
        <id>http://arxiv.org/abs/2309.10370</id>
        <link href="http://arxiv.org/abs/2309.10370"/>
        <updated>2023-09-20T02:20:25.020Z</updated>
        <summary type="html"><![CDATA[Thomas Chen, Patricia Mu\~noz Ewald]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometric structure of Deep Learning networks and construction of global
  ${\mathcal L}^2$ minimizers]]></title>
        <id>http://arxiv.org/abs/2309.10639</id>
        <link href="http://arxiv.org/abs/2309.10639"/>
        <updated>2023-09-20T02:20:24.959Z</updated>
        <summary type="html"><![CDATA[Thomas Chen, Patricia Mu\~noz Ewald]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring the Limits of Transfer Learning with a Unified Text-to-Text
  Transformer]]></title>
        <id>http://arxiv.org/abs/1910.10683</id>
        <link href="http://arxiv.org/abs/1910.10683"/>
        <updated>2023-09-20T02:20:17.929Z</updated>
        <summary type="html"><![CDATA[Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan
  Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up Floyd-Steinberg dithering: an optimization exercise]]></title>
        <id>https://pythonspeed.com/articles/optimizing-dithering/</id>
        <link href="https://pythonspeed.com/articles/optimizing-dithering/"/>
        <updated>2023-09-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[pre {
    white-space: pre;
    overflow-x: auto;
    font-size: 80%;
}


The common advice when Python is too slow is to switch to a low-level compiled language.
But what do you do if that code is too slow?
Almost always there’s still plenty of performance improvements you can get just by tweaking your code.
As a real-world example, in this article we’ll go about optimizing Floyd-Steinberg error diffusion dithering.
The specific variant of the  algorithm that we will implement converts a grayscale image with values of 0 to 255 into an image with just two colors, black and white.
This article is an excerpt from a book I’m working on that will help teach you how to optimize low-level code, the kind of code you’d write with C, Cython, or Rust.
The goal is to help data scientists and scientis…]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mandarin über alles]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60662</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60662&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mandarin-uber-alles"/>
        <updated>2023-09-19T23:35:33.000Z</updated>
        <summary type="html"><![CDATA[China’s Language PoliceWhy Beijing Seeks to Extend the Hegemony of MandarinBy Gina Anne Tam, Foreign AffairsSeptember 19, 2023 It's odd that the author knows about "topolect" and recognizes the inadequacy of "dialect" as a rendering of fāngyán 方言, but is unwilling to mention "topolect" in this article, which is so suitable for it.  Maybe the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TabPFN: A Transformer That Solves Small Tabular Classification Problems
  in a Second]]></title>
        <id>http://arxiv.org/abs/2207.01848</id>
        <link href="http://arxiv.org/abs/2207.01848"/>
        <updated>2023-09-19T03:15:27.394Z</updated>
        <summary type="html"><![CDATA[Noah Hollmann, Samuel M\"uller, Katharina Eggensperger, Frank Hutter]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When AUC meets DRO: Optimizing Partial AUC for Deep Learning with
  Non-Convex Convergence Guarantee]]></title>
        <id>http://arxiv.org/abs/2203.00176</id>
        <link href="http://arxiv.org/abs/2203.00176"/>
        <updated>2023-09-19T03:15:27.389Z</updated>
        <summary type="html"><![CDATA[Dixian Zhu, Gang Li, Bokun Wang, Xiaodong Wu, Tianbao Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive and Robust Multi-Task Learning]]></title>
        <id>http://arxiv.org/abs/2202.05250</id>
        <link href="http://arxiv.org/abs/2202.05250"/>
        <updated>2023-09-19T03:15:27.383Z</updated>
        <summary type="html"><![CDATA[Yaqi Duan, Kaizheng Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SplitEE: Early Exit in Deep Neural Networks with Split Computing]]></title>
        <id>http://arxiv.org/abs/2309.09195</id>
        <link href="http://arxiv.org/abs/2309.09195"/>
        <updated>2023-09-19T03:15:27.378Z</updated>
        <summary type="html"><![CDATA[Divya J. Bajpai, Vivek K. Trivedi, Sohan L. Yadav, Manjesh K.
  Hanawal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring and Learning in Sparse Linear MDPs without Computationally
  Intractable Oracles]]></title>
        <id>http://arxiv.org/abs/2309.09457</id>
        <link href="http://arxiv.org/abs/2309.09457"/>
        <updated>2023-09-19T03:15:27.358Z</updated>
        <summary type="html"><![CDATA[Noah Golowich, Dhruv Rohatgi, Ankur Moitra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A catalogue of genetic mutations to help pinpoint the cause of diseases]]></title>
        <id>https://www.deepmind.com/blog/alphamissense-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases</id>
        <link href="https://www.deepmind.com/blog/alphamissense-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases"/>
        <updated>2023-09-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We've released a catalogue of ‘missense’ mutations where researchers can learn more about what effect they may have. Missense variants are genetic mutations that can affect the function of human proteins. In some cases, they can lead to diseases such as cystic fibrosis, sickle-cell anaemia, or cancer. The AlphaMissense catalogue was developed using AlphaMissense, our new AI model which classifies missense variants.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[postdocs sought for NEMESIS]]></title>
        <id>http://xianblog.wordpress.com/?p=54032</id>
        <link href="https://xianblog.wordpress.com/2023/09/19/postdocs-sought-for-nemesis/"/>
        <updated>2023-09-18T22:23:49.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Grab / Mixed bag of crimes that "hurt the feelings of the Chinese people", part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60634</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60634&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=grab-mixed-bag-of-crimes-that-hurt-the-feelings-of-the-chinese-people-part-2"/>
        <updated>2023-09-18T18:09:39.000Z</updated>
        <summary type="html"><![CDATA[In recent weeks, the odd expression "kǒudài zuì 口袋罪" (lit., "pocket / bag crime"} has become a hot topic).  It's a vague, catch-all term without any juridical / official standing, yet it has left many people troubled over its implications.  To understand why people are unsettled over such a seemingly zany, innocuous term, we will […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Encoding Schemes in FHE]]></title>
        <id>https://jeremykun.com/?p=119941</id>
        <link href="https://jeremykun.com/2023/09/18/encoding-schemes-in-fhe/"/>
        <updated>2023-09-18T18:08:39.000Z</updated>
        <summary type="html"><![CDATA[In cryptography, we need a distinction between a cleartext and a plaintext. A cleartext is a message in its natural form. A plaintext is a cleartext that is represented in a specific way to prepare it for encryption in a specific scheme. The process of taking a cleartext and turning it into a plaintext is […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A new draft…]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60651</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60651&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=60651"/>
        <updated>2023-09-18T13:33:08.000Z</updated>
        <summary type="html"><![CDATA[This is not at all the experience that I've had with multiple-authored papers — but it's funny: “Thanks everyone for comments on the draft, here it is revised with all your edits.” pic.twitter.com/pSV16wQqca — Ben Phillips (@benphillips76) September 17, 2023 And I've sometimes had analogous issues with "copy editing" — see e.g. "Spectrums", 5/24/2022…]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Layer Adaptive Node Selection in Bayesian Neural Networks: Statistical
  Guarantees and Implementation Details]]></title>
        <id>http://arxiv.org/abs/2108.11000</id>
        <link href="http://arxiv.org/abs/2108.11000"/>
        <updated>2023-09-18T03:15:08.261Z</updated>
        <summary type="html"><![CDATA[Sanket Jantre, Shrijita Bhattacharya, Tapabrata Maiti]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Constraint-Free Structure Learning with Smooth Acyclic Orientations]]></title>
        <id>http://arxiv.org/abs/2309.08406</id>
        <link href="http://arxiv.org/abs/2309.08406"/>
        <updated>2023-09-18T03:15:08.219Z</updated>
        <summary type="html"><![CDATA[Riccardo Massidda, Francesco Landolfi, Martina Cinquini, Davide Bacciu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploiting Noise as a Resource for Computation and Learning in Spiking
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.16044</id>
        <link href="http://arxiv.org/abs/2305.16044"/>
        <updated>2023-09-18T03:15:08.214Z</updated>
        <summary type="html"><![CDATA[Gehua Ma, Rui Yan, Huajin Tang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How many Neurons do we need? A refined Analysis for Shallow Networks
  trained with Gradient Descent]]></title>
        <id>http://arxiv.org/abs/2309.08044</id>
        <link href="http://arxiv.org/abs/2309.08044"/>
        <updated>2023-09-18T03:15:08.021Z</updated>
        <summary type="html"><![CDATA[Mike Nguyen, Nicole M\"ucke]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Masked Generative Modeling with Enhanced Sampling Scheme]]></title>
        <id>http://arxiv.org/abs/2309.07945</id>
        <link href="http://arxiv.org/abs/2309.07945"/>
        <updated>2023-09-18T03:15:08.005Z</updated>
        <summary type="html"><![CDATA[Daesoo Lee, Erlend Aune, Sara Malacarne]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[volcanoes of Martinique now UNESCO World heritage]]></title>
        <id>http://xianblog.wordpress.com/?p=54055</id>
        <link href="https://xianblog.wordpress.com/2023/09/18/volcanoes-of-martinique-now-unesco-world-heritage/"/>
        <updated>2023-09-17T22:23:54.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rhetoric as music]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60637</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60637&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rhetoric-as-music"/>
        <updated>2023-09-17T14:25:47.000Z</updated>
        <summary type="html"><![CDATA[From Jon Stewart's 1997 interview with George Carlin (starting at about 1:17.6): Your browser does not support the audio element. well- well uh to- to go backward with the question, don't forget, what we do is oratory. It's rhetoric. It's not just comedy, it's a form of rhetoric and- and with rhetoric, you- you look […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some Old Chinese terms relating to religion, mythology, ritual]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60614</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60614&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=some-old-chinese-terms-relating-to-religion-mythology-ritual"/>
        <updated>2023-09-17T12:25:11.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Axel Schuessler] Some Old Chinese (OC) words that relate to religion, mythology and ritual, and words found in ritual literature (Yijing, Liji, Zhouli), have no Sino-Tibetan (ST) roots, but instead have connections with other language families.     For comparison, the first section of this paper will list (§1) Sino-Tibetan […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[the Amazon turning negative]]></title>
        <id>http://xianblog.wordpress.com/?p=53918</id>
        <link href="https://xianblog.wordpress.com/2023/09/17/the-amazon-turning-negative/"/>
        <updated>2023-09-16T22:23:24.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No sabo kids]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60617</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60617&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=no-sabo-kids"/>
        <updated>2023-09-16T16:54:55.000Z</updated>
        <summary type="html"><![CDATA[Edwin Flores and Maya Brown, "The 'no sabo kids' are pushing back on Spanish-language shaming", NBC News 9/16/2023: A growing group of young Latinos are using TikTok and social media to push back on not speaking perfect Spanish — an attempt to define their identity and heritage on their own terms. […] In recent years, […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hanziyu: The (cursed) Conlang of Characters]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60607</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60607&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hanziyu-the-cursed-conlang-of-characters"/>
        <updated>2023-09-16T11:01:29.000Z</updated>
        <summary type="html"><![CDATA[Fiendishly clever conlang (constructed language) invented by Eleanor Olson. Some Language Log readers will love it, some will hate it.  Most will probably not understand what the devil she is up to with her Hànzìyǔ 汉字语 ("Sinoglyphish"). Natural writing systems are created with the intention of mapping to and recording the sounds of spoken languages.  […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Students' perspectives on computational challenges in physics class]]></title>
        <id>http://arxiv.org/abs/2202.07718</id>
        <link href="http://arxiv.org/abs/2202.07718"/>
        <updated>2023-09-16T02:18:04.010Z</updated>
        <summary type="html"><![CDATA[Patti Hamerski, Daryl McPadden, Marcos D. Caballero, Paul W. Irving]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unigram随机分词：从Viterbi解码到随机采样]]></title>
        <id>https://kexue.fm/archives/9768</id>
        <link href="https://kexue.fm/archives/9768"/>
        <updated>2023-09-16T01:01:00.000Z</updated>
        <summary type="html"><![CDATA[上一篇文章《大词表语言模型在续写任务上的一个问题及对策》发布后，很快就有读者指出可以在训练阶段引入带有随机性的分词结果来解决同样的问题，并且已经有论文和实现。经过进一步查阅学习，笔者发现这是一个...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a day for social good in London]]></title>
        <id>http://xianblog.wordpress.com/?p=53906</id>
        <link href="https://xianblog.wordpress.com/2023/09/16/a-day-for-social-good-in-london/"/>
        <updated>2023-09-15T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[On Thursday, I went (from Paris) to London for the final day of Warwick DSSGx UK 2023 (Data Science for Social Good), which took place in The Shard, the tallest building in London (and certainly not the prettiest!), where the Warwick Business School has offices, and on the way, stopped by the nearby Tate Modern […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MediaPipe FaceStylizer: On-device real-time few-shot face stylization]]></title>
        <id>http://blog.research.google/2023/09/mediapipe-facestylizer-on-device-real.html</id>
        <link href="http://blog.research.google/2023/09/mediapipe-facestylizer-on-device-real.html"/>
        <updated>2023-09-15T17:39:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Haolin Jia, Software Engineer, and Qifei Wang, Senior Software Engineer, Core ML



In recent years, we have witnessed rising interest across consumers and researchers in integrated augmented reality (AR) experiences using real-time face feature generation and editing functions in mobile applications, including short videos, virtual reality, and gaming. As a result, there is a growing demand for lightweight, yet high-quality face generation and editing models, which are often based on generative adversarial network (GAN) techniques. However, the majority of GAN models suffer from high computational complexity and the need for a large training dataset. In addition, it is also important to employ GAN models responsibly. 



In this post, we introduce MediaPipe FaceStylizer, an effi…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Benchmark Analysis of Representative Deep Neural Network Architectures]]></title>
        <id>http://arxiv.org/abs/1810.00736</id>
        <link href="http://arxiv.org/abs/1810.00736"/>
        <updated>2023-09-15T17:12:59.614Z</updated>
        <summary type="html"><![CDATA[Simone Bianco, Remi Cadene, Luigi Celona, Paolo Napoletano]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pseudo-finite sets, pseudo-o-minimality]]></title>
        <id>http://arxiv.org/abs/1908.01660</id>
        <link href="http://arxiv.org/abs/1908.01660"/>
        <updated>2023-09-15T17:12:58.902Z</updated>
        <summary type="html"><![CDATA[Nadav Meir]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Euler systems for GSp(4)]]></title>
        <id>http://arxiv.org/abs/1706.00201</id>
        <link href="http://arxiv.org/abs/1706.00201"/>
        <updated>2023-09-15T17:12:58.883Z</updated>
        <summary type="html"><![CDATA[David Loeffler, Chris Skinner, Sarah Livia Zerbes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complete type amalgamation for non-standard finite groups]]></title>
        <id>http://arxiv.org/abs/2009.08967</id>
        <link href="http://arxiv.org/abs/2009.08967"/>
        <updated>2023-09-15T17:12:58.070Z</updated>
        <summary type="html"><![CDATA[Amador Martin-Pizarro, Daniel Palac\'in]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Scratch to Teach Undergraduate Students' Skills on Artificial
  Intelligence]]></title>
        <id>http://arxiv.org/abs/1904.00296</id>
        <link href="http://arxiv.org/abs/1904.00296"/>
        <updated>2023-09-15T17:12:58.065Z</updated>
        <summary type="html"><![CDATA[Julian Estevez, Gorka Garate, JM Lopez Guede, Manuel Gra\~na]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Denny Zhou - Teach language models to reason]]></title>
        <id>https://mlfoundations.org/talk/denny/</id>
        <link href="https://mlfoundations.org/talk/denny/"/>
        <updated>2023-09-15T14:15:00.000Z</updated>
        <summary type="html"><![CDATA[Over the past decades, the machine learning community has developed tons of data-driven techniques aimed at enhancing learning efficiency, like semi-supervised learning, meta learning, active learning, transfer learning, and more. However, none of these techniques have proven to be highly effective for real-world natural language processing tasks. This shortcoming uncovers a fundamental flaw in machine learning - the absence of reasoning. Humans often learn from just a few examples because of their capacity to reason, as opposed to relying on data statistics. In this talk, I will talk about the large language models (LLM) reasoning work that we pioneered, and show that the techniques we developed can greatly narrow the gap between human intelligence and machine learning - crushed SoTA in the literature while demanding only a few annotated examples and no training. Our work was presented by Google CEO Sundar Pichai at Google I/O 2022 as a showcase of Google AI.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
</feed>