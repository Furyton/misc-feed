<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-04-13T16:19:41.526Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[The "socialite" phenomenon in China]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58423</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58423&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-socialite-phenomenon-in-china"/>
        <updated>2023-04-13T11:12:42.000Z</updated>
        <summary type="html"><![CDATA[Source: China Media Project (12/7/2022)THE CMP DICTIONARY: Socialite 媛By XINYU DENG Once signifying graceful women of a distinguished background, the term “socialite,” or yuan (媛), has in recent years become a misogynistic umbrella term used on digital platforms in China to disparage women who advertise fancy lifestyles. The term has also been used by state-run media […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SoK: Certified Robustness for Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2009.04131</id>
        <link href="http://arxiv.org/abs/2009.04131"/>
        <updated>2023-04-13T07:13:53.212Z</updated>
        <summary type="html"><![CDATA[Linyi Li, Tao Xie, Bo Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Certified Robustness via Statistical Learning with Logical
  Reasoning]]></title>
        <id>http://arxiv.org/abs/2003.00120</id>
        <link href="http://arxiv.org/abs/2003.00120"/>
        <updated>2023-04-13T07:13:53.194Z</updated>
        <summary type="html"><![CDATA[Zhuolin Yang, Zhikuan Zhao, Boxin Wang, Jiawei Zhang, Linyi Li,
  Hengzhi Pei, Bojan Karlas, Ji Liu, Heng Guo, Ce Zhang, Bo Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Criticality versus uniformity in deep neural networks]]></title>
        <id>http://arxiv.org/abs/2304.04784</id>
        <link href="http://arxiv.org/abs/2304.04784"/>
        <updated>2023-04-13T07:13:53.186Z</updated>
        <summary type="html"><![CDATA[Aleksandar Bukva, Jurriaan de Gier, Kevin T. Grosvenor, Ro Jefferson,
  Koenraad Schalm, Eliot Schwander]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Selecting Robust Features for Machine Learning Applications using
  Multidata Causal Discovery]]></title>
        <id>http://arxiv.org/abs/2304.05294</id>
        <link href="http://arxiv.org/abs/2304.05294"/>
        <updated>2023-04-13T07:13:52.489Z</updated>
        <summary type="html"><![CDATA[Saranya Ganesh S., Tom Beucler, Frederick Iat-Hin Tam, Milton S.
  Gomez, Jakob Runge, Andreas Gerhardus]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[StatMathAppli, Fréjus, France [18-22 September 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=52493</id>
        <link href="https://xianblog.wordpress.com/2023/04/13/statmathappli-frejus-france-18-22-september-2023/"/>
        <updated>2023-04-12T22:23:22.000Z</updated>
        <summary type="html"><![CDATA[The bi-yearly StatMathAppli conference will take place next September in Fréjus, France, with guest lecturers Marco Cuturi (ENSAE & Apple ML Research) who will a lecture on “Optimal Transport: From Theory to Tweaks, Computations and Applications in Machine Learning”, and Gareth O. Roberts (University of Warwick) who will give a lecture on “Topics in Retrospective […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UniPi: Learning universal policies via text-guided video generation]]></title>
        <id>http://ai.googleblog.com/2023/04/unipi-learning-universal-policies-via.html</id>
        <link href="http://ai.googleblog.com/2023/04/unipi-learning-universal-policies-via.html"/>
        <updated>2023-04-12T20:04:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Sherry Yang, Research Scientist, and Yilun Du, Student Researcher, Google Research, Brain Team
Building models that solve a diverse set of tasks has become a dominant paradigm in the domains of vision and language. In natural language processing, large pre-trained models, such as PaLM, GPT-3 and Gopher, have demonstrated remarkable zero-shot learning of new language tasks. Similarly, in computer vision, models like CLIP and Flamingo have shown robust performance on zero-shot classification and object recognition. A natural next step is to use such tools to construct agents that can complete different decision-making tasks across many environments.



However, training such agents faces the inherent challenge of environmental diversity, since different environments operate with di…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Sutradhar and the Ringgit: A Study of Terms Related to the Early Puppet Theatres]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58410</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58410&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-sutradhar-and-the-ringgit-a-study-of-terms-related-to-the-early-puppet-theatres"/>
        <updated>2023-04-12T16:17:25.000Z</updated>
        <summary type="html"><![CDATA[Sino-Platonic Papers is pleased to announce the publication of its three-hundred-and-thirty-second issue: “The Sutradhar and the Ringgit: A Study of Terms Related to the Early Puppet Theatres,” by Keith Rawlings. ABSTRACT Certain words in Sanskrit, Old Javanese, and Ancient Greek that appear in centuries-old texts are thought by many scholars to be early references to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thoughts on AI safety]]></title>
        <id>http://windowsontheory.org/?p=8591</id>
        <link href="https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/"/>
        <updated>2023-04-12T15:25:45.000Z</updated>
        <summary type="html"><![CDATA[Last week, I gave a lecture on AI safety as part of my deep learning foundations course. In this post, I’ll try to write down a few of my thoughts on this topic. (The lecture was three hours, and this blog post will not cover all of what we discussed or all the points that … Continue reading Thoughts on AI safety]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thoughts on AI safety]]></title>
        <id>http://windowsontheory.org/?p=8591</id>
        <link href="https://windowsontheory.org/2023/04/12/thoughts-on-ai-safety/"/>
        <updated>2023-04-12T15:25:45.000Z</updated>
        <summary type="html"><![CDATA[Last week, I gave a lecture on AI safety as part of my deep learning foundations course. In this post, I’ll try to write down a few of my thoughts on this topic. (The lecture was three hours, and this blog post will not cover all of what we discussed or all the points that … Continue reading Thoughts on AI safety]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[报名开启！成都首个ChatGPT和大模型专题研讨会，期待您的参与！]]></title>
        <id>https://www.52nlp.cn/?p=13454</id>
        <link href="https://www.52nlp.cn/%e6%8a%a5%e5%90%8d%e5%bc%80%e5%90%af%ef%bc%81%e6%88%90%e9%83%bd%e9%a6%96%e4%b8%aachatgpt%e5%92%8c%e5%a4%a7%e6%a8%a1%e5%9e%8b%e4%b8%93%e9%a2%98%e7%a0%94%e8%ae%a8%e4%bc%9a%ef%bc%8c%e6%9c%9f%e5%be%85"/>
        <updated>2023-04-12T08:17:15.000Z</updated>
        <summary type="html"><![CDATA[在当今的数字时代，人工智能技术已成为推动社会发展的重要驱动力。作为人工智能领域的热点之一，ChatGPT和大模 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[年度AI对话|达观陈运文：做私有部署的大模型，数据安全更具优势]]></title>
        <id>https://www.52nlp.cn/?p=13451</id>
        <link href="https://www.52nlp.cn/%e5%b9%b4%e5%ba%a6ai%e5%af%b9%e8%af%9d%e8%be%be%e8%a7%82%e9%99%88%e8%bf%90%e6%96%87%ef%bc%9a%e5%81%9a%e7%a7%81%e6%9c%89%e9%83%a8%e7%bd%b2%e7%9a%84%e5%a4%a7%e6%a8%a1%e5%9e%8b%ef%bc%8c%e6%95%b0"/>
        <updated>2023-04-12T07:59:23.000Z</updated>
        <summary type="html"><![CDATA[本文内容来源于达观数据董事长兼CEO陈运文受邀出席36氪数字时氪的《年度AI对话》专栏采访内容 大模型既带来了 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[达观助手AI智能写作，全方位智能写作新体验]]></title>
        <id>https://www.52nlp.cn/?p=13449</id>
        <link href="https://www.52nlp.cn/%e8%be%be%e8%a7%82%e5%8a%a9%e6%89%8bai%e6%99%ba%e8%83%bd%e5%86%99%e4%bd%9c%ef%bc%8c%e5%85%a8%e6%96%b9%e4%bd%8d%e6%99%ba%e8%83%bd%e5%86%99%e4%bd%9c%e6%96%b0%e4%bd%93%e9%aa%8c"/>
        <updated>2023-04-12T07:44:40.000Z</updated>
        <summary type="html"><![CDATA[达观助手是一款智能辅助写作的wps插件工具，采用人工智能技术开发，拥有多项实用功能，如AI续写、AI润色、智能 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[全国首届大模型创新创意应用大赛开启，等你来赛！]]></title>
        <id>https://www.52nlp.cn/?p=13447</id>
        <link href="https://www.52nlp.cn/%e5%85%a8%e5%9b%bd%e9%a6%96%e5%b1%8a%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%88%9b%e6%96%b0%e5%88%9b%e6%84%8f%e5%ba%94%e7%94%a8%e5%a4%a7%e8%b5%9b%e5%bc%80%e5%90%af%ef%bc%8c%e7%ad%89%e4%bd%a0%e6%9d%a5%e8%b5%9b"/>
        <updated>2023-04-12T07:28:06.000Z</updated>
        <summary type="html"><![CDATA[近期，以ChatGPT和GPT4为代表的大规模语言模型陆续发布，带动了人工智能产业的快速发展。大模型已经成为实 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Feature Learning and Signal Propagation in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2110.11749</id>
        <link href="http://arxiv.org/abs/2110.11749"/>
        <updated>2023-04-12T07:13:41.804Z</updated>
        <summary type="html"><![CDATA[Yizhang Lou, Chris Mingard, Yoonsoo Nam, Soufiane Hayou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An analytic theory for the dynamics of wide quantum neural networks]]></title>
        <id>http://arxiv.org/abs/2203.16711</id>
        <link href="http://arxiv.org/abs/2203.16711"/>
        <updated>2023-04-12T07:13:41.797Z</updated>
        <summary type="html"><![CDATA[Junyu Liu, Khadijeh Najafi, Kunal Sharma, Francesco Tacchino, Liang
  Jiang, Antonio Mezzacapo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gradient-based Uncertainty Attribution for Explainable Bayesian Deep
  Learning]]></title>
        <id>http://arxiv.org/abs/2304.04824</id>
        <link href="http://arxiv.org/abs/2304.04824"/>
        <updated>2023-04-12T07:13:41.790Z</updated>
        <summary type="html"><![CDATA[Hanjing Wang, Dhiraj Joshi, Shiqiang Wang, Qiang Ji]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On a continuous time model of gradient descent dynamics and instability
  in deep learning]]></title>
        <id>http://arxiv.org/abs/2302.01952</id>
        <link href="http://arxiv.org/abs/2302.01952"/>
        <updated>2023-04-12T07:13:41.771Z</updated>
        <summary type="html"><![CDATA[Mihaela Rosca, Yan Wu, Chongli Qin, Benoit Dherin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Gradient Descent: Deep Learning without Hyperparameters]]></title>
        <id>http://arxiv.org/abs/2304.05187</id>
        <link href="http://arxiv.org/abs/2304.05187"/>
        <updated>2023-04-12T07:13:40.006Z</updated>
        <summary type="html"><![CDATA[Jeremy Bernstein, Chris Mingard, Kevin Huang, Navid Azizan
 , Yisong Yue]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[达观数据研发“曹植”大语言模型，致力于国产GPT模型]]></title>
        <id>https://www.52nlp.cn/?p=13445</id>
        <link href="https://www.52nlp.cn/%e8%be%be%e8%a7%82%e6%95%b0%e6%8d%ae%e7%a0%94%e5%8f%91%e6%9b%b9%e6%a4%8d%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%ef%bc%8c%e8%87%b4%e5%8a%9b%e4%ba%8e%e5%9b%bd%e4%ba%a7gpt"/>
        <updated>2023-04-12T07:01:37.000Z</updated>
        <summary type="html"><![CDATA[在通用领域，以ChatGPT为代表的生成式大规模语言模型展现出卓越的知识学习和文字创作能力，受到国内外的广泛关 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mixed Thai, English, and Chinese sign]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58404</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58404&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mixed-thai-english-and-chinese-sign"/>
        <updated>2023-04-12T04:28:39.000Z</updated>
        <summary type="html"><![CDATA[Photograph taken at a park in Chiang Mai, Thailand: In brief (and without marking the Thai tones here), the Thai text comprises two words [sa: la:] ‘pavilion’ and [phak pho:n] ‘to rest’, i.e., ‘pavilion for resting’. Complete transcription and explication of the Thai text by Robert S. Bauer (author of the monumental ABC Cantonese-English dictionary […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The genius and logic of French and English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58399</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58399&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-genius-and-logic-of-french-and-english"/>
        <updated>2023-04-12T04:16:46.000Z</updated>
        <summary type="html"><![CDATA[Here are the warning labels on the sun visors in my Toyota Tacoma: In almost every line, the French is longer longer than the English — demonstrably and conspicuously so. Why does the French feel more comfortable going on at length, while the English is happy being more concise — consistently so in both cases? […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five stars over China:  Central Kingdom in Central Asia]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58407</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58407&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=five-stars-over-china-central-kingdom-in-central-asia"/>
        <updated>2023-04-12T02:13:44.000Z</updated>
        <summary type="html"><![CDATA[新时代祥瑞层出不穷 pic.twitter.com/bVm5Vn4XC4 — 方舟子 (@fangshimin) April 9, 2023 "Five stars out of the east to benefit the Central Kingdom" Here is the original Weibo post: “Wǔxīng chū dōngfāng lì zhōngguó” Hàndài zhījǐn hù bì, fājué yú Xīnjiāng Tǎkèlāmǎgàn shāmò fùdì de Níyǎ yízhǐ, bèi yù wèi 20 shìjì Zhōngguó kǎogǔ zuì wěidà de fǎxiàn zhī […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the plague, sword, and famine year [far North]]]></title>
        <id>http://xianblog.wordpress.com/?p=52652</id>
        <link href="https://xianblog.wordpress.com/2023/04/12/a-journal-of-the-plague-sword-and-famine-year-far-north/"/>
        <updated>2023-04-11T22:23:52.000Z</updated>
        <summary type="html"><![CDATA[Read Le sabre des Takeda (Furin kazan, 風林火山) by Inoue Yasushi, a very interesting book set between Japanese history and feudal novel, with surgical descriptions of battles and psychological tensions. This book reminded me in some aspects of a novel of Yoshimura Akira on the earthquake of Kantô by its insistence on minutiae. Even though […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Developing an aging clock using deep learning on retinal images]]></title>
        <id>http://ai.googleblog.com/2023/04/developing-aging-clock-using-deep.html</id>
        <link href="http://ai.googleblog.com/2023/04/developing-aging-clock-using-deep.html"/>
        <updated>2023-04-11T18:22:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Sara Ahadi, Research Fellow, Applied Science, and Andrew Carroll, Product Lead, Genomics




Aging is a process that is characterized by physiological and molecular changes that increase an individual's risk of developing diseases and eventually dying. Being able to measure and estimate the biological signatures of aging can help researchers identify preventive measures to reduce disease risk and impact. Researchers have developed “aging clocks” based on markers such as blood proteins or DNA methylation to measure individuals’ biological age, which is distinct from one’s chronological age. These aging clocks help predict the risk of age-related diseases. But because protein and methylation markers require a blood draw, non-invasive ways to find similar measures could make aging i…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[中科院张家俊：ChatGPT中的提示与指令学习]]></title>
        <id>https://www.52nlp.cn/?p=13443</id>
        <link href="https://www.52nlp.cn/%e4%b8%ad%e7%a7%91%e9%99%a2%e5%bc%a0%e5%ae%b6%e4%bf%8a%ef%bc%9achatgpt%e4%b8%ad%e7%9a%84%e6%8f%90%e7%a4%ba%e4%b8%8e%e6%8c%87%e4%bb%a4%e5%ad%a6%e4%b9%a0"/>
        <updated>2023-04-11T10:30:15.000Z</updated>
        <summary type="html"><![CDATA[内容来源：ChatGPT 及大模型专题研讨会 分享嘉宾：中国科学院自动化研究所研究员 张家俊 分享主题：《Ch […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Generative Models of the Geometry and Topology of Tree-like 3D
  Objects]]></title>
        <id>http://arxiv.org/abs/2110.08693</id>
        <link href="http://arxiv.org/abs/2110.08693"/>
        <updated>2023-04-11T07:13:55.203Z</updated>
        <summary type="html"><![CDATA[Guan Wang, Hamid Laga, Anuj Srivastava]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Weighted Ensemble Self-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2211.09981</id>
        <link href="http://arxiv.org/abs/2211.09981"/>
        <updated>2023-04-11T07:13:55.197Z</updated>
        <summary type="html"><![CDATA[Yangjun Ruan, Saurabh Singh, Warren Morningstar, Alexander A. Alemi,
  Sergey Ioffe, Ian Fischer, Joshua V. Dillon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Theoretical Study of Inductive Biases in Contrastive Learning]]></title>
        <id>http://arxiv.org/abs/2211.14699</id>
        <link href="http://arxiv.org/abs/2211.14699"/>
        <updated>2023-04-11T07:13:55.192Z</updated>
        <summary type="html"><![CDATA[Jeff Z. HaoChen, Tengyu Ma]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phase Diagram of Initial Condensation for Two-layer Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.06561</id>
        <link href="http://arxiv.org/abs/2303.06561"/>
        <updated>2023-04-11T07:13:55.186Z</updated>
        <summary type="html"><![CDATA[Zhengan Chen, Yuqing Li, Tao Luo, Zhangchen Zhou, Zhi-Qin John Xu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian learning of Causal Structure and Mechanisms with GFlowNets and
  Variational Bayes]]></title>
        <id>http://arxiv.org/abs/2211.02763</id>
        <link href="http://arxiv.org/abs/2211.02763"/>
        <updated>2023-04-11T07:13:55.180Z</updated>
        <summary type="html"><![CDATA[Mizu Nishikawa-Toomey, Tristan Deleu, Jithendaraa Subramanian, Yoshua
  Bengio, Laurent Charlin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[flying static]]></title>
        <id>http://xianblog.wordpress.com/?p=52676</id>
        <link href="https://xianblog.wordpress.com/2023/04/11/flying-static/"/>
        <updated>2023-04-11T06:23:02.000Z</updated>
        <summary type="html"><![CDATA[[While flying to Venezia, two art professionals were sitting in front of me, talking the entirety of the flight in a rather affected way.] “La Fenice, j’ai pas du tout envie d’aller là. C’est pas intéressant, j’irais beaucoup plus vers le cinéma italien classique des années 60, avec une vision beaucoup plus sophistiquée…”]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[state of the [des]Union]]></title>
        <id>http://xianblog.wordpress.com/?p=52784</id>
        <link href="https://xianblog.wordpress.com/2023/04/10/state-of-the-desunion/"/>
        <updated>2023-04-10T14:07:26.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[从JL引理看熵不变性Attention]]></title>
        <id>https://kexue.fm/archives/9588</id>
        <link href="https://kexue.fm/archives/9588"/>
        <updated>2023-04-10T08:12:00.000Z</updated>
        <summary type="html"><![CDATA[在《从熵不变性看Attention的Scale操作》、《熵不变性Softmax的一个快速推导》中笔者提出了熵不变性Softmax，简单来说就是往Softmax之前的Attention矩阵多乘上一...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean
  Field Neural Networks]]></title>
        <id>http://arxiv.org/abs/2304.03408</id>
        <link href="http://arxiv.org/abs/2304.03408"/>
        <updated>2023-04-10T07:13:50.234Z</updated>
        <summary type="html"><![CDATA[Blake Bordelon, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modality-Agnostic Variational Compression of Implicit Neural
  Representations]]></title>
        <id>http://arxiv.org/abs/2301.09479</id>
        <link href="http://arxiv.org/abs/2301.09479"/>
        <updated>2023-04-10T07:13:50.229Z</updated>
        <summary type="html"><![CDATA[Jonathan Richard Schwarz, Jihoon Tack, Yee Whye Teh, Jaeho
  Lee, Jinwoo Shin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Replicability and stability in learning]]></title>
        <id>http://arxiv.org/abs/2304.03757</id>
        <link href="http://arxiv.org/abs/2304.03757"/>
        <updated>2023-04-10T07:13:50.223Z</updated>
        <summary type="html"><![CDATA[Zachary Chase, Shay Moran, Amir Yehudayoff]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Supervised Contrastive Learning with Heterogeneous Similarity for
  Distribution Shifts]]></title>
        <id>http://arxiv.org/abs/2304.03440</id>
        <link href="http://arxiv.org/abs/2304.03440"/>
        <updated>2023-04-10T07:13:49.496Z</updated>
        <summary type="html"><![CDATA[Takuro Kutsuna]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Centuries-old Quran being treated in a Taiwan "book hospital"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58393</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58393&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=centuries-old-quran-being-treated-in-a-taiwan-book-hospital"/>
        <updated>2023-04-10T03:42:57.000Z</updated>
        <summary type="html"><![CDATA[Article in Taiwan News (4/9/23): National Taiwan Library repairs 500-year-old Quran'Book Hospital' tasked with repairing ancient Quran damaged by time, elementsBy Sean Scanlan 500-year-old Quran being repaired (CNA photo) The National Taiwan Library accepted a commission to restore a 500-year-old handwritten version of the Quran. The ancient text was given to Tzu Chi Buddhist Humanitarian Foundation Master […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[religions in the classroom]]></title>
        <id>http://xianblog.wordpress.com/?p=52661</id>
        <link href="https://xianblog.wordpress.com/2023/04/10/religions-in-the-classroom/"/>
        <updated>2023-04-09T22:23:36.000Z</updated>
        <summary type="html"><![CDATA[Two recent stories reported in the New York Times about U.S. professors being fired for posting art pieces that students or parents found offensive to their beliefs. One (above) was a painting within a 14th-century Islamic history book supposed to represent G and M. As showed [with much warning] during an art class at Hamline […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Perspective: How to overcome dynamical density functional theory]]></title>
        <id>http://arxiv.org/abs/2301.12156</id>
        <link href="http://arxiv.org/abs/2301.12156"/>
        <updated>2023-04-09T07:12:22.577Z</updated>
        <summary type="html"><![CDATA[Daniel de las Heras, Toni Zimmermann, Florian Samm\"uller, Sophie
  Hermann, Matthias Schmidt]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximating the Prime Counting Function via an Operation on a Unique
  Prime Number Subsequence]]></title>
        <id>http://arxiv.org/abs/2112.08941</id>
        <link href="http://arxiv.org/abs/2112.08941"/>
        <updated>2023-04-09T07:12:22.569Z</updated>
        <summary type="html"><![CDATA[Michael P. May]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Please, please, please, please, please]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58386</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58386&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=please-please-please-please-please"/>
        <updated>2023-04-09T04:36:48.000Z</updated>
        <summary type="html"><![CDATA[The Chinese on the sign says: Wēnxīn tíshì 溫馨提示 ("Gentle Reminder") bǎochí ānjìng 保持安静 ("keep quiet") bǎochí qīngjié 保持清洁 ("keep clean") qǐng wù xīyān 请勿吸烟 ("no smoking") qǐng wù pāishè 请勿拍摄 ("no photos") qǐng wù fǔmō 请勿抚摸 ("don't touch") Such politeness! Selected readings "Beginning of the Semester Blues" (9/5/10) "Gentle reminder for women who approach […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Estimating means of bounded random variables by betting]]></title>
        <id>http://xianblog.wordpress.com/?p=52728</id>
        <link href="https://xianblog.wordpress.com/2023/04/09/estimating-means-of-bounded-random-variables-by-betting/"/>
        <updated>2023-04-08T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Ian Waudby-Smith and Aaditya Ramdas are presenting next month a Read Paper to the Royal Statistical Society in London on constructing a conservative confidence interval on the mean of a bounded random variable. Here is an extended abstract from within the paper: For each m ∈ [0, 1], we set up a “fair” multi-round game […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combinatory Sound Alternations in Proto-, Pre-, and Real Tibetan]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58375</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58375&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=combinatory-sound-alternations-in-proto-pre-and-real-tibetan"/>
        <updated>2023-04-08T12:24:50.000Z</updated>
        <summary type="html"><![CDATA[Sino-Platonic Papers is pleased to announce the publication of its three-hundred-and-thirty-first issue: “Combinatory Sound Alternations in Proto-, Pre-, and Real Tibetan: The Case of the Word Family *Mra(o) ‘Speak,’ ‘Speaker,’ ‘Human,’ ‘Lord’,” by Bettina Zeisler. (free pdf) Among many other terms, discusses the Eurasian word for "horse" often mentioned on Language Log (see "Selected readings" […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[StanCon 2023 [20-23 July 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=52753</id>
        <link href="https://xianblog.wordpress.com/2023/04/08/stancon-2023/"/>
        <updated>2023-04-07T22:23:46.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards ML-enabled cleaning robots]]></title>
        <id>http://ai.googleblog.com/2023/04/towards-ml-enabled-cleaning-robots.html</id>
        <link href="http://ai.googleblog.com/2023/04/towards-ml-enabled-cleaning-robots.html"/>
        <updated>2023-04-07T21:06:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Thomas Lew, Research Intern, and Montserrat Gonzalez Arenas, Research Engineer, Google Research, Brain Team


Over the past several years, the capabilities of robotic systems have improved dramatically. As the technology continues to improve and robotic agents are more routinely deployed in real-world environments, their capacity to assist in day-to-day activities will take on increasing importance. Repetitive tasks like wiping surfaces, folding clothes, and cleaning a room seem well-suited for robots, but remain challenging for robotic systems designed for structured environments like factories. Performing these types of tasks in more complex environments, like offices or homes, requires dealing with greater levels of environmental variability captured by high-dimensional sensor…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Directing ML toward natural hazard mitigation through collaboration]]></title>
        <id>http://ai.googleblog.com/2023/04/directing-ml-toward-natural-hazard.html</id>
        <link href="http://ai.googleblog.com/2023/04/directing-ml-toward-natural-hazard.html"/>
        <updated>2023-04-07T16:09:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Oren Gilon, Software Engineer, and Grey Nearing, Research Scientist, Google Research




Floods are the most common type of natural disaster, affecting more than 250 million people globally each year. As part of Google's Crisis Response and our efforts to address the climate crisis, we are using machine learning (ML) models for Flood Forecasting to alert people in areas that are impacted before disaster strikes.


Collaboration between researchers in the industry and academia is essential for accelerating progress towards mutual goals in ML-related research. Indeed, Google's current ML-based flood forecasting approach was developed in collaboration with researchers (1, 2) at the Johannes Kepler University in Vienna, Austria, the University of Alabama, and the Hebrew University of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantum Kerr Learning]]></title>
        <id>http://arxiv.org/abs/2205.12004</id>
        <link href="http://arxiv.org/abs/2205.12004"/>
        <updated>2023-04-07T07:13:38.602Z</updated>
        <summary type="html"><![CDATA[Junyu Liu, Changchun Zhong, Matthew Otten, Anirban Chandra, Cristian
  L. Cortes, Chaoyang Ti, Stephen K Gray, Xu Han]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2304.02911</id>
        <link href="http://arxiv.org/abs/2304.02911"/>
        <updated>2023-04-07T07:13:38.558Z</updated>
        <summary type="html"><![CDATA[Xuanzhe Xiao, Zeng Li, Chuanlong Xie, Fengwei Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Lipschitz Functions by GD-trained Shallow Overparameterized
  ReLU Neural Networks]]></title>
        <id>http://arxiv.org/abs/2212.13848</id>
        <link href="http://arxiv.org/abs/2212.13848"/>
        <updated>2023-04-07T07:13:38.552Z</updated>
        <summary type="html"><![CDATA[Ilja Kuzborskij, Csaba Szepesv\'ari]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Efficient MCMC Sampling in Bayesian Neural Networks by
  Exploiting Symmetry]]></title>
        <id>http://arxiv.org/abs/2304.02902</id>
        <link href="http://arxiv.org/abs/2304.02902"/>
        <updated>2023-04-07T07:13:37.582Z</updated>
        <summary type="html"><![CDATA[Jonas Gregor Wiese, Lisa Wimmer, Theodore Papamarkou, Bernd Bischl,
  Stephan G\"unnemann, David R\"ugamer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A review of ensemble learning and data augmentation models for class
  imbalanced problems: combination, implementation and evaluation]]></title>
        <id>http://arxiv.org/abs/2304.02858</id>
        <link href="http://arxiv.org/abs/2304.02858"/>
        <updated>2023-04-07T07:13:37.565Z</updated>
        <summary type="html"><![CDATA[Azal Ahmad Khan, Omkar Chaudhari, Rohitash Chandra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Celebrate PyTorch* 2.0 with New Performance Features for AI Developers]]></title>
        <id>https://pytorch.org/blog/celebrate-pytorch-2.0/</id>
        <link href="https://pytorch.org/blog/celebrate-pytorch-2.0/"/>
        <updated>2023-04-07T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Congratulations to the PyTorch Foundation for its release of PyTorch* 2.0! In this blog, I discuss the four features for which Intel made significant contributions to PyTorch 2.0:]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Straggler Mitigation On PyTorch DDP By Hierarchical SGD]]></title>
        <id>https://pytorch.org/blog/straggler-mitigation/</id>
        <link href="https://pytorch.org/blog/straggler-mitigation/"/>
        <updated>2023-04-07T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[PyTorch DDP has been widely adopted across the industry for distributed training, which by default runs synchronous SGD to synchronize gradients across model replicas at every step. The performance of this technique is critical for fast iteration during model exploration as well as resource and cost saving. The performance is critical for fast iteration and cost saving of model development and exploration. To resolve a ubiquitous performance bottleneck introduced by slow nodes in large-scale training, Cruise and Meta co-developed a solution based on the Hierarchical SGD algorithm to significantly accelerate training in the presence of these stragglers.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Polyglot Manchu emperor]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58356</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58356&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=polyglot-manchu-emperor"/>
        <updated>2023-04-07T04:50:28.000Z</updated>
        <summary type="html"><![CDATA[From the British Museum: The Chinese characters say: Měi suìnián bān Ménggǔ, Huí bù, Fān bù děng dào jīng jiējiàn, jí yǐ qí yǔ wèiwèn, wú jí tōngyì. Qiánlóng huángdì yùzhì shī 每歲年班蒙古，回部，番部等到京接見，即以其語慰問，無藉通譯。乾隆皇帝 《御製詩》 We will start with the assumption that the English translation on the wall of the BM is serviceable, but will find, by […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[English for Singapore]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58370</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58370&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=english-for-singapore"/>
        <updated>2023-04-06T23:38:00.000Z</updated>
        <summary type="html"><![CDATA["Majority supports adding English requirement for applicants for Singapore citizenship: poll" Pinyin News (4/6/23) The opposition leader of Singapore, Pritam Singh, said in late February that he supported adding an English test to the requirements for applications for citizenship or permanent residency in Singapore. A recent poll of five hundred Singapore-born citizens found strong popular […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fusing Simulation with Data Science [ CRiSM workshop, 18-9/07/23]]]></title>
        <id>http://xianblog.wordpress.com/?p=52631</id>
        <link href="https://xianblog.wordpress.com/2023/04/07/fusing-simulation-with-data-science-crism-workshop-18-9-07-23/"/>
        <updated>2023-04-06T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Project Starline improves remote communication]]></title>
        <id>http://ai.googleblog.com/2023/04/how-project-starline-improves-remote.html</id>
        <link href="http://ai.googleblog.com/2023/04/how-project-starline-improves-remote.html"/>
        <updated>2023-04-06T19:22:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Greg Blascovich and Eric Gomez, User Researchers, Google




As companies settle into a new normal of hybrid and distributed work, remote communication technology remains critical for connecting and collaborating with colleagues. While this technology has improved, the core user experience often falls short: conversation can feel stilted, attention can be difficult to maintain, and usage can be fatiguing. 





Project Starline renders people at natural scale on a 3D display and enables natural eye contact.

Project Starline, a technology project that combines advances in hardware and software to create a remote communication experience that feels like you’re together, even when you’re thousands of miles apart. This perception of co-presence is created by representing users in 3D…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pre-trained Gaussian processes for Bayesian optimization]]></title>
        <id>http://ai.googleblog.com/2023/04/pre-trained-gaussian-processes-for.html</id>
        <link href="http://ai.googleblog.com/2023/04/pre-trained-gaussian-processes-for.html"/>
        <updated>2023-04-06T17:02:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Zi Wang and Kevin Swersky, Research Scientists, Google Research, Brain Team 





Bayesian optimization (BayesOpt) is a powerful tool widely used for global optimization tasks, such as hyperparameter tuning, protein engineering, synthetic chemistry, robot learning, and even baking cookies. BayesOpt is a great strategy for these problems because they all involve optimizing black-box functions that are expensive to evaluate. A black-box function’s underlying mapping from inputs (configurations of the thing we want to optimize) to outputs (a measure of performance) is unknown. However, we can attempt to understand its internal workings by evaluating the function for different combinations of inputs. Because each evaluation can be computationally expensive, we need to find the best i…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interactive Fleet Learning]]></title>
        <id>http://bair.berkeley.edu/blog/2023/04/06/ifl/</id>
        <link href="http://bair.berkeley.edu/blog/2023/04/06/ifl/"/>
        <updated>2023-04-06T09:00:00.000Z</updated>
        <summary type="html"><![CDATA[Figure 1: “Interactive Fleet Learning” (IFL) refers to robot fleets in industry and academia that fall back on human teleoperators when necessary and continually learn from them over time.


In the last few years we have seen an exciting development in robotics and artificial intelligence: large fleets of robots have left the lab and entered the real world. Waymo, for example, has over 700 self-driving cars operating in Phoenix and San Francisco and is currently expanding to Los Angeles. Other industrial deployments of robot fleets include applications like e-commerce order fulfillment at Amazon and Ambi Robotics as well as food delivery at Nuro and Kiwibot.
Commercial and industrial deployments of robot fleets: package delivery (top left), food delivery (bottom left), e-commerce order ful…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the universal approximation property of radial basis function neural
  networks]]></title>
        <id>http://arxiv.org/abs/2304.02220</id>
        <link href="http://arxiv.org/abs/2304.02220"/>
        <updated>2023-04-06T07:13:33.299Z</updated>
        <summary type="html"><![CDATA[Aysu Ismayilova, Muhammad Ismayilov]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian neural networks via MCMC: a Python-based tutorial]]></title>
        <id>http://arxiv.org/abs/2304.02595</id>
        <link href="http://arxiv.org/abs/2304.02595"/>
        <updated>2023-04-06T07:13:33.294Z</updated>
        <summary type="html"><![CDATA[Rohitash Chandra, Royce Chen, Joshua Simmons]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Algorithm-Dependent Bounds for Representation Learning of Multi-Source
  Domain Adaptation]]></title>
        <id>http://arxiv.org/abs/2304.02064</id>
        <link href="http://arxiv.org/abs/2304.02064"/>
        <updated>2023-04-06T07:13:33.269Z</updated>
        <summary type="html"><![CDATA[Qi Chen, Mario Marchand]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Data Representations with Joint Diffusion Models]]></title>
        <id>http://arxiv.org/abs/2301.13622</id>
        <link href="http://arxiv.org/abs/2301.13622"/>
        <updated>2023-04-06T07:13:33.198Z</updated>
        <summary type="html"><![CDATA[Kamil Deja, Tomasz Trzcinski, Jakub M. Tomczak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized
  Cases]]></title>
        <id>http://arxiv.org/abs/2303.15739</id>
        <link href="http://arxiv.org/abs/2303.15739"/>
        <updated>2023-04-06T07:13:33.192Z</updated>
        <summary type="html"><![CDATA[Shuya Nagayasu, Sumio Watanabe]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mandarin with an English accent]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58368</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58368&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mandarin-with-an-english-accent"/>
        <updated>2023-04-06T01:31:13.000Z</updated>
        <summary type="html"><![CDATA[Something very funny happened to me earlier today, funny enough that I would like to share it with all Language Log readers who may be desirous of something more than a cup of coffee to perk them up on a gray, midweek morning. I entered the following Mandarin expression into Google Translate and wanted to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[[A]ABC in Hawai’i]]></title>
        <id>http://xianblog.wordpress.com/?p=52670</id>
        <link href="https://xianblog.wordpress.com/2023/04/06/aabc-in-hawaii/"/>
        <updated>2023-04-05T22:23:46.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An AI Miracle Malcontent]]></title>
        <id>https://hunch.net/?p=13763005</id>
        <link href="https://hunch.net/?p=13763005"/>
        <updated>2023-04-05T21:44:38.000Z</updated>
        <summary type="html"><![CDATA[The stark success of OpenAI’s GPT4 model surprised me shifting my view from “really good autocomplete” (roughly inline with intuitions here) to a dialog agent exhibiting a significant scope of reasoning and intelligence. Some of the MSR folks did a fairly thorough study of capabilities which seems like a good reference. I think of GPT4 … 
Continue reading "An AI Miracle Malcontent"]]></summary>
        <author>
            <name>John Langford</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An AI Miracle Malcontent]]></title>
        <id>https://hunch.net/?p=13763005</id>
        <link href="https://hunch.net/?p=13763005"/>
        <updated>2023-04-05T21:44:38.000Z</updated>
        <summary type="html"><![CDATA[The stark success of OpenAI’s GPT4 model surprised me shifting my view from “really good autocomplete” (roughly inline with intuitions here) to a dialog agent exhibiting a significant scope of reasoning and intelligence. Some of the MSR folks did a fairly thorough study of capabilities which seems like a good reference. I think of GPT4 … 
Continue reading "An AI Miracle Malcontent"]]></summary>
        <author>
            <name>John Langford</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning-Rate-Free Learning by D-Adaptation]]></title>
        <id>http://arxiv.org/abs/2301.07733</id>
        <link href="http://arxiv.org/abs/2301.07733"/>
        <updated>2023-04-05T07:15:00.853Z</updated>
        <summary type="html"><![CDATA[Aaron Defazio, Konstantin Mishchenko]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Framework and Benchmark for Deep Batch Active Learning for Regression]]></title>
        <id>http://arxiv.org/abs/2203.09410</id>
        <link href="http://arxiv.org/abs/2203.09410"/>
        <updated>2023-04-05T07:15:00.846Z</updated>
        <summary type="html"><![CDATA[David Holzm\"uller, Viktor Zaverkin, Johannes K\"astner, Ingo
  Steinwart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal rates of approximation by shallow ReLU$^k$ neural networks and
  applications to nonparametric regression]]></title>
        <id>http://arxiv.org/abs/2304.01561</id>
        <link href="http://arxiv.org/abs/2304.01561"/>
        <updated>2023-04-05T07:15:00.838Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning and Concentration for High Dimensional Linear Gaussians: an
  Invariant Subspace Approach]]></title>
        <id>http://arxiv.org/abs/2304.01708</id>
        <link href="http://arxiv.org/abs/2304.01708"/>
        <updated>2023-04-05T07:15:00.822Z</updated>
        <summary type="html"><![CDATA[Muhammad Abdullah Naeem]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incorporating Unlabelled Data into Bayesian Neural Networks]]></title>
        <id>http://arxiv.org/abs/2304.01762</id>
        <link href="http://arxiv.org/abs/2304.01762"/>
        <updated>2023-04-05T07:15:00.816Z</updated>
        <summary type="html"><![CDATA[Mrinank Sharma, Tom Rainforth, Yee Whye Teh, Vincent Fortuin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Polars for initial data analysis, Polars for production]]></title>
        <id>https://pythonspeed.com/articles/polars-exploratory-data-analysis-vs-production/</id>
        <link href="https://pythonspeed.com/articles/polars-exploratory-data-analysis-vs-production/"/>
        <updated>2023-04-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Initial data analysis (IDA) has different goals than your final, production data analysis:
With IDA you need to examine the initial data and intermediate results, check your assumptions, and try different approaches.
Exploratory data analysis has similar requirements.
Once you’re happy with your approach, and you’re ready to run the analysis in an automated manner, you care a lot more about speed and resource usage.
These different goals often benefit from different implementation strategies and tools—unless you have a sufficiently flexible tool like Polars, the super-fast dataframe library.
In particular, Polars has two fundamental APIs, each of which is useful in different situations:
“Eager” mode, which is similar to how Pandas works, is well-suited for initial and exploratory data analysis.
For production use, “lazy” mode often execute much faster, with lower memory usage, at the cost of not giving you access to intermediate result.
In this article we’ll use both two APIs and see how Polars lets you transition from looking at the data to something we can run even more efficiently in production.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[common leftovers]]></title>
        <id>http://xianblog.wordpress.com/?p=52527</id>
        <link href="https://xianblog.wordpress.com/2023/04/05/common-leftovers/"/>
        <updated>2023-04-04T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[The Riddler was about a number game, which meant starting a sum at 0 and adding i to the current sum at time i, almost a Fibonacci sequence but not exactly, since the sequence is simply which is easy to code, is of period 200, and this code showed that 3, 28, 53, and 78 […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Topical weather prediction]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58361</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58361&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=topical-weather-prediction"/>
        <updated>2023-04-04T21:03:36.000Z</updated>
        <summary type="html"><![CDATA[Weather outlook: MOSTLY STORMY on Tuesday. 😉 pic.twitter.com/qKcqZa6svL — Jon Cooper (@joncoopertweets) April 3, 2023]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Desultory philological, literary, and historical notes on Xanadu]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58348</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58348&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=desultory-philological-literary-and-historical-notes-on-xanadu"/>
        <updated>2023-04-04T12:46:53.000Z</updated>
        <summary type="html"><![CDATA[Our previous post was on "Hallucinations: In Xanadu did LLMs vainly fancify" (4/3/23).  If you were wondering where such an evocative, exotic name came from, it has a direct lineage back to the Mongol Yuan Dynasty (1271-1368) of China where it was called Shàngdū 上都 ("Upper Capital") in Mandarin, ultimately from early Mandarin ʂaŋ` tū.  […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Fitness Functions for Machine Programming]]></title>
        <id>http://arxiv.org/abs/1908.08783</id>
        <link href="http://arxiv.org/abs/1908.08783"/>
        <updated>2023-04-04T07:13:40.997Z</updated>
        <summary type="html"><![CDATA[Shantanu Mandal, Todd A. Anderson, Javier S. Turek, Justin
  Gottschlich, Shengtian Zhou, Abdullah Muzahid]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modelling customer churn for the retail industry in a deep learning
  based sequential framework]]></title>
        <id>http://arxiv.org/abs/2304.00575</id>
        <link href="http://arxiv.org/abs/2304.00575"/>
        <updated>2023-04-04T07:13:40.990Z</updated>
        <summary type="html"><![CDATA[Juan Pablo Equihua, Henrik Nordmark, Maged Ali, Berthold Lausen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Indeterminate Probability Neural Network]]></title>
        <id>http://arxiv.org/abs/2303.11536</id>
        <link href="http://arxiv.org/abs/2303.11536"/>
        <updated>2023-04-04T07:13:40.985Z</updated>
        <summary type="html"><![CDATA[Tao Yang, Chuang Liu, Xiaofeng Ma, Weijia Lu, Ning Wu, Bingyang Li,
  Zhifei Yang, Peng Liu, Lin Sun, Xiaodong Zhang, Can Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient human-in-loop deep learning model training with iterative
  refinement and statistical result validation]]></title>
        <id>http://arxiv.org/abs/2304.00990</id>
        <link href="http://arxiv.org/abs/2304.00990"/>
        <updated>2023-04-04T07:13:40.978Z</updated>
        <summary type="html"><![CDATA[Manuel Zahn, Douglas P. Perrin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linguistic nationalism news from Ohio, Italy, and California]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58351</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58351&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=linguistic-nationalism-news-from-ohio-italy-and-california"/>
        <updated>2023-04-04T02:43:07.000Z</updated>
        <summary type="html"><![CDATA[Adam Schrader, "Ohio Sen. J.D. Vance introduces bill to make English official U.S. language", UPI 3/30/2023. A press release from Vance's office is here, and here's the text of the bill. "Meloni's party looks to shield Italian language from foreign contamination", Reuters 3/31/2023. Prime Minister Giorgia Meloni's party has proposed imposing fines of up to […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[portrait of the author as a young man [X rated]]]></title>
        <id>http://xianblog.wordpress.com/?p=52454</id>
        <link href="https://xianblog.wordpress.com/2023/04/04/portrait-of-the-author-as-a-young-man-x-ray/"/>
        <updated>2023-04-03T22:23:17.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alef Corner: Deep Learning 2020, 2030, 2040]]></title>
        <id>http://gilkalai.wordpress.com/?p=24111</id>
        <link href="https://gilkalai.wordpress.com/2023/04/03/alef-corner-deep-learning-2020-2030-2040/"/>
        <updated>2023-04-03T20:36:02.000Z</updated>
        <summary type="html"><![CDATA[Deep learning 2020 Deep learning 2030 Deep learning 2040]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alef Corner: Deep Learning 2020, 2030, 2040]]></title>
        <id>http://gilkalai.wordpress.com/?p=24111</id>
        <link href="https://gilkalai.wordpress.com/2023/04/03/alef-corner-deep-learning-2020-2030-2040/"/>
        <updated>2023-04-03T20:36:02.000Z</updated>
        <summary type="html"><![CDATA[Deep learning 2020 Deep learning 2030 Deep learning 2040]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hallucinations:  In Xanadu did LLMs vainly fancify]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58338</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58338&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hallucinations-in-xanadu-did-llms-vainly-fancify"/>
        <updated>2023-04-03T15:55:16.000Z</updated>
        <summary type="html"><![CDATA[Bill Benzon has been our most prolific humanistic commentator about GPTs, almost as prolific as GPTs themselves.  Here he introduces his latest creation in / on the genre: "From 'Kubla Khan' through GPT and beyond", 3 Quarks Daily (3/27/23) In a covering note to me, Bill writes: A story about how I came to be […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Koala: A Dialogue Model for Academic Research]]></title>
        <id>http://bair.berkeley.edu/blog/2023/04/03/koala/</id>
        <link href="http://bair.berkeley.edu/blog/2023/04/03/koala/"/>
        <updated>2023-04-03T14:30:00.000Z</updated>
        <summary type="html"><![CDATA[In this post, we introduce Koala, a chatbot trained by fine-tuning Meta’s LLaMA on dialogue data gathered from the web. We describe the dataset curation and training process of our model, and also present the results of a user study that compares our model to ChatGPT and Stanford’s Alpaca. Our results show that Koala can effectively respond to a variety of user queries, generating responses that are often preferred over Alpaca, and at least tied with ChatGPT in over half of the cases.
We hope that these results contribute further to the discourse around the relative performance of large closed-source models to smaller public models. In particular, it suggests that models that are small enough to be run locally can capture much of the performance of their larger cousins if trained on carefu…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bias项的神奇作用：RoPE + Bias = 更好的长度外推性]]></title>
        <id>https://kexue.fm/archives/9577</id>
        <link href="https://kexue.fm/archives/9577"/>
        <updated>2023-04-03T12:56:00.000Z</updated>
        <summary type="html"><![CDATA[万万没想到，Bias项能跟Transformer的长度外推性联系在一起！长度外推性是我们希望Transformer具有的一个理想性质，笔者曾在《Transformer升级之路：7、长度外推性与局...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An interpretable neural network-based non-proportional odds model for
  ordinal regression with continuous response]]></title>
        <id>http://arxiv.org/abs/2303.17823</id>
        <link href="http://arxiv.org/abs/2303.17823"/>
        <updated>2023-04-03T08:19:34.861Z</updated>
        <summary type="html"><![CDATA[Akifumi Okuno, Kazuharu Harada]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Estimators Show Information Compression in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/1902.09037</id>
        <link href="http://arxiv.org/abs/1902.09037"/>
        <updated>2023-04-03T07:14:03.000Z</updated>
        <summary type="html"><![CDATA[Ivan Chelombiev, Conor Houghton, Cian O'Donnell]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rapid prediction of lab-grown tissue properties using deep learning]]></title>
        <id>http://arxiv.org/abs/2303.18017</id>
        <link href="http://arxiv.org/abs/2303.18017"/>
        <updated>2023-04-03T07:14:02.992Z</updated>
        <summary type="html"><![CDATA[Allison E. Andrews, Hugh Dickinson, James P. Hague]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near-Optimal Learning of Extensive-Form Games with Imperfect Information]]></title>
        <id>http://arxiv.org/abs/2202.01752</id>
        <link href="http://arxiv.org/abs/2202.01752"/>
        <updated>2023-04-03T07:14:02.958Z</updated>
        <summary type="html"><![CDATA[Yu Bai, Chi Jin, Song Mei, Tiancheng Yu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Kernel Approach for PDE Discovery and Operator Learning]]></title>
        <id>http://arxiv.org/abs/2210.08140</id>
        <link href="http://arxiv.org/abs/2210.08140"/>
        <updated>2023-04-03T07:14:02.939Z</updated>
        <summary type="html"><![CDATA[Da Long, Nicole Mrvaljevic, Shandian Zhe, Bamdad Hosseini]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch &amp; OpenXLA: The Path Forward]]></title>
        <id>https://pytorch.org/blog/pytorch-2.0-xla-path-forward/</id>
        <link href="https://pytorch.org/blog/pytorch-2.0-xla-path-forward/"/>
        <updated>2023-04-03T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[As we celebrate the release of OpenXLA, PyTorch 2.0, and PyTorch/XLA 2.0, it’s worth taking a step back and sharing where we see it all going in the short to medium term. With PyTorch adoption leading in the AI space and XLA supporting best-in-class compiler features, PyTorch/XLA is well positioned to provide a cutting edge development stack for both model training and inference. To achieve this, we see investments in three main areas:]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lapparadish]]></title>
        <id>http://xianblog.wordpress.com/?p=52618</id>
        <link href="https://xianblog.wordpress.com/2023/04/03/lapparadish/"/>
        <updated>2023-04-02T22:23:08.000Z</updated>
        <summary type="html"><![CDATA[On top of BayesComp 2023 being rich and exciting, spending a week above the Arctic circle, by about 68⁰ North was most pleasurable. If we did not really see Northern Lights/auroras, as the above was taken by one of us with a long exposure shot on a particularly cold evening, rather than the diaphanous veils […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Invented Chinese name of an LA lawyer]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58318</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58318&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=invented-chinese-name-of-an-la-lawyer"/>
        <updated>2023-04-02T13:31:03.000Z</updated>
        <summary type="html"><![CDATA[Around 60% of the people living in the San Gabriel area are Asians, and the largest proportion among them are Chinese.  To attract the business of the local population, attorney Scott Warmuth decided to put up Chinese billboards in Monterey Park about a decade ago.  How it happened is described in this article: "Column: Racial […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thrilling linguistics?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58333</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58333&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=thrilling-linguistics"/>
        <updated>2023-04-02T13:16:40.000Z</updated>
        <summary type="html"><![CDATA[A recent linguistic message from Dinosaur Comics: The first five panels have a clear socio- and psycholinguistic message: T-Rex: Gasp! I should use the word "frisson" more often! There's been so many OPPORTUNITIES to use the word, Dromiceiomimus, but I let them all pass me by because I say "thrill" instead. But wouldn't I seem […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Monte Carlo swindles]]></title>
        <id>http://xianblog.wordpress.com/?p=52480</id>
        <link href="https://xianblog.wordpress.com/2023/04/02/monte-carlo-swindles/"/>
        <updated>2023-04-01T22:23:23.000Z</updated>
        <summary type="html"><![CDATA[While reading Boos and Hugues-Olivier’s 1998 American Statistician paper on the applications of Basu’s theorem I can across the notion of Monte Carlo swindles. Where a reduced variance can be achieved without the corresponding increase in Monte Carlo budget. For instance, approximating the variance of the median statistic Μ for a Normal location family can […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Literally CVS"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58320</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58320&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=literally-cvs"/>
        <updated>2023-04-01T12:27:15.000Z</updated>
        <summary type="html"><![CDATA[In at least two recent interviews, Eric Trump has objected to his father's recent indictment by complaining about the lack of prosecutorial attention to the factors leading NYC drugstores (he says) to lock up Tylenol and Advil. On Fox News: Your browser does not support the audio element. And this is a city — I […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We’re Knot Friends]]></title>
        <id>https://jeremykun.com/?p=119235</id>
        <link href="https://jeremykun.com/2023/04/01/were-knot-friends/"/>
        <updated>2023-04-01T12:00:00.000Z</updated>
        <summary type="html"><![CDATA[It’s April Cools again. For a few summers in high school and undergrad, I was a day camp counselor. I’ve written before about how it helped me develop storytelling skills, but recently I thought of it again because, while I was cleaning out a closet full of old junk, I happened upon a bag of […]]]></summary>
        <author>
            <name>j2kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Three negations in one headline]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58307</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58307&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=three-negations-in-one-headline"/>
        <updated>2023-04-01T10:45:59.000Z</updated>
        <summary type="html"><![CDATA[From François-Michel Lang, "I had to read the article to be sure I understood what exactly had happened!"   G.O.P. Lawmakers Override Kentucky Governor’s Veto on Anti-Trans Law   The Kentucky measure bans access to gender-transition care for young people, and West Virginia’s governor signed a similar bill on Wednesday. Passage of bans also appears […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[统计月读（2023 年 3 月）]]></title>
        <id>https://cosx.org/2023/04/monthly/</id>
        <link href="https://cosx.org/2023/04/monthly/"/>
        <updated>2023-04-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[推荐语：想要把ChatGPT转化成实在的生产力吗？这个包把ChatGPT的一些功能嵌入到RStudio内，通过Add-In栏的按钮即可使用。]]></summary>
        <author>
            <name>统计之都</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChomGTPT]]></title>
        <id>http://xianblog.wordpress.com/?p=52533</id>
        <link href="https://xianblog.wordpress.com/2023/04/01/chomgtpt/"/>
        <updated>2023-03-31T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[I got pointed out at an interesting NTY editorial of March 8, 2023, on ChatGPT written by Noam Chomsky, Ian Roberts and Jeffrey Watumull. “we fear that the most popular and fashionable strain of A.I. — machine learning — will degrade [linguistics] and debase our ethics by incorporating into our technology a fundamentally flawed conception […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scaling vision transformers to 22 billion parameters]]></title>
        <id>http://ai.googleblog.com/2023/03/scaling-vision-transformers-to-22.html</id>
        <link href="http://ai.googleblog.com/2023/03/scaling-vision-transformers-to-22.html"/>
        <updated>2023-03-31T20:48:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Piotr Padlewski and Josip Djolonga, Software Engineers, Google Research




Large Language Models (LLMs) like PaLM or GPT-3 showed that scaling transformers to hundreds of billions of parameters improves performance and unlocks emergent abilities. The biggest dense models for image understanding, however, have reached only 4 billion parameters, despite research indicating that promising multimodal models like PaLI continue to benefit from scaling vision models alongside their language counterparts. Motivated by this, and the results from scaling LLMs, we decided to undertake the next step in the journey of scaling the Vision Transformer.
 

In “Scaling Vision Transformers to 22 Billion Parameters”, we introduce the biggest dense vision model, ViT-22B. It is 5.5x larger than the p…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["An exercise in inference sabotage"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58310</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58310&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=an-exercise-in-inference-sabotage"/>
        <updated>2023-03-31T14:42:16.000Z</updated>
        <summary type="html"><![CDATA[Eve Armstrong, "I Murdered Conan O'Brien and Nobody Will Ever Know — an exercise in inference sabotage", 3/30/2023: Abstract: I employ an optimization-based inference methodology together with an Ising model, in an intentionally ineffectual manner, to get away with murdering an obstreperous scientific collaborator. The antics of this collaborator, hereafter "Conan O'Brien," were impeding the […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sebastien Bubeck - First Contact]]></title>
        <id>https://mlfoundations.org/talk/bubeck/</id>
        <link href="https://mlfoundations.org/talk/bubeck/"/>
        <updated>2023-03-31T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[The new wave of AI systems, ChatGPT and its more powerful successors, exhibit extraordinary capabilities across a broad swath of domains. In light of this, we will discuss whether artificial INTELLIGENCE has arrived.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kong Yiji ("Confucius ABC"), another self-deprecating meme for young Chinese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58301</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58301&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=kong-yiji-confucius-abc-another-self-deprecating-meme-for-young-chinese"/>
        <updated>2023-03-31T12:11:39.000Z</updated>
        <summary type="html"><![CDATA["Kong Yiji" is one of the most famous short stories by Lu Xun (1881-1936), the most celebrated Chinese author of the 20th century. "Kong Yiji" (Chinese: 孔乙己; pinyin: Kǒng Yǐjǐ) is a short-story by Lu Xun, the founder of modern Chinese literature. The story was originally published in the journal New Youth (Chinese: 新青年) in […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leveraging joint sparsity in hierarchical Bayesian learning]]></title>
        <id>http://arxiv.org/abs/2303.16954</id>
        <link href="http://arxiv.org/abs/2303.16954"/>
        <updated>2023-03-31T07:14:28.406Z</updated>
        <summary type="html"><![CDATA[Jan Glaubitz, Anne Gelb]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal training of integer-valued neural networks with mixed integer
  programming]]></title>
        <id>http://arxiv.org/abs/2009.03825</id>
        <link href="http://arxiv.org/abs/2009.03825"/>
        <updated>2023-03-31T07:14:28.391Z</updated>
        <summary type="html"><![CDATA[T\'omas Thorbjarnarson, Neil Yorke-Smith]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Are Neural Architecture Search Benchmarks Well Designed? A Deeper Look
  Into Operation Importance]]></title>
        <id>http://arxiv.org/abs/2303.16938</id>
        <link href="http://arxiv.org/abs/2303.16938"/>
        <updated>2023-03-31T07:14:27.531Z</updated>
        <summary type="html"><![CDATA[Vasco Lopes, Bruno Degardin, Lu\'is A. Alexandre]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training Neural Networks is NP-Hard in Fixed Dimension]]></title>
        <id>http://arxiv.org/abs/2303.17045</id>
        <link href="http://arxiv.org/abs/2303.17045"/>
        <updated>2023-03-31T07:14:27.506Z</updated>
        <summary type="html"><![CDATA[Vincent Froese, Christoph Hertrich]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation bounds for norm constrained neural networks with
  applications to regression and GANs]]></title>
        <id>http://arxiv.org/abs/2201.09418</id>
        <link href="http://arxiv.org/abs/2201.09418"/>
        <updated>2023-03-31T07:14:27.499Z</updated>
        <summary type="html"><![CDATA[Yuling Jiao, Yang Wang, Yunfei Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Staying secure by breaking Docker caching]]></title>
        <id>https://pythonspeed.com/articles/disabling-docker-caching/</id>
        <link href="https://pythonspeed.com/articles/disabling-docker-caching/"/>
        <updated>2023-03-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[When building Docker images, caching lets you speed up rebuilding images.
But this has a downside: it can keep you from installing security updates from your base Linux distribution.
If you cache the image layer that includes the security update… you’re not getting new security updates!
There are a number of ways you can try to balance caching with getting security updates, with different tradeoffs.
In this article we’ll cover:
Caching by default, with recurring rebuild and redeploys.
Deliberately breaking caching.
Caching during development, never caching in production builds.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Number savvy [book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=52383</id>
        <link href="https://xianblog.wordpress.com/2023/03/31/number-savvy-book-review/"/>
        <updated>2023-03-30T22:23:15.000Z</updated>
        <summary type="html"><![CDATA[“This book aspires to contribute to overall numeracy through a tour de force presentation of the production, use, and evolution of data.” Number Savvy: From the Invention of Numbers to the Future of Data is written by George Sciadas, a  statistician working at Statistics Canada. This book is mostly about data, even though it starts […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data-centric ML benchmarking: Announcing DataPerf’s 2023 challenges]]></title>
        <id>http://ai.googleblog.com/2023/03/data-centric-ml-benchmarking-announcing.html</id>
        <link href="http://ai.googleblog.com/2023/03/data-centric-ml-benchmarking-announcing.html"/>
        <updated>2023-03-30T17:05:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Peter Mattson, Senior Staff Engineer, ML Performance, and Praveen Paritosh, Senior Research Scientist, Google Research, Brain Team  
Machine learning (ML) offers tremendous potential, from diagnosing cancer to engineering safe self-driving cars to amplifying human productivity. To realize this potential, however, organizations need ML solutions to be reliable with ML solution development that is predictable and tractable. The key to both is a deeper understanding of ML data — how to engineer training datasets that produce high quality models and test datasets that deliver accurate indicators of how close we are to solving the target problem.  

The process of creating high quality datasets is complicated and error-prone, from the initial selection and cleaning of raw data, to lab…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TCS for all travel grants and speaker nominations (guest post by Elena Grigorescu)]]></title>
        <id>http://windowsontheory.org/?p=8588</id>
        <link href="https://windowsontheory.org/2023/03/30/tcs-for-all-travel-grants-and-speaker-nominations-guest-post-by-elena-grigorescu/"/>
        <updated>2023-03-30T13:10:38.000Z</updated>
        <summary type="html"><![CDATA[TCS for All (previously TCS Women) Spotlight Workshop at STOC 2023/Theory Fest: Travel grants and call for speaker nominations You are cordially invited to our TCS for All Spotlight Workshop! The workshop will be held on Thursday, June 22nd, 2023 (2-4pm), in Orlando, Florida, USA, as part of the 54th Symposium on Theory of Computing (STOC) and TheoryFest! The workshop … Continue reading TCS for all travel grants and speaker nominations (guest post by Elena Grigorescu)]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TCS for all travel grants and speaker nominations (guest post by Elena Grigorescu)]]></title>
        <id>http://windowsontheory.org/?p=8588</id>
        <link href="https://windowsontheory.org/2023/03/30/tcs-for-all-travel-grants-and-speaker-nominations-guest-post-by-elena-grigorescu/"/>
        <updated>2023-03-30T13:10:38.000Z</updated>
        <summary type="html"><![CDATA[TCS for All (previously TCS Women) Spotlight Workshop at STOC 2023/Theory Fest: Travel grants and call for speaker nominations You are cordially invited to our TCS for All Spotlight Workshop! The workshop will be held on Thursday, June 22nd, 2023 (2-4pm), in Orlando, Florida, USA, as part of the 54th Symposium on Theory of Computing (STOC) and TheoryFest! The workshop … Continue reading TCS for all travel grants and speaker nominations (guest post by Elena Grigorescu)]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Day in the Life of Ancient China (in Japanese)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58289</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58289&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-day-in-the-life-of-ancient-china-in-japanese"/>
        <updated>2023-03-30T12:04:05.000Z</updated>
        <summary type="html"><![CDATA[In November, 2021, a small paperback published in Japan was selling well and causing a buzz among the twitterati. Here's the listing on Amazon (note the cover illustration).  The author acknowledges that he followed the style of (the Japanese translation of) A Day in the Life of Ancient Rome by Italian paleontologist, writer, and journalist, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Autoregressive Models, OOD prompts and the Interpolation Regime]]></title>
        <id>64230e9f8c9ebb003c71c8d7</id>
        <link href="https://www.inference.vc/autoregressive-models-in-out-of-distribution/"/>
        <updated>2023-03-30T11:54:26.000Z</updated>
        <summary type="html"><![CDATA[A few years ago I was very much into maximum likelihood-based generative modeling and autoregressive models (see this, this or this). More recently, my focus shifted to characterising inductive biases of gradient-based optimization focussing mostly on supervised learning. I only very recently started revisiting autoregressive models, motivated by a desire]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal approximation of $C^k$-functions using shallow complex-valued
  neural networks]]></title>
        <id>http://arxiv.org/abs/2303.16813</id>
        <link href="http://arxiv.org/abs/2303.16813"/>
        <updated>2023-03-30T07:14:35.526Z</updated>
        <summary type="html"><![CDATA[Paul Geuchen, Felix Voigtlaender]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Byzantine-Resilient Aggregation Scheme for Federated Learning via
  Matrix Autoregression on Client Updates]]></title>
        <id>http://arxiv.org/abs/2303.16668</id>
        <link href="http://arxiv.org/abs/2303.16668"/>
        <updated>2023-03-30T07:14:35.476Z</updated>
        <summary type="html"><![CDATA[Gabriele Tolomei, Edoardo Gabrielli, Dimitri Belli, Vittorio
  Miori]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interpolating Discriminant Functions in High-Dimensional Gaussian Latent
  Mixtures]]></title>
        <id>http://arxiv.org/abs/2210.14347</id>
        <link href="http://arxiv.org/abs/2210.14347"/>
        <updated>2023-03-30T07:14:35.468Z</updated>
        <summary type="html"><![CDATA[Xin Bing, Marten Wegkamp]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PAC-Bayesian bounds for learning LTI-ss systems with input from
  empirical loss]]></title>
        <id>http://arxiv.org/abs/2303.16816</id>
        <link href="http://arxiv.org/abs/2303.16816"/>
        <updated>2023-03-30T07:14:35.065Z</updated>
        <summary type="html"><![CDATA[Deividas Eringis, John Leth, Zheng-Hua Tan, Rafael Wisniewski, Mihaly
  Petreczky]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nonlinear Independent Component Analysis for Principled Disentanglement
  in Unsupervised Deep Learning]]></title>
        <id>http://arxiv.org/abs/2303.16535</id>
        <link href="http://arxiv.org/abs/2303.16535"/>
        <updated>2023-03-30T07:14:35.059Z</updated>
        <summary type="html"><![CDATA[Aapo Hyvarinen, Ilyes Khemakhem, Hiroshi Morioka]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[même pas peur [not afrAId]]]></title>
        <id>http://xianblog.wordpress.com/?p=52702</id>
        <link href="https://xianblog.wordpress.com/2023/03/30/meme-pas-peur-not-afraid/"/>
        <updated>2023-03-29T22:23:21.000Z</updated>
        <summary type="html"><![CDATA[Both the Beeb and The New York Times are posting tonight about a call to pause AI experiments, by AI researchers and others, due to the danger they could pose to humanity. While this reminds me of Superintelligence, a book by Nick Bostrom I found rather unconvincing, and although I agree that automated help-to-decision systems […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Review of Yoshida Yutaka's Lectures on Sogdian Grammar]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58281</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58281&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=review-of-yoshida-yutakas-lectures-on-sogdian-grammar"/>
        <updated>2023-03-29T11:38:00.000Z</updated>
        <summary type="html"><![CDATA[Despite its being a Middle Iranian language that has been extinct for a millennium, we've often mentioned Sogdian on Language Log.  That's because of its intrinsic linguistic interest, but also because its speakers, as I have often said, were Eurasian Kulturvermittlers par excellence and outstanding socioeconomic entrepreneurs. Now we have a comprehensive, reliable grammar of […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mathematical Challenges in Deep Learning]]></title>
        <id>http://arxiv.org/abs/2303.15464</id>
        <link href="http://arxiv.org/abs/2303.15464"/>
        <updated>2023-03-29T07:14:56.860Z</updated>
        <summary type="html"><![CDATA[Vahid Partovi Nia, Guojun Zhang, Ivan Kobyzev, Michael R. Metel,
  Xinlin Li, Ke Sun, Sobhan Hemati, Masoud Asgharian, Linglong Kong, Wulong
  Liu, Boxing Chen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization and Stability of Interpolating Neural Networks with
  Minimal Width]]></title>
        <id>http://arxiv.org/abs/2302.09235</id>
        <link href="http://arxiv.org/abs/2302.09235"/>
        <updated>2023-03-29T07:14:56.854Z</updated>
        <summary type="html"><![CDATA[Hossein Taheri, Christos Thrampoulidis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Rate Schedules in the Presence of Distribution Shift]]></title>
        <id>http://arxiv.org/abs/2303.15634</id>
        <link href="http://arxiv.org/abs/2303.15634"/>
        <updated>2023-03-29T07:14:56.838Z</updated>
        <summary type="html"><![CDATA[Matthew Fahrbach, Adel Javanmard, Vahab Mirrokni, Pratik Worah]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Statistical Model for Predicting Generalization in Few-Shot
  Classification]]></title>
        <id>http://arxiv.org/abs/2212.06461</id>
        <link href="http://arxiv.org/abs/2212.06461"/>
        <updated>2023-03-29T07:14:56.832Z</updated>
        <summary type="html"><![CDATA[Yassir Bendou, Vincent Gripon, Bastien Pasdeloup, Lukas Mauch, Stefan
  Uhlich, Fabien Cardinaux, Ghouthi Boukli Hacene, Javier Alonso Garcia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complementary Domain Adaptation and Generalization for Unsupervised
  Continual Domain Shift Learning]]></title>
        <id>http://arxiv.org/abs/2303.15833</id>
        <link href="http://arxiv.org/abs/2303.15833"/>
        <updated>2023-03-29T07:14:56.826Z</updated>
        <summary type="html"><![CDATA[Wonguk Cho, Jinha Park, Taesup Kim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Experience the power of PyTorch 2.0 on AMD Solutions]]></title>
        <id>https://pytorch.org/blog/experience-power/</id>
        <link href="https://pytorch.org/blog/experience-power/"/>
        <updated>2023-03-29T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[PyTorch 2.0 represents a significant step forward for the PyTorch machine learning framework. The stable release of PyTorch 2.0 brings new features that unlock even higher performance, while remaining backward compatible with prior releases and retaining the Pythonic focus which has helped to make PyTorch so enthusiastically adopted by the AI/ML community. AMD has long been a strong proponent of PyTorch, and we are delighted that PyTorch 2.0 stable release includes support for AMD Instinct™ and Radeon™ GPUs that are supported by the ROCm™ software platform.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian inference: challenges, perspectives, and prospects]]></title>
        <id>http://xianblog.wordpress.com/?p=52686</id>
        <link href="https://xianblog.wordpress.com/2023/03/29/bayesian-inference-challenges-perspectives-and-prospects/"/>
        <updated>2023-03-28T22:23:15.000Z</updated>
        <summary type="html"><![CDATA[Over the past year, Judith, Michael and I edited a special issue of Philosophical Transactions of the Royal Society on Bayesian inference: challenges, perspectives, and prospects, in celebration of the current President of the Royal Society, Adrian Smith, and his contributions to Bayesian analysis that have impacted the field up to this day. The issue […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leveraging transfer learning for large scale differentially private image classification]]></title>
        <id>http://ai.googleblog.com/2023/03/leveraging-transfer-learning-for-large.html</id>
        <link href="http://ai.googleblog.com/2023/03/leveraging-transfer-learning-for-large.html"/>
        <updated>2023-03-28T18:26:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Harsh Mehta, Software Engineer, and Walid Krichene, Research Scientist, Google Research  
Large deep learning models are becoming the workhorse of a variety of critical machine learning (ML) tasks. However, it has been shown that without any protection it is plausible for bad actors to attack a variety of models, across modalities, to reveal information from individual training examples. As such, it’s essential to protect against this sort of information leakage. 

Differential privacy (DP) provides formal protection against an attacker who aims to extract information about the training data. The most popular method for DP training in deep learning is differentially private stochastic gradient descent (DP-SGD). The core recipe implements a common theme in DP: “fuzzing” an algorit…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google新作试图“复活”RNN：RNN能否再次辉煌？]]></title>
        <id>https://kexue.fm/archives/9554</id>
        <link href="https://kexue.fm/archives/9554"/>
        <updated>2023-03-28T12:44:00.000Z</updated>
        <summary type="html"><![CDATA[当前，像ChatGPT之类的LLM可谓是“风靡全球”。有读者留意到，几乎所有LLM都还是用最初的Multi-Head Scaled-Dot Attention，近年来大量的Efficient工作...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PIE Day]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58286</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58286&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pie-day"/>
        <updated>2023-03-28T11:19:35.000Z</updated>
        <summary type="html"><![CDATA[Today SMBC: Mouseover title: "If anyone does this, please pour out a glass of eggnog antecedent beverage for me." The aftercomic:]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Port-metriplectic neural networks: thermodynamics-informed machine
  learning of complex physical systems]]></title>
        <id>http://arxiv.org/abs/2211.01873</id>
        <link href="http://arxiv.org/abs/2211.01873"/>
        <updated>2023-03-28T09:16:40.364Z</updated>
        <summary type="html"><![CDATA[Quercus Hern\'andez, Alberto Bad\'ias, Francisco Chinesta, El\'ias
  Cueto]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identification of Negative Transfers in Multitask Learning Using
  Surrogate Models]]></title>
        <id>http://arxiv.org/abs/2303.14582</id>
        <link href="http://arxiv.org/abs/2303.14582"/>
        <updated>2023-03-28T09:16:40.356Z</updated>
        <summary type="html"><![CDATA[Dongyue Li, Huy L. Nguyen, Hongyang R. Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring Continual Learning of Diffusion Models]]></title>
        <id>http://arxiv.org/abs/2303.15342</id>
        <link href="http://arxiv.org/abs/2303.15342"/>
        <updated>2023-03-28T09:16:40.349Z</updated>
        <summary type="html"><![CDATA[Micha{\l} Zaj\k{a}c, Kamil Deja, Anna Kuzina, Jakub M. Tomczak, Tomasz
  Trzci\'nski, Florian Shkurti, Piotr Mi{\l}o\'s]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Information-Theoretic Framework for Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2203.00246</id>
        <link href="http://arxiv.org/abs/2203.00246"/>
        <updated>2023-03-28T09:16:40.340Z</updated>
        <summary type="html"><![CDATA[Hong Jun Jeon, Yifan Zhu, Benjamin Van Roy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning with Explanation Constraints]]></title>
        <id>http://arxiv.org/abs/2303.14496</id>
        <link href="http://arxiv.org/abs/2303.14496"/>
        <updated>2023-03-28T09:16:40.332Z</updated>
        <summary type="html"><![CDATA[Rattana Pukdee, Dylan Sam, J. Zico Kolter, Maria-Florina Balcan,
  Pradeep Ravikumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some Problems]]></title>
        <id>http://gilkalai.wordpress.com/?p=23906</id>
        <link href="https://gilkalai.wordpress.com/2023/03/28/some-problems/"/>
        <updated>2023-03-28T08:24:43.000Z</updated>
        <summary type="html"><![CDATA[In the previous post, Two Three Four posts ago I wrote about three recent breakthroughs in combinatorics and here I want to mention some problems that I posed over the years that are loosely related to these advances. Rank of … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some Problems]]></title>
        <id>http://gilkalai.wordpress.com/?p=23906</id>
        <link href="https://gilkalai.wordpress.com/2023/03/28/some-problems/"/>
        <updated>2023-03-28T08:24:43.000Z</updated>
        <summary type="html"><![CDATA[In the previous post, Two Three Four posts ago I wrote about three recent breakthroughs in combinatorics and here I want to mention some problems that I posed over the years that are loosely related to these advances. Rank of … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bao: Learning to Steer Query Optimizers]]></title>
        <id>http://arxiv.org/abs/2004.03814</id>
        <link href="http://arxiv.org/abs/2004.03814"/>
        <updated>2023-03-28T07:15:05.408Z</updated>
        <summary type="html"><![CDATA[Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad
  Alizadeh, Tim Kraska]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differential forms, Fukaya $A_\infty$ algebras, and Gromov-Witten axioms]]></title>
        <id>http://arxiv.org/abs/1608.01304</id>
        <link href="http://arxiv.org/abs/1608.01304"/>
        <updated>2023-03-28T07:15:05.401Z</updated>
        <summary type="html"><![CDATA[Jake P. Solomon, Sara B. Tukachinsky]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Orbit closures of unipotent flows for hyperbolic manifolds with Fuchsian
  ends]]></title>
        <id>http://arxiv.org/abs/1902.06621</id>
        <link href="http://arxiv.org/abs/1902.06621"/>
        <updated>2023-03-28T07:15:05.381Z</updated>
        <summary type="html"><![CDATA[Minju Lee, Hee Oh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalized domination structure in cubic graphs]]></title>
        <id>http://arxiv.org/abs/1901.10781</id>
        <link href="http://arxiv.org/abs/1901.10781"/>
        <updated>2023-03-28T07:15:05.375Z</updated>
        <summary type="html"><![CDATA[Misa Nakanishi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learned Garbage Collection]]></title>
        <id>http://arxiv.org/abs/2004.13301</id>
        <link href="http://arxiv.org/abs/2004.13301"/>
        <updated>2023-03-28T07:15:05.338Z</updated>
        <summary type="html"><![CDATA[Lujing Cen, Ryan Marcus, Hongzi Mao, Justin Gottschlich, Mohammad
  Alizadeh, Tim Kraska]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerated PyTorch 2 Transformers]]></title>
        <id>https://pytorch.org/blog/accelerated-pytorch-2/</id>
        <link href="https://pytorch.org/blog/accelerated-pytorch-2/"/>
        <updated>2023-03-28T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[The PyTorch 2.0 release includes a new high-performance implementation of the PyTorch Transformer API with the goal of making training and deployment of state-of-the-art Transformer models affordable. Following the successful release of “fastpath” inference execution (“Better Transformer”), this release introduces high-performance support for training and inference using a custom kernel architecture for scaled dot product attention (SPDA).]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Egregious errors]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58271</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58271&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=egregious-errors"/>
        <updated>2023-03-28T04:54:33.000Z</updated>
        <summary type="html"><![CDATA[From Taiwan News (3/25/23), by Keoni Everington: "Taiwanese 'Hello Kitty' English-Chinese dictionary has 70 'egregious errors' Publisher ACME Cultural Enterprise Co has admitted errors but not recalled dictionaries" Cover of dictionary, example of misspelling. (Eryk Smith photo) The article presents photographic evidence of such errors, such as ncluding mis-spelling rice as "rest", and many typos, wrong parts of […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[brave new worlds]]></title>
        <id>http://xianblog.wordpress.com/?p=52473</id>
        <link href="https://xianblog.wordpress.com/2023/03/28/brave-new-worlds/"/>
        <updated>2023-03-27T22:23:14.000Z</updated>
        <summary type="html"><![CDATA[The 23 Feb issue of Nature has several “political” articles, if not the title, which refers to the James Webb space telescope bringing in a wealth of information on exoplanets (through five Nature papers!). Beyond the usual editorial (on the need to help rebuilding Ukraine’s research infrastructure as an introduction to the main article on […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PRESTO – A multilingual dataset for parsing realistic task-oriented dialogues]]></title>
        <id>http://ai.googleblog.com/2023/03/presto-multilingual-dataset-for-parsing.html</id>
        <link href="http://ai.googleblog.com/2023/03/presto-multilingual-dataset-for-parsing.html"/>
        <updated>2023-03-27T17:02:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Rahul Goel and Aditya Gupta, Software Engineers, Google Assistant  
Virtual assistants are increasingly integrated into our daily routines. They can help with everything from setting alarms to giving map directions and can even assist people with disabilities to more easily manage their homes. As we use these assistants, we are also becoming more accustomed to using natural language to accomplish tasks that we once did by hand.  
   
One of the biggest challenges in building a robust virtual assistant is identifying what a user wants and what information is needed to perform the task at hand. In the natural language processing (NLP) literature, this is mainly framed as a task-oriented dialogue parsing task, where a given dialogue needs to be parsed by a system to understand the u…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The historical vagaries of a Shanghai temple and town name:  Lu Ji and the "Wenfu" ("Rhapsody on literature")]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58278</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58278&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-historical-vagaries-of-a-shanghai-temple-and-town-name-lu-ji-and-the-wenfu-rhapsody-on-literature"/>
        <updated>2023-03-27T13:35:02.000Z</updated>
        <summary type="html"><![CDATA[From Rostislav Berezkin, who teaches at Fudan University: The place where I stay is called Qibao town, now Minhang district of Shanghai. The name means "Seven Treasures". It comes from the name of the Buddhist temple called Qibaosi. Legend says that the temple was built by the Lu family to commemorate Lu Ji* and Lu […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[“国产类 ChatGPT ”所存在的差距与挑战-专家圆桌]]></title>
        <id>https://www.52nlp.cn/?p=13435</id>
        <link href="https://www.52nlp.cn/%e5%9b%bd%e4%ba%a7%e7%b1%bb-chatgpt-%e6%89%80%e5%ad%98%e5%9c%a8%e7%9a%84%e5%b7%ae%e8%b7%9d%e4%b8%8e%e6%8c%91%e6%88%98-%e4%b8%93%e5%ae%b6%e5%9c%86%e6%a1%8c"/>
        <updated>2023-03-27T11:02:27.000Z</updated>
        <summary type="html"><![CDATA[内容来源：ChatGPT 及大模型专题研讨会  转载自CSDN稿件 在经历寒冬、雾霾，甚至大家纷纷看 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Critical Times in Israel: Last Night’s Demonstrations]]></title>
        <id>http://gilkalai.wordpress.com/?p=24065</id>
        <link href="https://gilkalai.wordpress.com/2023/03/27/critical-times-in-israel-last-nights-demonstrations/"/>
        <updated>2023-03-27T06:54:21.000Z</updated>
        <summary type="html"><![CDATA[Last night, the demonstrations in Israel regarding the “judicial reforms” escalated after the prime minister Netanyahu fired the defense minister Galant who called to stop the legislation. My wife and I enjoyed a concert and after it we heard loud … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Critical Times in Israel: Last Night’s Demonstrations]]></title>
        <id>http://gilkalai.wordpress.com/?p=24065</id>
        <link href="https://gilkalai.wordpress.com/2023/03/27/critical-times-in-israel-last-nights-demonstrations/"/>
        <updated>2023-03-27T06:54:21.000Z</updated>
        <summary type="html"><![CDATA[Last night, the demonstrations in Israel regarding the “judicial reforms” escalated after the prime minister Netanyahu fired the defense minister Galant who called to stop the legislation. My wife and I enjoyed a concert and after it we heard loud … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[partenza per Venezia²³]]></title>
        <id>http://xianblog.wordpress.com/?p=52635</id>
        <link href="https://xianblog.wordpress.com/2023/03/27/partenza-per-venezia%c2%b2%c2%b3/"/>
        <updated>2023-03-26T22:23:46.000Z</updated>
        <summary type="html"><![CDATA[This week I will be visiting Roberto Casarin at Ca’Foscari University of Venice, with presumably a quieter atmosphere than the past year, when I stayed there during Carnevale. Staying at the same flat as before in one of the quiet calli near the university.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kempt and sheveled]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58275</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58275&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=kempt-and-sheveled"/>
        <updated>2023-03-26T13:15:41.000Z</updated>
        <summary type="html"><![CDATA[From François Lang: I did not know you'd invented "topolect" and "character amnesia"!   Now…since you have a predilection for naming heretofore unnamed things, I am wondering if you could work your linguistic magic to describe words like "unkempt" and "disheveled", which appear far more often than their equivalent without the negative prefix.   I […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[signed mixtures [X’ed]]]></title>
        <id>http://xianblog.wordpress.com/?p=52462</id>
        <link href="https://xianblog.wordpress.com/2023/03/26/signed-mixtures-xed/"/>
        <updated>2023-03-25T23:23:42.000Z</updated>
        <summary type="html"><![CDATA[Following a question on X validated, the hypoexponential distribution, I came across (for the second time) a realistic example of a mixture (of exponentials) whose density wrote as a signed mixture, i.e. involving both negative and positive weights (with sum still equal to one). Namely, representing the density of a sum of d Exponential variates. […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[E-mail etiquette]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58268</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58268&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=e-mail-etiquette"/>
        <updated>2023-03-25T19:13:59.000Z</updated>
        <summary type="html"><![CDATA[New article by Stephen Johnson in Lifehacker (3/24/23): "These Are the Most Savage Ways to Start or End an Email: How you start and end your work email says something about your worth as a person" N.B.:  This is about work email — a very different kettle of fish from personal email, email with friends, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Aperiodic Monotile]]></title>
        <id>http://gilkalai.wordpress.com/?p=24036</id>
        <link href="https://gilkalai.wordpress.com/2023/03/25/an-aperiodic-monotile/"/>
        <updated>2023-03-25T19:10:04.000Z</updated>
        <summary type="html"><![CDATA[I suppose that most of you already heard about the first ever aperiodic planar tiling with one type of tiles. It was discovered by David Smith, Joseph Samuel Myers, Craig S. Kaplan, and Chaim Goodman-Strauss. Amazing!!! Here are  blogposts … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Aperiodic Monotile]]></title>
        <id>http://gilkalai.wordpress.com/?p=24036</id>
        <link href="https://gilkalai.wordpress.com/2023/03/25/an-aperiodic-monotile/"/>
        <updated>2023-03-25T19:10:04.000Z</updated>
        <summary type="html"><![CDATA[I suppose that most of you already heard about the first ever aperiodic planar tiling with one type of tiles. It was discovered by David Smith, Joseph Samuel Myers, Craig S. Kaplan, and Chaim Goodman-Strauss. Amazing!!! Here are  blogposts … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[La “main de Moscou“ ?]]></title>
        <id>http://xianblog.wordpress.com/?p=52640</id>
        <link href="https://xianblog.wordpress.com/2023/03/25/la-main-de-moscou/"/>
        <updated>2023-03-24T23:23:33.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Detecting novel systemic biomarkers in external eye photos]]></title>
        <id>http://ai.googleblog.com/2023/03/detecting-novel-systemic-biomarkers-in.html</id>
        <link href="http://ai.googleblog.com/2023/03/detecting-novel-systemic-biomarkers-in.html"/>
        <updated>2023-03-24T19:13:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Boris Babenko, Software Engineer, and Akib Uddin, Product Manager, Google Research    
Last year we presented results demonstrating that a deep learning system (DLS) can be trained to analyze external eye photos and predict a person’s diabetic retinal disease status and elevated glycated hemoglobin (or HbA1c, a biomarker that indicates the three-month average level of blood glucose). It was previously unknown that external eye photos contained signals for these conditions. This exciting finding suggested the potential to reduce the need for specialized equipment since such photos can be captured using smartphones and other consumer devices. Encouraged by these findings, we set out to discover what other biomarkers can be found in this imaging modality. 

In “A deep learning model…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[can you not]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58263</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58263&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=can-you-not"/>
        <updated>2023-03-24T14:22:52.000Z</updated>
        <summary type="html"><![CDATA[Hidden behind the Keurig in our departmental office, I've been noticing a gawky, ungainly, stray coffee mug with these three words on the side: can you not No capitalization and no punctuation. I was mystified.  Whatever could that mean?  I can imagine an arch, haughty, snotty person saying that to someone implying that they don't […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representation Ensembling for Synergistic Lifelong Learning with
  Quasilinear Complexity]]></title>
        <id>http://arxiv.org/abs/2004.12908</id>
        <link href="http://arxiv.org/abs/2004.12908"/>
        <updated>2023-03-24T07:14:06.680Z</updated>
        <summary type="html"><![CDATA[Joshua T. Vogelstein, Jayanta Dey, Hayden S. Helm, Will LeVine, Ronak
  D. Mehta, Tyler M. Tomita, Haoyin Xu, Ali Geisa, Qingyang Wang, Gido M. van
  de Ven, Chenyu Gao, Weiwei Yang, Bryan Tower, Jonathan Larson, Christopher M.
  White, Carey E. Priebe]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continuous Indeterminate Probability Neural Network]]></title>
        <id>http://arxiv.org/abs/2303.12964</id>
        <link href="http://arxiv.org/abs/2303.12964"/>
        <updated>2023-03-24T07:14:06.675Z</updated>
        <summary type="html"><![CDATA[Tao Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization with quantum geometry for learning unitaries]]></title>
        <id>http://arxiv.org/abs/2303.13462</id>
        <link href="http://arxiv.org/abs/2303.13462"/>
        <updated>2023-03-24T07:14:06.669Z</updated>
        <summary type="html"><![CDATA[Tobias Haug, M.S. Kim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fixed points of arbitrarily deep 1-dimensional neural networks]]></title>
        <id>http://arxiv.org/abs/2303.12814</id>
        <link href="http://arxiv.org/abs/2303.12814"/>
        <updated>2023-03-24T07:14:06.152Z</updated>
        <summary type="html"><![CDATA[Andrew Cook, Andy Hammerlindl, Warwick Tucker]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The power and limitations of learning quantum dynamics incoherently]]></title>
        <id>http://arxiv.org/abs/2303.12834</id>
        <link href="http://arxiv.org/abs/2303.12834"/>
        <updated>2023-03-24T07:14:06.147Z</updated>
        <summary type="html"><![CDATA[Sofiene Jerbi, Joe Gibbs, Manuel S. Rudolph, Matthias C. Caro, Patrick
  J. Coles, Hsin-Yuan Huang, Zo\"e Holmes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kuva Lapista⁻²³ [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=52611</id>
        <link href="https://xianblog.wordpress.com/2023/03/24/kuva-lapista%e2%81%bb%c2%b2%c2%b3-jatp/"/>
        <updated>2023-03-23T23:23:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual language maps for robot navigation]]></title>
        <id>http://ai.googleblog.com/2023/03/visual-language-maps-for-robot.html</id>
        <link href="http://ai.googleblog.com/2023/03/visual-language-maps-for-robot.html"/>
        <updated>2023-03-23T19:08:00.005Z</updated>
        <summary type="html"><![CDATA[Posted by Oier Mees, PhD Student, University of Freiburg, and Andy Zeng, Research Scientist, Robotics at Google   
People are excellent navigators of the physical world, due in part to their remarkable ability to build cognitive maps that form the basis of spatial memory — from localizing landmarks at varying ontological levels (like a book on a shelf in the living room) to determining whether a layout permits navigation from point A to point B. Building robots that are proficient at navigation requires an interconnected understanding of (a) vision and natural language (to associate landmarks or follow instructions), and (b) spatial reasoning (to connect a map representing an environment to the true spatial distribution of objects). While there have been many recent advances in training jo…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable Bayesian optimization with high-dimensional outputs using
  randomized prior networks]]></title>
        <id>http://arxiv.org/abs/2302.07260</id>
        <link href="http://arxiv.org/abs/2302.07260"/>
        <updated>2023-03-23T07:14:03.565Z</updated>
        <summary type="html"><![CDATA[Mohamed Aziz Bhouri, Michael Joly, Robert Yu, Soumalya Sarkar
 , Paris Perdikaris]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unbiased Supervised Contrastive Learning]]></title>
        <id>http://arxiv.org/abs/2211.05568</id>
        <link href="http://arxiv.org/abs/2211.05568"/>
        <updated>2023-03-23T07:14:03.543Z</updated>
        <summary type="html"><![CDATA[Carlo Alberto Barbano, Benoit Dufumier, Enzo Tartaglione, Marco
  Grangetto, Pietro Gori]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near-optimal inference in adaptive linear regression]]></title>
        <id>http://arxiv.org/abs/2107.02266</id>
        <link href="http://arxiv.org/abs/2107.02266"/>
        <updated>2023-03-23T07:14:03.530Z</updated>
        <summary type="html"><![CDATA[Koulik Khamaru, Yash Deshpande, Tor Lattimore, Lester Mackey, Martin
  J. Wainwright]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hardness of Independent Learning and Sparse Equilibrium Computation in
  Markov Games]]></title>
        <id>http://arxiv.org/abs/2303.12287</id>
        <link href="http://arxiv.org/abs/2303.12287"/>
        <updated>2023-03-23T07:14:03.488Z</updated>
        <summary type="html"><![CDATA[Dylan J. Foster, Noah Golowich, Sham M. Kakade]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal Approximation Property of Hamiltonian Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.12147</id>
        <link href="http://arxiv.org/abs/2303.12147"/>
        <updated>2023-03-23T07:14:03.468Z</updated>
        <summary type="html"><![CDATA[Muhammad Zakwan, Massimiliano d'Angelo, Giancarlo Ferrari-Trecate]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pablumese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58260</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58260&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pablumese"/>
        <updated>2023-03-23T03:33:53.000Z</updated>
        <summary type="html"><![CDATA[Knowing how much I like to invent terms for things that have no name ("topolect", "character amnesia", etc.), and needing a word for the parlance produced by ChatGPT-4 and kindred AI chatbots, Conal Boyce asked me to coin a term for it.  I instantly obliged him by coming up with "pablumese" to designate the sort […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The mind of artificial intelligence]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58255</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58255&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-mind-of-artificial-intelligence"/>
        <updated>2023-03-23T02:39:32.000Z</updated>
        <summary type="html"><![CDATA[Sean Carroll's Preposterous Universe Podcast #230 Raphaël Millière on How Artificial Intelligence Thinks, March 20, 2023 / Philosophy, Technology, Thinking / Comments     Includes transcript of the two hour podcast. Welcome to another episode of Sean Carroll's Mindscape. Today, we're joined by Raphaël Millière, a philosopher and cognitive scientist at Columbia University. We'll be exploring the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up text processing in Python (is hard)]]></title>
        <id>https://pythonspeed.com/articles/faster-text-processing/</id>
        <link href="https://pythonspeed.com/articles/faster-text-processing/"/>
        <updated>2023-03-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[If you’re doing text or string manipulation in Python, what do you do if your code is too slow?
Assuming your algorithm is reasonably efficient, the next step is to try faster alternatives to Python: a compiled extension.
Unfortunately, this is harder than it seems.
Some options don’t offer an easy path to optimizations, others are actually slower.
To see this limitation in action, we’ll consider some alternatives:
Pure Python, with the default Python interpreter.
Cython.
mypyc.
Rust.
Pure Python, with the PyPy interpreter.
We’ll also consider what can be done if these option don’t help.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[nominees for Nebula 2022 [reposted]]]></title>
        <id>http://xianblog.wordpress.com/?p=52523</id>
        <link href="https://xianblog.wordpress.com/2023/03/23/nominees-for-nebula-2022-reposted/"/>
        <updated>2023-03-22T23:23:47.000Z</updated>
        <summary type="html"><![CDATA[Books I had not read, although some are on my reading list… Novel Legends & Lattes, Travis Baldree [to read] Spear, Nicola Griffith Nettle and Bone, T. Kingfisher [to read] Babel, Or the Necessity of Violence: An Arcane History of the Oxford Translators’ Revolution, R.F. Kuang [to read] Nona the Ninth, Tamsyn Muir [to read] […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We May be Surprised Again: Why I take LLMs seriously.]]></title>
        <id>6409ab352445f5003d117961</id>
        <link href="https://www.inference.vc/we-may-be-surprised-again/"/>
        <updated>2023-03-22T14:55:54.000Z</updated>
        <summary type="html"><![CDATA["Deep Learning is Easy, Learn something Harder" - I proclaimed in one of my early and provocative blog posts from 2016. While some observations were fair, that post is now evidence that I clearly underestimated the the impact simple techniques will have, and probably gave counterproductive advice.
I]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fighting Money Laundering with Statistics and Machine Learning]]></title>
        <id>http://arxiv.org/abs/2201.04207</id>
        <link href="http://arxiv.org/abs/2201.04207"/>
        <updated>2023-03-22T07:14:22.810Z</updated>
        <summary type="html"><![CDATA[Rasmus Jensen, Alexandros Iosifidis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How (Implicit) Regularization of ReLU Neural Networks Characterizes the
  Learned Function -- Part II: the Multi-D Case of Two Layers with Random First
  Layer]]></title>
        <id>http://arxiv.org/abs/2303.11454</id>
        <link href="http://arxiv.org/abs/2303.11454"/>
        <updated>2023-03-22T07:14:22.779Z</updated>
        <summary type="html"><![CDATA[Jakob Heiss, Josef Teichmann, Hanna Wutte]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing
  and Neural Networks with Quadratic Activations]]></title>
        <id>http://arxiv.org/abs/2303.11453</id>
        <link href="http://arxiv.org/abs/2303.11453"/>
        <updated>2023-03-22T07:14:18.103Z</updated>
        <summary type="html"><![CDATA[Nived Rajaraman, Devvrit, Aryan Mokhtari, Kannan Ramchandran]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uniform Risk Bounds for Learning with Dependent Data Sequences]]></title>
        <id>http://arxiv.org/abs/2303.11650</id>
        <link href="http://arxiv.org/abs/2303.11650"/>
        <updated>2023-03-22T07:14:18.096Z</updated>
        <summary type="html"><![CDATA[Fabien Lauer (ABC)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DIPPM: a Deep Learning Inference Performance Predictive Model using
  Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.11733</id>
        <link href="http://arxiv.org/abs/2303.11733"/>
        <updated>2023-03-22T07:14:18.059Z</updated>
        <summary type="html"><![CDATA[Karthick Panner Selvam, Mats Brorsson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch 2.0 &amp; XLA—The Latest Cutting Edge Features]]></title>
        <id>https://pytorch.org/blog/pytorch-2.0-xla/</id>
        <link href="https://pytorch.org/blog/pytorch-2.0-xla/"/>
        <updated>2023-03-22T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today, we are excited to share our latest work for PyTorch/XLA 2.0. The release of PyTorch 2.0 is yet another major milestone for this storied community and we are excited to continue to be part of it. When the PyTorch/XLA project started in 2018 between Google and Meta, the focus was on bringing cutting edge Cloud TPUs to help support the PyTorch community. Along the way, others in the community such as Amazon joined the project and very quickly the community expanded. We are excited about XLA’s direction and the benefits this project continues to bring to the PyTorch community. In this blog we’d like to showcase some key features that have been in development, show code snippets, and illustrate the benefit through some benchmarks.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT-4:  threat or boon to the Great Firewall?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58250</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58250&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-4-threat-or-boon-to-the-great-firewall"/>
        <updated>2023-03-22T00:57:55.000Z</updated>
        <summary type="html"><![CDATA["The practical value of LLMs is high enough that it will induce Chinese to seek out the best systems, and they will not be censored by China.” "Yes, the Chinese Great Firewall will be collapsing" by  Tyler Cowen Marginal Revolution (March 21, 2023) Something that the PRC censors had not predicted: As framed from China: […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[畅谈 GhatGPT 在学界的应用]]></title>
        <id>https://cosx.org/2023/03/chatgpt-in-education/</id>
        <link href="https://cosx.org/2023/03/chatgpt-in-education/"/>
        <updated>2023-03-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[本文根据作者在 2023 年 2 月 18 日统计之都云讲堂的发言整理修改而成。 1 惊人的体验 最近试用了一下 ChatGPT。正如很多人描绘的那样，这个产品震撼人心]]></summary>
        <author>
            <name>统计之都</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[partial rankings and aggregate ranks]]></title>
        <id>http://xianblog.wordpress.com/?p=52519</id>
        <link href="https://xianblog.wordpress.com/2023/03/22/partial-rankings-and-aggregate-ranks/"/>
        <updated>2023-03-21T23:23:05.000Z</updated>
        <summary type="html"><![CDATA[When interviewing impressive applicants from a stunning variety of places and background for fellows in our Data Science for Social Good program (in Warwick and Kaiserslautern) this summer, we came through the common conundrum of comparing ranks while each of us only meeting a subset of the candidates. Over a free morning, I briefly thought […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Writing English with Chinese characters]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58243</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58243&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=writing-english-with-chinese-characters-2"/>
        <updated>2023-03-21T10:47:55.000Z</updated>
        <summary type="html"><![CDATA[Responding to "Transcriptional Chinese animal imagery for English daily greetings" (3/13/23), Mary Erbaugh, using Yale Cantonese romanization, writes: ———— I've never seen it done with animal names, though probably easier to remember, amusing. I'm used to the English word pronunciations in old fashioned HK (& Taiwan) almanacs, like the Bou Lòh Maahn Yauh (Cant.) / […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calibration of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.10761</id>
        <link href="http://arxiv.org/abs/2303.10761"/>
        <updated>2023-03-21T07:14:24.812Z</updated>
        <summary type="html"><![CDATA[Ruslan Vasilev, Alexander D'yakonov]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is Q-Learning Minimax Optimal? A Tight Sample Complexity Analysis]]></title>
        <id>http://arxiv.org/abs/2102.06548</id>
        <link href="http://arxiv.org/abs/2102.06548"/>
        <updated>2023-03-21T07:14:24.806Z</updated>
        <summary type="html"><![CDATA[Gen Li, Changxiao Cai, Yuxin Chen, Yuting Wei, Yuejie Chi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spatially heterogeneous learning by a deep student machine]]></title>
        <id>http://arxiv.org/abs/2302.07419</id>
        <link href="http://arxiv.org/abs/2302.07419"/>
        <updated>2023-03-21T07:14:24.799Z</updated>
        <summary type="html"><![CDATA[Hajime Yoshino]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Byzantine-Robust Federated Learning with Optimal Statistical Rates and
  Privacy Guarantees]]></title>
        <id>http://arxiv.org/abs/2205.11765</id>
        <link href="http://arxiv.org/abs/2205.11765"/>
        <updated>2023-03-21T07:14:24.793Z</updated>
        <summary type="html"><![CDATA[Banghua Zhu, Lun Wang, Qi Pang, Shuai Wang, Jiantao Jiao, Dawn Song,
  Michael I. Jordan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantile and moment neural networks for learning functionals of
  distributions]]></title>
        <id>http://arxiv.org/abs/2303.11060</id>
        <link href="http://arxiv.org/abs/2303.11060"/>
        <updated>2023-03-21T07:14:24.768Z</updated>
        <summary type="html"><![CDATA[Xavier Warin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Donoho: 数据科学50年]]></title>
        <id>https://cosx.org/2023/03/50-years-of-data-science-cn/</id>
        <link href="https://cosx.org/2023/03/50-years-of-data-science-cn/"/>
        <updated>2023-03-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[统计之都编辑部按：本文译自 Donoho (2017): 50 Years of Data Science，发表在 Journal of Computational and Graphical Statistics 杂志。在正式发表前数年，其初版就广为流传，引发了学术界深入、持续的讨]]></summary>
        <author>
            <name>统计之都</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAGS Workshop [10-14 July 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=52500</id>
        <link href="https://xianblog.wordpress.com/2023/03/21/jags-workshop-10-14-july-2023/"/>
        <updated>2023-03-20T23:23:44.000Z</updated>
        <summary type="html"><![CDATA[Hey, JAGS users and would-be users, be warned that registration is now open for the annual JAGS workshop on probabilistic modelling for cognitive science. The tenth instalment of this workshop takes place July 10–14, 2023 in Amsterdam and online. This workshop is meant for researchers who want to learn how to apply Bayesian inference in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chateau Puy-Bardens [second hand Cadillac]]]></title>
        <id>http://xianblog.wordpress.com/?p=52434</id>
        <link href="https://xianblog.wordpress.com/2023/03/20/chateay-puy-bardens-second-hand-cadillac/"/>
        <updated>2023-03-20T19:20:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[达观数据陈运文：探索大语言模型，“对症下药”很关键]]></title>
        <id>https://www.52nlp.cn/?p=13430</id>
        <link href="https://www.52nlp.cn/%e8%be%be%e8%a7%82%e6%95%b0%e6%8d%ae%e9%99%88%e8%bf%90%e6%96%87%ef%bc%9a%e6%8e%a2%e7%b4%a2%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%ef%bc%8c%e5%af%b9%e7%97%87%e4%b8%8b%e8%8d%af"/>
        <updated>2023-03-20T10:33:59.000Z</updated>
        <summary type="html"><![CDATA[内容来源：ChatGPT 及大模型专题研讨会  分享嘉宾：达观数据董事长兼CEO 陈运文博士 分享主 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multivariate Probabilistic CRPS Learning with an Application to
  Day-Ahead Electricity Prices]]></title>
        <id>http://arxiv.org/abs/2303.10019</id>
        <link href="http://arxiv.org/abs/2303.10019"/>
        <updated>2023-03-20T07:15:53.287Z</updated>
        <summary type="html"><![CDATA[Jonathan Berrisch, Florian Ziel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Breaking the Sample Size Barrier in Model-Based Reinforcement Learning
  with a Generative Model]]></title>
        <id>http://arxiv.org/abs/2005.12900</id>
        <link href="http://arxiv.org/abs/2005.12900"/>
        <updated>2023-03-20T07:15:53.282Z</updated>
        <summary type="html"><![CDATA[Gen Li, Yuting Wei, Yuejie Chi, Yuxin Chen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised domain adaptation by learning using privileged information]]></title>
        <id>http://arxiv.org/abs/2303.09350</id>
        <link href="http://arxiv.org/abs/2303.09350"/>
        <updated>2023-03-20T07:15:53.276Z</updated>
        <summary type="html"><![CDATA[Adam Breitholtz, Anton Matsson, Fredrik D. Johansson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Non-Asymptotic Framework for Approximate Message Passing in Spiked
  Models]]></title>
        <id>http://arxiv.org/abs/2208.03313</id>
        <link href="http://arxiv.org/abs/2208.03313"/>
        <updated>2023-03-20T07:15:53.271Z</updated>
        <summary type="html"><![CDATA[Gen Li, Yuting Wei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[《为什么现在的LLM都是Decoder-only的架构？》FAQ]]></title>
        <id>https://kexue.fm/archives/9547</id>
        <link href="https://kexue.fm/archives/9547"/>
        <updated>2023-03-20T06:53:00.000Z</updated>
        <summary type="html"><![CDATA[上周笔者写了《为什么现在的LLM都是Decoder-only的架构？》，总结了一下我在这个问题上的一些实验结论和猜测。果然是热点问题流量大，paperweekly的转发没多久阅读量就破万了，知乎...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No depth-charge channel is too noisy to be confused by]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58246</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58246&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=no-depth-charge-channel-is-too-noisy-to-be-confused-by"/>
        <updated>2023-03-20T02:10:45.000Z</updated>
        <summary type="html"><![CDATA[Yuhan Zhang, Rachel Ryskin & Edward Gibson, "A noisy-channel approach to depth-charge illusions." Cognition, March 2023: The “depth-charge” sentence, No head injury is too trivial to be ignored, is often interpreted as “no matter how trivial head injuries are, we should not ignore them” while the literal meaning is the opposite – “we should ignore […]]]></summary>
        <author>
            <name>Neal Goldfarb</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BayesComp²³ [aka MCMski⁶]]]></title>
        <id>http://xianblog.wordpress.com/?p=52587</id>
        <link href="https://xianblog.wordpress.com/2023/03/20/bayescomp%c2%b2%c2%b3-aka-mcmski%e2%81%b6/"/>
        <updated>2023-03-19T23:23:09.000Z</updated>
        <summary type="html"><![CDATA[The main BayesComp meeting started right after the ABC workshop and went on at a grueling pace, and offered a constant conundrum as to which of the four sessions to attend, the more when trying to enjoy some outdoor activity during the lunch breaks. My overall feeling is that it went on too fast, too […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Serif or sans serif?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58227</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58227&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=serif-or-sans-serif"/>
        <updated>2023-03-19T10:39:31.000Z</updated>
        <summary type="html"><![CDATA[Most people care about their typefaces Appearances matter, especially whether fonts have serifs or not. "Font Wars Spread After State Department Replaces Times New Roman with Calibri "'I'm banging my head against the wall;' camps divided in fallout from government efforts to make documents easier to read" By Katie Deighton, WSJ (3/14/23) One wonders whether […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[optimal scaling for proximal MALA [All about that Bayes seminar, 21/03, Palaiseau]]]></title>
        <id>http://xianblog.wordpress.com/?p=52571</id>
        <link href="https://xianblog.wordpress.com/2023/03/19/optimal-scaling-for-proximal-mala-21-03/"/>
        <updated>2023-03-18T23:23:18.000Z</updated>
        <summary type="html"><![CDATA[An All about that Bayes seminar next Tuesday, at 2pm, at AgroParisTech, Francesca Crucinio (formerly Warwick and now ENSAE): We consider a recently proposed class of MCMC methods which uses proximity maps instead of gradients to build proposal mechanisms which can be employed for both differentiable and non-differentiable targets. These methods have been shown to […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Subscribe to Open"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58232</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58232&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=subscribe-to-open"/>
        <updated>2023-03-18T12:02:34.000Z</updated>
        <summary type="html"><![CDATA[As the S2O website explains, “Subscribe to Open” (S2O) is a pragmatic approach for converting subscription journals to open access—free and immediate online availability of research—without reliance on either article processing charges (APCs) or altruism. […] S2O allows publishers to convert journals from subscriptions to OA, one year at a time. Using S2O, a publisher […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Black hole information recovery from gravitational waves]]></title>
        <id>http://arxiv.org/abs/2211.13736</id>
        <link href="http://arxiv.org/abs/2211.13736"/>
        <updated>2023-03-18T07:13:58.483Z</updated>
        <summary type="html"><![CDATA[Louis Hamaide, Theo Torres]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kuva Lapista⁴]]></title>
        <id>http://xianblog.wordpress.com/?p=52604</id>
        <link href="https://xianblog.wordpress.com/2023/03/18/kuva-lapista%e2%81%b4/"/>
        <updated>2023-03-17T23:23:15.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vid2Seq: a pretrained visual language model for describing multi-event videos]]></title>
        <id>http://ai.googleblog.com/2023/03/vid2seq-pretrained-visual-language.html</id>
        <link href="http://ai.googleblog.com/2023/03/vid2seq-pretrained-visual-language.html"/>
        <updated>2023-03-17T17:52:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Antoine Yang, Student Researcher, and Arsha Nagrani, Research Scientist, Google Research, Perception team    
Videos have become an increasingly important part of our daily lives, spanning fields such as entertainment, education, and communication. Understanding the content of videos, however, is a challenging task as videos often contain multiple events occurring at different time scales. For example, a video of a musher hitching up dogs to a dog sled before they all race away involves a long event (the dogs pulling the sled) and a short event (the dogs being hitched to the sled). One way to spur research in video understanding is via the task of dense video captioning, which consists of temporally localizing and describing all events in a minutes-long video. This differs from s…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[So many words for "donkey"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58210</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58210&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=so-many-words-for-donkey"/>
        <updated>2023-03-17T10:37:20.000Z</updated>
        <summary type="html"><![CDATA[Almost as many as Eskimo words for "snow".  (hee-hee haw-haw) (see below for a sampling) I've always been a great admirer of donkeys, and I love to hear them bray and make all sorts of other expressive sounds, some of which I am incapable of adequately expressing in words — especially when they are being […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Sea of Words: An In-Depth Analysis of Anchors for Text Data]]></title>
        <id>http://arxiv.org/abs/2205.13789</id>
        <link href="http://arxiv.org/abs/2205.13789"/>
        <updated>2023-03-17T07:15:04.611Z</updated>
        <summary type="html"><![CDATA[Gianluigi Lopardo, Frederic Precioso, Damien Garreau]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combining Distance to Class Centroids and Outlier Discounting for
  Improved Learning with Noisy Labels]]></title>
        <id>http://arxiv.org/abs/2303.09470</id>
        <link href="http://arxiv.org/abs/2303.09470"/>
        <updated>2023-03-17T07:15:04.606Z</updated>
        <summary type="html"><![CDATA[Farooq Ahmad Wani, Maria Sofia Bucarelli, Fabrizio Silvestri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Generalization Error in Linear Neural Networks with Concept
  Bottleneck Structure and Multitask Formulation]]></title>
        <id>http://arxiv.org/abs/2303.09154</id>
        <link href="http://arxiv.org/abs/2303.09154"/>
        <updated>2023-03-17T07:15:04.600Z</updated>
        <summary type="html"><![CDATA[Naoki Hayashi, Yoshihide Sawada]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Lower Bounds on the Depth of ReLU Neural Networks]]></title>
        <id>http://arxiv.org/abs/2105.14835</id>
        <link href="http://arxiv.org/abs/2105.14835"/>
        <updated>2023-03-17T07:15:04.592Z</updated>
        <summary type="html"><![CDATA[Christoph Hertrich, Amitabh Basu, Marco Di Summa, Martin Skutella]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[为什么现在的LLM都是Decoder-only的架构？]]></title>
        <id>https://kexue.fm/archives/9529</id>
        <link href="https://kexue.fm/archives/9529"/>
        <updated>2023-03-17T02:44:00.000Z</updated>
        <summary type="html"><![CDATA[LLM是“Large Language Model”的简写，目前一般指百亿参数以上的语言模型，主要面向文本生成任务。跟小尺度模型（10亿或以内量级）的“百花齐放”不同，目前LLM的一个现状是De...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Personalized Decision Making under Concurrent-Controlled RCT Data]]></title>
        <id>http://causality.cs.ucla.edu/blog/?p=2463</id>
        <link href="http://causality.cs.ucla.edu/blog/index.php/2023/03/17/personalized-decision-making-under-concurrent-controlled-rct-data/"/>
        <updated>2023-03-17T02:31:21.000Z</updated>
        <summary type="html"><![CDATA[Scott Mueller and Judea Pearl Introduction This note supplements the analysis of [Mueller and Pearl 2023] by introducing an important restriction on the data obtained from Randomized Control Trials (RCT). In Mueller and Pearl, it is assumed that RCTs provide estimates of two probabilities, \(P(y_t)\) and \(P(y_c)\), standing for the probability of the outcome \(Y\) […]]]></summary>
        <author>
            <name>Scott Mueller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kuva Lapista³ [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=52580</id>
        <link href="https://xianblog.wordpress.com/2023/03/17/kuva-lapista%c2%b3-jatp/"/>
        <updated>2023-03-16T23:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: The Impact Lab]]></title>
        <id>http://ai.googleblog.com/2023/03/responsible-ai-at-google-research.html</id>
        <link href="http://ai.googleblog.com/2023/03/responsible-ai-at-google-research.html"/>
        <updated>2023-03-16T20:13:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Jamila Smith-Loud, Human Rights & Social Impact Research Lead, Google Research, Responsible AI and Human-Centered Technology Team 
    

Globalized technology has the potential to create large-scale societal impact, and having a grounded research approach rooted in existing international human and civil rights standards is a critical component to assuring responsible and ethical AI development and deployment. The Impact Lab team, part of Google’s Responsible AI Team, employs a range of interdisciplinary methodologies to ensure critical and rich analysis of the potential implications of technology development. The team’s mission is to examine socioeconomic and human rights impacts of AI,  publish foundational research, and incubate novel mitigations enabling machine learning (ML) …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some News from a Seminar in Cambridge]]></title>
        <id>http://gilkalai.wordpress.com/?p=24009</id>
        <link href="https://gilkalai.wordpress.com/2023/03/16/some-news-from-a-seminar-in-cambridge/"/>
        <updated>2023-03-16T19:02:01.000Z</updated>
        <summary type="html"><![CDATA[On an old problems of Erdős (h/t Michael Simkin and Nati Linial) Here is a somewhat mysterious announcement for a combinatorics seminar lecture at Cambridge. Which old problems of Erdős are we talking about? Here is a picture from the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some News from a Seminar in Cambridge]]></title>
        <id>http://gilkalai.wordpress.com/?p=24009</id>
        <link href="https://gilkalai.wordpress.com/2023/03/16/some-news-from-a-seminar-in-cambridge/"/>
        <updated>2023-03-16T19:02:01.000Z</updated>
        <summary type="html"><![CDATA[On an old problems of Erdős (h/t Michael Simkin and Nati Linial) Here is a somewhat mysterious announcement for a combinatorics seminar lecture at Cambridge. Which old problems of Erdős are we talking about? Here is a picture from the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[arX[g]iv[e]]]></title>
        <id>http://xianblog.wordpress.com/?p=52591</id>
        <link href="https://xianblog.wordpress.com/2023/03/16/give2arxive/"/>
        <updated>2023-03-16T13:44:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[复旦邱锡鹏：深度剖析 ChatGPT 类大语言模型的关键技术]]></title>
        <id>https://www.52nlp.cn/?p=13428</id>
        <link href="https://www.52nlp.cn/%e5%a4%8d%e6%97%a6%e9%82%b1%e9%94%a1%e9%b9%8f%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%89%96%e6%9e%90-chatgpt-%e7%b1%bb%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%85%b3%e9%94%ae%e6%8a%80%e6%9c%af"/>
        <updated>2023-03-16T08:42:14.000Z</updated>
        <summary type="html"><![CDATA[内容来源：ChatGPT 及大模型专题研讨会分享嘉宾：复旦大教授 邱锡鹏分享主题：《对话式大型语言模型》转载自 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Benefits of Mixup for Feature Learning]]></title>
        <id>http://arxiv.org/abs/2303.08433</id>
        <link href="http://arxiv.org/abs/2303.08433"/>
        <updated>2023-03-16T07:15:38.179Z</updated>
        <summary type="html"><![CDATA[Difan Zou, Yuan Cao, Yuanzhi Li, Quanquan Gu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Policy learning "without'' overlap: Pessimism and generalized empirical
  Bernstein's inequality]]></title>
        <id>http://arxiv.org/abs/2212.09900</id>
        <link href="http://arxiv.org/abs/2212.09900"/>
        <updated>2023-03-16T07:15:38.167Z</updated>
        <summary type="html"><![CDATA[Ying Jin, Zhimei Ren, Zhuoran Yang, Zhaoran Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Incentivize Information Acquisition: Proper Scoring Rules
  Meet Principal-Agent Model]]></title>
        <id>http://arxiv.org/abs/2303.08613</id>
        <link href="http://arxiv.org/abs/2303.08613"/>
        <updated>2023-03-16T07:15:38.151Z</updated>
        <summary type="html"><![CDATA[Siyu Chen, Jibang Wu, Yifan Wu, Zhuoran Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Resilient Radio Resource Management Policies with Graph Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2203.11012</id>
        <link href="http://arxiv.org/abs/2203.11012"/>
        <updated>2023-03-16T07:15:38.145Z</updated>
        <summary type="html"><![CDATA[Navid NaderiAlizadeh, Mark Eisen, Alejandro Ribeiro]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Delay-SDE-net: A deep learning approach for time series modelling with
  memory and uncertainty estimates]]></title>
        <id>http://arxiv.org/abs/2303.08587</id>
        <link href="http://arxiv.org/abs/2303.08587"/>
        <updated>2023-03-16T07:15:38.140Z</updated>
        <summary type="html"><![CDATA[Mari Dahl Eggen, Alise Danielle Midtfjord]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerated Diffusers with PyTorch 2.0]]></title>
        <id>https://pytorch.org/blog/accelerated-diffusers-pt-20/</id>
        <link href="https://pytorch.org/blog/accelerated-diffusers-pt-20/"/>
        <updated>2023-03-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[PyTorch 2.0 has just been released. Its flagship new feature is torch.compile(), a one-line code change that promises to automatically improve performance across codebases. We have previously checked on that promise in Hugging Face Transformers and TIMM models, and delved deep into its motivation, architecture and the road ahead.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[This is the 4th time I've gotten Jack and his beanstalk]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58196</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58196&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=this-is-the-4th-time-ive-gotten-jack-and-his-beanstalk"/>
        <updated>2023-03-16T00:45:39.000Z</updated>
        <summary type="html"><![CDATA[Bill Benzon shares the response he got from ChatGPT to the prompt, "Tell me a story." Here's the response: Once upon a time, in a far-off land, there was a young boy named Jack who lived with his mother. They were very poor and struggled to make ends meet. One day, Jack's mother sent him […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ABC in Lapland²]]></title>
        <id>http://xianblog.wordpress.com/?p=52563</id>
        <link href="https://xianblog.wordpress.com/2023/03/16/abc-in-lapland%c2%b2/"/>
        <updated>2023-03-15T23:23:18.000Z</updated>
        <summary type="html"><![CDATA[On the second day of our workshop, Aki Vehtari gave a short talk about his recent works on speed up post processing by importance sampling a simulation of an imprecise version of the likelihood until the desired precision is attained, importance corrected by Pareto smoothing¹⁵. A very interesting foray into the meaning of practical models […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tasty McDonald's customer]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58188</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58188&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tasty-mcdonalds-customer"/>
        <updated>2023-03-15T18:40:52.000Z</updated>
        <summary type="html"><![CDATA[The Chinese notice says: Běn yíngyè chǎngsuǒ jǐn xiàn Màidāngláo yòngcān gùkè shǐyòng 本营业场所仅限麦当劳用餐顾客使用 "This place of business is reserved for McDonald's dine-in customers" Can't be too careful when you enter certain places of business. Selected readings "I'm lovin' it — next to the toilet" (12/12/09) "Clipping McDonald's" (7/29/13) [h.t. John Rohsenow]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ABC in Lapland²]]></title>
        <id>http://xianblog.wordpress.com/?p=52563</id>
        <link href="https://xianblog.wordpress.com/2023/03/15/abc-in-lapland%c2%b2/"/>
        <updated>2023-03-15T08:17:18.000Z</updated>
        <summary type="html"><![CDATA[On the second day of our workshop, Aki Vehtari gave a short talk about his recent works on speed up post processing by importance sampling a simulation of an imprecise version of the likelihood until the desired precision is attained, importance corrected by Pareto smoothing¹⁵. A very interesting foray into the meaning of practical models […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generation of Paths in a Maze using a Deep Network without Learning]]></title>
        <id>http://arxiv.org/abs/2004.00540</id>
        <link href="http://arxiv.org/abs/2004.00540"/>
        <updated>2023-03-15T07:14:58.971Z</updated>
        <summary type="html"><![CDATA[Tomas Kulvicius, Sebastian Herzog, Minija Tamosiunaite, Florentin
  W\"org\"otter]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Algorithms that get old : the case of generative deep neural networks]]></title>
        <id>http://arxiv.org/abs/2202.03008</id>
        <link href="http://arxiv.org/abs/2202.03008"/>
        <updated>2023-03-15T07:14:58.966Z</updated>
        <summary type="html"><![CDATA[Gabriel Turinici]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pretrained Language Models are Symbolic Mathematics Solvers too!]]></title>
        <id>http://arxiv.org/abs/2110.03501</id>
        <link href="http://arxiv.org/abs/2110.03501"/>
        <updated>2023-03-15T07:14:58.961Z</updated>
        <summary type="html"><![CDATA[Kimia Noorbakhsh, Modar Sulaiman, Mahdi Sharifi, Kallol Roy, Pooyan
  Jamshidi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning-Based Estimation and Goodness-of-Fit for Large-Scale
  Confirmatory Item Factor Analysis]]></title>
        <id>http://arxiv.org/abs/2109.09500</id>
        <link href="http://arxiv.org/abs/2109.09500"/>
        <updated>2023-03-15T07:14:58.096Z</updated>
        <summary type="html"><![CDATA[Christopher J. Urban, Daniel J. Bauer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New Library Updates in PyTorch 2.0]]></title>
        <id>https://pytorch.org/blog/new-library-updates-in-pytorch-2.0/</id>
        <link href="https://pytorch.org/blog/new-library-updates-in-pytorch-2.0/"/>
        <updated>2023-03-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Summary]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever]]></title>
        <id>https://pytorch.org/blog/pytorch-2.0-release/</id>
        <link href="https://pytorch.org/blog/pytorch-2.0-release/"/>
        <updated>2023-03-15T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to announce the release of PyTorch® 2.0 which we highlighted during the PyTorch Conference on 12/2/22! PyTorch 2.0 offers the same eager-mode development and user experience, while fundamentally changing and supercharging how PyTorch operates at compiler level under the hood with faster performance and support for Dynamic Shapes and Distributed.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
</feed>