<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-09-22T22:13:43.712Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Heavily accented Mandarin]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60680</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60680&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=heavily-accented-mandarin"/>
        <updated>2023-09-22T10:49:45.000Z</updated>
        <summary type="html"><![CDATA[In "Voice-activated lights" (9/20/23), we saw how difficult it is even for native speakers of Modern Standard Mandarin to understand other varieties, and can be thankful to Zeyao Wu, who comes from the area where the topolect in the film is spoken, for kindly identifying and transcribing it for all of us. rit malors writes: […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dogged by an etymological shape]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60673</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60673&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dogged-by-an-etymological-shape"/>
        <updated>2023-09-22T04:21:22.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Martin Schwartz] The following is just an idle speculation for which I have no answer, but somehow I don't think mere coincidence is really a factor. A number of Old World languages of different groups show a word for 'dog' or a doglike beast of the type affricate/sibilant plus […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Online Self-Concordant and Relatively Smooth Minimization, With
  Applications to Online Portfolio Selection and Learning Quantum States]]></title>
        <id>http://arxiv.org/abs/2210.00997</id>
        <link href="http://arxiv.org/abs/2210.00997"/>
        <updated>2023-09-22T03:15:09.516Z</updated>
        <summary type="html"><![CDATA[Chung-En Tsai, Hao-Chung Cheng, Yen-Huan Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TrueLearn: A Python Library for Personalised Informational
  Recommendations with (Implicit) Feedback]]></title>
        <id>http://arxiv.org/abs/2309.11527</id>
        <link href="http://arxiv.org/abs/2309.11527"/>
        <updated>2023-09-22T03:15:09.427Z</updated>
        <summary type="html"><![CDATA[Yuxiang Qiu, Karim Djemili, Denis Elezi, Aaneel Shalman, Mar\'ia
  P\'erez-Ortiz, Sahan Bulathwela]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models]]></title>
        <id>http://arxiv.org/abs/2309.12307</id>
        <link href="http://arxiv.org/abs/2309.12307"/>
        <updated>2023-09-22T03:15:09.347Z</updated>
        <summary type="html"><![CDATA[Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, Song
  Han, Jiaya Jia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Activation Compression of Graph Neural Networks using Block-wise
  Quantization with Improved Variance Minimization]]></title>
        <id>http://arxiv.org/abs/2309.11856</id>
        <link href="http://arxiv.org/abs/2309.11856"/>
        <updated>2023-09-22T03:15:09.314Z</updated>
        <summary type="html"><![CDATA[Sebastian Eliassen, Raghavendra Selvan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian sparsification for deep neural networks with Bayesian model
  reduction]]></title>
        <id>http://arxiv.org/abs/2309.12095</id>
        <link href="http://arxiv.org/abs/2309.12095"/>
        <updated>2023-09-22T03:15:09.309Z</updated>
        <summary type="html"><![CDATA[Dimitrije Markovi\'c, Karl J. Friston, Stefan J. Kiebel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=53873</id>
        <link href="https://xianblog.wordpress.com/2023/09/22/a-journal-of-the-conquest-war-famine-and-death-year-4/"/>
        <updated>2023-09-21T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[Read [on the way back home (and during the following jet-lagged nights)] the Ninth Rain and its sequel the Bitter Twins, by Jen Williams, for which she won twice a British Fantasy Award. I am twice as surprised given that it is quite a poor series, with a simplistic approach to its world building, a […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes]]></title>
        <id>http://blog.research.google/2023/09/distilling-step-by-step-outperforming.html</id>
        <link href="http://blog.research.google/2023/09/distilling-step-by-step-outperforming.html"/>
        <updated>2023-09-21T21:25:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Cheng-Yu Hsieh, Student Researcher, and Chen-Yu Lee, Research Scientist, Cloud AI Team





Large language models (LLMs) have enabled a new data-efficient learning paradigm wherein they can be used to solve unseen new tasks via zero-shot or few-shot prompting. However, LLMs are challenging to deploy for real-world applications due to their sheer size. For instance, serving a single 175 billion LLM requires at least 350GB of GPU memory using specialized infrastructure, not to mention that today's state-of-the-art LLMs are composed of over 500 billion parameters. Such computational requirements are inaccessible for many research teams, especially for applications that require low latency performance.




To circumvent these deployment challenges, practitioners often choose to deplo…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Earwormitis]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60666</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60666&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=earwormitis"/>
        <updated>2023-09-21T18:56:32.000Z</updated>
        <summary type="html"><![CDATA[I'm not the first person to use that word, but I probably mean it in a distinctive way.  What I'm talking about is not the usual sort of earworm / öhrwurm that gets stuck in your brain and you just can't make it go away.  That's the usual kind, and I get it fairly often, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Networks as Denoising Algorithms: Sample-Efficient Learning of
  Diffusion Models in High-Dimensional Graphical Models]]></title>
        <id>http://arxiv.org/abs/2309.11420</id>
        <link href="http://arxiv.org/abs/2309.11420"/>
        <updated>2023-09-21T02:19:57.126Z</updated>
        <summary type="html"><![CDATA[Song Mei, Yuchen Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Prediction is Robust to Dispersive Label Noise]]></title>
        <id>http://arxiv.org/abs/2209.14295</id>
        <link href="http://arxiv.org/abs/2209.14295"/>
        <updated>2023-09-21T02:19:47.000Z</updated>
        <summary type="html"><![CDATA[Shai Feldman, Bat-Sheva Einbinder, Stephen Bates, Anastasios N.
  Angelopoulos, Asaf Gendler, Yaniv Romano]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classification Under Misspecification: Halfspaces, Generalized Linear
  Models, and Connections to Evolvability]]></title>
        <id>http://arxiv.org/abs/2006.04787</id>
        <link href="http://arxiv.org/abs/2006.04787"/>
        <updated>2023-09-21T02:19:46.993Z</updated>
        <summary type="html"><![CDATA[Sitan Chen, Frederic Koehler, Ankur Moitra, Morris Yau]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning]]></title>
        <id>http://arxiv.org/abs/2106.12059</id>
        <link href="http://arxiv.org/abs/2106.12059"/>
        <updated>2023-09-21T02:19:46.987Z</updated>
        <summary type="html"><![CDATA[Andreas Kirsch, Sebastian Farquhar, Parmida Atighehchian, Andrew
  Jesson, Frederic Branchaud-Charron, Yarin Gal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Pragmatic Look at Deep Imitation Learning]]></title>
        <id>http://arxiv.org/abs/2108.01867</id>
        <link href="http://arxiv.org/abs/2108.01867"/>
        <updated>2023-09-21T02:19:46.982Z</updated>
        <summary type="html"><![CDATA[Kai Arulkumaran, Dan Ogawa Lillrank]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Voice-activated lights]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60593</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60593&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=voice-activated-lights"/>
        <updated>2023-09-21T01:59:11.000Z</updated>
        <summary type="html"><![CDATA[I showed this mp4 video to a dozen native speakers of Sinitic languages (mostly Mandarin), but no one could identify, much less understand, what it was: https://i.imgur.com/MesyF9r.mp4   (from imgur) Chau Wu ruled out Taiwanese, Hakka, and Cantonese, but he said that he heard words that sounded like chú sī 廚司 ("chef") and chǎocài 炒菜 […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[All About that Bayes restart]]></title>
        <id>http://xianblog.wordpress.com/?p=54070</id>
        <link href="https://xianblog.wordpress.com/2023/09/21/all-about-that-bayes-restart/"/>
        <updated>2023-09-20T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[For all Bayesians and sympathisers in the Paris area, All about that Bayes seminars are restarting this semester with a talk by Kaniav Kamari (Centrale Supélec) on 10 October, 16h00, on Campus Pierre & Marie Curie, SCAI: Bayesian principal component analysis The technique of principal component analysis (PCA) has recently been expressed as the maximum […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arrowleaf pinot noir]]></title>
        <id>http://xianblog.wordpress.com/?p=53723</id>
        <link href="https://xianblog.wordpress.com/2023/09/20/arrowleaf-pinot-noir/"/>
        <updated>2023-09-20T18:20:21.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Buoyancy-driven exchange flows in inclined ducts]]></title>
        <id>http://arxiv.org/abs/1907.03502</id>
        <link href="http://arxiv.org/abs/1907.03502"/>
        <updated>2023-09-20T17:13:14.259Z</updated>
        <summary type="html"><![CDATA[Adrien Lefauve, P. F. Linden]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distinguished elements in semiring extensions]]></title>
        <id>http://arxiv.org/abs/1811.02142</id>
        <link href="http://arxiv.org/abs/1811.02142"/>
        <updated>2023-09-20T17:13:14.217Z</updated>
        <summary type="html"><![CDATA[Peyman Nasehpour]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approaches to analysis with infinitesimals following Robinson, Nelson,
  and others]]></title>
        <id>http://arxiv.org/abs/1703.00425</id>
        <link href="http://arxiv.org/abs/1703.00425"/>
        <updated>2023-09-20T17:13:14.204Z</updated>
        <summary type="html"><![CDATA[Peter Fletcher, Karel Hrbacek, Vladimir Kanovei, Mikhail G. Katz,
  Claude Lobry, Sam Sanders]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An extension of Calderon Transfer Principle]]></title>
        <id>http://arxiv.org/abs/2004.00462</id>
        <link href="http://arxiv.org/abs/2004.00462"/>
        <updated>2023-09-20T17:13:14.169Z</updated>
        <summary type="html"><![CDATA[Sakin Demir]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Canonicalizers and Declarative Rewrite Patterns]]></title>
        <id>https://jeremykun.com/?p=120004</id>
        <link href="https://jeremykun.com/2023/09/20/mlir-canonicalizers-and-declarative-rewrite-patterns/"/>
        <updated>2023-09-20T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents In a previous article we defined folding functions, and used them to enable some canonicalization and the sccp constant propagation pass for the poly dialect. This time we’ll see how to add more general canonicalization patterns. The code for this article is in this pull request, and as usual the commits are organized to be […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[自然数域中 N = ab + c 时 a + b + c 的最小值]]></title>
        <id>https://kexue.fm/archives/9775</id>
        <link href="https://kexue.fm/archives/9775"/>
        <updated>2023-09-20T06:16:00.000Z</updated>
        <summary type="html"><![CDATA[前天晚上微信群里有群友提出了一个问题：对于一个任意整数$N > 100$，求一个近似算法，使得$N=a\times b+c$（其中$a,b,c$都是非负整数），并且令$a+b+c$尽量地小。初看...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometric structure of shallow neural networks and constructive
  ${\mathcal L}^2$ cost minimization]]></title>
        <id>http://arxiv.org/abs/2309.10370</id>
        <link href="http://arxiv.org/abs/2309.10370"/>
        <updated>2023-09-20T02:20:25.020Z</updated>
        <summary type="html"><![CDATA[Thomas Chen, Patricia Mu\~noz Ewald]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometric structure of Deep Learning networks and construction of global
  ${\mathcal L}^2$ minimizers]]></title>
        <id>http://arxiv.org/abs/2309.10639</id>
        <link href="http://arxiv.org/abs/2309.10639"/>
        <updated>2023-09-20T02:20:24.959Z</updated>
        <summary type="html"><![CDATA[Thomas Chen, Patricia Mu\~noz Ewald]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring the Limits of Transfer Learning with a Unified Text-to-Text
  Transformer]]></title>
        <id>http://arxiv.org/abs/1910.10683</id>
        <link href="http://arxiv.org/abs/1910.10683"/>
        <updated>2023-09-20T02:20:17.929Z</updated>
        <summary type="html"><![CDATA[Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan
  Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up Floyd-Steinberg dithering: an optimization exercise]]></title>
        <id>https://pythonspeed.com/articles/optimizing-dithering/</id>
        <link href="https://pythonspeed.com/articles/optimizing-dithering/"/>
        <updated>2023-09-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[pre {
    white-space: pre;
    overflow-x: auto;
    font-size: 80%;
}


The common advice when Python is too slow is to switch to a low-level compiled language.
But what do you do if that code is too slow?
Almost always there’s still plenty of performance improvements you can get just by tweaking your code.
As a real-world example, in this article we’ll go about optimizing Floyd-Steinberg error diffusion dithering.
The specific variant of the  algorithm that we will implement converts a grayscale image with values of 0 to 255 into an image with just two colors, black and white.
This article is an excerpt from a book I’m working on that will help teach you how to optimize low-level code, the kind of code you’d write with C, Cython, or Rust.
The goal is to help data scientists and scientis…]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mandarin über alles]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60662</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60662&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mandarin-uber-alles"/>
        <updated>2023-09-19T23:35:33.000Z</updated>
        <summary type="html"><![CDATA[China’s Language PoliceWhy Beijing Seeks to Extend the Hegemony of MandarinBy Gina Anne Tam, Foreign AffairsSeptember 19, 2023 It's odd that the author knows about "topolect" and recognizes the inadequacy of "dialect" as a rendering of fāngyán 方言, but is unwilling to mention "topolect" in this article, which is so suitable for it.  Maybe the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TabPFN: A Transformer That Solves Small Tabular Classification Problems
  in a Second]]></title>
        <id>http://arxiv.org/abs/2207.01848</id>
        <link href="http://arxiv.org/abs/2207.01848"/>
        <updated>2023-09-19T03:15:27.394Z</updated>
        <summary type="html"><![CDATA[Noah Hollmann, Samuel M\"uller, Katharina Eggensperger, Frank Hutter]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When AUC meets DRO: Optimizing Partial AUC for Deep Learning with
  Non-Convex Convergence Guarantee]]></title>
        <id>http://arxiv.org/abs/2203.00176</id>
        <link href="http://arxiv.org/abs/2203.00176"/>
        <updated>2023-09-19T03:15:27.389Z</updated>
        <summary type="html"><![CDATA[Dixian Zhu, Gang Li, Bokun Wang, Xiaodong Wu, Tianbao Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive and Robust Multi-Task Learning]]></title>
        <id>http://arxiv.org/abs/2202.05250</id>
        <link href="http://arxiv.org/abs/2202.05250"/>
        <updated>2023-09-19T03:15:27.383Z</updated>
        <summary type="html"><![CDATA[Yaqi Duan, Kaizheng Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SplitEE: Early Exit in Deep Neural Networks with Split Computing]]></title>
        <id>http://arxiv.org/abs/2309.09195</id>
        <link href="http://arxiv.org/abs/2309.09195"/>
        <updated>2023-09-19T03:15:27.378Z</updated>
        <summary type="html"><![CDATA[Divya J. Bajpai, Vivek K. Trivedi, Sohan L. Yadav, Manjesh K.
  Hanawal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring and Learning in Sparse Linear MDPs without Computationally
  Intractable Oracles]]></title>
        <id>http://arxiv.org/abs/2309.09457</id>
        <link href="http://arxiv.org/abs/2309.09457"/>
        <updated>2023-09-19T03:15:27.358Z</updated>
        <summary type="html"><![CDATA[Noah Golowich, Dhruv Rohatgi, Ankur Moitra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A catalogue of genetic mutations to help pinpoint the cause of diseases]]></title>
        <id>https://www.deepmind.com/blog/alphamissense-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases</id>
        <link href="https://www.deepmind.com/blog/alphamissense-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases"/>
        <updated>2023-09-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We've released a catalogue of ‘missense’ mutations where researchers can learn more about what effect they may have. Missense variants are genetic mutations that can affect the function of human proteins. In some cases, they can lead to diseases such as cystic fibrosis, sickle-cell anaemia, or cancer. The AlphaMissense catalogue was developed using AlphaMissense, our new AI model which classifies missense variants.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[postdocs sought for NEMESIS]]></title>
        <id>http://xianblog.wordpress.com/?p=54032</id>
        <link href="https://xianblog.wordpress.com/2023/09/19/postdocs-sought-for-nemesis/"/>
        <updated>2023-09-18T22:23:49.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Grab / Mixed bag of crimes that "hurt the feelings of the Chinese people", part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60634</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60634&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=grab-mixed-bag-of-crimes-that-hurt-the-feelings-of-the-chinese-people-part-2"/>
        <updated>2023-09-18T18:09:39.000Z</updated>
        <summary type="html"><![CDATA[In recent weeks, the odd expression "kǒudài zuì 口袋罪" (lit., "pocket / bag crime"} has become a hot topic).  It's a vague, catch-all term without any juridical / official standing, yet it has left many people troubled over its implications.  To understand why people are unsettled over such a seemingly zany, innocuous term, we will […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Encoding Schemes in FHE]]></title>
        <id>https://jeremykun.com/?p=119941</id>
        <link href="https://jeremykun.com/2023/09/18/encoding-schemes-in-fhe/"/>
        <updated>2023-09-18T18:08:39.000Z</updated>
        <summary type="html"><![CDATA[In cryptography, we need a distinction between a cleartext and a plaintext. A cleartext is a message in its natural form. A plaintext is a cleartext that is represented in a specific way to prepare it for encryption in a specific scheme. The process of taking a cleartext and turning it into a plaintext is […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A new draft…]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60651</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60651&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=60651"/>
        <updated>2023-09-18T13:33:08.000Z</updated>
        <summary type="html"><![CDATA[This is not at all the experience that I've had with multiple-authored papers — but it's funny: “Thanks everyone for comments on the draft, here it is revised with all your edits.” pic.twitter.com/pSV16wQqca — Ben Phillips (@benphillips76) September 17, 2023 And I've sometimes had analogous issues with "copy editing" — see e.g. "Spectrums", 5/24/2022…]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Layer Adaptive Node Selection in Bayesian Neural Networks: Statistical
  Guarantees and Implementation Details]]></title>
        <id>http://arxiv.org/abs/2108.11000</id>
        <link href="http://arxiv.org/abs/2108.11000"/>
        <updated>2023-09-18T03:15:08.261Z</updated>
        <summary type="html"><![CDATA[Sanket Jantre, Shrijita Bhattacharya, Tapabrata Maiti]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Constraint-Free Structure Learning with Smooth Acyclic Orientations]]></title>
        <id>http://arxiv.org/abs/2309.08406</id>
        <link href="http://arxiv.org/abs/2309.08406"/>
        <updated>2023-09-18T03:15:08.219Z</updated>
        <summary type="html"><![CDATA[Riccardo Massidda, Francesco Landolfi, Martina Cinquini, Davide Bacciu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploiting Noise as a Resource for Computation and Learning in Spiking
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.16044</id>
        <link href="http://arxiv.org/abs/2305.16044"/>
        <updated>2023-09-18T03:15:08.214Z</updated>
        <summary type="html"><![CDATA[Gehua Ma, Rui Yan, Huajin Tang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How many Neurons do we need? A refined Analysis for Shallow Networks
  trained with Gradient Descent]]></title>
        <id>http://arxiv.org/abs/2309.08044</id>
        <link href="http://arxiv.org/abs/2309.08044"/>
        <updated>2023-09-18T03:15:08.021Z</updated>
        <summary type="html"><![CDATA[Mike Nguyen, Nicole M\"ucke]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Masked Generative Modeling with Enhanced Sampling Scheme]]></title>
        <id>http://arxiv.org/abs/2309.07945</id>
        <link href="http://arxiv.org/abs/2309.07945"/>
        <updated>2023-09-18T03:15:08.005Z</updated>
        <summary type="html"><![CDATA[Daesoo Lee, Erlend Aune, Sara Malacarne]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[volcanoes of Martinique now UNESCO World heritage]]></title>
        <id>http://xianblog.wordpress.com/?p=54055</id>
        <link href="https://xianblog.wordpress.com/2023/09/18/volcanoes-of-martinique-now-unesco-world-heritage/"/>
        <updated>2023-09-17T22:23:54.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rhetoric as music]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60637</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60637&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rhetoric-as-music"/>
        <updated>2023-09-17T14:25:47.000Z</updated>
        <summary type="html"><![CDATA[From Jon Stewart's 1997 interview with George Carlin (starting at about 1:17.6): Your browser does not support the audio element. well- well uh to- to go backward with the question, don't forget, what we do is oratory. It's rhetoric. It's not just comedy, it's a form of rhetoric and- and with rhetoric, you- you look […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some Old Chinese terms relating to religion, mythology, ritual]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60614</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60614&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=some-old-chinese-terms-relating-to-religion-mythology-ritual"/>
        <updated>2023-09-17T12:25:11.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Axel Schuessler] Some Old Chinese (OC) words that relate to religion, mythology and ritual, and words found in ritual literature (Yijing, Liji, Zhouli), have no Sino-Tibetan (ST) roots, but instead have connections with other language families.     For comparison, the first section of this paper will list (§1) Sino-Tibetan […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[the Amazon turning negative]]></title>
        <id>http://xianblog.wordpress.com/?p=53918</id>
        <link href="https://xianblog.wordpress.com/2023/09/17/the-amazon-turning-negative/"/>
        <updated>2023-09-16T22:23:24.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No sabo kids]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60617</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60617&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=no-sabo-kids"/>
        <updated>2023-09-16T16:54:55.000Z</updated>
        <summary type="html"><![CDATA[Edwin Flores and Maya Brown, "The 'no sabo kids' are pushing back on Spanish-language shaming", NBC News 9/16/2023: A growing group of young Latinos are using TikTok and social media to push back on not speaking perfect Spanish — an attempt to define their identity and heritage on their own terms. […] In recent years, […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hanziyu: The (cursed) Conlang of Characters]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60607</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60607&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hanziyu-the-cursed-conlang-of-characters"/>
        <updated>2023-09-16T11:01:29.000Z</updated>
        <summary type="html"><![CDATA[Fiendishly clever conlang (constructed language) invented by Eleanor Olson. Some Language Log readers will love it, some will hate it.  Most will probably not understand what the devil she is up to with her Hànzìyǔ 汉字语 ("Sinoglyphish"). Natural writing systems are created with the intention of mapping to and recording the sounds of spoken languages.  […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Students' perspectives on computational challenges in physics class]]></title>
        <id>http://arxiv.org/abs/2202.07718</id>
        <link href="http://arxiv.org/abs/2202.07718"/>
        <updated>2023-09-16T02:18:04.010Z</updated>
        <summary type="html"><![CDATA[Patti Hamerski, Daryl McPadden, Marcos D. Caballero, Paul W. Irving]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unigram随机分词：从Viterbi解码到随机采样]]></title>
        <id>https://kexue.fm/archives/9768</id>
        <link href="https://kexue.fm/archives/9768"/>
        <updated>2023-09-16T01:01:00.000Z</updated>
        <summary type="html"><![CDATA[上一篇文章《大词表语言模型在续写任务上的一个问题及对策》发布后，很快就有读者指出可以在训练阶段引入带有随机性的分词结果来解决同样的问题，并且已经有论文和实现。经过进一步查阅学习，笔者发现这是一个...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a day for social good in London]]></title>
        <id>http://xianblog.wordpress.com/?p=53906</id>
        <link href="https://xianblog.wordpress.com/2023/09/16/a-day-for-social-good-in-london/"/>
        <updated>2023-09-15T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[On Thursday, I went (from Paris) to London for the final day of Warwick DSSGx UK 2023 (Data Science for Social Good), which took place in The Shard, the tallest building in London (and certainly not the prettiest!), where the Warwick Business School has offices, and on the way, stopped by the nearby Tate Modern […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MediaPipe FaceStylizer: On-device real-time few-shot face stylization]]></title>
        <id>http://blog.research.google/2023/09/mediapipe-facestylizer-on-device-real.html</id>
        <link href="http://blog.research.google/2023/09/mediapipe-facestylizer-on-device-real.html"/>
        <updated>2023-09-15T17:39:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Haolin Jia, Software Engineer, and Qifei Wang, Senior Software Engineer, Core ML



In recent years, we have witnessed rising interest across consumers and researchers in integrated augmented reality (AR) experiences using real-time face feature generation and editing functions in mobile applications, including short videos, virtual reality, and gaming. As a result, there is a growing demand for lightweight, yet high-quality face generation and editing models, which are often based on generative adversarial network (GAN) techniques. However, the majority of GAN models suffer from high computational complexity and the need for a large training dataset. In addition, it is also important to employ GAN models responsibly. 



In this post, we introduce MediaPipe FaceStylizer, an effi…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Benchmark Analysis of Representative Deep Neural Network Architectures]]></title>
        <id>http://arxiv.org/abs/1810.00736</id>
        <link href="http://arxiv.org/abs/1810.00736"/>
        <updated>2023-09-15T17:12:59.614Z</updated>
        <summary type="html"><![CDATA[Simone Bianco, Remi Cadene, Luigi Celona, Paolo Napoletano]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pseudo-finite sets, pseudo-o-minimality]]></title>
        <id>http://arxiv.org/abs/1908.01660</id>
        <link href="http://arxiv.org/abs/1908.01660"/>
        <updated>2023-09-15T17:12:58.902Z</updated>
        <summary type="html"><![CDATA[Nadav Meir]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Euler systems for GSp(4)]]></title>
        <id>http://arxiv.org/abs/1706.00201</id>
        <link href="http://arxiv.org/abs/1706.00201"/>
        <updated>2023-09-15T17:12:58.883Z</updated>
        <summary type="html"><![CDATA[David Loeffler, Chris Skinner, Sarah Livia Zerbes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complete type amalgamation for non-standard finite groups]]></title>
        <id>http://arxiv.org/abs/2009.08967</id>
        <link href="http://arxiv.org/abs/2009.08967"/>
        <updated>2023-09-15T17:12:58.070Z</updated>
        <summary type="html"><![CDATA[Amador Martin-Pizarro, Daniel Palac\'in]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Scratch to Teach Undergraduate Students' Skills on Artificial
  Intelligence]]></title>
        <id>http://arxiv.org/abs/1904.00296</id>
        <link href="http://arxiv.org/abs/1904.00296"/>
        <updated>2023-09-15T17:12:58.065Z</updated>
        <summary type="html"><![CDATA[Julian Estevez, Gorka Garate, JM Lopez Guede, Manuel Gra\~na]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Denny Zhou - Teach language models to reason]]></title>
        <id>https://mlfoundations.org/talk/denny/</id>
        <link href="https://mlfoundations.org/talk/denny/"/>
        <updated>2023-09-15T14:15:00.000Z</updated>
        <summary type="html"><![CDATA[Over the past decades, the machine learning community has developed tons of data-driven techniques aimed at enhancing learning efficiency, like semi-supervised learning, meta learning, active learning, transfer learning, and more. However, none of these techniques have proven to be highly effective for real-world natural language processing tasks. This shortcoming uncovers a fundamental flaw in machine learning - the absence of reasoning. Humans often learn from just a few examples because of their capacity to reason, as opposed to relying on data statistics. In this talk, I will talk about the large language models (LLM) reasoning work that we pioneered, and show that the techniques we developed can greatly narrow the gap between human intelligence and machine learning - crushed SoTA in the literature while demanding only a few annotated examples and no training. Our work was presented by Google CEO Sundar Pichai at Google I/O 2022 as a showcase of Google AI.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How do you say "polo", "logo", and "erase with Photoshop" in Chinese?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60597</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60597&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-do-you-say-polo-logo-and-erase-with-photoshop-in-chinese"/>
        <updated>2023-09-15T10:45:46.000Z</updated>
        <summary type="html"><![CDATA["Hebei official’s shirt logo removed for ‘aesthetic reasons,’ triggering speculation among netizens" By Global Times (Sep 05, 2023) Official photos of a city Party chief in North China's Hebei Province, with his shirt's logo removed by editing, have sparked a wide-ranging discussion among Chinese netizens, with some speculating that it was a move to obscure […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test Your Intuition 53 by Ehud Friedgut: Which Way to Ride Your Bike]]></title>
        <id>http://gilkalai.wordpress.com/?p=24686</id>
        <link href="https://gilkalai.wordpress.com/2023/09/15/test-your-intuition-53-by-ehud-friedgut-which-way-to-ride-your-bike/"/>
        <updated>2023-09-15T06:26:18.000Z</updated>
        <summary type="html"><![CDATA[This post was kindly written by Ehud Friedgut. Shana Tova (= Happy New Jewish Year) to all our readers. The following is a real-life question. I recently rode my bike around a closed track. The track consists of a flat … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test Your Intuition 53 by Ehud Friedgut: Which Way to Ride Your Bike]]></title>
        <id>http://gilkalai.wordpress.com/?p=24686</id>
        <link href="https://gilkalai.wordpress.com/2023/09/15/test-your-intuition-53-by-ehud-friedgut-which-way-to-ride-your-bike/"/>
        <updated>2023-09-15T06:26:18.000Z</updated>
        <summary type="html"><![CDATA[This post was kindly written by Ehud Friedgut. Shana Tova (= Happy New Jewish Year) to all our readers. The following is a real-life question. I recently rode my bike around a closed track. The track consists of a flat … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up Learning Quantum States through Group Equivariant
  Convolutional Quantum Ans\"atze]]></title>
        <id>http://arxiv.org/abs/2112.07611</id>
        <link href="http://arxiv.org/abs/2112.07611"/>
        <updated>2023-09-15T03:15:04.999Z</updated>
        <summary type="html"><![CDATA[Han Zheng, Zimu Li, Junyu Liu, Sergii Strelchuk, Risi Kondor]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Source Domain Adaptation meets Dataset Distillation through
  Dataset Dictionary Learning]]></title>
        <id>http://arxiv.org/abs/2309.07666</id>
        <link href="http://arxiv.org/abs/2309.07666"/>
        <updated>2023-09-15T03:15:04.843Z</updated>
        <summary type="html"><![CDATA[Eduardo Fernandes Montesuma, Fred Ngol\`e Mboula, Antoine Souloumiac]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Benign Overfitting without Linearity: Neural Network Classifiers Trained
  by Gradient Descent for Noisy Linear Data]]></title>
        <id>http://arxiv.org/abs/2202.05928</id>
        <link href="http://arxiv.org/abs/2202.05928"/>
        <updated>2023-09-15T03:15:04.814Z</updated>
        <summary type="html"><![CDATA[Spencer Frei, Niladri S. Chatterji, Peter L. Bartlett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On a continuous time model of gradient descent dynamics and instability
  in deep learning]]></title>
        <id>http://arxiv.org/abs/2302.01952</id>
        <link href="http://arxiv.org/abs/2302.01952"/>
        <updated>2023-09-15T03:15:04.668Z</updated>
        <summary type="html"><![CDATA[Mihaela Rosca, Yan Wu, Chongli Qin, Benoit Dherin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random Feature Amplification: Feature Learning and Generalization in
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2202.07626</id>
        <link href="http://arxiv.org/abs/2202.07626"/>
        <updated>2023-09-15T03:15:04.656Z</updated>
        <summary type="html"><![CDATA[Spencer Frei, Niladri S. Chatterji, Peter L. Bartlett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[junior position in statistics and econometrics at ESSEC, Cergy-Pontoise]]></title>
        <id>http://xianblog.wordpress.com/?p=54028</id>
        <link href="https://xianblog.wordpress.com/2023/09/15/junior-position-in-statistics-and-econometrics-at-essec-cergy-pontoise/"/>
        <updated>2023-09-14T22:23:24.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On-device content distillation with graph neural networks]]></title>
        <id>http://blog.research.google/2023/09/on-device-content-distillation-with.html</id>
        <link href="http://blog.research.google/2023/09/on-device-content-distillation-with.html"/>
        <updated>2023-09-14T19:39:00.031Z</updated>
        <summary type="html"><![CDATA[Posted by Gabriel Barcik and Duc-Hieu Tran, Research Engineers, Google Research




In today's digital age, smartphones and desktop web browsers serve as the primary tools for accessing news and information. However, the proliferation of website clutter — encompassing complex layouts, navigation elements, and extraneous links — significantly impairs both the reading experience and article navigation. This issue is particularly acute for individuals with accessibility requirements.



To improve the user experience and make reading more accessible, Android and Chrome users may leverage the Reading Mode feature, which enhances accessibility by processing webpages to allow customizable contrast, adjustable text size, more legible fonts, and to enable text-to-speech utilities. Additionally, An…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mongolian language genocide]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60560</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60560&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mongolian-language-genocide"/>
        <updated>2023-09-14T09:55:52.000Z</updated>
        <summary type="html"><![CDATA[During the past few weeks, we've looked at the throttling of Cantonese in Hong Kong.  Now, far to the north of the Chinese empire, the CCP is ramping up the war against Mongolian: Inner Mongolia: China accused of 'cultural genocide' for school language shift Debi Edward, ITV News (9/1/23) —- Inner Mongolia is the latest province in China where […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Comparative Analysis of Contextual Relation Extraction based on Deep
  Learning Models]]></title>
        <id>http://arxiv.org/abs/2309.06814</id>
        <link href="http://arxiv.org/abs/2309.06814"/>
        <updated>2023-09-14T02:20:32.196Z</updated>
        <summary type="html"><![CDATA[R.Priyadharshini, G.Jeyakodi, P.Shanthi Bala]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Imprecise Bayesian Neural Networks]]></title>
        <id>http://arxiv.org/abs/2302.09656</id>
        <link href="http://arxiv.org/abs/2302.09656"/>
        <updated>2023-09-14T02:20:24.599Z</updated>
        <summary type="html"><![CDATA[Michele Caprio, Souradeep Dutta, Kuk Jin Jang, Vivian Lin, Radoslav
  Ivanov, Oleg Sokolsky, Insup Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Energy-Based Models by Cooperative Diffusion Recovery
  Likelihood]]></title>
        <id>http://arxiv.org/abs/2309.05153</id>
        <link href="http://arxiv.org/abs/2309.05153"/>
        <updated>2023-09-14T02:20:14.214Z</updated>
        <summary type="html"><![CDATA[Yaxuan Zhu, Jianwen Xie, Yingnian Wu, Ruiqi Gao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Supervised Machine Learning and Physics based Machine Learning approach
  for prediction of peak temperature distribution in Additive Friction Stir
  Deposition of Aluminium Alloy]]></title>
        <id>http://arxiv.org/abs/2309.06838</id>
        <link href="http://arxiv.org/abs/2309.06838"/>
        <updated>2023-09-14T02:20:14.214Z</updated>
        <summary type="html"><![CDATA[Akshansh Mishra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised Contrast-Consistent Ranking with Language Models]]></title>
        <id>http://arxiv.org/abs/2309.06991</id>
        <link href="http://arxiv.org/abs/2309.06991"/>
        <updated>2023-09-14T02:20:13.485Z</updated>
        <summary type="html"><![CDATA[Niklas Stoehr, Pengxiang Cheng, Jing Wang, Daniel Preotiuc-Pietro,
  Rajarshi Bhowmik]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-compositional compounds of the week]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60581</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60581&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=semi-compositional-compounds-of-the-week"/>
        <updated>2023-09-13T23:57:40.000Z</updated>
        <summary type="html"><![CDATA[I've previously written more than once about the problem of compound words whose meaning is partly but not entirely related to the meanings of their parts, often referring back to a passage in my 1992 chapter with Richard Sproat, "The Stress and Structure of Modified Noun Phrases in English": We now turn to N0 compounds where […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[no [Google] play]]></title>
        <id>http://xianblog.wordpress.com/?p=53774</id>
        <link href="https://xianblog.wordpress.com/2023/09/14/no-google-play/"/>
        <updated>2023-09-13T22:23:36.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inter-syllable intervals]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60563</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60563&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=inter-syllable-intervals"/>
        <updated>2023-09-13T18:18:28.000Z</updated>
        <summary type="html"><![CDATA[This is a simple-minded follow-up to "New models of speech timing?" (9/11/2023). Before getting into fancy stochastic-point-process models, neural or otherwise, I though I'd start with something really basic: just the distribution of inter-syllable intervals, and its relationship to overall speech-segment and silence-segment durations. For data, I took one-minute samples from 2006 TED talks by […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Verifiers]]></title>
        <id>https://jeremykun.com/?p=119898</id>
        <link href="https://jeremykun.com/2023/09/13/mlir-verifiers/"/>
        <updated>2023-09-13T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents Last time we defined folders and used them to enable some canonicalization and the sccp constant propagation pass for the poly dialect. This time we’ll add some additional safety checks to the dialect in the form of verifiers. The code for this article is in this pull request, and as usual the […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[大词表语言模型在续写任务上的一个问题及对策]]></title>
        <id>https://kexue.fm/archives/9762</id>
        <link href="https://kexue.fm/archives/9762"/>
        <updated>2023-09-13T13:22:00.000Z</updated>
        <summary type="html"><![CDATA[对于LLM来说，通过增大Tokenizer的词表来提高压缩率，从而缩短序列长度、降低解码成本，是大家都喜闻乐见的事情。毕竟增大词表只需要增大Embedding层和输出的Dense层，这部分增加的...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Overall, why do Mandarin enrollments continue to decline?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60540</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60540&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=overall-why-do-mandarin-enrollments-continue-to-decline"/>
        <updated>2023-09-13T10:41:57.000Z</updated>
        <summary type="html"><![CDATA[This is a problem that has been troubling colleagues across the country. "Why fewer university students are studying Mandarin" Learning the difficult language does not seem as worthwhile as it once did Economist (Aug 24th 2023) China | How do you say “not interested”? Ten years ago Mandarin, the mother tongue of most Chinese, was […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Consistency and adaptivity are complementary targets for the validation
  of variance-based uncertainty quantification metrics in machine learning
  regression tasks]]></title>
        <id>http://arxiv.org/abs/2309.06240</id>
        <link href="http://arxiv.org/abs/2309.06240"/>
        <updated>2023-09-13T04:17:39.712Z</updated>
        <summary type="html"><![CDATA[Pascal Pernot]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Out-of-distribution detection for regression tasks: parameter versus
  predictor entropy]]></title>
        <id>http://arxiv.org/abs/2010.12995</id>
        <link href="http://arxiv.org/abs/2010.12995"/>
        <updated>2023-09-13T04:17:39.704Z</updated>
        <summary type="html"><![CDATA[Yann Pequignot, Mathieu Alain, Patrick Dallaire, Alireza
  Yeganehparast, Pascal Germain, Jos\'ee Desharnais, Fran\c{c}ois Laviolette]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ModuleFormer: Modularity Emerges from Mixture-of-Experts]]></title>
        <id>http://arxiv.org/abs/2306.04640</id>
        <link href="http://arxiv.org/abs/2306.04640"/>
        <updated>2023-09-13T04:17:39.578Z</updated>
        <summary type="html"><![CDATA[Yikang Shen, Zheyu Zhang, Tianyou Cao, Shawn Tan, Zhenfang Chen,
  Chuang Gan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Path classification by stochastic linear recurrent neural networks]]></title>
        <id>http://arxiv.org/abs/2108.03090</id>
        <link href="http://arxiv.org/abs/2108.03090"/>
        <updated>2023-09-13T04:17:39.571Z</updated>
        <summary type="html"><![CDATA[Wiebke Bartolomaeus, Youness Boutaib, Sandra Nestler, Holger Rauhut]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep-OSG: Deep Learning of Operators in Semigroup]]></title>
        <id>http://arxiv.org/abs/2302.03358</id>
        <link href="http://arxiv.org/abs/2302.03358"/>
        <updated>2023-09-13T04:17:39.539Z</updated>
        <summary type="html"><![CDATA[Junfeng Chen, Kailiang Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[snowballs in summer]]></title>
        <id>http://xianblog.wordpress.com/?p=53885</id>
        <link href="https://xianblog.wordpress.com/2023/09/13/snowballs-in-summer/"/>
        <updated>2023-09-12T22:23:59.000Z</updated>
        <summary type="html"><![CDATA[A new arXival on nested sampling, Snowballing Nested Sampling by Johannes Buchner, just appeared. The idea behind this short note is to increase the number of “live” points at each iteration. (How?! Depending on how the different additions are dependent, the effective sample size will vary.) This exacerbates the tendency of the algorithm to concentrate […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[World scale inverse reinforcement learning in Google Maps]]></title>
        <id>http://blog.research.google/2023/09/world-scale-inverse-reinforcement.html</id>
        <link href="http://blog.research.google/2023/09/world-scale-inverse-reinforcement.html"/>
        <updated>2023-09-12T21:22:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Matt Barnes, Software Engineer, Google Research




Routing in Google Maps remains one of our most helpful and frequently used features. Determining the best route from A to B requires making complex trade-offs between factors including the estimated time of arrival (ETA), tolls, directness, surface conditions (e.g., paved, unpaved roads), and user preferences, which vary across transportation mode and local geography. Often, the most natural visibility we have into travelers' preferences is by analyzing real-world travel patterns.



Learning preferences from observed sequential decision making behavior is a classic application of inverse reinforcement learning (IRL). Given a Markov decision process (MDP) — a formalization of the road network — and a set of demonstration traject…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chatbot censorship in China]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60536</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60536&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatbot-censorship-in-china"/>
        <updated>2023-09-12T19:44:32.000Z</updated>
        <summary type="html"><![CDATA["Elusive Ernie: China's new chatbot has a censorship problem"    By Stephen McDonell, BBC, 1 day ago It seems that Ernie's favorite response is "Let's talk about something else", particularly when you ask it a "difficult" question. For example, Ernie seemed baffled by the question: "Why is Xi Jinping not attending the upcoming G20 meeting?" […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[One Year of PyTorch Foundation]]></title>
        <id>https://pytorch.org/blog/one-year-pytorch/</id>
        <link href="https://pytorch.org/blog/one-year-pytorch/"/>
        <updated>2023-09-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[It’s been one year since we announced the formation of the PyTorch Foundation! 🎉]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[remember Allende]]></title>
        <id>http://xianblog.wordpress.com/?p=54015</id>
        <link href="https://xianblog.wordpress.com/2023/09/12/remember-allende/"/>
        <updated>2023-09-11T22:23:21.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Folders and Constant Propagation]]></title>
        <id>https://jeremykun.com/?p=119834</id>
        <link href="https://jeremykun.com/2023/09/11/mlir-folders/"/>
        <updated>2023-09-11T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents Last time we saw how to use pre-defined MLIR traits to enable upstream MLIR passes like loop-invariant-code-motion to apply to poly programs. We left out -sccp (sparse conditional constant propagation), and so this time we’ll add what is needed to make that pass work. It requires the concept of folding. The code […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New models of speech timing?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60543</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60543&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=new-models-of-speech-timing"/>
        <updated>2023-09-11T13:57:01.000Z</updated>
        <summary type="html"><![CDATA[There are many statistics used to characterize timing patterns in speech, at various scales, with applications in many areas. Among them: Intervals  between phonetic events, by category and/or position and/or context; Overall measures of speaking rate (words per minute, syllables per minute), relative to total time or total speaking time (leaving out silences); Mean and […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Network Revenue Management with Demand Learning and Fair
  Resource-Consumption Balancing]]></title>
        <id>http://arxiv.org/abs/2207.11159</id>
        <link href="http://arxiv.org/abs/2207.11159"/>
        <updated>2023-09-11T04:17:31.064Z</updated>
        <summary type="html"><![CDATA[Xi Chen, Jiameng Lyu, Yining Wang, Yuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Rate of Kernel Regression in Large Dimensions]]></title>
        <id>http://arxiv.org/abs/2309.04268</id>
        <link href="http://arxiv.org/abs/2309.04268"/>
        <updated>2023-09-11T02:20:52.531Z</updated>
        <summary type="html"><![CDATA[Weihao Lu, Haobo Zhang, Yicheng Li, Manyun Xu, Qian Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Distributed Kernel Ridge Regression: A Feasible Distributed
  Learning Scheme for Data Silos]]></title>
        <id>http://arxiv.org/abs/2309.04236</id>
        <link href="http://arxiv.org/abs/2309.04236"/>
        <updated>2023-09-11T02:20:51.236Z</updated>
        <summary type="html"><![CDATA[Di Wang, Xiaotong Liu, Shao-Bo Lin, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Actor critic learning algorithms for mean-field control with moment
  neural networks]]></title>
        <id>http://arxiv.org/abs/2309.04317</id>
        <link href="http://arxiv.org/abs/2309.04317"/>
        <updated>2023-09-11T02:20:51.167Z</updated>
        <summary type="html"><![CDATA[Huy\^en Pham, Xavier Warin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization Bounds: Perspectives from Information Theory and
  PAC-Bayes]]></title>
        <id>http://arxiv.org/abs/2309.04381</id>
        <link href="http://arxiv.org/abs/2309.04381"/>
        <updated>2023-09-11T02:20:51.160Z</updated>
        <summary type="html"><![CDATA[Fredrik Hellstr\"om, Giuseppe Durisi, Benjamin Guedj, Maxim Raginsky]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Postprocessing of Ensemble Weather Forecasts Using Permutation-invariant
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2309.04452</id>
        <link href="http://arxiv.org/abs/2309.04452"/>
        <updated>2023-09-11T02:20:50.965Z</updated>
        <summary type="html"><![CDATA[Kevin H\"ohlein, Benedikt Schulz, R\"udiger Westermann, Sebastian
  Lerch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[support for Moroccans]]></title>
        <id>http://xianblog.wordpress.com/?p=54012</id>
        <link href="https://xianblog.wordpress.com/2023/09/11/support-for-moroccans/"/>
        <updated>2023-09-10T22:23:20.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A new, old letter:  spellings and the pronoun wars, part ∞]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60531</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60531&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-new-old-letter-spellings-and-the-pronoun-wars-part-%25e2%2588%259e"/>
        <updated>2023-09-10T15:59:10.000Z</updated>
        <summary type="html"><![CDATA[Thæ're serious: Why There's A Campaign To Re-Introduce A Historic Letter Back Into The Alphabet It all stems from Old English By Kate Nicholson, HuffPost (9/6/23) FWIW: A new campaign hopes to make day-to-day life more gender-inclusive by reintroducing the ancient symbol Æ back into the alphabet. Five global organisations, Divergenres, Aunt Nell, Gender X, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spin and spin current -- From fundamentals to recent progress]]></title>
        <id>http://arxiv.org/abs/2211.02241</id>
        <link href="http://arxiv.org/abs/2211.02241"/>
        <updated>2023-09-10T01:07:00.584Z</updated>
        <summary type="html"><![CDATA[Sadamichi Maekawa, Takashi Kikkawa, Hiroyuki Chudo, Jun'ichi Ieda,
  Eiji Saitoh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[scikit-learn 2023 In-person Developer Sprint in Paris, France]]></title>
        <id>https://blog.scikit-learn.org/events/paris-dev-sprint/</id>
        <link href="https://blog.scikit-learn.org/events/paris-dev-sprint/"/>
        <updated>2023-09-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Author: Reshama Shaikh , François Goupil]]></summary>
        <author>
            <name>scikit-learn Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[approximate computation for exact statistical inference from differentially private data]]></title>
        <id>http://xianblog.wordpress.com/?p=53876</id>
        <link href="https://xianblog.wordpress.com/2023/09/10/approximate-computation-for-exact-statistical-inference-from-differentially-private-data/"/>
        <updated>2023-09-09T22:23:35.000Z</updated>
        <summary type="html"><![CDATA[“the employment of ABC for differentially private data serendipitously eradicates the “approximate” nature of the resulting posterior  samples, which otherwise would be the case if the data were noise-free.” In parallel or conjunction with the 23w5601 workshop, I was reading some privacy literature and came across this Exact inference with approximate computation for differentially private […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hurrian hymn from Ugarit, Canaan in northern Syria, 1400 BC]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60527</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60527&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hurrian-hymn-from-ugarit-canaan-in-northern-syria-1400-bc"/>
        <updated>2023-09-09T11:52:06.000Z</updated>
        <summary type="html"><![CDATA["The Oldest (Known) Song of All Time" Includes spectrograms of different reconstructions. Although this YouTube was made three years ago, I am calling it to the attention of Language Log readers now that I know about it because it draws together many themes we have discussed in previous posts. Note by the author, hochelaga: The […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerated CPU Inference with PyTorch Inductor using torch.compile]]></title>
        <id>https://pytorch.org/blog/accelerated-cpu-inference/</id>
        <link href="https://pytorch.org/blog/accelerated-cpu-inference/"/>
        <updated>2023-09-09T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Story at a Glance]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inverted writing in video subtitles:  traditional cotton processing]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60523</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60523&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=inverted-writing-in-video-subtitles-traditional-cotton-processing"/>
        <updated>2023-09-09T00:53:03.000Z</updated>
        <summary type="html"><![CDATA[In an off-topic comment (4/27/08), DDeden requested an English translation of the subtitles of a video about "Cotton: from fluff to dyed cloth the traditional Chinese way" (the video is embedded in this tweet).  It seemed a worthwhile endeavor, since the film itself was visually quite informative, though the subtitles looked rather sketchy. I asked […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially private median and more]]></title>
        <id>http://blog.research.google/2023/09/differentially-private-median-and-more.html</id>
        <link href="http://blog.research.google/2023/09/differentially-private-median-and-more.html"/>
        <updated>2023-09-08T22:59:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Edith Cohen and Uri Stemmer, Research Scientists, Google Research





Differential privacy (DP) is a rigorous mathematical definition of privacy. DP algorithms are randomized to protect user data by ensuring that the probability of any particular output is nearly unchanged when a data point is added or removed. Therefore, the output of a DP algorithm does not disclose the presence of any one data point. There has been significant progress in both foundational research and adoption of differential privacy with contributions such as the Privacy Sandbox and Google Open Source Library.


ML and data analytics algorithms can often be described as performing multiple basic computation steps on the same dataset. When each such step is differentially private, so is the output, but with …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rushbrook Harbour, Prince Rupert j́atp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53831</id>
        <link href="https://xianblog.wordpress.com/2023/09/09/rushbrook-harbour-prince-rupert-jatp/"/>
        <updated>2023-09-08T22:23:14.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tom Goldstein - Dataset security issues in generative AI]]></title>
        <id>https://mlfoundations.org/talk/tom/</id>
        <link href="https://mlfoundations.org/talk/tom/"/>
        <updated>2023-09-08T14:15:00.000Z</updated>
        <summary type="html"><![CDATA[Machine learning systems are built using large troves of training data that may contain private or copyrighted content. In this talk, I'll survey a number of security issues that arise when sensitive data is used. I'll begin by talking about attack methods that extract private training data from federated learning protocols. Then, I'll discuss data privacy issues that arise when using generative models. These models are often created using a training objective that explicitly promotes their ability to regenerate their training data, causing a host of issues.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Black Hand:  Language Log foretells the future]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60519</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60519&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=black-hand-language-log-foretells-the-future"/>
        <updated>2023-09-08T11:43:48.000Z</updated>
        <summary type="html"><![CDATA[From Brian Miller: I believe it was your comment here on a 2019 use of a phrase in China politics or press “Thus my second surmise was that, by 'black hand', the CCP / PRC mean 'stealthy manipulator who remains totally out of view'.  But how does it get that meaning in Chinese?” I think […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Metric Learning with Chance Constraints]]></title>
        <id>http://arxiv.org/abs/2209.09060</id>
        <link href="http://arxiv.org/abs/2209.09060"/>
        <updated>2023-09-08T02:20:06.402Z</updated>
        <summary type="html"><![CDATA[Yeti Z. Gurbuz, Ogul Can, A. Aydin Alatan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and
  Luck]]></title>
        <id>http://arxiv.org/abs/2309.03800</id>
        <link href="http://arxiv.org/abs/2309.03800"/>
        <updated>2023-09-08T02:20:06.095Z</updated>
        <summary type="html"><![CDATA[Benjamin L. Edelman, Surbhi Goel, Sham Kakade, Eran Malach, Cyril
  Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural lasso: a unifying approach of lasso and neural networks]]></title>
        <id>http://arxiv.org/abs/2309.03770</id>
        <link href="http://arxiv.org/abs/2309.03770"/>
        <updated>2023-09-08T02:20:06.089Z</updated>
        <summary type="html"><![CDATA[David Delgado, Ernesto Curbelo, Danae Carreras]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enhancing Pipeline-Based Conversational Agents with Large Language
  Models]]></title>
        <id>http://arxiv.org/abs/2309.03748</id>
        <link href="http://arxiv.org/abs/2309.03748"/>
        <updated>2023-09-08T02:20:04.935Z</updated>
        <summary type="html"><![CDATA[Mina Foosherian, Hendrik Purwins, Purna Rathnayake, Touhidul Alam, Rui
  Teimao, Klaus-Dieter Thoben]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adversarially Robust Deep Learning with Optimal-Transport-Regularized
  Divergences]]></title>
        <id>http://arxiv.org/abs/2309.03791</id>
        <link href="http://arxiv.org/abs/2309.03791"/>
        <updated>2023-09-08T02:20:04.929Z</updated>
        <summary type="html"><![CDATA[Jeremiah Birrell, Mohammadreza Ebrahimi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[back to horizon]]></title>
        <id>http://xianblog.wordpress.com/?p=54001</id>
        <link href="https://xianblog.wordpress.com/2023/09/08/back-to-horizon/"/>
        <updated>2023-09-07T22:23:22.000Z</updated>
        <summary type="html"><![CDATA[“[the UK rejoining Horizon Europe programme is] fantastic news not just for the UK but for scientists across the EU and for all the people of Europe”. Sir Adrian Smith, president of the Royal Society The EU and the UK Government have come to an agreement on the UK rejoining the Horizon Europe funding programme […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A novel computational fluid dynamics framework for turbulent flow research]]></title>
        <id>http://blog.research.google/2023/09/a-novel-computational-fluid-dynamics.html</id>
        <link href="http://blog.research.google/2023/09/a-novel-computational-fluid-dynamics.html"/>
        <updated>2023-09-07T22:03:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Shantanu Shahane, Software Engineer, and Matthias Ihme, Research Scientist, Athena Team




Turbulence is ubiquitous in environmental and engineering fluid flows, and is encountered routinely in everyday life. A better understanding of these turbulent processes could provide valuable insights across a variety of research areas — improving the prediction of cloud formation by atmospheric transport and the spreading of wildfires by turbulent energy exchange, understanding sedimentation of deposits in rivers, and improving the efficiency of combustion in aircraft engines to reduce emissions, to name a few. However, despite its importance, our current understanding and our ability to reliably predict such flows remains limited. This is mainly attributed to the highly chaotic nature a…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Using Traits]]></title>
        <id>https://jeremykun.com/?p=119774</id>
        <link href="https://jeremykun.com/2023/09/07/mlir-using-traits/"/>
        <updated>2023-09-07T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents Last time we defined a new dialect poly for polynomial arithmetic. This time we’ll spruce up the dialect by adding some pre-defined MLIR traits, and see how the application of traits enables some general purpose passes to optimize poly programs. The code for this article is in this pull request, and as […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On-the-job jargon]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60516</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60516&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=on-the-job-jargon"/>
        <updated>2023-09-07T12:11:31.000Z</updated>
        <summary type="html"><![CDATA[There seem to be a lot of people complaining about it these days, so maybe there's something to worry about here.  Francois Lang, who called this current wave of criticism to my attention asks whether academia is isolated from such horrors. FWIW, here's what it's like in business: "A look at the most annoying workplace […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BytePiece：更纯粹、更高压缩率的Tokenizer]]></title>
        <id>https://kexue.fm/archives/9752</id>
        <link href="https://kexue.fm/archives/9752"/>
        <updated>2023-09-07T07:05:00.000Z</updated>
        <summary type="html"><![CDATA[目前在LLM中最流行的Tokenizer（分词器）应该是Google的SentencePiece了，因为它符合Tokenizer的一些理想特性，比如语言无关、数据驱动等，并且由于它是C++写的，...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Variational Models with Unrolling and Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2209.12651</id>
        <link href="http://arxiv.org/abs/2209.12651"/>
        <updated>2023-09-07T02:19:38.123Z</updated>
        <summary type="html"><![CDATA[Christoph Brauer, Niklas Breustedt, Timo de Wolff, Dirk A. Lorenz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Active Subspaces for Effective and Scalable Uncertainty
  Quantification in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2309.03061</id>
        <link href="http://arxiv.org/abs/2309.03061"/>
        <updated>2023-09-07T02:19:38.046Z</updated>
        <summary type="html"><![CDATA[Sanket Jantre, Nathan M. Urban, Xiaoning Qian, Byung-Jun Yoon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explaining the Behavior of Black-Box Prediction Algorithms with Causal
  Learning]]></title>
        <id>http://arxiv.org/abs/2006.02482</id>
        <link href="http://arxiv.org/abs/2006.02482"/>
        <updated>2023-09-07T02:19:34.348Z</updated>
        <summary type="html"><![CDATA[Numair Sani, Daniel Malinsky, Ilya Shpitser]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Topological Deep Learning Framework for Neural Spike Decoding]]></title>
        <id>http://arxiv.org/abs/2212.05037</id>
        <link href="http://arxiv.org/abs/2212.05037"/>
        <updated>2023-09-07T02:19:34.335Z</updated>
        <summary type="html"><![CDATA[Edward C. Mitchell, Brittany Story, David Boothe, Piotr J.
  Franaszczuk, Vasileios Maroulas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayes-optimal Learning of Deep Random Networks of Extensive-width]]></title>
        <id>http://arxiv.org/abs/2302.00375</id>
        <link href="http://arxiv.org/abs/2302.00375"/>
        <updated>2023-09-07T02:19:34.330Z</updated>
        <summary type="html"><![CDATA[Hugo Cui, Florent Krzakala, Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[data science ≠ algebra ???]]></title>
        <id>http://xianblog.wordpress.com/?p=53505</id>
        <link href="https://xianblog.wordpress.com/2023/09/07/data-science-%e2%89%a0-algebra/"/>
        <updated>2023-09-06T22:23:43.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Policeman to Tesla driver:  “It Is a Bit Ridiculous, But You Must Obey”]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60508</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60508&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=policeman-to-tesla-driver-it-is-a-bit-ridiculous-but-you-must-obey"/>
        <updated>2023-09-06T21:22:15.000Z</updated>
        <summary type="html"><![CDATA[9月1日，杭州高架禁止特斯拉通行。车主吐槽“这有点搞笑了呀”交警回复“是有点搞笑但是你要服从” pic.twitter.com/z7Tm7cN1Yi — 李老师不是你老师 (@whyyoutouzhele) September 1, 2023 The text says: 9 yuè 1 rì, Hángzhōu gāojià jìnzhǐ Tèsīlā tōngxíng.Chēzhǔ tǔcáo “Zhè yǒudiǎn gǎoxiàole ya”. Jiāojǐng huífù “Shì yǒudiǎn gǎoxiào dànshì nǐ yào fúcóng. 9月1日，杭州高架禁止特斯拉通行。车主吐槽“这有点搞笑了呀”交警回复“是有点搞笑但是你要服从” On September 1, a Tesla was banned from passing through the Hangzhou Elevated Highway.The car owner complained, "This is a bit […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TSMixer: An all-MLP architecture for time series forecasting]]></title>
        <id>http://blog.research.google/2023/09/tsmixer-all-mlp-architecture-for-time.html</id>
        <link href="http://blog.research.google/2023/09/tsmixer-all-mlp-architecture-for-time.html"/>
        <updated>2023-09-06T19:47:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Si-An Chen, Student Researcher, Cloud AI Team, and Chun-Liang Li, Research Scientist, Cloud AI Team




Time series forecasting is critical to various real-world applications, from demand forecasting to pandemic spread prediction. In multivariate time series forecasting (forecasting multiple variants at the same time), one can split existing methods into two categories: univariate models and multivariate models. Univariate models focus on inter-series interactions or temporal patterns that encompass trends and seasonal patterns on a time series with a single variable. Examples of such trends and seasonal patterns might be the way mortgage rates increase due to inflation, and how traffic peaks during rush hour. In addition to inter-series patterns, multivariate models process intr…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graphcore Joins the PyTorch Foundation as a General Member]]></title>
        <id>https://pytorch.org/blog/graphcore-joins-pytorch/</id>
        <link href="https://pytorch.org/blog/graphcore-joins-pytorch/"/>
        <updated>2023-09-06T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[<div type="html"/>]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computing Percentages Easier]]></title>
        <id>https://jeremykun.com/?p=119800</id>
        <link href="https://jeremykun.com/2023/09/05/computing-percentages-easier/"/>
        <updated>2023-09-06T04:47:37.000Z</updated>
        <summary type="html"><![CDATA[Problem: Compute 16% of 25 in your head. Solution: 16% of 25 is equivalent to 25% of 16, which is clearly 4. This is true for all numbers: $x\%$ of $y$ is always equal to $y\%$ of $x$. The first one is $\frac{x}{100} y$ and the second is $\frac{y}{100}x$, and because multiplication is commutative and […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalizations of local bijectivity of Keller maps and a proof of
  $2$-dimensional Jacobian conjecture]]></title>
        <id>http://arxiv.org/abs/1603.01867</id>
        <link href="http://arxiv.org/abs/1603.01867"/>
        <updated>2023-09-06T03:14:50.079Z</updated>
        <summary type="html"><![CDATA[Yucai Su]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Margulis cusps of hyperbolic 4-manifolds]]></title>
        <id>http://arxiv.org/abs/1304.5316</id>
        <link href="http://arxiv.org/abs/1304.5316"/>
        <updated>2023-09-06T03:14:50.073Z</updated>
        <summary type="html"><![CDATA[Viveka Erlandsson, Saeed Zakeri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Pure Degree Sequence Manipulations Forcing Long Cycles in Graphs]]></title>
        <id>http://arxiv.org/abs/1711.04134</id>
        <link href="http://arxiv.org/abs/1711.04134"/>
        <updated>2023-09-06T03:14:50.061Z</updated>
        <summary type="html"><![CDATA[Zhora Nikoghosyan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A discreteness criterion for groups containing parabolic isometries]]></title>
        <id>http://arxiv.org/abs/1304.2298</id>
        <link href="http://arxiv.org/abs/1304.2298"/>
        <updated>2023-09-06T03:14:50.056Z</updated>
        <summary type="html"><![CDATA[Viveka Erlandsson, Saeed Zakeri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physical mechanisms influencing life origin and development.
  Physical-biochemical paradigm of Life]]></title>
        <id>http://arxiv.org/abs/1609.09421</id>
        <link href="http://arxiv.org/abs/1609.09421"/>
        <updated>2023-09-06T03:14:50.045Z</updated>
        <summary type="html"><![CDATA[Yuri K. Shestopaloff]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[400 bright minds]]></title>
        <id>http://xianblog.wordpress.com/?p=53996</id>
        <link href="https://xianblog.wordpress.com/2023/09/06/400-bright-minds/"/>
        <updated>2023-09-05T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[↗↘↗]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60503</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60503&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=%25e2%2586%2597%25e2%2586%2598%25e2%2586%2597"/>
        <updated>2023-09-05T21:52:54.000Z</updated>
        <summary type="html"><![CDATA[That's one of the extreme nicknames for Xi Jinping that are being used to avoid censorship.  It consists of the three tones for his name, Xí Jìnpíng 习近平. Likewise, netizens are referring to him as "2-4-2".  He is also called "N" because that reminds people of ↗↘↗.  Another emerging Xi nickname is “n-butane,” whose chemical […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automated trace collection and analysis]]></title>
        <id>https://pytorch.org/blog/automated-trace-collection/</id>
        <link href="https://pytorch.org/blog/automated-trace-collection/"/>
        <updated>2023-09-05T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[In this blog, we share how we enabled the collection and analysis of PyTorch Profiler traces for training workloads without any user side code instrumentation. We leveraged Dynolog - an open source daemon for CPU and GPU telemetry to collect PyTorch Profiler traces, and analyzed the collected traces using Holistic Trace Analysis - an open source library for analyzing PyTorch Profiler traces. This toolchain has allowed engineers at Meta to accelerate their performance optimization workflows. The keystone to our solution was implementing pre and post hooks for the base Optimizer class in PyTorch. We demo PyTorch trace collection using Dynolog in a short video.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[capture & maybe recapture]]></title>
        <id>http://xianblog.wordpress.com/?p=53568</id>
        <link href="https://xianblog.wordpress.com/2023/09/05/capture-maybe-recapture-estimation/"/>
        <updated>2023-09-04T22:23:42.000Z</updated>
        <summary type="html"><![CDATA[I read population size estimation with capture-recapture in presence of individual misidentification and low recapture arXived by Rémy Fraysse and coauthors on my flight back from Saigon. The setup is one of a capture-recapture experience where potential misidentification (of a recapture individual labelled as new) may occur due to visual identification errors as, e.g., in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tatar Journalism in Tatar]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60494</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60494&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tatar-journalism-in-tatar"/>
        <updated>2023-09-04T12:35:03.000Z</updated>
        <summary type="html"><![CDATA[Tatar Tatars "Tatar Journalists More Likely to Cover Controversial Topics When They Write or Speak in Tatar, One of Their Number Says" Paul Goble, Window on Eurasia — New Series Monday, August 28, 2023            Staunton, Aug. 28 – Tatar journalists are more likely to cover controversial topics when they write or speak in Tatar […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VDM++: Variational Diffusion Models for High-Quality Synthesis]]></title>
        <id>http://arxiv.org/abs/2303.00848</id>
        <link href="http://arxiv.org/abs/2303.00848"/>
        <updated>2023-09-04T02:20:36.085Z</updated>
        <summary type="html"><![CDATA[Diederik P. Kingma, Ruiqi Gao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge Infused Learning (K-IL): Towards Deep Incorporation of
  Knowledge in Deep Learning]]></title>
        <id>http://arxiv.org/abs/1912.00512</id>
        <link href="http://arxiv.org/abs/1912.00512"/>
        <updated>2023-09-04T02:20:36.080Z</updated>
        <summary type="html"><![CDATA[Ugur Kursuncu, Manas Gaur, Amit Sheth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diversified Ensemble of Independent Sub-Networks for Robust
  Self-Supervised Representation Learning]]></title>
        <id>http://arxiv.org/abs/2308.14705</id>
        <link href="http://arxiv.org/abs/2308.14705"/>
        <updated>2023-09-04T02:20:36.074Z</updated>
        <summary type="html"><![CDATA[Amirhossein Vahidi, Lisa Wimmer, H\"useyin Anil G\"und\"uz, Bernd
  Bischl, Eyke H\"ullermeier, Mina Rezaei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Implicit Bias of Adam]]></title>
        <id>http://arxiv.org/abs/2309.00079</id>
        <link href="http://arxiv.org/abs/2309.00079"/>
        <updated>2023-09-04T02:20:36.039Z</updated>
        <summary type="html"><![CDATA[Matias D. Cattaneo, Jason M. Klusowski, Boris Shigida]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SGD learning on neural networks: leap complexity and saddle-to-saddle
  dynamics]]></title>
        <id>http://arxiv.org/abs/2302.11055</id>
        <link href="http://arxiv.org/abs/2302.11055"/>
        <updated>2023-09-04T02:20:36.034Z</updated>
        <summary type="html"><![CDATA[Emmanuel Abbe, Enric Boix-Adsera, Theodor Misiakiewicz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UTMB congratulations!]]></title>
        <id>http://xianblog.wordpress.com/?p=53990</id>
        <link href="https://xianblog.wordpress.com/2023/09/04/utmb-congratulations/"/>
        <updated>2023-09-03T22:23:41.000Z</updated>
        <summary type="html"><![CDATA[Congrats to all runners of the UTMB 2023 this weekend, but most particularly to Alexis Baron a friend and colleague of our daughter in Martinique, who finished 164th in less than 30 hours the 172.2km length and  9967m elevation race.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PRC-style censorship of "Oppenheimer"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60487</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60487&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=prc-style-censorship-of-oppenheimer"/>
        <updated>2023-09-03T12:45:31.000Z</updated>
        <summary type="html"><![CDATA[奥本海默中国大陆版本剪辑情况 pic.twitter.com/Nbjxy5PJ4J — 小径残雪 (@xiaojingcanxue) September 1, 2023 [link to full tweet here] Notice the title of each group of five panels: yuánbǎn 原版 ("original edition") for the uncut version, and jiǎnbǎn ✂️版 [=剪版] (meaning jiǎnjí bǎn 剪輯版) for the censored version — all the more notable for its being written in pen, not typed […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sài Gòn food scene [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53679</id>
        <link href="https://xianblog.wordpress.com/2023/09/03/sai-gon-food-scene-jatp/"/>
        <updated>2023-09-02T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[An additional perk of visiting Sài Gòn last week was in enjoying the rich and diverse food scene there, even though, obviously, I only scratched the surface of the offer there. Among dishes, a morning rice pancake called bunh cuon,   several phos,  sweet sea snails, another broth called bun thang (with blood sausage), a […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Old, Middle, and Modern English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60482</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60482&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=old-middle-and-modern-english"/>
        <updated>2023-09-02T12:14:42.000Z</updated>
        <summary type="html"><![CDATA[The Differences between Old English, Middle English and Modern English By Danièle Cybulskie When people study Shakespeare in high school, I often hear them refer to his language as “Old English.” As far as the language goes, Shakespeare’s English actually falls under the category of “Modern English.” This may be a little hard to believe, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantum-enhanced Markov chain Monte Carlo]]></title>
        <id>http://xianblog.wordpress.com/?p=53575</id>
        <link href="https://xianblog.wordpress.com/2023/09/02/quantum-enhanced-markov-chain-monte-carlo/"/>
        <updated>2023-09-01T22:23:51.000Z</updated>
        <summary type="html"><![CDATA[A rare occurrence of an MCMC paper in Nature!!! David Layden and co-authors published this paper on 12 July, about using a quantum proposal in a Metropolis-Rosenbluth-Hastings simulation of an Ising model. More specifically, based on “quenched dynamics of a transverse-field quantum Ising model20, which can be efficiently simulated on a quantum computer21“, which amounts […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[论文阅读：MHA、MQA、GQA的差异与共性]]></title>
        <id>https://yongyuan.name//blog/mha-mqa-gqa.html</id>
        <link href="https://yongyuan.name//blog/mha-mqa-gqa.html"/>
        <updated>2023-09-01T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[MHA: Attention is All You Need
MQA：Fast Transformer Decoding: One Write-Head is All You Need
GQA: Training Generalized Multi-Query Transformer Models fromMulti-Head Checkpoints
MHA、MQA、GQA差异

MHA：Multi-Head Attention，QKV 三部分有相同数量的头，且一一对应。每次做 Attention，head1 的 QKV 就做好自己运算就可以，输出时各个头加起来就行。
MQA：Multi-Query Attention，让 Q 仍然保持原来的头数，但 K 和 V 只有一个头，相当于所有的 Q 头共享一组 K 和 V 头，所以叫做 Multi-Query 了。
实现改变了会不会影响效果呢？确实会影响但相对它能带来的收益，性能的些微降低是可以接受的。能带来多大的收益呢，实验发现一般能提高 30%-40% 的吞吐。收益主要就是由降低了 KV cache 带来的。实际上 MQA 运算量和 MHA 是差不多的，可理解为读取一组 KV 头之后，给所有 Q 头用，但因为之前提到的内存和计算的不对称，所以是有利的。
GQA：Grouped-Query Attention，是 MHA 和 MQA 的折衷方案，既不想损失性能太多，又想获得 MQA 带来的推理加速好处。具体思想是，不是所有 Q 头共享一组 KV，而是分组一定头数 Q 共享一组 KV，比如上面图片就是两组 Q 共享一组 KV。
MHA、MQA、GQA共性
实际上，MHA、MQA可以看做是GQA两个特例版本：
MQA对应GQA-1，即只有一个分组，对应一个K和V；
MHA对应GQA-H，对应H个head，对应H个K和V；
怎么从MHA模型得到MQA和GQA？

从MHA得到MQA：将MHA中H个head的的K和V，分别做mean pooling后得到一个K和V，用得到的K和V继续训练。
从MHA得到GQA：将MHA中H个head的的K和V，分别做mean pooling后，得到H个K和V，用得到的K和V继续训练。
MHA、MQA、GQA效果
在LLAMA2中，在不同的数据数据集上对比的效果（注意：为了维持参数量一致，对于MQA、GQA的FFN layer的维度，会有一定的拓宽）：]]></summary>
        <author>
            <name>YongYuan's homepage</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Central Asian Turkish languages]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60479</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60479&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=central-asian-turkish-languages"/>
        <updated>2023-09-01T12:33:21.000Z</updated>
        <summary type="html"><![CDATA[I write to announce an exceptional opportunity to learn the Turkish languages of Central Asia. There is a new Turkic course at Penn: TURK 1050.   This is a survey course that introduces students to the main languages spoken in Central Asia: Kazakh, Uzbek, Kyrgyz, Azeri. The language study will facilitate student research in topics like […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Don't speak Japanese loudly outside!"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60476</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60476&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dont-speak-japanese-loudly-outside"/>
        <updated>2023-09-01T01:29:55.000Z</updated>
        <summary type="html"><![CDATA[Advisory to staff of the embassy of Japan in Beijing: ALPS shori mizu no kaiyō hōshutsu kaishi ni tomonau chūi kanki (2023-nen 8 tsuki 25-nichi) ALPS処理水の海洋放出開始に伴う注意喚起（2023年8月25日） Warning regarding the start of ocean discharge of ALPS-treated water (August 25, 2023) Kinō (24-nichi), fusoku no jitai ga hassei suru kanōsei wa haijo dekinai tame chūi shite itadaku […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Open MatSci ML Toolkit: A Flexible Framework for Machine Learning in
  Materials Science]]></title>
        <id>http://arxiv.org/abs/2210.17484</id>
        <link href="http://arxiv.org/abs/2210.17484"/>
        <updated>2023-09-01T01:07:38.561Z</updated>
        <summary type="html"><![CDATA[Santiago Miret, Kin Long Kelvin Lee, Carmelo Gonzales, Marcel Nassar,
  Matthew Spellings]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[0/1 Deep Neural Networks via Block Coordinate Descent]]></title>
        <id>http://arxiv.org/abs/2206.09379</id>
        <link href="http://arxiv.org/abs/2206.09379"/>
        <updated>2023-09-01T01:07:34.775Z</updated>
        <summary type="html"><![CDATA[Hui Zhang, Shenglong Zhou, Geoffrey Ye Li, Naihua Xiu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Optimal Strategies for Temporal Tasks in Stochastic Games]]></title>
        <id>http://arxiv.org/abs/2102.04307</id>
        <link href="http://arxiv.org/abs/2102.04307"/>
        <updated>2023-09-01T01:07:34.769Z</updated>
        <summary type="html"><![CDATA[Alper Kamil Bozkurt, Yu Wang, Michael M. Zavlanos, Miroslav Pajic]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leveraging Image-based Generative Adversarial Networks for Time Series
  Generation]]></title>
        <id>http://arxiv.org/abs/2112.08060</id>
        <link href="http://arxiv.org/abs/2112.08060"/>
        <updated>2023-09-01T01:07:34.763Z</updated>
        <summary type="html"><![CDATA[Justin Hellermann, Stefan Lessmann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GRASP: A Goodness-of-Fit Test for Classification Learning]]></title>
        <id>http://arxiv.org/abs/2209.02064</id>
        <link href="http://arxiv.org/abs/2209.02064"/>
        <updated>2023-09-01T01:07:34.757Z</updated>
        <summary type="html"><![CDATA[Adel Javanmard, Mohammad Mehrabi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the year of fires]]></title>
        <id>http://xianblog.wordpress.com/?p=53752</id>
        <link href="https://xianblog.wordpress.com/2023/09/01/a-journal-of-the-year-of-fires/"/>
        <updated>2023-08-31T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Indeed, the year of the mega-fires in West and East Canada, with Kelowna (and UBC Okanagan where BIRS 23w5106 took place) severely hit. Travelling through BC by car and plane, we saw several wildfire fume clouds, incl. a massive one from the Yellowknife region… Read a few dozen pages of Gene Wolfe’s The Knight, in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No Japanese people or American dogs]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60466</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60466&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=no-japanese-people-or-american-dogs"/>
        <updated>2023-08-31T20:56:32.000Z</updated>
        <summary type="html"><![CDATA[From the Twitter / X account of the famous popular science writer and muckraker, Fang Zhouzi / Fang Shimin: 光禁止“日本人”“美国狗”入内哪够啊，还有欧盟、英国、澳大利亚、加拿大……呢？不如干脆搞一个白名单，只欢迎朝鲜人、俄国狗入内。 pic.twitter.com/fhVu6oMyZx — 方舟子 (@fangshimin) August 31, 2023 The sign says: Rìběn rénMěiguó gǒujìnzhǐ rùnèi 日本人美国狗禁止入内 "Japanese peopleAmerican dogsAre forbidden from entering" It seems that Americans are of a lower order than Japanese.  What did we […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WeatherBench 2: A benchmark for the next generation of data-driven weather models]]></title>
        <id>http://blog.research.google/2023/08/weatherbench-2-benchmark-for-next.html</id>
        <link href="http://blog.research.google/2023/08/weatherbench-2-benchmark-for-next.html"/>
        <updated>2023-08-31T17:14:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Stephan Rasp, Research Scientist, and Carla Bromberg, Program Lead, Google Research





In 1950, weather forecasting started its digital revolution when researchers used the first programmable, general-purpose computer ENIAC to solve mathematical equations describing how weather evolves. In the more than 70 years since, continuous advancements in computing power and improvements to the model formulations have led to steady gains in weather forecast skill: a 7-day forecast today is about as accurate as a 5-day forecast in 2000 and a 3-day forecast in 1980. While improving forecast accuracy at the pace of approximately one day per decade may not seem like a big deal, every day improved is important in far reaching use cases, such as for logistics planning, disaster management, agr…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Get some linguists out here"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60468</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60468&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=get-some-linguists-out-here"/>
        <updated>2023-08-31T12:02:17.000Z</updated>
        <summary type="html"><![CDATA[Email from John B.: Writing to you about a never-expected-to-see sentence, in a novel I’m reading. “And get some linguists out here as fast as you can.” (Well, but why not?) It’s a newly released off the wall novel, The Road to Roswell by Connie Willis. The heroine, Francie, has agreed to be maid of […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Viral vibe]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60461</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60461&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=viral-vibe"/>
        <updated>2023-08-31T10:23:58.000Z</updated>
        <summary type="html"><![CDATA["Chinese Song Streamed Billions of Times for ‘Satirical’ Vibe" By Miho Tamura / Yomiuri Shimbun Correspondent Yomiuri Shimbun (August 29, 2023) Here's the song, with the lyrics in characters, pinyin romanization, and a poor English translation: There are several other inferior English translations on the internet.  I have yet to find one that is serviceable, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch/XLA SPMD: Scale Up Model Training and Serving with Automatic Parallelization]]></title>
        <id>https://pytorch.org/blog/pytorch-xla-spmd/</id>
        <link href="https://pytorch.org/blog/pytorch-xla-spmd/"/>
        <updated>2023-08-31T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today, we are delighted to announce PyTorch/XLA SPMD: the integration of GSPMD into PyTorch with an easy to use API. PyTorch developers seeking superior performance and scale can train and serve the largest neural networks while maximizing utilization of AI accelerators, such as Google Cloud TPUs.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Coagent Networks Revisited]]></title>
        <id>http://arxiv.org/abs/2001.10474</id>
        <link href="http://arxiv.org/abs/2001.10474"/>
        <updated>2023-08-31T02:20:13.444Z</updated>
        <summary type="html"><![CDATA[Modjtaba Shokrian Zini, Mohammad Pedramfar, Matthew Riemer, Ahmadreza
  Moradipari, Miao Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Application of Zone Method based Machine Learning and Physics-Informed
  Neural Networks in Reheating Furnaces]]></title>
        <id>http://arxiv.org/abs/2308.16089</id>
        <link href="http://arxiv.org/abs/2308.16089"/>
        <updated>2023-08-31T02:20:13.399Z</updated>
        <summary type="html"><![CDATA[Ujjal Kr Dutta, Aldo Lipani, Chuan Wang, Yukun Hu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convolutional Analysis Operator Learning: Acceleration and Convergence]]></title>
        <id>http://arxiv.org/abs/1802.05584</id>
        <link href="http://arxiv.org/abs/1802.05584"/>
        <updated>2023-08-31T02:20:13.343Z</updated>
        <summary type="html"><![CDATA[Il Yong Chun, Jeffrey A. Fessler]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment]]></title>
        <id>http://arxiv.org/abs/2304.06767</id>
        <link href="http://arxiv.org/abs/2304.06767"/>
        <updated>2023-08-31T02:20:13.273Z</updated>
        <summary type="html"><![CDATA[Hanze Dong, Wei Xiong, Deepanshu Goyal, Yihan Zhang, Winnie Chow, Rui
  Pan, Shizhe Diao, Jipeng Zhang, Kashun Shum, Tong Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[survex: an R package for explaining machine learning survival models]]></title>
        <id>http://arxiv.org/abs/2308.16113</id>
        <link href="http://arxiv.org/abs/2308.16113"/>
        <updated>2023-08-31T02:20:13.266Z</updated>
        <summary type="html"><![CDATA[Miko{\l}aj Spytek, Mateusz Krzyzi\'nski, Sophie Hanna Langbein
 , Hubert Baniecki, Marvin N. Wright, Przemys{\l}aw Biecek]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Korean words for "bottle gourd"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60457</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60457&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=korean-words-for-bottle-gourd"/>
        <updated>2023-08-30T22:51:10.000Z</updated>
        <summary type="html"><![CDATA[I spent much of the summer in Vermont ensconced in a hermit's cottage reading, writing, and, of course, running through the Green Mountains and verdant woods.  When I left last week to come back for the fall semester at Penn, I brought with me about fifty bottle gourds (Lagenaria siceraria) that had been abandoned by […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ISBA²⁴ [website]]]></title>
        <id>http://xianblog.wordpress.com/?p=53938</id>
        <link href="https://xianblog.wordpress.com/2023/08/31/isba%c2%b2%e2%81%b4-website/"/>
        <updated>2023-08-30T22:24:14.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modeling and improving text stability in live captions]]></title>
        <id>http://blog.research.google/2023/08/modeling-and-improving-text-stability.html</id>
        <link href="http://blog.research.google/2023/08/modeling-and-improving-text-stability.html"/>
        <updated>2023-08-30T19:34:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Vikas Bahirwani, Research Scientist, and Susan Xu, Software Engineer, Google Augmented Reality





Automatic speech recognition (ASR) technology has made conversations more accessible with live captions in remote conferencing software, mobile applications, and head-worn displays. However, to maintain real-time responsiveness, live caption systems often display interim predictions that are updated as new utterances are received. This can cause text instability (a “flicker” where previously displayed text is updated, shown in the captions on the left in the video below), which can impair users' reading experience due to distraction, fatigue, and difficulty following the conversation.






In “Modeling and Improving Text Stability in Live Captions”, presented at ACM CHI 2023, we f…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Once in a blue moon]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60454</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60454&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=once-in-a-blue-moon"/>
        <updated>2023-08-30T14:17:17.000Z</updated>
        <summary type="html"><![CDATA[From the MIT International Student Office: Blue moons are best known from the phrase “once in a blue moon,” which means “extremely rarely.” The first recorded use of this idiomatic phrase is in an anti-clerical flyer in 1528, published by William Roy and Jeremy Barlowe. In reference to the clerical corruptions, one said in Old […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Empowering Clinicians and Democratizing Data Science: Large Language
  Models Automate Machine Learning for Clinical Studies]]></title>
        <id>http://arxiv.org/abs/2308.14120</id>
        <link href="http://arxiv.org/abs/2308.14120"/>
        <updated>2023-08-30T04:17:23.914Z</updated>
        <summary type="html"><![CDATA[Soroosh Tayebi Arasteh, Tianyu Han, Mahshad Lotfinia, Christiane Kuhl,
  Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Based Residuals in Non-linear Factor Models: Precision
  Matrix Estimation of Returns with Low Signal-to-Noise Ratio]]></title>
        <id>http://arxiv.org/abs/2209.04512</id>
        <link href="http://arxiv.org/abs/2209.04512"/>
        <updated>2023-08-30T04:17:23.909Z</updated>
        <summary type="html"><![CDATA[Mehmet Caner, Maurizio Daniele]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Empirical Bregman Divergence for Uncertain Distance
  Representation]]></title>
        <id>http://arxiv.org/abs/2304.07689</id>
        <link href="http://arxiv.org/abs/2304.07689"/>
        <updated>2023-08-30T04:17:23.640Z</updated>
        <summary type="html"><![CDATA[Zhiyuan Li, Ziru Liu, Anna Zou, Anca L. Ralescu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Theoretical Guarantees of Learning Ensembling Strategies with
  Applications to Time Series Forecasting]]></title>
        <id>http://arxiv.org/abs/2305.15786</id>
        <link href="http://arxiv.org/abs/2305.15786"/>
        <updated>2023-08-30T04:17:23.619Z</updated>
        <summary type="html"><![CDATA[Hilaf Hasson, Danielle C. Maddix, Yuyang Wang, Gaurav Gupta, Youngsuk
  Park]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[differentially private distributed Bayesian linear regression with MCMC]]></title>
        <id>http://xianblog.wordpress.com/?p=53623</id>
        <link href="https://xianblog.wordpress.com/2023/08/30/differentially-private-distributed-bayesian-linear-regression-with-mcmc/"/>
        <updated>2023-08-29T22:23:23.000Z</updated>
        <summary type="html"><![CDATA[An ICML 2023 paper by Barıs¸ Alparslan, Sinan Yıldırım¸ and Ilker Birbil that (re)addresses the issue of privacy when running a Bayesian regression analysis. Resorting to the common notion of differential privacy, imposing a limited variability if a single observation is modified, and a Gaussian randomisation of the observations. “A differentially private algorithm constrains the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[De-Japanification of Japanese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60435</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60435&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=de-japanification-of-japanese"/>
        <updated>2023-08-29T22:22:30.000Z</updated>
        <summary type="html"><![CDATA[This morning in the first class of my course on "Language, Script, and Society in China", I had just spoken about the most frequent morphemes in Mandarin, Taiwanese, and Japanese (the possessive particles de 的, e, and no の) and other common terms that had no fixed characters to write them or had to borrow […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SayTap: Language to quadrupedal locomotion]]></title>
        <id>http://blog.research.google/2023/08/saytap-language-to-quadrupedal.html</id>
        <link href="http://blog.research.google/2023/08/saytap-language-to-quadrupedal.html"/>
        <updated>2023-08-29T19:57:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Yujin Tang and Wenhao Yu, Research Scientists, Google




Simple and effective interaction between human and quadrupedal robots paves the way towards creating intelligent and capable helper robots, forging a future where technology enhances our lives in ways beyond our imagination. Key to such human-robot interaction systems is enabling quadrupedal robots to respond to natural language instructions. Recent developments in large language models (LLMs) have demonstrated the potential to perform high-level planning. Yet, it remains a challenge for LLMs to comprehend low-level commands, such as joint angle targets or motor torques, especially for inherently unstable legged robots, necessitating high-frequency control signals. Consequently, most existing work presumes the provision of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Re-Grand Opening"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60440</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60440&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=re-grand-opening"/>
        <updated>2023-08-29T16:22:55.000Z</updated>
        <summary type="html"><![CDATA[From John Bell: I thought of you and your interest in the oddities of linguistic expression a few days ago when I noticed that the local Safeway supermarket had large signs up saying "RE-GRAND OPENING".   They had recently done some renovation in a corner of the store — enlarging the self-checkout and the Starbucks […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Estimation of Derivatives Using Plug-in Kernel Ridge Regression
  Estimators]]></title>
        <id>http://arxiv.org/abs/2006.01350</id>
        <link href="http://arxiv.org/abs/2006.01350"/>
        <updated>2023-08-29T02:49:37.845Z</updated>
        <summary type="html"><![CDATA[Zejian Liu, Meng Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multilevel orthogonal Bochner function subspaces with applications to
  robust machine learning]]></title>
        <id>http://arxiv.org/abs/2110.01729</id>
        <link href="http://arxiv.org/abs/2110.01729"/>
        <updated>2023-08-29T02:49:37.824Z</updated>
        <summary type="html"><![CDATA[Julio Enrique Castrillon-Candas, Dingning Liu, Sicheng Yang, Mark Kon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Calibration: Learning of Model Calibration Using Differentiable
  Expected Calibration Error]]></title>
        <id>http://arxiv.org/abs/2106.09613</id>
        <link href="http://arxiv.org/abs/2106.09613"/>
        <updated>2023-08-29T02:49:37.801Z</updated>
        <summary type="html"><![CDATA[Ondrej Bohdal, Yongxin Yang, Timothy Hospedales]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sufficient Invariant Learning for Distribution Shift]]></title>
        <id>http://arxiv.org/abs/2210.13533</id>
        <link href="http://arxiv.org/abs/2210.13533"/>
        <updated>2023-08-29T02:49:37.795Z</updated>
        <summary type="html"><![CDATA[Taero Kim, Sungjun Lim, Kyungwoo Song]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TuneUp: A Simple Improved Training Strategy for Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2210.14843</id>
        <link href="http://arxiv.org/abs/2210.14843"/>
        <updated>2023-08-29T02:49:37.689Z</updated>
        <summary type="html"><![CDATA[Weihua Hu, Kaidi Cao, Kexin Huang, Edward W Huang, Karthik Subbian,
  Kenji Kawaguchi, Jure Leskovec]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identifying AI-generated images with SynthID]]></title>
        <id>https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid</id>
        <link href="https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid"/>
        <updated>2023-08-29T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today, in partnership with Google Cloud, we’re beta launching SynthID, a new tool for watermarking and identifying AI-generated images. It’s being released to a limited number of Vertex AI customers using Imagen, one of our latest text-to-image models that uses input text to create photorealistic images. This technology embeds a digital watermark directly into the pixels of an image, making it imperceptible to the human eye, but detectable for identification. While generative AI can unlock huge creative potential, it also presents new risks, like creators spreading false information — both intentionally or unintentionally. Being able to identify AI-generated content is critical to empowering people with knowledge of when they’re interacting with generated media, and for helping prevent the spread of misinformation.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayes on the Beach²⁴]]></title>
        <id>http://xianblog.wordpress.com/?p=53928</id>
        <link href="https://xianblog.wordpress.com/2023/08/29/bayes-on-the-beach%c2%b2%e2%81%b4/"/>
        <updated>2023-08-28T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language and politics in Hong Kong: National Security and the promotion of topolect]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60423</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60423&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-and-politics-in-hong-kong-national-security-and-the-promotion-of-topolect"/>
        <updated>2023-08-28T19:20:14.000Z</updated>
        <summary type="html"><![CDATA[From the Hong Kong Language Learning Association: Announcement Regarding Suspension of Hong Kong Language Learning Association Given recent events, wherein personnel from the Hong Kong National Security Department (NSD) visited both my former residence and the residence of my family members for searches and inquiries, alleging a violation of the National Security Law in connection with […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RO-ViT: Region-aware pre-training for open-vocabulary object detection with vision transformers]]></title>
        <id>http://blog.research.google/2023/08/ro-vit-region-aware-pre-training-for.html</id>
        <link href="http://blog.research.google/2023/08/ro-vit-region-aware-pre-training-for.html"/>
        <updated>2023-08-28T16:59:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Dahun Kim and Weicheng Kuo, Research Scientists, Google



The ability to detect objects in the visual world is crucial for computer vision and machine intelligence, enabling applications like adaptive autonomous agents and versatile shopping systems. However, modern object detectors are limited by the manual annotations of their training data, resulting in a vocabulary size significantly smaller than the vast array of objects encountered in reality. To overcome this, the open-vocabulary detection task (OVD) has emerged, utilizing image-text pairs for training and incorporating new category names at test time by associating them with the image content. By treating categories as text embeddings, open-vocabulary detectors can predict a wide range of unseen objects. Various techniqu…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RO-ViT: Region-aware pre-training for open-vocabulary object detection with vision transformers]]></title>
        <id>http://ai.googleblog.com/2023/08/ro-vit-region-aware-pre-training-for.html</id>
        <link href="http://ai.googleblog.com/2023/08/ro-vit-region-aware-pre-training-for.html"/>
        <updated>2023-08-28T16:59:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Dahun Kim and Weicheng Kuo, Research Scientists, Google



The ability to detect objects in the visual world is crucial for computer vision and machine intelligence, enabling applications like adaptive autonomous agents and versatile shopping systems. However, modern object detectors are limited by the manual annotations of their training data, resulting in a vocabulary size significantly smaller than the vast array of objects encountered in reality. To overcome this, the open-vocabulary detection task (OVD) has emerged, utilizing image-text pairs for training and incorporating new category names at test time by associating them with the image content. By treating categories as text embeddings, open-vocabulary detectors can predict a wide range of unseen objects. Various techniqu…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mugshot, racketeering, listless …]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60427</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60427&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mugshot-racketeering-listless"/>
        <updated>2023-08-28T11:57:06.000Z</updated>
        <summary type="html"><![CDATA[Over the past few months, U.S. political events have given Ben Zimmer opportunity for some fun etymologies in his WSJ column: mug shot, racketeering, listless. There are plenty more targets Out There — like candidate, from Latin candidus (“dazzling white, shining, clear”); or debate, originally from Latin dis- (“apart, in different directions”) + battuere (“to […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lion/Tiger优化器训练下的Embedding异常和对策]]></title>
        <id>https://kexue.fm/archives/9736</id>
        <link href="https://kexue.fm/archives/9736"/>
        <updated>2023-08-28T06:44:00.000Z</updated>
        <summary type="html"><![CDATA[打从在《Tiger：一个“抠”到极致的优化器》提出了Tiger优化器之后，Tiger就一直成为了我训练模型的“标配”优化器。最近笔者已经尝试将Tiger用到了70亿参数模型的预训练之中，前期效果...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Reasoning for Physics Informed Neural Networks]]></title>
        <id>http://arxiv.org/abs/2308.13222</id>
        <link href="http://arxiv.org/abs/2308.13222"/>
        <updated>2023-08-28T02:20:34.966Z</updated>
        <summary type="html"><![CDATA[Krzysztof M. Graczyk, Kornel Witkowski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PDSketch: Integrated Planning Domain Programming and Learning]]></title>
        <id>http://arxiv.org/abs/2303.05501</id>
        <link href="http://arxiv.org/abs/2303.05501"/>
        <updated>2023-08-28T02:20:34.959Z</updated>
        <summary type="html"><![CDATA[Jiayuan Mao, Tom\'as Lozano-P\'erez, Joshua B. Tenenbaum, Leslie Pack
  Kaelbling]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kernel Density Matrices for Probabilistic Deep Learning]]></title>
        <id>http://arxiv.org/abs/2305.18204</id>
        <link href="http://arxiv.org/abs/2305.18204"/>
        <updated>2023-08-28T02:20:34.918Z</updated>
        <summary type="html"><![CDATA[Fabio A. Gonz\'alez, Ra\'ul Ramos-Poll\'an, Joseph A. Gallego-Mejia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Six Lectures on Linearized Neural Networks]]></title>
        <id>http://arxiv.org/abs/2308.13431</id>
        <link href="http://arxiv.org/abs/2308.13431"/>
        <updated>2023-08-28T02:20:34.912Z</updated>
        <summary type="html"><![CDATA[Theodor Misiakiewicz, Andrea Montanari]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A topological model for partial equivariance in deep learning and data
  analysis]]></title>
        <id>http://arxiv.org/abs/2308.13357</id>
        <link href="http://arxiv.org/abs/2308.13357"/>
        <updated>2023-08-28T02:20:34.906Z</updated>
        <summary type="html"><![CDATA[Lucia Ferrari, Patrizio Frosini, Nicola Quercioli, Francesca Tombari]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The geometry of diffusion guidance]]></title>
        <id>https://sander.ai/2023/08/28/geometry.html</id>
        <link href="https://sander.ai/2023/08/28/geometry.html"/>
        <updated>2023-08-27T23:00:00.000Z</updated>
        <summary type="html"><![CDATA[Guidance is a powerful method that can be used to enhance diffusion model sampling. As I’ve discussed in an earlier blog post, it’s almost like a cheat code: it can improve sample quality so much that it’s as if the model had ten times the number of parameters – an order of magnitude improvement, basically for free! This follow-up post provides a geometric interpretation and visualisation of the diffusion sampling procedure, which I’ve found particularly useful to explain how guidance works.]]></summary>
        <author>
            <name>Sander Dieleman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BayesComp²⁵ in Singapore]]></title>
        <id>http://xianblog.wordpress.com/?p=53654</id>
        <link href="https://xianblog.wordpress.com/2023/08/28/bayescomp%c2%b2%e2%81%b5-in-singapore/"/>
        <updated>2023-08-27T22:23:38.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Core socialist values]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60406</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60406&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=core-socialist-values"/>
        <updated>2023-08-27T19:58:05.000Z</updated>
        <summary type="html"><![CDATA["Chinese slogans on London wall hold mirror to society: artist" Zhejiang-born Yique tries to find his place in UK after Brick Lane work TAY HAN NEE, Nikkei Asia Here are the 24 Chinese characters that constitute the twelve disyllabic words that make up the official "Core Socialist Values" of the PRC government: National values Prosperity […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Calimony"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60400</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60400&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=calimony"/>
        <updated>2023-08-27T13:28:59.000Z</updated>
        <summary type="html"><![CDATA[I recently learned about the lexical blend calimony, which refers to a planned multi-million-dollar annual payment from UCLA (the University of California, Los Angeles) to Berkeley (the University of California, Berkeley, known in athletic contexts as "California" or "Cal"). Why will this payment exist? And why is it a metaphorical form of alimony? Short form: […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bilingual book takes top honors at New Zealand Children's Book Awards]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60382</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60382&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bilingual-book-takes-top-honors-at-new-zealand-childrens-book-awards"/>
        <updated>2023-08-27T12:55:14.000Z</updated>
        <summary type="html"><![CDATA[Press comment:   "A bilingual book about the Māori creation story has won the highest accolade in children's literature."   Awards Announcement:   "Te Wehenga: The Separation of Ranginui and Papatūānuku presents the Māori creation pūrākau in a bold design using universal elements recognised across iwi. The bilingual text is poetic, and integrated into the artwork […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[23w5106 [group picture]]]></title>
        <id>http://xianblog.wordpress.com/?p=53766</id>
        <link href="https://xianblog.wordpress.com/2023/08/27/23w5106-group-picture/"/>
        <updated>2023-08-26T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[English accents]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60344</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60344&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=english-accents"/>
        <updated>2023-08-26T13:13:05.000Z</updated>
        <summary type="html"><![CDATA[Entertaining and edifying. As I said recently (last paragraph of this post:  "Irish accents" [8/13/23]), I'm enchanted by all the accents that I've ever heard.  I find them to be endlessly fascinating.   Selected readings "What makes an accent 'good' or 'bad?" (11/17/20) "Dialect vs. accent (vs. language)" (11/30/18) "Mandarin with an English accent" (4/5/23) […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Debate-night pronouns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60372</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60372&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=debate-night-pronouns"/>
        <updated>2023-08-26T13:13:00.000Z</updated>
        <summary type="html"><![CDATA[In a comment on yesterday's "Debate words" post, I noted that Donald Trump's ratio of I-words to we-words was "off the charts" compared the other eight candidates, and several people have asked me to give all the numbers. There's an idea Out There that such numbers are related to issues of personality and mood, though […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calyampudi Radhakrishna Rao (1920-2023)]]></title>
        <id>http://xianblog.wordpress.com/?p=53899</id>
        <link href="https://xianblog.wordpress.com/2023/08/26/calyampudi-radhakrishna-rao-1920-2023/"/>
        <updated>2023-08-25T22:23:46.000Z</updated>
        <summary type="html"><![CDATA[Just heard that C.R. Rao had passed away on Wednesday. Above is a 1941 picture I photographed while attending the jubilee of the Department of Statistics of the University of Calcuta. Showing R.A. Fisher and P.C. Mahalanobis surrounded by faculty and students from the Department. Including a very young Rao who would a few years […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: Perception Fairness]]></title>
        <id>http://blog.research.google/2023/08/responsible-ai-at-google-research.html</id>
        <link href="http://blog.research.google/2023/08/responsible-ai-at-google-research.html"/>
        <updated>2023-08-25T17:38:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Susanna Ricco and Utsav Prabhu, co-leads, Perception Fairness Team, Google Research





Google’s Responsible AI research is built on a foundation of collaboration — between teams with diverse backgrounds and expertise, between researchers and product developers, and ultimately with the community at large. The Perception Fairness team drives progress by combining deep subject-matter expertise in both computer vision and machine learning (ML) fairness with direct connections to the researchers building the perception systems that power products across Google and beyond. Together, we are working to intentionally design our systems to be inclusive from the ground up, guided by Google’s AI Principles.






Perception Fairness research spans the design, development, and deployment of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: Perception Fairness]]></title>
        <id>http://ai.googleblog.com/2023/08/responsible-ai-at-google-research.html</id>
        <link href="http://ai.googleblog.com/2023/08/responsible-ai-at-google-research.html"/>
        <updated>2023-08-25T17:38:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Susanna Ricco and Utsav Prabhu, co-leads, Perception Fairness Team, Google Research





Google’s Responsible AI research is built on a foundation of collaboration — between teams with diverse backgrounds and expertise, between researchers and product developers, and ultimately with the community at large. The Perception Fairness team drives progress by combining deep subject-matter expertise in both computer vision and machine learning (ML) fairness with direct connections to the researchers building the perception systems that power products across Google and beyond. Together, we are working to intentionally design our systems to be inclusive from the ground up, guided by Google’s AI Principles.






Perception Fairness research spans the design, development, and deployment of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Debate words]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60351</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60351&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=debate-words-3"/>
        <updated>2023-08-25T12:41:38.000Z</updated>
        <summary type="html"><![CDATA[The Transcript Library at rev.com is a great resource — within 24 hours, they had transcripts of Wednesday's Fox News Republican presidential debate, and also of Tucker Carlson's debate night interview with Donald Trump on X. So this morning I downloaded the transcripts, and ran the code that I've used several times over the years […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calligraphic license]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60331</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60331&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=calligraphic-license"/>
        <updated>2023-08-25T03:07:39.000Z</updated>
        <summary type="html"><![CDATA[Shaing tai asked whether I recognized these characters: I didn't recognize the two characters, so I asked several Chinese and Japanese friends, and none of them recognized the characters either.  My curiosity piqued, I figured I might as well take a stab on my own to figure out what they were. The calligraphy was displayed […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[StableDR: Stabilized Doubly Robust Learning for Recommendation on Data
  Missing Not at Random]]></title>
        <id>http://arxiv.org/abs/2205.04701</id>
        <link href="http://arxiv.org/abs/2205.04701"/>
        <updated>2023-08-25T02:20:22.385Z</updated>
        <summary type="html"><![CDATA[Haoxuan Li, Chunyuan Zheng, Peng Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Intentional Forgetting-Driven Self-Healing Method For Deep
  Reinforcement Learning Systems]]></title>
        <id>http://arxiv.org/abs/2308.12445</id>
        <link href="http://arxiv.org/abs/2308.12445"/>
        <updated>2023-08-25T02:20:22.378Z</updated>
        <summary type="html"><![CDATA[Ahmed Haj Yahmed, Rached Bouchoucha, Houssem Ben Braiek, Foutse Khomh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Single-shot Bayesian approximation for neural networks]]></title>
        <id>http://arxiv.org/abs/2308.12785</id>
        <link href="http://arxiv.org/abs/2308.12785"/>
        <updated>2023-08-25T02:20:22.204Z</updated>
        <summary type="html"><![CDATA[Kai Brach, Beate Sick, Oliver D\"urr]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interneurons accelerate learning dynamics in recurrent neural networks
  for statistical adaptation]]></title>
        <id>http://arxiv.org/abs/2209.10634</id>
        <link href="http://arxiv.org/abs/2209.10634"/>
        <updated>2023-08-25T02:20:22.197Z</updated>
        <summary type="html"><![CDATA[David Lipshutz, Cengiz Pehlevan, Dmitri B. Chklovskii]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[making the next meeting more productive]]></title>
        <id>http://xianblog.wordpress.com/?p=53619</id>
        <link href="https://xianblog.wordpress.com/2023/08/25/making-the-next-meeting-more-productive/"/>
        <updated>2023-08-24T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[One of the students’ requests I almost invariably reject is code debugging (and they are warned about it from the start). Here is an illustration why, with an R code sent by a student working this summer on the standard estimators of a Cauchy location parameter, asking for debugging help in order “to make the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to compare a noisy quantum processor to a classical computer]]></title>
        <id>http://blog.research.google/2023/08/how-to-compare-noisy-quantum-processor.html</id>
        <link href="http://blog.research.google/2023/08/how-to-compare-noisy-quantum-processor.html"/>
        <updated>2023-08-24T22:10:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Sergio Boixo and Vadim Smelyanskiy, Principal Scientists, Google Quantum AI Team




A full-scale error-corrected quantum computer will be able to solve some problems that are impossible for classical computers, but building such a device is a huge endeavor. We are proud of the milestones that we have achieved toward a fully error-corrected quantum computer, but that large-scale computer is still some number of years away. Meanwhile, we are using our current noisy quantum processors as flexible platforms for quantum experiments. 



In contrast to an error-corrected quantum computer, experiments in noisy quantum processors are currently limited to a few thousand quantum operations or gates, before noise degrades the quantum state. In 2019 we implemented a specific computational t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to compare a noisy quantum processor to a classical computer]]></title>
        <id>http://ai.googleblog.com/2023/08/how-to-compare-noisy-quantum-processor.html</id>
        <link href="http://ai.googleblog.com/2023/08/how-to-compare-noisy-quantum-processor.html"/>
        <updated>2023-08-24T22:10:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Sergio Boixo and Vadim Smelyanskiy, Principal Scientists, Google Quantum AI Team




A full-scale error-corrected quantum computer will be able to solve some problems that are impossible for classical computers, but building such a device is a huge endeavor. We are proud of the milestones that we have achieved toward a fully error-corrected quantum computer, but that large-scale computer is still some number of years away. Meanwhile, we are using our current noisy quantum processors as flexible platforms for quantum experiments. 



In contrast to an error-corrected quantum computer, experiments in noisy quantum processors are currently limited to a few thousand quantum operations or gates, before noise degrades the quantum state. In 2019 we implemented a specific computational t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teaching language models to reason algorithmically]]></title>
        <id>http://blog.research.google/2023/08/teaching-language-models-to-reason.html</id>
        <link href="http://blog.research.google/2023/08/teaching-language-models-to-reason.html"/>
        <updated>2023-08-24T19:33:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Hattie Zhou, Graduate Student at MILA, Hanie Sedghi, Research Scientist, Google




Large language models (LLMs), such as GPT-3 and PaLM, have shown impressive progress in recent years, which have been driven by scaling up models and training data sizes. Nonetheless, a long standing debate has been whether LLMs can reason symbolically (i.e., manipulating symbols based on logical rules). For example, LLMs are able to perform simple arithmetic operations when numbers are small, but struggle to perform with large numbers. This suggests that LLMs have not learned the underlying rules needed to perform these arithmetic operations. 



While neural networks have powerful pattern matching capabilities, they are prone to overfitting to spurious statistical patterns in the data. This does…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teaching language models to reason algorithmically]]></title>
        <id>http://ai.googleblog.com/2023/08/teaching-language-models-to-reason.html</id>
        <link href="http://ai.googleblog.com/2023/08/teaching-language-models-to-reason.html"/>
        <updated>2023-08-24T19:33:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Hattie Zhou, Graduate Student at MILA, Hanie Sedghi, Research Scientist, Google




Large language models (LLMs), such as GPT-3 and PaLM, have shown impressive progress in recent years, which have been driven by scaling up models and training data sizes. Nonetheless, a long standing debate has been whether LLMs can reason symbolically (i.e., manipulating symbols based on logical rules). For example, LLMs are able to perform simple arithmetic operations when numbers are small, but struggle to perform with large numbers. This suggests that LLMs have not learned the underlying rules needed to perform these arithmetic operations. 



While neural networks have powerful pattern matching capabilities, they are prone to overfitting to spurious statistical patterns in the data. This does…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer升级之路：14、当HWFA遇见ReRoPE]]></title>
        <id>https://kexue.fm/archives/9731</id>
        <link href="https://kexue.fm/archives/9731"/>
        <updated>2023-08-24T10:24:00.000Z</updated>
        <summary type="html"><![CDATA[在上一篇文章《Transformer升级之路：13、逆用Leaky ReRoPE》中，笔者尝试通过在训练阶段逆用Leaky ReRoPE的思路，使得推理阶段的位置编码变为正常的RoPE，从而在达...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
</feed>