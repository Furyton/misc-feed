<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-03-25T20:15:38.321Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[E-mail etiquette]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58268</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58268&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=e-mail-etiquette"/>
        <updated>2023-03-25T19:13:59.000Z</updated>
        <summary type="html"><![CDATA[New article by Stephen Johnson in Lifehacker (3/24/23): "These Are the Most Savage Ways to Start or End an Email: How you start and end your work email says something about your worth as a person" N.B.:  This is about work email — a very different kettle of fish from personal email, email with friends, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Aperiodic Monotile]]></title>
        <id>http://gilkalai.wordpress.com/?p=24036</id>
        <link href="https://gilkalai.wordpress.com/2023/03/25/an-aperiodic-monotile/"/>
        <updated>2023-03-25T19:10:04.000Z</updated>
        <summary type="html"><![CDATA[I suppose that most of you already heard about the first ever aperiodic planar tiling with one type of tiles. It was discovered by David Smith, Joseph Samuel Myers, Craig S. Kaplan, and Chaim Goodman-Strauss. Amazing!!! Here are  blogposts … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Aperiodic Monotile]]></title>
        <id>http://gilkalai.wordpress.com/?p=24036</id>
        <link href="https://gilkalai.wordpress.com/2023/03/25/an-aperiodic-monotile/"/>
        <updated>2023-03-25T19:10:04.000Z</updated>
        <summary type="html"><![CDATA[I suppose that most of you already heard about the first ever aperiodic planar tiling with one type of tiles. It was discovered by David Smith, Joseph Samuel Myers, Craig S. Kaplan, and Chaim Goodman-Strauss. Amazing!!! Here are  blogposts … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[La “main de Moscou“ ?]]></title>
        <id>http://xianblog.wordpress.com/?p=52640</id>
        <link href="https://xianblog.wordpress.com/2023/03/25/la-main-de-moscou/"/>
        <updated>2023-03-24T23:23:33.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Detecting novel systemic biomarkers in external eye photos]]></title>
        <id>http://ai.googleblog.com/2023/03/detecting-novel-systemic-biomarkers-in.html</id>
        <link href="http://ai.googleblog.com/2023/03/detecting-novel-systemic-biomarkers-in.html"/>
        <updated>2023-03-24T19:13:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Boris Babenko, Software Engineer, and Akib Uddin, Product Manager, Google Research    
Last year we presented results demonstrating that a deep learning system (DLS) can be trained to analyze external eye photos and predict a person’s diabetic retinal disease status and elevated glycated hemoglobin (or HbA1c, a biomarker that indicates the three-month average level of blood glucose). It was previously unknown that external eye photos contained signals for these conditions. This exciting finding suggested the potential to reduce the need for specialized equipment since such photos can be captured using smartphones and other consumer devices. Encouraged by these findings, we set out to discover what other biomarkers can be found in this imaging modality. 

In “A deep learning model…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[can you not]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58263</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58263&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=can-you-not"/>
        <updated>2023-03-24T14:22:52.000Z</updated>
        <summary type="html"><![CDATA[Hidden behind the Keurig in our departmental office, I've been noticing a gawky, ungainly, stray coffee mug with these three words on the side: can you not No capitalization and no punctuation. I was mystified.  Whatever could that mean?  I can imagine an arch, haughty, snotty person saying that to someone implying that they don't […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representation Ensembling for Synergistic Lifelong Learning with
  Quasilinear Complexity]]></title>
        <id>http://arxiv.org/abs/2004.12908</id>
        <link href="http://arxiv.org/abs/2004.12908"/>
        <updated>2023-03-24T07:14:06.680Z</updated>
        <summary type="html"><![CDATA[Joshua T. Vogelstein, Jayanta Dey, Hayden S. Helm, Will LeVine, Ronak
  D. Mehta, Tyler M. Tomita, Haoyin Xu, Ali Geisa, Qingyang Wang, Gido M. van
  de Ven, Chenyu Gao, Weiwei Yang, Bryan Tower, Jonathan Larson, Christopher M.
  White, Carey E. Priebe]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continuous Indeterminate Probability Neural Network]]></title>
        <id>http://arxiv.org/abs/2303.12964</id>
        <link href="http://arxiv.org/abs/2303.12964"/>
        <updated>2023-03-24T07:14:06.675Z</updated>
        <summary type="html"><![CDATA[Tao Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization with quantum geometry for learning unitaries]]></title>
        <id>http://arxiv.org/abs/2303.13462</id>
        <link href="http://arxiv.org/abs/2303.13462"/>
        <updated>2023-03-24T07:14:06.669Z</updated>
        <summary type="html"><![CDATA[Tobias Haug, M.S. Kim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fixed points of arbitrarily deep 1-dimensional neural networks]]></title>
        <id>http://arxiv.org/abs/2303.12814</id>
        <link href="http://arxiv.org/abs/2303.12814"/>
        <updated>2023-03-24T07:14:06.152Z</updated>
        <summary type="html"><![CDATA[Andrew Cook, Andy Hammerlindl, Warwick Tucker]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The power and limitations of learning quantum dynamics incoherently]]></title>
        <id>http://arxiv.org/abs/2303.12834</id>
        <link href="http://arxiv.org/abs/2303.12834"/>
        <updated>2023-03-24T07:14:06.147Z</updated>
        <summary type="html"><![CDATA[Sofiene Jerbi, Joe Gibbs, Manuel S. Rudolph, Matthias C. Caro, Patrick
  J. Coles, Hsin-Yuan Huang, Zo\"e Holmes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kuva Lapista⁻²³ [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=52611</id>
        <link href="https://xianblog.wordpress.com/2023/03/24/kuva-lapista%e2%81%bb%c2%b2%c2%b3-jatp/"/>
        <updated>2023-03-23T23:23:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual language maps for robot navigation]]></title>
        <id>http://ai.googleblog.com/2023/03/visual-language-maps-for-robot.html</id>
        <link href="http://ai.googleblog.com/2023/03/visual-language-maps-for-robot.html"/>
        <updated>2023-03-23T19:08:00.005Z</updated>
        <summary type="html"><![CDATA[Posted by Oier Mees, PhD Student, University of Freiburg, and Andy Zeng, Research Scientist, Robotics at Google   
People are excellent navigators of the physical world, due in part to their remarkable ability to build cognitive maps that form the basis of spatial memory — from localizing landmarks at varying ontological levels (like a book on a shelf in the living room) to determining whether a layout permits navigation from point A to point B. Building robots that are proficient at navigation requires an interconnected understanding of (a) vision and natural language (to associate landmarks or follow instructions), and (b) spatial reasoning (to connect a map representing an environment to the true spatial distribution of objects). While there have been many recent advances in training jo…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable Bayesian optimization with high-dimensional outputs using
  randomized prior networks]]></title>
        <id>http://arxiv.org/abs/2302.07260</id>
        <link href="http://arxiv.org/abs/2302.07260"/>
        <updated>2023-03-23T07:14:03.565Z</updated>
        <summary type="html"><![CDATA[Mohamed Aziz Bhouri, Michael Joly, Robert Yu, Soumalya Sarkar
 , Paris Perdikaris]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unbiased Supervised Contrastive Learning]]></title>
        <id>http://arxiv.org/abs/2211.05568</id>
        <link href="http://arxiv.org/abs/2211.05568"/>
        <updated>2023-03-23T07:14:03.543Z</updated>
        <summary type="html"><![CDATA[Carlo Alberto Barbano, Benoit Dufumier, Enzo Tartaglione, Marco
  Grangetto, Pietro Gori]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near-optimal inference in adaptive linear regression]]></title>
        <id>http://arxiv.org/abs/2107.02266</id>
        <link href="http://arxiv.org/abs/2107.02266"/>
        <updated>2023-03-23T07:14:03.530Z</updated>
        <summary type="html"><![CDATA[Koulik Khamaru, Yash Deshpande, Tor Lattimore, Lester Mackey, Martin
  J. Wainwright]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hardness of Independent Learning and Sparse Equilibrium Computation in
  Markov Games]]></title>
        <id>http://arxiv.org/abs/2303.12287</id>
        <link href="http://arxiv.org/abs/2303.12287"/>
        <updated>2023-03-23T07:14:03.488Z</updated>
        <summary type="html"><![CDATA[Dylan J. Foster, Noah Golowich, Sham M. Kakade]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal Approximation Property of Hamiltonian Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.12147</id>
        <link href="http://arxiv.org/abs/2303.12147"/>
        <updated>2023-03-23T07:14:03.468Z</updated>
        <summary type="html"><![CDATA[Muhammad Zakwan, Massimiliano d'Angelo, Giancarlo Ferrari-Trecate]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pablumese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58260</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58260&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pablumese"/>
        <updated>2023-03-23T03:33:53.000Z</updated>
        <summary type="html"><![CDATA[Knowing how much I like to invent terms for things that have no name ("topolect", "character amnesia", etc.), and needing a word for the parlance produced by ChatGPT-4 and kindred AI chatbots, Conal Boyce asked me to coin a term for it.  I instantly obliged him by coming up with "pablumese" to designate the sort […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The mind of artificial intelligence]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58255</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58255&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-mind-of-artificial-intelligence"/>
        <updated>2023-03-23T02:39:32.000Z</updated>
        <summary type="html"><![CDATA[Sean Carroll's Preposterous Universe Podcast #230 Raphaël Millière on How Artificial Intelligence Thinks, March 20, 2023 / Philosophy, Technology, Thinking / Comments     Includes transcript of the two hour podcast. Welcome to another episode of Sean Carroll's Mindscape. Today, we're joined by Raphaël Millière, a philosopher and cognitive scientist at Columbia University. We'll be exploring the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up text processing in Python (is hard)]]></title>
        <id>https://pythonspeed.com/articles/faster-text-processing/</id>
        <link href="https://pythonspeed.com/articles/faster-text-processing/"/>
        <updated>2023-03-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[If you’re doing text or string manipulation in Python, what do you do if your code is too slow?
Assuming your algorithm is reasonably efficient, the next step is to try faster alternatives to Python: a compiled extension.
Unfortunately, this is harder than it seems.
Some options don’t offer an easy path to optimizations, others are actually slower.
To see this limitation in action, we’ll consider some alternatives:
Pure Python, with the default Python interpreter.
Cython.
mypyc.
Rust.
Pure Python, with the PyPy interpreter.
We’ll also consider what can be done if these option don’t help.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[nominees for Nebula 2022 [reposted]]]></title>
        <id>http://xianblog.wordpress.com/?p=52523</id>
        <link href="https://xianblog.wordpress.com/2023/03/23/nominees-for-nebula-2022-reposted/"/>
        <updated>2023-03-22T23:23:47.000Z</updated>
        <summary type="html"><![CDATA[Books I had not read, although some are on my reading list… Novel Legends & Lattes, Travis Baldree [to read] Spear, Nicola Griffith Nettle and Bone, T. Kingfisher [to read] Babel, Or the Necessity of Violence: An Arcane History of the Oxford Translators’ Revolution, R.F. Kuang [to read] Nona the Ninth, Tamsyn Muir [to read] […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We May be Surprised Again: Why I take LLMs seriously.]]></title>
        <id>6409ab352445f5003d117961</id>
        <link href="https://www.inference.vc/we-may-be-surprised-again/"/>
        <updated>2023-03-22T14:55:54.000Z</updated>
        <summary type="html"><![CDATA["Deep Learning is Easy, Learn something Harder" - I proclaimed in one of my early and provocative blog posts from 2016. While some observations were fair, that post is now evidence that I clearly underestimated the the impact simple techniques will have, and probably gave counterproductive advice.
I]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fighting Money Laundering with Statistics and Machine Learning]]></title>
        <id>http://arxiv.org/abs/2201.04207</id>
        <link href="http://arxiv.org/abs/2201.04207"/>
        <updated>2023-03-22T07:14:22.810Z</updated>
        <summary type="html"><![CDATA[Rasmus Jensen, Alexandros Iosifidis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How (Implicit) Regularization of ReLU Neural Networks Characterizes the
  Learned Function -- Part II: the Multi-D Case of Two Layers with Random First
  Layer]]></title>
        <id>http://arxiv.org/abs/2303.11454</id>
        <link href="http://arxiv.org/abs/2303.11454"/>
        <updated>2023-03-22T07:14:22.779Z</updated>
        <summary type="html"><![CDATA[Jakob Heiss, Josef Teichmann, Hanna Wutte]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing
  and Neural Networks with Quadratic Activations]]></title>
        <id>http://arxiv.org/abs/2303.11453</id>
        <link href="http://arxiv.org/abs/2303.11453"/>
        <updated>2023-03-22T07:14:18.103Z</updated>
        <summary type="html"><![CDATA[Nived Rajaraman, Devvrit, Aryan Mokhtari, Kannan Ramchandran]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uniform Risk Bounds for Learning with Dependent Data Sequences]]></title>
        <id>http://arxiv.org/abs/2303.11650</id>
        <link href="http://arxiv.org/abs/2303.11650"/>
        <updated>2023-03-22T07:14:18.096Z</updated>
        <summary type="html"><![CDATA[Fabien Lauer (ABC)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DIPPM: a Deep Learning Inference Performance Predictive Model using
  Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.11733</id>
        <link href="http://arxiv.org/abs/2303.11733"/>
        <updated>2023-03-22T07:14:18.059Z</updated>
        <summary type="html"><![CDATA[Karthick Panner Selvam, Mats Brorsson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch 2.0 &amp; XLA—The Latest Cutting Edge Features]]></title>
        <id>https://pytorch.org/blog/pytorch-2.0-xla/</id>
        <link href="https://pytorch.org/blog/pytorch-2.0-xla/"/>
        <updated>2023-03-22T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today, we are excited to share our latest work for PyTorch/XLA 2.0. The release of PyTorch 2.0 is yet another major milestone for this storied community and we are excited to continue to be part of it. When the PyTorch/XLA project started in 2018 between Google and Meta, the focus was on bringing cutting edge Cloud TPUs to help support the PyTorch community. Along the way, others in the community such as Amazon joined the project and very quickly the community expanded. We are excited about XLA’s direction and the benefits this project continues to bring to the PyTorch community. In this blog we’d like to showcase some key features that have been in development, show code snippets, and illustrate the benefit through some benchmarks.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT-4:  threat or boon to the Great Firewall?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58250</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58250&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-4-threat-or-boon-to-the-great-firewall"/>
        <updated>2023-03-22T00:57:55.000Z</updated>
        <summary type="html"><![CDATA["The practical value of LLMs is high enough that it will induce Chinese to seek out the best systems, and they will not be censored by China.” "Yes, the Chinese Great Firewall will be collapsing" by  Tyler Cowen Marginal Revolution (March 21, 2023) Something that the PRC censors had not predicted: As framed from China: […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[畅谈 GhatGPT 在学界的应用]]></title>
        <id>https://cosx.org/2023/03/chatgpt-in-education/</id>
        <link href="https://cosx.org/2023/03/chatgpt-in-education/"/>
        <updated>2023-03-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[本文根据作者在 2023 年 2 月 18 日统计之都云讲堂的发言整理修改而成。 1 惊人的体验 最近试用了一下 ChatGPT。正如很多人描绘的那样，这个产品震撼人心]]></summary>
        <author>
            <name>统计之都</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[partial rankings and aggregate ranks]]></title>
        <id>http://xianblog.wordpress.com/?p=52519</id>
        <link href="https://xianblog.wordpress.com/2023/03/22/partial-rankings-and-aggregate-ranks/"/>
        <updated>2023-03-21T23:23:05.000Z</updated>
        <summary type="html"><![CDATA[When interviewing impressive applicants from a stunning variety of places and background for fellows in our Data Science for Social Good program (in Warwick and Kaiserslautern) this summer, we came through the common conundrum of comparing ranks while each of us only meeting a subset of the candidates. Over a free morning, I briefly thought […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Writing English with Chinese characters]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58243</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58243&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=writing-english-with-chinese-characters-2"/>
        <updated>2023-03-21T10:47:55.000Z</updated>
        <summary type="html"><![CDATA[Responding to "Transcriptional Chinese animal imagery for English daily greetings" (3/13/23), Mary Erbaugh, using Yale Cantonese romanization, writes: ———— I've never seen it done with animal names, though probably easier to remember, amusing. I'm used to the English word pronunciations in old fashioned HK (& Taiwan) almanacs, like the Bou Lòh Maahn Yauh (Cant.) / […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calibration of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.10761</id>
        <link href="http://arxiv.org/abs/2303.10761"/>
        <updated>2023-03-21T07:14:24.812Z</updated>
        <summary type="html"><![CDATA[Ruslan Vasilev, Alexander D'yakonov]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is Q-Learning Minimax Optimal? A Tight Sample Complexity Analysis]]></title>
        <id>http://arxiv.org/abs/2102.06548</id>
        <link href="http://arxiv.org/abs/2102.06548"/>
        <updated>2023-03-21T07:14:24.806Z</updated>
        <summary type="html"><![CDATA[Gen Li, Changxiao Cai, Yuxin Chen, Yuting Wei, Yuejie Chi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spatially heterogeneous learning by a deep student machine]]></title>
        <id>http://arxiv.org/abs/2302.07419</id>
        <link href="http://arxiv.org/abs/2302.07419"/>
        <updated>2023-03-21T07:14:24.799Z</updated>
        <summary type="html"><![CDATA[Hajime Yoshino]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Byzantine-Robust Federated Learning with Optimal Statistical Rates and
  Privacy Guarantees]]></title>
        <id>http://arxiv.org/abs/2205.11765</id>
        <link href="http://arxiv.org/abs/2205.11765"/>
        <updated>2023-03-21T07:14:24.793Z</updated>
        <summary type="html"><![CDATA[Banghua Zhu, Lun Wang, Qi Pang, Shuai Wang, Jiantao Jiao, Dawn Song,
  Michael I. Jordan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantile and moment neural networks for learning functionals of
  distributions]]></title>
        <id>http://arxiv.org/abs/2303.11060</id>
        <link href="http://arxiv.org/abs/2303.11060"/>
        <updated>2023-03-21T07:14:24.768Z</updated>
        <summary type="html"><![CDATA[Xavier Warin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Donoho: 数据科学50年]]></title>
        <id>https://cosx.org/2023/03/50-years-of-data-science-cn/</id>
        <link href="https://cosx.org/2023/03/50-years-of-data-science-cn/"/>
        <updated>2023-03-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[统计之都编辑部按：本文译自 Donoho (2017): 50 Years of Data Science，发表在 Journal of Computational and Graphical Statistics 杂志。在正式发表前数年，其初版就广为流传，引发了学术界深入、持续的讨]]></summary>
        <author>
            <name>统计之都</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[JAGS Workshop [10-14 July 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=52500</id>
        <link href="https://xianblog.wordpress.com/2023/03/21/jags-workshop-10-14-july-2023/"/>
        <updated>2023-03-20T23:23:44.000Z</updated>
        <summary type="html"><![CDATA[Hey, JAGS users and would-be users, be warned that registration is now open for the annual JAGS workshop on probabilistic modelling for cognitive science. The tenth instalment of this workshop takes place July 10–14, 2023 in Amsterdam and online. This workshop is meant for researchers who want to learn how to apply Bayesian inference in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chateau Puy-Bardens [second hand Cadillac]]]></title>
        <id>http://xianblog.wordpress.com/?p=52434</id>
        <link href="https://xianblog.wordpress.com/2023/03/20/chateay-puy-bardens-second-hand-cadillac/"/>
        <updated>2023-03-20T19:20:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[达观数据陈运文：探索大语言模型，“对症下药”很关键]]></title>
        <id>https://www.52nlp.cn/?p=13430</id>
        <link href="https://www.52nlp.cn/%e8%be%be%e8%a7%82%e6%95%b0%e6%8d%ae%e9%99%88%e8%bf%90%e6%96%87%ef%bc%9a%e6%8e%a2%e7%b4%a2%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%ef%bc%8c%e5%af%b9%e7%97%87%e4%b8%8b%e8%8d%af"/>
        <updated>2023-03-20T10:33:59.000Z</updated>
        <summary type="html"><![CDATA[内容来源：ChatGPT 及大模型专题研讨会  分享嘉宾：达观数据董事长兼CEO 陈运文博士 分享主 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multivariate Probabilistic CRPS Learning with an Application to
  Day-Ahead Electricity Prices]]></title>
        <id>http://arxiv.org/abs/2303.10019</id>
        <link href="http://arxiv.org/abs/2303.10019"/>
        <updated>2023-03-20T07:15:53.287Z</updated>
        <summary type="html"><![CDATA[Jonathan Berrisch, Florian Ziel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Breaking the Sample Size Barrier in Model-Based Reinforcement Learning
  with a Generative Model]]></title>
        <id>http://arxiv.org/abs/2005.12900</id>
        <link href="http://arxiv.org/abs/2005.12900"/>
        <updated>2023-03-20T07:15:53.282Z</updated>
        <summary type="html"><![CDATA[Gen Li, Yuting Wei, Yuejie Chi, Yuxin Chen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised domain adaptation by learning using privileged information]]></title>
        <id>http://arxiv.org/abs/2303.09350</id>
        <link href="http://arxiv.org/abs/2303.09350"/>
        <updated>2023-03-20T07:15:53.276Z</updated>
        <summary type="html"><![CDATA[Adam Breitholtz, Anton Matsson, Fredrik D. Johansson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Non-Asymptotic Framework for Approximate Message Passing in Spiked
  Models]]></title>
        <id>http://arxiv.org/abs/2208.03313</id>
        <link href="http://arxiv.org/abs/2208.03313"/>
        <updated>2023-03-20T07:15:53.271Z</updated>
        <summary type="html"><![CDATA[Gen Li, Yuting Wei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[《为什么现在的LLM都是Decoder-only的架构？》FAQ]]></title>
        <id>https://kexue.fm/archives/9547</id>
        <link href="https://kexue.fm/archives/9547"/>
        <updated>2023-03-20T06:53:00.000Z</updated>
        <summary type="html"><![CDATA[上周笔者写了《为什么现在的LLM都是Decoder-only的架构？》，总结了一下我在这个问题上的一些实验结论和猜测。果然是热点问题流量大，paperweekly的转发没多久阅读量就破万了，知乎...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No depth-charge channel is too noisy to be confused by]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58246</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58246&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=no-depth-charge-channel-is-too-noisy-to-be-confused-by"/>
        <updated>2023-03-20T02:10:45.000Z</updated>
        <summary type="html"><![CDATA[Yuhan Zhang, Rachel Ryskin & Edward Gibson, "A noisy-channel approach to depth-charge illusions." Cognition, March 2023: The “depth-charge” sentence, No head injury is too trivial to be ignored, is often interpreted as “no matter how trivial head injuries are, we should not ignore them” while the literal meaning is the opposite – “we should ignore […]]]></summary>
        <author>
            <name>Neal Goldfarb</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BayesComp²³ [aka MCMski⁶]]]></title>
        <id>http://xianblog.wordpress.com/?p=52587</id>
        <link href="https://xianblog.wordpress.com/2023/03/20/bayescomp%c2%b2%c2%b3-aka-mcmski%e2%81%b6/"/>
        <updated>2023-03-19T23:23:09.000Z</updated>
        <summary type="html"><![CDATA[The main BayesComp meeting started right after the ABC workshop and went on at a grueling pace, and offered a constant conundrum as to which of the four sessions to attend, the more when trying to enjoy some outdoor activity during the lunch breaks. My overall feeling is that it went on too fast, too […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Serif or sans serif?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58227</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58227&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=serif-or-sans-serif"/>
        <updated>2023-03-19T10:39:31.000Z</updated>
        <summary type="html"><![CDATA[Most people care about their typefaces Appearances matter, especially whether fonts have serifs or not. "Font Wars Spread After State Department Replaces Times New Roman with Calibri "'I'm banging my head against the wall;' camps divided in fallout from government efforts to make documents easier to read" By Katie Deighton, WSJ (3/14/23) One wonders whether […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[optimal scaling for proximal MALA [All about that Bayes seminar, 21/03, Palaiseau]]]></title>
        <id>http://xianblog.wordpress.com/?p=52571</id>
        <link href="https://xianblog.wordpress.com/2023/03/19/optimal-scaling-for-proximal-mala-21-03/"/>
        <updated>2023-03-18T23:23:18.000Z</updated>
        <summary type="html"><![CDATA[An All about that Bayes seminar next Tuesday, at 2pm, at AgroParisTech, Francesca Crucinio (formerly Warwick and now ENSAE): We consider a recently proposed class of MCMC methods which uses proximity maps instead of gradients to build proposal mechanisms which can be employed for both differentiable and non-differentiable targets. These methods have been shown to […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Subscribe to Open"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58232</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58232&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=subscribe-to-open"/>
        <updated>2023-03-18T12:02:34.000Z</updated>
        <summary type="html"><![CDATA[As the S2O website explains, “Subscribe to Open” (S2O) is a pragmatic approach for converting subscription journals to open access—free and immediate online availability of research—without reliance on either article processing charges (APCs) or altruism. […] S2O allows publishers to convert journals from subscriptions to OA, one year at a time. Using S2O, a publisher […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Black hole information recovery from gravitational waves]]></title>
        <id>http://arxiv.org/abs/2211.13736</id>
        <link href="http://arxiv.org/abs/2211.13736"/>
        <updated>2023-03-18T07:13:58.483Z</updated>
        <summary type="html"><![CDATA[Louis Hamaide, Theo Torres]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kuva Lapista⁴]]></title>
        <id>http://xianblog.wordpress.com/?p=52604</id>
        <link href="https://xianblog.wordpress.com/2023/03/18/kuva-lapista%e2%81%b4/"/>
        <updated>2023-03-17T23:23:15.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vid2Seq: a pretrained visual language model for describing multi-event videos]]></title>
        <id>http://ai.googleblog.com/2023/03/vid2seq-pretrained-visual-language.html</id>
        <link href="http://ai.googleblog.com/2023/03/vid2seq-pretrained-visual-language.html"/>
        <updated>2023-03-17T17:52:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Antoine Yang, Student Researcher, and Arsha Nagrani, Research Scientist, Google Research, Perception team    
Videos have become an increasingly important part of our daily lives, spanning fields such as entertainment, education, and communication. Understanding the content of videos, however, is a challenging task as videos often contain multiple events occurring at different time scales. For example, a video of a musher hitching up dogs to a dog sled before they all race away involves a long event (the dogs pulling the sled) and a short event (the dogs being hitched to the sled). One way to spur research in video understanding is via the task of dense video captioning, which consists of temporally localizing and describing all events in a minutes-long video. This differs from s…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[So many words for "donkey"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58210</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58210&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=so-many-words-for-donkey"/>
        <updated>2023-03-17T10:37:20.000Z</updated>
        <summary type="html"><![CDATA[Almost as many as Eskimo words for "snow".  (hee-hee haw-haw) (see below for a sampling) I've always been a great admirer of donkeys, and I love to hear them bray and make all sorts of other expressive sounds, some of which I am incapable of adequately expressing in words — especially when they are being […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Sea of Words: An In-Depth Analysis of Anchors for Text Data]]></title>
        <id>http://arxiv.org/abs/2205.13789</id>
        <link href="http://arxiv.org/abs/2205.13789"/>
        <updated>2023-03-17T07:15:04.611Z</updated>
        <summary type="html"><![CDATA[Gianluigi Lopardo, Frederic Precioso, Damien Garreau]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combining Distance to Class Centroids and Outlier Discounting for
  Improved Learning with Noisy Labels]]></title>
        <id>http://arxiv.org/abs/2303.09470</id>
        <link href="http://arxiv.org/abs/2303.09470"/>
        <updated>2023-03-17T07:15:04.606Z</updated>
        <summary type="html"><![CDATA[Farooq Ahmad Wani, Maria Sofia Bucarelli, Fabrizio Silvestri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Generalization Error in Linear Neural Networks with Concept
  Bottleneck Structure and Multitask Formulation]]></title>
        <id>http://arxiv.org/abs/2303.09154</id>
        <link href="http://arxiv.org/abs/2303.09154"/>
        <updated>2023-03-17T07:15:04.600Z</updated>
        <summary type="html"><![CDATA[Naoki Hayashi, Yoshihide Sawada]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Lower Bounds on the Depth of ReLU Neural Networks]]></title>
        <id>http://arxiv.org/abs/2105.14835</id>
        <link href="http://arxiv.org/abs/2105.14835"/>
        <updated>2023-03-17T07:15:04.592Z</updated>
        <summary type="html"><![CDATA[Christoph Hertrich, Amitabh Basu, Marco Di Summa, Martin Skutella]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[为什么现在的LLM都是Decoder-only的架构？]]></title>
        <id>https://kexue.fm/archives/9529</id>
        <link href="https://kexue.fm/archives/9529"/>
        <updated>2023-03-17T02:44:00.000Z</updated>
        <summary type="html"><![CDATA[LLM是“Large Language Model”的简写，目前一般指百亿参数以上的语言模型，主要面向文本生成任务。跟小尺度模型（10亿或以内量级）的“百花齐放”不同，目前LLM的一个现状是De...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Personalized Decision Making under Concurrent-Controlled RCT Data]]></title>
        <id>http://causality.cs.ucla.edu/blog/?p=2463</id>
        <link href="http://causality.cs.ucla.edu/blog/index.php/2023/03/17/personalized-decision-making-under-concurrent-controlled-rct-data/"/>
        <updated>2023-03-17T02:31:21.000Z</updated>
        <summary type="html"><![CDATA[Scott Mueller and Judea Pearl Introduction This note supplements the analysis of [Mueller and Pearl 2023] by introducing an important restriction on the data obtained from Randomized Control Trials (RCT). In Mueller and Pearl, it is assumed that RCTs provide estimates of two probabilities, \(P(y_t)\) and \(P(y_c)\), standing for the probability of the outcome \(Y\) […]]]></summary>
        <author>
            <name>Scott Mueller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kuva Lapista³ [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=52580</id>
        <link href="https://xianblog.wordpress.com/2023/03/17/kuva-lapista%c2%b3-jatp/"/>
        <updated>2023-03-16T23:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: The Impact Lab]]></title>
        <id>http://ai.googleblog.com/2023/03/responsible-ai-at-google-research.html</id>
        <link href="http://ai.googleblog.com/2023/03/responsible-ai-at-google-research.html"/>
        <updated>2023-03-16T20:13:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Jamila Smith-Loud, Human Rights & Social Impact Research Lead, Google Research, Responsible AI and Human-Centered Technology Team 
    

Globalized technology has the potential to create large-scale societal impact, and having a grounded research approach rooted in existing international human and civil rights standards is a critical component to assuring responsible and ethical AI development and deployment. The Impact Lab team, part of Google’s Responsible AI Team, employs a range of interdisciplinary methodologies to ensure critical and rich analysis of the potential implications of technology development. The team’s mission is to examine socioeconomic and human rights impacts of AI,  publish foundational research, and incubate novel mitigations enabling machine learning (ML) …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some News from a Seminar in Cambridge]]></title>
        <id>http://gilkalai.wordpress.com/?p=24009</id>
        <link href="https://gilkalai.wordpress.com/2023/03/16/some-news-from-a-seminar-in-cambridge/"/>
        <updated>2023-03-16T19:02:01.000Z</updated>
        <summary type="html"><![CDATA[On an old problems of Erdős (h/t Michael Simkin and Nati Linial) Here is a somewhat mysterious announcement for a combinatorics seminar lecture at Cambridge. Which old problems of Erdős are we talking about? Here is a picture from the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some News from a Seminar in Cambridge]]></title>
        <id>http://gilkalai.wordpress.com/?p=24009</id>
        <link href="https://gilkalai.wordpress.com/2023/03/16/some-news-from-a-seminar-in-cambridge/"/>
        <updated>2023-03-16T19:02:01.000Z</updated>
        <summary type="html"><![CDATA[On an old problems of Erdős (h/t Michael Simkin and Nati Linial) Here is a somewhat mysterious announcement for a combinatorics seminar lecture at Cambridge. Which old problems of Erdős are we talking about? Here is a picture from the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[arX[g]iv[e]]]></title>
        <id>http://xianblog.wordpress.com/?p=52591</id>
        <link href="https://xianblog.wordpress.com/2023/03/16/give2arxive/"/>
        <updated>2023-03-16T13:44:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[复旦邱锡鹏：深度剖析 ChatGPT 类大语言模型的关键技术]]></title>
        <id>https://www.52nlp.cn/?p=13428</id>
        <link href="https://www.52nlp.cn/%e5%a4%8d%e6%97%a6%e9%82%b1%e9%94%a1%e9%b9%8f%ef%bc%9a%e6%b7%b1%e5%ba%a6%e5%89%96%e6%9e%90-chatgpt-%e7%b1%bb%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%85%b3%e9%94%ae%e6%8a%80%e6%9c%af"/>
        <updated>2023-03-16T08:42:14.000Z</updated>
        <summary type="html"><![CDATA[内容来源：ChatGPT 及大模型专题研讨会分享嘉宾：复旦大教授 邱锡鹏分享主题：《对话式大型语言模型》转载自 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Benefits of Mixup for Feature Learning]]></title>
        <id>http://arxiv.org/abs/2303.08433</id>
        <link href="http://arxiv.org/abs/2303.08433"/>
        <updated>2023-03-16T07:15:38.179Z</updated>
        <summary type="html"><![CDATA[Difan Zou, Yuan Cao, Yuanzhi Li, Quanquan Gu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Policy learning "without'' overlap: Pessimism and generalized empirical
  Bernstein's inequality]]></title>
        <id>http://arxiv.org/abs/2212.09900</id>
        <link href="http://arxiv.org/abs/2212.09900"/>
        <updated>2023-03-16T07:15:38.167Z</updated>
        <summary type="html"><![CDATA[Ying Jin, Zhimei Ren, Zhuoran Yang, Zhaoran Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Incentivize Information Acquisition: Proper Scoring Rules
  Meet Principal-Agent Model]]></title>
        <id>http://arxiv.org/abs/2303.08613</id>
        <link href="http://arxiv.org/abs/2303.08613"/>
        <updated>2023-03-16T07:15:38.151Z</updated>
        <summary type="html"><![CDATA[Siyu Chen, Jibang Wu, Yifan Wu, Zhuoran Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Resilient Radio Resource Management Policies with Graph Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2203.11012</id>
        <link href="http://arxiv.org/abs/2203.11012"/>
        <updated>2023-03-16T07:15:38.145Z</updated>
        <summary type="html"><![CDATA[Navid NaderiAlizadeh, Mark Eisen, Alejandro Ribeiro]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Delay-SDE-net: A deep learning approach for time series modelling with
  memory and uncertainty estimates]]></title>
        <id>http://arxiv.org/abs/2303.08587</id>
        <link href="http://arxiv.org/abs/2303.08587"/>
        <updated>2023-03-16T07:15:38.140Z</updated>
        <summary type="html"><![CDATA[Mari Dahl Eggen, Alise Danielle Midtfjord]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerated Diffusers with PyTorch 2.0]]></title>
        <id>https://pytorch.org/blog/accelerated-diffusers-pt-20/</id>
        <link href="https://pytorch.org/blog/accelerated-diffusers-pt-20/"/>
        <updated>2023-03-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[PyTorch 2.0 has just been released. Its flagship new feature is torch.compile(), a one-line code change that promises to automatically improve performance across codebases. We have previously checked on that promise in Hugging Face Transformers and TIMM models, and delved deep into its motivation, architecture and the road ahead.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[This is the 4th time I've gotten Jack and his beanstalk]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58196</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58196&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=this-is-the-4th-time-ive-gotten-jack-and-his-beanstalk"/>
        <updated>2023-03-16T00:45:39.000Z</updated>
        <summary type="html"><![CDATA[Bill Benzon shares the response he got from ChatGPT to the prompt, "Tell me a story." Here's the response: Once upon a time, in a far-off land, there was a young boy named Jack who lived with his mother. They were very poor and struggled to make ends meet. One day, Jack's mother sent him […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ABC in Lapland²]]></title>
        <id>http://xianblog.wordpress.com/?p=52563</id>
        <link href="https://xianblog.wordpress.com/2023/03/16/abc-in-lapland%c2%b2/"/>
        <updated>2023-03-15T23:23:18.000Z</updated>
        <summary type="html"><![CDATA[On the second day of our workshop, Aki Vehtari gave a short talk about his recent works on speed up post processing by importance sampling a simulation of an imprecise version of the likelihood until the desired precision is attained, importance corrected by Pareto smoothing¹⁵. A very interesting foray into the meaning of practical models […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tasty McDonald's customer]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58188</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58188&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tasty-mcdonalds-customer"/>
        <updated>2023-03-15T18:40:52.000Z</updated>
        <summary type="html"><![CDATA[The Chinese notice says: Běn yíngyè chǎngsuǒ jǐn xiàn Màidāngláo yòngcān gùkè shǐyòng 本营业场所仅限麦当劳用餐顾客使用 "This place of business is reserved for McDonald's dine-in customers" Can't be too careful when you enter certain places of business. Selected readings "I'm lovin' it — next to the toilet" (12/12/09) "Clipping McDonald's" (7/29/13) [h.t. John Rohsenow]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ABC in Lapland²]]></title>
        <id>http://xianblog.wordpress.com/?p=52563</id>
        <link href="https://xianblog.wordpress.com/2023/03/15/abc-in-lapland%c2%b2/"/>
        <updated>2023-03-15T08:17:18.000Z</updated>
        <summary type="html"><![CDATA[On the second day of our workshop, Aki Vehtari gave a short talk about his recent works on speed up post processing by importance sampling a simulation of an imprecise version of the likelihood until the desired precision is attained, importance corrected by Pareto smoothing¹⁵. A very interesting foray into the meaning of practical models […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generation of Paths in a Maze using a Deep Network without Learning]]></title>
        <id>http://arxiv.org/abs/2004.00540</id>
        <link href="http://arxiv.org/abs/2004.00540"/>
        <updated>2023-03-15T07:14:58.971Z</updated>
        <summary type="html"><![CDATA[Tomas Kulvicius, Sebastian Herzog, Minija Tamosiunaite, Florentin
  W\"org\"otter]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Algorithms that get old : the case of generative deep neural networks]]></title>
        <id>http://arxiv.org/abs/2202.03008</id>
        <link href="http://arxiv.org/abs/2202.03008"/>
        <updated>2023-03-15T07:14:58.966Z</updated>
        <summary type="html"><![CDATA[Gabriel Turinici]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pretrained Language Models are Symbolic Mathematics Solvers too!]]></title>
        <id>http://arxiv.org/abs/2110.03501</id>
        <link href="http://arxiv.org/abs/2110.03501"/>
        <updated>2023-03-15T07:14:58.961Z</updated>
        <summary type="html"><![CDATA[Kimia Noorbakhsh, Modar Sulaiman, Mahdi Sharifi, Kallol Roy, Pooyan
  Jamshidi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning-Based Estimation and Goodness-of-Fit for Large-Scale
  Confirmatory Item Factor Analysis]]></title>
        <id>http://arxiv.org/abs/2109.09500</id>
        <link href="http://arxiv.org/abs/2109.09500"/>
        <updated>2023-03-15T07:14:58.096Z</updated>
        <summary type="html"><![CDATA[Christopher J. Urban, Daniel J. Bauer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prompt Engineering]]></title>
        <id>https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/</id>
        <link href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/"/>
        <updated>2023-03-15T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.
Useful resources:
 OpenAI Cookbook has many in-depth examples for how to utilize LLM efficiently. Prompt Engineering Guide repo contains a pretty comprehensive collection of education materials on prompt engineering.]]></summary>
        <author>
            <name>Lil'Log</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ABC in Lapland]]></title>
        <id>http://xianblog.wordpress.com/?p=52548</id>
        <link href="https://xianblog.wordpress.com/2023/03/15/abc-in-lapland/"/>
        <updated>2023-03-14T23:23:58.000Z</updated>
        <summary type="html"><![CDATA[Greetings from Levi, Lapland! Sonia Petrone beautifully started the ABC workshop with a (the!) plenary Sunday night talk on quasi-Bayes in the spirit of both Fortini & Petrone (2020) and the more recent Fong, Holmes, and Walker (2023). The talk got me puzzled by wondering the nature of convergence, in that it happens no matter […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Female voyeuristic literature on male homoerotic themes]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58202</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58202&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=female-voyeuristic-literature-on-male-homoerotic-themes"/>
        <updated>2023-03-14T22:46:22.000Z</updated>
        <summary type="html"><![CDATA[When I first heard of this phenomenon about three years ago, I could scarcely believe my ears.  I was told in no uncertain terms that, by and large, Chinese women (especially in their 20s and 30s, but even in their teens) much more enjoy watching or reading about men making out than engaging in hetero- […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning from deep learning: a case study of feature discovery and validation in pathology]]></title>
        <id>http://ai.googleblog.com/2023/03/learning-from-deep-learning-case-study.html</id>
        <link href="http://ai.googleblog.com/2023/03/learning-from-deep-learning-case-study.html"/>
        <updated>2023-03-14T18:16:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Ellery Wulczyn and Yun Liu, Google Research  
When a patient is diagnosed with cancer, one of the most important steps is examination of the tumor under a microscope by pathologists to determine the cancer stage and to characterize the tumor. This information is central to understanding clinical prognosis (i.e., likely patient outcomes) and for determining the most appropriate treatment, such as undergoing surgery alone versus surgery plus chemotherapy. Developing machine learning (ML) tools in pathology to assist with the microscopic review represents a compelling research area with many potential applications. 

Previous studies have shown that ML can accurately identify and classify tumors in pathology images and can even predict patient prognosis using known pathology feature…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[缓解交叉熵过度自信的一个简明方案]]></title>
        <id>https://kexue.fm/archives/9526</id>
        <link href="https://kexue.fm/archives/9526"/>
        <updated>2023-03-14T08:01:00.000Z</updated>
        <summary type="html"><![CDATA[众所周知，分类问题的常规评估指标是正确率，而标准的损失函数则是交叉熵，交叉熵有着收敛快的优点，但它并非是正确率的光滑近似，这就带来了训练和预测的不一致性问题。另一方面，当训练样本的预测概率很低时...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Score Attack: A Lower Bound Technique for Optimal Differentially Private
  Learning]]></title>
        <id>http://arxiv.org/abs/2303.07152</id>
        <link href="http://arxiv.org/abs/2303.07152"/>
        <updated>2023-03-14T07:16:32.259Z</updated>
        <summary type="html"><![CDATA[T. Tony Cai, Yichen Wang, Linjun Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stabilizing Transformer Training by Preventing Attention Entropy
  Collapse]]></title>
        <id>http://arxiv.org/abs/2303.06296</id>
        <link href="http://arxiv.org/abs/2303.06296"/>
        <updated>2023-03-14T07:16:32.215Z</updated>
        <summary type="html"><![CDATA[Shuangfei Zhai, Tatiana Likhomanenko, Etai Littwin, Dan Busbridge,
  Jason Ramapuram, Yizhe Zhang, Jiatao Gu, Josh Susskind]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Comparing statistical and machine learning methods for time series
  forecasting in data-driven logistics -- A simulation study]]></title>
        <id>http://arxiv.org/abs/2303.07139</id>
        <link href="http://arxiv.org/abs/2303.07139"/>
        <updated>2023-03-14T07:16:32.191Z</updated>
        <summary type="html"><![CDATA[Lena Schmid, Moritz Roidl, Markus Pauly]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Feature Screening: Feature Selection for Ultra High-Dimensional
  Data via Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2204.01682</id>
        <link href="http://arxiv.org/abs/2204.01682"/>
        <updated>2023-03-14T07:16:31.952Z</updated>
        <summary type="html"><![CDATA[Kexuan Li, Fangfang Wang, Lingli Yang, Ruiqi Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kuva Lapista² [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=52544</id>
        <link href="https://xianblog.wordpress.com/2023/03/14/kuva-lapista%c2%b2-jatp/"/>
        <updated>2023-03-13T23:23:26.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transcriptional Chinese animal imagery for English daily greetings]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58199</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58199&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=transcriptional-chinese-animal-imagery-for-english-daily-greetings"/>
        <updated>2023-03-13T22:35:47.000Z</updated>
        <summary type="html"><![CDATA[As those students who take my early morning classes know, I sometimes greet them with "gǒutóu māo níng 狗头猫咛" ("good morning"; lit. "dog's head cat's meow").  I learned that method of transcription from my father-in-law, who didn't know the alphabet but picked up a few words of English and wanted to write them down for […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DORA: Exploring outlier representations in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2206.04530</id>
        <link href="http://arxiv.org/abs/2206.04530"/>
        <updated>2023-03-13T07:15:14.746Z</updated>
        <summary type="html"><![CDATA[Kirill Bykov, Mayukh Deb, Dennis Grinwald, Klaus-Robert M\"uller,
  Marina M.-C. H\"ohne]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An analytic theory for the dynamics of wide quantum neural networks]]></title>
        <id>http://arxiv.org/abs/2203.16711</id>
        <link href="http://arxiv.org/abs/2203.16711"/>
        <updated>2023-03-13T07:15:14.740Z</updated>
        <summary type="html"><![CDATA[Junyu Liu, Khadijeh Najafi, Kunal Sharma, Francesco Tacchino, Liang
  Jiang, Antonio Mezzacapo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2211.01340</id>
        <link href="http://arxiv.org/abs/2211.01340"/>
        <updated>2023-03-13T07:15:14.703Z</updated>
        <summary type="html"><![CDATA[Randall Balestriero, Yann LeCun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variance-aware robust reinforcement learning with linear function
  approximation with heavy-tailed rewards]]></title>
        <id>http://arxiv.org/abs/2303.05606</id>
        <link href="http://arxiv.org/abs/2303.05606"/>
        <updated>2023-03-13T07:15:14.697Z</updated>
        <summary type="html"><![CDATA[Xiang Li, Qiang Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Seq2Seq Surrogates of Epidemic Models to Facilitate Bayesian Inference]]></title>
        <id>http://arxiv.org/abs/2209.09617</id>
        <link href="http://arxiv.org/abs/2209.09617"/>
        <updated>2023-03-13T07:15:14.690Z</updated>
        <summary type="html"><![CDATA[Giovanni Charles, Timothy M. Wolock, Peter Winskill, Azra Ghani, Samir
  Bhatt, Seth Flaxman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New Library Updates in PyTorch 2.0]]></title>
        <id>https://pytorch.org/blog/new-library-updates-in-pytorch-2.0/</id>
        <link href="https://pytorch.org/blog/new-library-updates-in-pytorch-2.0/"/>
        <updated>2023-03-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Summary]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever]]></title>
        <id>https://pytorch.org/blog/pytorch-2.0-release/</id>
        <link href="https://pytorch.org/blog/pytorch-2.0-release/"/>
        <updated>2023-03-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to announce the release of PyTorch® 2.0 which we highlighted during the PyTorch Conference on 12/2/22! PyTorch 2.0 offers the same eager-mode development and user experience, while fundamentally changing and supercharging how PyTorch operates at compiler level under the hood with faster performance and support for Dynamic Shapes and Distributed.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[alone in Napoli]]></title>
        <id>http://xianblog.wordpress.com/?p=52333</id>
        <link href="https://xianblog.wordpress.com/2023/03/13/alone-in-napoli/"/>
        <updated>2023-03-12T23:23:39.000Z</updated>
        <summary type="html"><![CDATA[A combinatorics puzzle from The Riddler about a Napoli solitaire where 4 x 10 cards numbered from 1 to 10 are shuffled and the game is lost when a number (1,2, or 3) is equal to its position modulo 3 (1,2 or 3). A simple R code shows that the probability of winning is around […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[kuva Lapista¹]]></title>
        <id>http://xianblog.wordpress.com/?p=52539</id>
        <link href="https://xianblog.wordpress.com/2023/03/13/kuva-lapista/"/>
        <updated>2023-03-12T23:23:06.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the plague, sword, and famine year [no end on sight]]]></title>
        <id>http://xianblog.wordpress.com/?p=52340</id>
        <link href="https://xianblog.wordpress.com/2023/03/12/a-journal-of-the-plague-sword-and-famine-year-4/"/>
        <updated>2023-03-11T23:23:21.000Z</updated>
        <summary type="html"><![CDATA[Read the second volume of The Craft Sequence, Two Serpents Rise, by Max Gladstone,  with great difficulties as I found the story (again) poorly constructed, despite some characters being mostly well-designed (no connection with volume 1, except for taking place in the same universe, if at another time period). Mixing steampunk and hard fantasy involving […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Idle thoughts upon the Ides of March:  the feathered man]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58178</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58178&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=idle-thoughts-upon-the-ides-of-march-the-feathered-man"/>
        <updated>2023-03-11T19:16:11.000Z</updated>
        <summary type="html"><![CDATA[It's a bad month in general:  dark, dreary, drizzly, dank, and damp.  Soon one's thoughts are flitting* about as though one had taken wings, like Eros or Cupid. In Chinese mythology, there is a deity called Yǔrén 羽人 ("Feathered Man").  It has an ambiguous origin — first appears in Shānhǎi jīng 山海經 (Classic of the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[off to BayesComp!]]></title>
        <id>http://xianblog.wordpress.com/?p=52425</id>
        <link href="https://xianblog.wordpress.com/2023/03/11/off-to-bayescomp/"/>
        <updated>2023-03-10T23:23:38.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PaLM-E: An embodied multimodal language model]]></title>
        <id>http://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html</id>
        <link href="http://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html"/>
        <updated>2023-03-10T17:25:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Danny Driess, Student Researcher, and Pete Florence, Research Scientist, Robotics at Google  
Recent years have seen tremendous advances across machine learning domains, from models that can explain jokes or answer visual questions in a variety of languages to those that can produce images based on text descriptions. Such innovations have been possible due to the increase in availability of large scale datasets along with novel advances that enable the training of models on these data. While scaling of robotics models has seen some success, it is outpaced by other domains due to a lack of datasets available on a scale comparable to large text corpora or image datasets.  
  
Today we introduce PaLM-E, a new generalist robotics model that overcomes these issues by transferring know…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ludwig Schmidt - A data-centric view on reliable generalization: From ImageNet to LAION-5B]]></title>
        <id>https://mlfoundations.org/talk/schmidt/</id>
        <link href="https://mlfoundations.org/talk/schmidt/"/>
        <updated>2023-03-10T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Researchers have proposed many methods to make neural networks more reliable under distribution shift, yet there is still large room for improvement. Are better training algorithms or training data the more promising way forward? In this talk, we study this question in the context of OpenAI’s CLIP model for learning from image-text data. First, we survey the current robustness landscape based on a large-scale experimental study involving more than 200 different models and test conditions. The CLIP models stand out with unprecedented robustness on multiple challenging distribution shifts. To further improve CLIP, we then introduce new methods for reliably fine-tuning models by interpolating the weights of multiple models. Next, we investigate the cause of CLIP’s robustness via controlled experiments to disentangle the influence of language supervision and training distribution. While CLIP leveraged large scale language supervision for the first time, its robustness actually comes from the pre-training dataset. We conclude with a brief overview of ongoing work to improve pre-training datasets: LAION-5B, the largest public image-text dataset, and initial experiments to increase the robustness induced by pre-training data. Bio: Ludwig Schmidt is an assistant professor in the Paul G. Allen School of Computer Science & Engineering at the University of Washington. Ludwig’s research interests revolve around the empirical foundations of machine learning, often with a focus on datasets, reliable generalization, and large models. Ludwig completed his PhD at MIT under the supervision of Piotr Indyk and was a postdoc at UC Berkeley hosted by Benjamin Recht and Moritz Hardt. Recently, Ludwig’s research group contributed to multimodal language & vision models by creating OpenCLIP and the LAION-5B dataset. Ludwig’s research received a new horizons award at EAAMO, best paper awards at ICML & NeurIPS, a best paper finalist at CVPR, and the Sprowls dissertation award from MIT.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subspace Designs, Unit and Distinct Distances, and Piercing Standard Boxes.]]></title>
        <id>http://gilkalai.wordpress.com/?p=23968</id>
        <link href="https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/"/>
        <updated>2023-03-10T11:28:42.000Z</updated>
        <summary type="html"><![CDATA[A lot of things are happening and let me briefly report on three major advancements in combinatorics. Peter Keevash, Ashwin Sah and Mehtaab Sawhney proved the existence of subspace designs with any given parameters, provided that the dimension of the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subspace Designs, Unit and Distinct Distances, and Piercing Standard Boxes.]]></title>
        <id>http://gilkalai.wordpress.com/?p=23968</id>
        <link href="https://gilkalai.wordpress.com/2023/03/10/subspace-designs-unit-and-distinct-distances-and-piercing-standard-boxes/"/>
        <updated>2023-03-10T11:28:42.000Z</updated>
        <summary type="html"><![CDATA[A lot of things are happening and let me briefly report on three major advancements in combinatorics. Peter Keevash, Ashwin Sah and Mehtaab Sawhney proved the existence of subspace designs with any given parameters, provided that the dimension of the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Expressiveness and Generalization of Hypergraph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.05490</id>
        <link href="http://arxiv.org/abs/2303.05490"/>
        <updated>2023-03-10T07:15:52.089Z</updated>
        <summary type="html"><![CDATA[Zhezheng Luo, Jiayuan Mao, Joshua B. Tenenbaum, Leslie Pack Kaelbling]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TANGOS: Regularizing Tabular Neural Networks through Gradient
  Orthogonalization and Specialization]]></title>
        <id>http://arxiv.org/abs/2303.05506</id>
        <link href="http://arxiv.org/abs/2303.05506"/>
        <updated>2023-03-10T07:15:52.084Z</updated>
        <summary type="html"><![CDATA[Alan Jeffares, Tennison Liu, Jonathan Crabb\'e, Fergus Imrie, Mihaela
  van der Schaar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Rational Subgoals from Demonstrations and Instructions]]></title>
        <id>http://arxiv.org/abs/2303.05487</id>
        <link href="http://arxiv.org/abs/2303.05487"/>
        <updated>2023-03-10T07:15:52.064Z</updated>
        <summary type="html"><![CDATA[Zhezheng Luo, Jiayuan Mao, Jiajun Wu, Tom\'as Lozano-P\'erez, Joshua
  B. Tenenbaum, Leslie Pack Kaelbling]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Agnostic PAC Learning of k-juntas Using L2-Polynomial Regression]]></title>
        <id>http://arxiv.org/abs/2303.04859</id>
        <link href="http://arxiv.org/abs/2303.04859"/>
        <updated>2023-03-10T07:15:52.059Z</updated>
        <summary type="html"><![CDATA[Mohsen Heidari, Wojciech Szpankowski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continual Learning for Monolingual End-to-End Automatic Speech
  Recognition]]></title>
        <id>http://arxiv.org/abs/2112.09427</id>
        <link href="http://arxiv.org/abs/2112.09427"/>
        <updated>2023-03-10T07:15:52.029Z</updated>
        <summary type="html"><![CDATA[Steven Vander Eeckt, Hugo Van hamme]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Running from China]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58175</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58175&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=running-from-china"/>
        <updated>2023-03-10T03:05:23.000Z</updated>
        <summary type="html"><![CDATA[The following image is from a guest post on the Tangle newsletter (3/3/23) that comes from a Chinese dissident who recently fled to the U.S.: The political slogan on the sign glares: xǐ yíng èrshí dà wénmíng rùn wàn jiā 喜迎二十大 文明润万家 "Welcome to the20th National Congress [The Party's] civilized [policies] enrich a myriad families" The […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Effect [book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=52414</id>
        <link href="https://xianblog.wordpress.com/2023/03/10/the-effect-book-review/"/>
        <updated>2023-03-09T23:23:59.000Z</updated>
        <summary type="html"><![CDATA[While it sounds like the title of a science-fiction catastrophe novel or of a (of course) convoluted nouveau roman, this book by Nick Huntington-Klein is a massive initiation to econometrics and causality. As explained by the subtitle, An Introduction to Research Design and Causality. This is a hüûüge book, actually made of two parts that […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The reality of Happiness is Bitterness]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58160</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58160&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-reality-of-happiness-is-bitterness"/>
        <updated>2023-03-09T19:55:38.000Z</updated>
        <summary type="html"><![CDATA[From Kiewwoo Goh: The actual transcription and translation of the first two lines and their one line English mistranslation should be: Shénme dōu shì jiǎ de Zhǐyǒu kǔ shì zhēn de 什么都是假的 只有苦是真的 Everything is false Only suffering is real The next big, composite, quadripartite glyph consists of four "kǔ 苦" ("bitterness; suffering") stacked side by side and on top of each […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The BirdCLEF 2023 Challenge: Pushing the frontiers of biodiversity monitoring]]></title>
        <id>http://ai.googleblog.com/2023/03/the-birdclef-2023-challenge-pushing.html</id>
        <link href="http://ai.googleblog.com/2023/03/the-birdclef-2023-challenge-pushing.html"/>
        <updated>2023-03-09T19:27:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Tom Denton, Software Engineer, Google Research, Brain Team   
Worldwide bird populations are declining at an alarming rate, with approximately 48% of existing bird species known or suspected to be experiencing population declines. For instance, the U.S. and Canada have reported 29% fewer birds since 1970. 

Effective monitoring of bird populations is essential for the development of solutions that promote conservation. Monitoring allows researchers to better understand the severity of the problem for specific bird populations and evaluate whether existing interventions are working. To scale monitoring, bird researchers have started analyzing ecosystems remotely using bird sound recordings instead of physically in-person via passive acoustic monitoring. Researchers can gather thou…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Causal Representation Learning for Instantaneous and Temporal Effects in
  Interactive Systems]]></title>
        <id>http://arxiv.org/abs/2206.06169</id>
        <link href="http://arxiv.org/abs/2206.06169"/>
        <updated>2023-03-09T07:15:59.019Z</updated>
        <summary type="html"><![CDATA[Phillip Lippe, Sara Magliacane, Sindy L\"owe, Yuki M. Asano, Taco
  Cohen, Efstratios Gavves]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Causal Dependence Plots for Interpretable Machine Learning]]></title>
        <id>http://arxiv.org/abs/2303.04209</id>
        <link href="http://arxiv.org/abs/2303.04209"/>
        <updated>2023-03-09T07:15:58.985Z</updated>
        <summary type="html"><![CDATA[Joshua R. Loftus, Lucius E. J. Bynum, Sakina Hansen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Generalization Power of Overfitted Two-Layer Neural Tangent
  Kernel Models]]></title>
        <id>http://arxiv.org/abs/2103.05243</id>
        <link href="http://arxiv.org/abs/2103.05243"/>
        <updated>2023-03-09T07:15:58.941Z</updated>
        <summary type="html"><![CDATA[Peizhong Ju, Xiaojun Lin, Ness B. Shroff]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Message Passing Perspective on Learning Dynamics of Contrastive
  Learning]]></title>
        <id>http://arxiv.org/abs/2303.04435</id>
        <link href="http://arxiv.org/abs/2303.04435"/>
        <updated>2023-03-09T07:15:58.936Z</updated>
        <summary type="html"><![CDATA[Yifei Wang, Qi Zhang, Tianqi Du, Jiansheng Yang, Zhouchen Lin, Yisen
  Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Questions and answers, part 2 (a veritable juggernaut)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58172</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58172&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=questions-and-answers-part-2-a-veritable-juggernaut"/>
        <updated>2023-03-09T02:02:44.000Z</updated>
        <summary type="html"><![CDATA[In my experience, folks have different approaches / attitudes to questions (and answers): 1. some people love to ask questions 2. some people like to answer questions 3. some people don't like to ask questions 4. some people don't like to be asked questions 5. some people like to ask a question as a prelude […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[the secret history of the Lord of Musashi [book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=52404</id>
        <link href="https://xianblog.wordpress.com/2023/03/09/the-secret-history-of-the-lord-of-musashi-book-review/"/>
        <updated>2023-03-08T23:23:16.000Z</updated>
        <summary type="html"><![CDATA[This 1931 book, The Secret History of the Lord of Musashi (武州公秘話) by Jun’ichirō Tanizaki, is a hilarious pastiche of Japanese historical novels. I saw it in a Paris bookstore near my son’s and bought it without realising how much of a gem it is! I actually thought it was connected with the famous swordsman […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interview about this blog in the Bulletin of the EATCS]]></title>
        <id>http://windowsontheory.org/?p=8582</id>
        <link href="https://windowsontheory.org/2023/03/08/interview-about-this-blog-in-the-bulletin-of-the-eatcs/"/>
        <updated>2023-03-08T14:13:20.000Z</updated>
        <summary type="html"><![CDATA[Luca Trevisan recently interviewed me for the Bulletin of the EATCS (see link for the full issue, including an interview with Alexandra Silva, and technical columns by Naama Ben-David, Ryan Williams, and Yuri Gurevich). With Luca’s permission, I am cross-posting it here. (I added some hyperlinks to relevant documents.) Q. Boaz, thanks for taking the … Continue reading Interview about this blog in the Bulletin of the EATCS]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interview about this blog in the Bulletin of the EATCS]]></title>
        <id>http://windowsontheory.org/?p=8582</id>
        <link href="https://windowsontheory.org/2023/03/08/interview-about-this-blog-in-the-bulletin-of-the-eatcs/"/>
        <updated>2023-03-08T14:13:20.000Z</updated>
        <summary type="html"><![CDATA[Luca Trevisan recently interviewed me for the Bulletin of the EATCS (see link for the full issue, including an interview with Alexandra Silva, and technical columns by Naama Ben-David, Ryan Williams, and Yuri Gurevich). With Luca’s permission, I am cross-posting it here. (I added some hyperlinks to relevant documents.) Q. Boaz, thanks for taking the … Continue reading Interview about this blog in the Bulletin of the EATCS]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning particle swarming models from data with Gaussian processes]]></title>
        <id>http://arxiv.org/abs/2106.02735</id>
        <link href="http://arxiv.org/abs/2106.02735"/>
        <updated>2023-03-08T07:16:07.576Z</updated>
        <summary type="html"><![CDATA[Jinchao Feng, Charles Kulick, Yunxiang Ren, Sui Tang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using multimodal learning and deep generative models for corporate
  bankruptcy prediction]]></title>
        <id>http://arxiv.org/abs/2211.08405</id>
        <link href="http://arxiv.org/abs/2211.08405"/>
        <updated>2023-03-08T07:16:07.571Z</updated>
        <summary type="html"><![CDATA[Rogelio A. Mancisidor]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prior and Posterior Networks: A Survey on Evidential Deep Learning
  Methods For Uncertainty Estimation]]></title>
        <id>http://arxiv.org/abs/2110.03051</id>
        <link href="http://arxiv.org/abs/2110.03051"/>
        <updated>2023-03-08T07:16:07.563Z</updated>
        <summary type="html"><![CDATA[Dennis Ulmer, Christian Hardmeier, Jes Frellsen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Free Lunch from the Noise: Provable and Practical Exploration for
  Representation Learning]]></title>
        <id>http://arxiv.org/abs/2111.11485</id>
        <link href="http://arxiv.org/abs/2111.11485"/>
        <updated>2023-03-08T07:16:07.545Z</updated>
        <summary type="html"><![CDATA[Tongzheng Ren, Tianjun Zhang, Csaba Szepesv\'ari, Bo Dai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hanmoji, part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58169</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58169&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hanmoji-part-2"/>
        <updated>2023-03-07T23:26:52.000Z</updated>
        <summary type="html"><![CDATA["Hanmoji" is a portmanteau consisting of the first syllable of hanzi ("Chinese character") and the second part of emoji. From Bob Bauer: Have you heard of or seen the book entitled The Hanmoji Handbook: Your Guide to the Chinese Language through Emoji, MITeen Press, published August 30, 2022? The day before yesterday (Thursday, 2 March […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[International Women’s Day 2023 [and how far from a fair society…]]]></title>
        <id>http://xianblog.wordpress.com/?p=52505</id>
        <link href="https://xianblog.wordpress.com/2023/03/08/international-womens-day-2023-and-how-far-from-a-fair-society/"/>
        <updated>2023-03-07T23:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greg Kuperberg @ Tel Aviv University]]></title>
        <id>http://gilkalai.wordpress.com/?p=23935</id>
        <link href="https://gilkalai.wordpress.com/2023/03/07/greg-kuperberg-tel-aviv-university/"/>
        <updated>2023-03-07T19:45:54.000Z</updated>
        <summary type="html"><![CDATA[Greg Kuperberg is having a short visit in Israel and yesterday he gave a fantastic lecture on an improved bound for the Kitaev-Solovay theorem. Here is a videotaped lecture of Greg on the same topic in QIP2023. Kitaev-Solovay theorem from … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greg Kuperberg @ Tel Aviv University]]></title>
        <id>http://gilkalai.wordpress.com/?p=23935</id>
        <link href="https://gilkalai.wordpress.com/2023/03/07/greg-kuperberg-tel-aviv-university/"/>
        <updated>2023-03-07T19:45:54.000Z</updated>
        <summary type="html"><![CDATA[Greg Kuperberg is having a short visit in Israel and yesterday he gave a fantastic lecture on an improved bound for the Kitaev-Solovay theorem. Here is a videotaped lecture of Greg on the same topic in QIP2023. Kitaev-Solovay theorem from … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing the ICDAR 2023 Competition on Hierarchical Text Detection and Recognition]]></title>
        <id>http://ai.googleblog.com/2023/03/announcing-icdar-2023-competition-on.html</id>
        <link href="http://ai.googleblog.com/2023/03/announcing-icdar-2023-competition-on.html"/>
        <updated>2023-03-07T18:10:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Shangbang Long, Software Engineer, Google Research   
The last few decades have witnessed the rapid development of Optical Character Recognition (OCR) technology, which has evolved from an academic benchmark task used in early breakthroughs of deep learning research to tangible products available in consumer devices and to third party developers for daily use. These OCR products digitize and democratize the valuable information that is stored in paper or image-based sources (e.g., books, magazines, newspapers, forms, street signs, restaurant menus) so that they can be indexed, searched, translated, and further processed by state-of-the-art natural language processing techniques.  
 
Research in scene text detection and recognition (or scene text spotting) has been the major drive…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning low-rank latent mesoscale structures in networks]]></title>
        <id>http://arxiv.org/abs/2102.06984</id>
        <link href="http://arxiv.org/abs/2102.06984"/>
        <updated>2023-03-07T07:14:49.194Z</updated>
        <summary type="html"><![CDATA[Hanbaek Lyu, Yacoub H. Kureh, Joshua Vendrow, Mason A. Porter]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pre-trained Gaussian processes for Bayesian optimization]]></title>
        <id>http://arxiv.org/abs/2109.08215</id>
        <link href="http://arxiv.org/abs/2109.08215"/>
        <updated>2023-03-07T07:14:49.153Z</updated>
        <summary type="html"><![CDATA[Zi Wang, George E. Dahl, Kevin Swersky, Chansoo Lee and
  Zachary Nado, Justin Gilmer, Jasper Snoek, Zoubin Ghahramani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning High-Dimensional Single-Neuron ReLU Networks with Finite
  Samples]]></title>
        <id>http://arxiv.org/abs/2303.02255</id>
        <link href="http://arxiv.org/abs/2303.02255"/>
        <updated>2023-03-07T07:14:49.084Z</updated>
        <summary type="html"><![CDATA[Jingfeng Wu, Difan Zou, Zixiang Chen, Vladimir Braverman and
  Quanquan Gu, Sham M. Kakade]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning k-Level Sparse Neural Networks Using a New Generalized Weighted
  Group Sparse Envelope Regularization]]></title>
        <id>http://arxiv.org/abs/2212.12921</id>
        <link href="http://arxiv.org/abs/2212.12921"/>
        <updated>2023-03-07T07:14:49.075Z</updated>
        <summary type="html"><![CDATA[Yehonathan Refael, Iftach Arbel, Wasim Huleihel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Collaborative Learning with a Drone Orchestrator]]></title>
        <id>http://arxiv.org/abs/2303.02266</id>
        <link href="http://arxiv.org/abs/2303.02266"/>
        <updated>2023-03-07T07:14:48.956Z</updated>
        <summary type="html"><![CDATA[Mahnoosh Mahdavimoghadam, Mahdi Boloursaz Mashhadi, Rahim Tafazolli,
  Walid Saad]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tiger：一个“抠”到极致的优化器]]></title>
        <id>https://kexue.fm/archives/9512</id>
        <link href="https://kexue.fm/archives/9512"/>
        <updated>2023-03-07T02:33:00.000Z</updated>
        <summary type="html"><![CDATA[这段时间笔者一直在实验《Google新搜出的优化器Lion：效率与效果兼得的“训练狮”》所介绍的Lion优化器。之所以对Lion饶有兴致，是因为它跟笔者之前的关于理想优化器的一些想法不谋而合，但...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anti-collision particle physics]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58156</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58156&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=anti-collision-particle-physics"/>
        <updated>2023-03-07T01:13:30.000Z</updated>
        <summary type="html"><![CDATA[From the Temu website. They're the kind of bumper buttons you put on cabinet doors or sometimes on the bottoms of fragile things. IKEA furniture used to come with a couple of these. Just peel and stick in the corner so cabinet doors don't slam. Selected readings "'These can be aptly compared with the challenges, problems, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ABConic mean evidence approximation]]></title>
        <id>http://xianblog.wordpress.com/?p=52370</id>
        <link href="https://xianblog.wordpress.com/2023/03/07/abconic-mean-evidence-approximation/"/>
        <updated>2023-03-06T23:23:28.000Z</updated>
        <summary type="html"><![CDATA[Following a question on X validated about evidence approximation in ABC settings, i.e., on returning an approximation of the evidence based on the outputs of parallel ABC runs for the models under comparison, I wondered at the relevance of an harmonic mean estimator in that context. Rather than using the original ABC algorithm that proposes […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal Speech Model (USM): State-of-the-art speech AI for 100+ languages]]></title>
        <id>http://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html</id>
        <link href="http://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html"/>
        <updated>2023-03-06T18:06:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Yu Zhang, Research Scientist, and James Qin, Software Engineer, Google Research  
Last November, we announced the 1,000 Languages Initiative, an ambitious commitment to build a machine learning (ML) model that would support the world’s one thousand most-spoken languages, bringing greater inclusion to billions of people around the globe. However, some of these languages are spoken by fewer than twenty million people, so a core challenge is how to support languages for which there are relatively few speakers or limited available data. 

Today, we are excited to share more about the Universal Speech Model (USM), a critical first step towards supporting 1,000 languages. USM is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 b…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spectral learning of Bernoulli linear dynamical systems models for
  decision-making]]></title>
        <id>http://arxiv.org/abs/2303.02060</id>
        <link href="http://arxiv.org/abs/2303.02060"/>
        <updated>2023-03-06T07:16:08.680Z</updated>
        <summary type="html"><![CDATA[Iris R. Stone, Yotam Sagiv, Il Memming Park, Jonathan W. Pillow]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continual Learning of Language Models]]></title>
        <id>http://arxiv.org/abs/2302.03241</id>
        <link href="http://arxiv.org/abs/2302.03241"/>
        <updated>2023-03-06T07:16:08.209Z</updated>
        <summary type="html"><![CDATA[Zixuan Ke, Yijia Shao, Haowei Lin, Tatsuya Konishi, Gyuhak Kim, and
  Bing Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning on heterogeneous graphs using high-order relations]]></title>
        <id>http://arxiv.org/abs/2103.15532</id>
        <link href="http://arxiv.org/abs/2103.15532"/>
        <updated>2023-03-06T07:16:08.165Z</updated>
        <summary type="html"><![CDATA[See Hian Lee, Feng Ji, Wee Peng Tay]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Don't fear the unlabelled: safe semi-supervised learning via simple
  debiasing]]></title>
        <id>http://arxiv.org/abs/2203.07512</id>
        <link href="http://arxiv.org/abs/2203.07512"/>
        <updated>2023-03-06T07:16:06.488Z</updated>
        <summary type="html"><![CDATA[Hugo Schmutz, Olivier Humbert, Pierre-Alexandre Mattei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uncertainty Estimation by Fisher Information-based Evidential Deep
  Learning]]></title>
        <id>http://arxiv.org/abs/2303.02045</id>
        <link href="http://arxiv.org/abs/2303.02045"/>
        <updated>2023-03-06T07:16:06.482Z</updated>
        <summary type="html"><![CDATA[Danruo Deng, Guangyong Chen, Yang Yu, Furui Liu, Pheng-Ann Heng]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[slice samplers for nested sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=52350</id>
        <link href="https://xianblog.wordpress.com/2023/03/06/slice-samplers-for-nested-sampling/"/>
        <updated>2023-03-05T23:23:26.000Z</updated>
        <summary type="html"><![CDATA[“…the likelihoods of discarded points have interesting properties. In particular, the fraction of prior mass below the likelihood threshold is approximately 1/K [number of particles].” I came across a newly arXived paper on nested sampling, written by Johannes Buchner, with a focus on sampling over the constrained space defined by the lower bound on the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The earliest horse riders]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58152</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58152&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-earliest-horse-riders"/>
        <updated>2023-03-05T15:40:05.000Z</updated>
        <summary type="html"><![CDATA[The implications of horse domestication — above all its consequent equine chariotry and horseback riding — for the spread of Indo-European are topics we have addressed on numerous occasions before.  A paper that was published just two days ago has made a stunning, convincing breakthrough concerning when and where humans began to ride horses: "First […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[47e cross de Sceaux [22:08, 31/226, 2/6 M5]]]></title>
        <id>http://xianblog.wordpress.com/?p=52356</id>
        <link href="https://xianblog.wordpress.com/2023/03/05/47e-cross-de-sceaux-2208-31-226-2-6-m5/"/>
        <updated>2023-03-04T23:23:28.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lecture on the anatomical origins of language]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58141</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58141&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=lecture-on-the-anatomical-origins-of-language"/>
        <updated>2023-03-04T10:39:14.000Z</updated>
        <summary type="html"><![CDATA[[Please read all the way to the bottom of this post.  There are some big surprises here, including references to a book and an article on linguistics by the novelist Tom Wolfe (1930-2018), who's clearly on the wrong side of the political fence.  Despite the spate of mostly unremittingly anti-Wolfe comments, many important issues about […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Israel AGT Day, Reichman University, March 5, 2023]]></title>
        <id>http://gilkalai.wordpress.com/?p=23922</id>
        <link href="https://gilkalai.wordpress.com/2023/03/04/israel-agt-day-reichman-university-march-5-2023/"/>
        <updated>2023-03-04T10:13:37.000Z</updated>
        <summary type="html"><![CDATA[We are running tomorrow the annual Israeli workshop in algorithmic game theory. Where: Reichman University. The conference will take place in room EL03, Adelson building.  Program: here. Registration: here (free). Main speakers: Moshe Babaioff (Microsoft Research), Gil Kalai (Reichman University … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Israel AGT Day, Reichman University, March 5, 2023]]></title>
        <id>http://gilkalai.wordpress.com/?p=23922</id>
        <link href="https://gilkalai.wordpress.com/2023/03/04/israel-agt-day-reichman-university-march-5-2023/"/>
        <updated>2023-03-04T10:13:37.000Z</updated>
        <summary type="html"><![CDATA[We are running tomorrow the annual Israeli workshop in algorithmic game theory. Where: Reichman University. The conference will take place in room EL03, Adelson building.  Program: here. Registration: here (free). Main speakers: Moshe Babaioff (Microsoft Research), Gil Kalai (Reichman University … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[extra layers for BayesComp]]></title>
        <id>http://xianblog.wordpress.com/?p=52430</id>
        <link href="https://xianblog.wordpress.com/2023/03/04/extra-layers-for-bayescomp/"/>
        <updated>2023-03-03T23:23:45.000Z</updated>
        <summary type="html"><![CDATA[Just a reminder that Levi stands at 67.8⁰ North, which is way north of Iceland latitude-wise, and therefore prone to low temperatures, as shown by the above forecast. Hence bring extra layers! And, for the few remaining stragglers, register before the deadline, Monday 06 March.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Performer-MPC: Navigation via real-time, on-robot transformers]]></title>
        <id>http://ai.googleblog.com/2023/03/performer-mpc-navigation-via-real-time.html</id>
        <link href="http://ai.googleblog.com/2023/03/performer-mpc-navigation-via-real-time.html"/>
        <updated>2023-03-03T18:20:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Krzysztof Choromanski, Staff Research Scientist, Robotics at Google, and Xuesu Xiao, Visiting Researcher, George Mason University   
Despite decades of research, we don’t see many mobile robots roaming our homes, offices, and streets. Real-world robot navigation in human-centric environments remains an unsolved problem. These challenging situations require safe and efficient navigation through tight spaces, such as squeezing between coffee tables and couches, maneuvering in tight corners, doorways, untidy rooms, and more. An equally critical requirement is to navigate in a manner that complies with unwritten social norms around people, for example, yielding at blind corners or staying at a comfortable distance. Google Research is committed to examining how advances in ML may enab…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Japanese arrow emojis]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58135</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58135&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=japanese-arrow-emojis"/>
        <updated>2023-03-03T15:05:03.000Z</updated>
        <summary type="html"><![CDATA[I often receive anguished inquiries about emojis, emoticons, hanzi, hangul, kana, and similar matters.  I try to answer as many of them as I can, and many of them have important implications for the nature of writing, the relationship between speech and script, cultural interactions and contexts, and so forth. Back in mid-January, there was […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In all LikelihoodS: How to Reliably Select Pseudo-Labeled Data for
  Self-Training in Semi-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2303.01117</id>
        <link href="http://arxiv.org/abs/2303.01117"/>
        <updated>2023-03-03T07:15:56.301Z</updated>
        <summary type="html"><![CDATA[Julian Rodemann, Christoph Jansen, Georg Schollmeyer, Thomas Augustin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NTS-NOTEARS: Learning Nonparametric DBNs With Prior Knowledge]]></title>
        <id>http://arxiv.org/abs/2109.04286</id>
        <link href="http://arxiv.org/abs/2109.04286"/>
        <updated>2023-03-03T07:15:55.453Z</updated>
        <summary type="html"><![CDATA[Xiangyu Sun, Oliver Schulte, Guiliang Liu, Pascal Poupart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Weighted Ensemble Self-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2211.09981</id>
        <link href="http://arxiv.org/abs/2211.09981"/>
        <updated>2023-03-03T07:15:55.448Z</updated>
        <summary type="html"><![CDATA[Yangjun Ruan, Saurabh Singh, Warren Morningstar, Alexander A. Alemi,
  Sergey Ioffe, Ian Fischer, Joshua V. Dillon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards the Generalization of Contrastive Self-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2111.00743</id>
        <link href="http://arxiv.org/abs/2111.00743"/>
        <updated>2023-03-03T07:15:54.783Z</updated>
        <summary type="html"><![CDATA[Weiran Huang, Mingyang Yi, Xuyang Zhao, Zihao Jiang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse-penalized deep neural networks estimator under weak dependence]]></title>
        <id>http://arxiv.org/abs/2303.01406</id>
        <link href="http://arxiv.org/abs/2303.01406"/>
        <updated>2023-03-03T07:15:54.769Z</updated>
        <summary type="html"><![CDATA[William Kengne, Modou Wade]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[sticker for birds]]></title>
        <id>http://xianblog.wordpress.com/?p=52235</id>
        <link href="https://xianblog.wordpress.com/2023/03/03/sticker-for-birds/"/>
        <updated>2023-03-02T23:23:45.000Z</updated>
        <summary type="html"><![CDATA[A moderately interesting article in the NYT on why birds crash into (my) windows and the limited efficiency of bird stickers, esp. those glued from the inside. Just like insects, who have difficulties understanding the concept of glass (!), birds fly into glass windows because they do not realise they are there. What I find […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distributed differential privacy for federated learning]]></title>
        <id>http://ai.googleblog.com/2023/03/distributed-differential-privacy-for.html</id>
        <link href="http://ai.googleblog.com/2023/03/distributed-differential-privacy-for.html"/>
        <updated>2023-03-02T21:14:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Florian Hartmann, Software Engineer, and Peter Kairouz, Research Scientist, Google Research  
Federated learning is a distributed way of training machine learning (ML) models where data is locally processed and only focused model updates and metrics that are intended for immediate aggregation are shared with a server that orchestrates training. This allows the training of models on locally available signals without exposing raw data to servers, increasing user privacy. In 2021, we announced that we are using federated learning to train Smart Text Selection models, an Android feature that helps users select and copy text easily by predicting what text they want to select and then automatically expanding the selection for them. 
 
Since that launch, we have worked to improve the pr…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning time-scales in two-layers neural networks]]></title>
        <id>http://arxiv.org/abs/2303.00055</id>
        <link href="http://arxiv.org/abs/2303.00055"/>
        <updated>2023-03-02T07:15:44.567Z</updated>
        <summary type="html"><![CDATA[Rapha\"el Berthier, Andrea Montanari, Kangjie Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy
  Improvement]]></title>
        <id>http://arxiv.org/abs/1810.09103</id>
        <link href="http://arxiv.org/abs/1810.09103"/>
        <updated>2023-03-02T07:15:44.561Z</updated>
        <summary type="html"><![CDATA[Samuel Neumann, Sungsu Lim, Ajin Joseph, Yangchen Pan, Adam White,
  Martha White]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning curves for deep structured Gaussian feature models]]></title>
        <id>http://arxiv.org/abs/2303.00564</id>
        <link href="http://arxiv.org/abs/2303.00564"/>
        <updated>2023-03-02T07:15:44.542Z</updated>
        <summary type="html"><![CDATA[Jacob A. Zavatone-Veth, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random Features Model with General Convex Regularization: A Fine Grained
  Analysis with Precise Asymptotic Learning Curves]]></title>
        <id>http://arxiv.org/abs/2204.02678</id>
        <link href="http://arxiv.org/abs/2204.02678"/>
        <updated>2023-03-02T07:15:44.537Z</updated>
        <summary type="html"><![CDATA[David Bosch, Ashkan Panahi, Ayca \"Ozcelikkale, Devdatt Dubhash]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Berkeley Working Papers in Middle Iranian Philology]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58116</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58116&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=berkeley-working-papers-in-middle-iranian-philology"/>
        <updated>2023-03-02T03:19:06.000Z</updated>
        <summary type="html"><![CDATA[Meant to send this more than a month ago. Interesting new journal in Iranian Studies Berkeley Working Papers in Middle Iranian Philology is a new open access e-journal hosted by UC Berkeley’s Department of Middle Eastern Languages and Cultures and edited by Adam Benkato and Arash Zeini. It publishes short and longer articles or research […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[keep thunderbird alive!]]></title>
        <id>http://xianblog.wordpress.com/?p=52316</id>
        <link href="https://xianblog.wordpress.com/2023/03/02/52316/"/>
        <updated>2023-03-01T23:23:28.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding the attention mechanism in sequence models]]></title>
        <id>63f42411c79d98004d9f8686</id>
        <link href="https://www.jeremyjordan.me/attention/"/>
        <updated>2023-03-01T22:44:22.000Z</updated>
        <summary type="html"><![CDATA[In this blog post, we'll discuss a key innovation in sequence-to-sequence model architectures: the attention mechanism. This architecture innovation dramatically improved model performance for sequence-to-sequence tasks such as machine translation and text summarization. 
Moreover, the success of this attention mechanism led to the seminal paper, "Attention Is]]></summary>
        <author>
            <name>Jeremy Jordan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teaching old labels new tricks in heterogeneous graphs]]></title>
        <id>http://ai.googleblog.com/2023/03/teaching-old-labels-new-tricks-in.html</id>
        <link href="http://ai.googleblog.com/2023/03/teaching-old-labels-new-tricks-in.html"/>
        <updated>2023-03-01T18:15:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Minji Yoon, Research Intern, and Bryan Perozzi, Research Scientist, Google Research, Graph Mining Team  
Industrial applications of machine learning are commonly composed of various items that have differing data modalities or feature distributions. Heterogeneous graphs (HGs) offer a unified view of these multimodal data systems by defining multiple types of nodes (for each data type) and edges (for the relation between data items). For instance, e-commerce networks might have [user, product, review] nodes or video platforms might have [channel, user, video, comment] nodes. Heterogeneous graph neural networks (HGNNs) learn node embeddings summarizing each node’s relationships into a vector. However, in real world HGs, there is often a label imbalance issue between different node …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning ReLU networks to high uniform accuracy is intractable]]></title>
        <id>http://arxiv.org/abs/2205.13531</id>
        <link href="http://arxiv.org/abs/2205.13531"/>
        <updated>2023-03-01T07:15:24.618Z</updated>
        <summary type="html"><![CDATA[Julius Berner, Philipp Grohs, Felix Voigtlaender]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Agent-based Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2206.11010</id>
        <link href="http://arxiv.org/abs/2206.11010"/>
        <updated>2023-03-01T07:15:24.573Z</updated>
        <summary type="html"><![CDATA[Karolis Martinkus, P\'al Andr\'as Papp, Benedikt Schesch, Roger
  Wattenhofer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How optimal transport can tackle gender biases in multi-class
  neural-network classifiers for job recommendations?]]></title>
        <id>http://arxiv.org/abs/2302.14063</id>
        <link href="http://arxiv.org/abs/2302.14063"/>
        <updated>2023-03-01T07:15:24.513Z</updated>
        <summary type="html"><![CDATA[Fanny Jourdan, Titon Tshiongo Kaninku, Nicholas Asher, Jean-Michel
  Loubes, Laurent Risser]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Hidden Markov Models Using Conditional Samples]]></title>
        <id>http://arxiv.org/abs/2302.14753</id>
        <link href="http://arxiv.org/abs/2302.14753"/>
        <updated>2023-03-01T07:15:24.508Z</updated>
        <summary type="html"><![CDATA[Sham M. Kakade, Akshay Krishnamurthy, Gaurav Mahajan, Cyril Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding The Robustness of Self-supervised Learning Through Topic
  Modeling]]></title>
        <id>http://arxiv.org/abs/2203.03539</id>
        <link href="http://arxiv.org/abs/2203.03539"/>
        <updated>2023-03-01T07:15:24.466Z</updated>
        <summary type="html"><![CDATA[Zeping Luo, Shiyou Wu, Cindy Weng, Mo Zhou, Rong Ge]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[统计月读（2023 年 2 月）]]></title>
        <id>https://cosx.org/2023/03/monthly/</id>
        <link href="https://cosx.org/2023/03/monthly/"/>
        <updated>2023-03-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[推荐语：Gurobi是由美国 Gurobi Optimization 公司开发新一代大规模优化器，能够处理很多优化问题，充分利用多核处理器优势，且支持并行计算。这篇博客提供了如何]]></summary>
        <author>
            <name>统计之都</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[snapshot of Les Diablerets³ [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=52249</id>
        <link href="https://xianblog.wordpress.com/2023/03/01/snapshot-of-les-diablerets%c2%b3-jatp/"/>
        <updated>2023-02-28T23:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Datasets at your fingertips in Google Search]]></title>
        <id>http://ai.googleblog.com/2023/02/datasets-at-your-fingertips-in-google.html</id>
        <link href="http://ai.googleblog.com/2023/02/datasets-at-your-fingertips-in-google.html"/>
        <updated>2023-02-28T22:13:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Natasha Noy, Research Scientist, and Omar Benjelloun, Software Engineer, Google Research  
Access to datasets is critical to many of today's endeavors across verticals and industries, whether scientific research, business analysis, or public policy. In the scientific community and throughout various levels of the public sector, reproducibility and transparency are essential for progress, so sharing data is vital. For one example, in the United States a recent new policy requires free and equitable access to outcomes of all federally funded research, including data and statistical information along with publications. 

To facilitate discovery of content with this level of statistical detail and better distill this information from across the web, Google now makes it easier to sear…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google Research, 2022 & beyond: Research community engagement]]></title>
        <id>http://ai.googleblog.com/2023/02/google-research-2022-beyond-research.html</id>
        <link href="http://ai.googleblog.com/2023/02/google-research-2022-beyond-research.html"/>
        <updated>2023-02-28T19:40:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Posted by Leslie Yeh, Director, University Relations    
    

(This is Part 9 in our series of posts covering different topical areas of research at Google. You can find other posts in the series here.)
   

Sharing knowledge is essential to Google’s research philosophy — it accelerates technological progress and expands capabilities community-wide. Solving complex problems requires bringing together diverse minds and resources collaboratively. This can be accomplished through building local and global connections with multidisciplinary experts and impacted communities. In partnership with these stakeholders, we bring our technical leadership, product footprint, and resources to make progress against some of society's greatest opportunities and challenges.   
 We at Google see i…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alef’s Corner: Democracy (Israel, 2023)]]></title>
        <id>http://gilkalai.wordpress.com/?p=23914</id>
        <link href="https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/"/>
        <updated>2023-02-28T16:27:04.000Z</updated>
        <summary type="html"><![CDATA[Democracy in Hebrew is דמוקרטיה represented by the letter “dalet” ד]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alef’s Corner: Democracy (Israel, 2023)]]></title>
        <id>http://gilkalai.wordpress.com/?p=23914</id>
        <link href="https://gilkalai.wordpress.com/2023/02/28/alefs-corner-democracy-israel-2023/"/>
        <updated>2023-02-28T16:27:04.000Z</updated>
        <summary type="html"><![CDATA[Democracy in Hebrew is דמוקרטיה represented by the letter “dalet” ד]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Syllable rhythm in English and Mandarin]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58120</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58120&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=syllable-rhythm-in-english-and-mandarin"/>
        <updated>2023-02-28T16:20:00.000Z</updated>
        <summary type="html"><![CDATA[I've always been skeptical of the distinction between "stress-timed" and "syllable-timed" languages, at least as a claim about the phonetic facts of speech timing as opposed to the psychological dimensions of speech production and perception. Syllable durations in all languages vary widely, due to differences in the intrinsic durations of different vowels and consonants, the […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[生成扩散模型漫谈（十八）：得分匹配 = 条件得分匹配]]></title>
        <id>https://kexue.fm/archives/9509</id>
        <link href="https://kexue.fm/archives/9509"/>
        <updated>2023-02-28T13:23:00.000Z</updated>
        <summary type="html"><![CDATA[在前面的介绍中，我们多次提及“得分匹配”和“条件得分匹配”，它们是扩散模型、能量模型等经常出现的概念，特别是很多文章直接说扩散模型的训练目标是“得分匹配”，但事实上当前主流的扩散模型如DDPM的...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT writes VHM]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58111</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58111&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-writes-vhm"/>
        <updated>2023-02-28T10:47:25.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by ChatGPT] Write a Language Log blog post by Victor H. Mair Title: "The Wonders of the Chinese Language" As one of the world's oldest and most complex languages, Chinese has captivated linguists and language enthusiasts for centuries. From its unique writing system to its vast vocabulary and intricate grammar, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Empowering Graph Representation Learning with Test-Time Graph
  Transformation]]></title>
        <id>http://arxiv.org/abs/2210.03561</id>
        <link href="http://arxiv.org/abs/2210.03561"/>
        <updated>2023-02-28T07:15:52.573Z</updated>
        <summary type="html"><![CDATA[Wei Jin, Tong Zhao, Jiayuan Ding, Yozen Liu, Jiliang Tang, Neil Shah]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural networks for learning personality traits from natural language]]></title>
        <id>http://arxiv.org/abs/2302.13782</id>
        <link href="http://arxiv.org/abs/2302.13782"/>
        <updated>2023-02-28T07:15:52.566Z</updated>
        <summary type="html"><![CDATA[Giorgia Adorni]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Principled and Efficient Transfer Learning of Deep Models via Neural
  Collapse]]></title>
        <id>http://arxiv.org/abs/2212.12206</id>
        <link href="http://arxiv.org/abs/2212.12206"/>
        <updated>2023-02-28T07:15:52.526Z</updated>
        <summary type="html"><![CDATA[Xiao Li, Sheng Liu, Jinxin Zhou, Xinyu Lu, Carlos Fernandez-Granda,
  Zhihui Zhu, Qing Qu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[One-Pixel Shortcut: on the Learning Preference of Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2205.12141</id>
        <link href="http://arxiv.org/abs/2205.12141"/>
        <updated>2023-02-28T07:15:52.516Z</updated>
        <summary type="html"><![CDATA[Shutong Wu, Sizhe Chen, Cihang Xie, Xiaolin Huang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the plague, sword, and famine year [with avocados]]]></title>
        <id>http://xianblog.wordpress.com/?p=52168</id>
        <link href="https://xianblog.wordpress.com/2023/02/28/a-journal-of-the-plague-sword-and-famine-year-with-avocados/"/>
        <updated>2023-02-27T23:23:19.000Z</updated>
        <summary type="html"><![CDATA[Read two books by Alix E. Harrow, A Spindle Splintered and A Mirror Mended, which are modern takes on Sleeping Beauty and Snow White. Rather hilarious for their tone and dry humour, if rather YAs… And Undercover, a novella by Tasmyn Muir. Rather well-build steampunk around a moving city and… zombies. Plus a new volume […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Iteration marks and repeaters in ancient Chinese texts]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58102</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58102&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=iteration-marks-and-repeaters-in-ancient-chinese-texts"/>
        <updated>2023-02-27T17:49:47.000Z</updated>
        <summary type="html"><![CDATA[Let us begin this post with a brief introduction to the 16th-century Hokkien (Minnan) drama, Tale of the Lychee Mirror: The Tale of the Lychee Mirror (traditional Chinese: 荔鏡記; simplified Chinese: 荔镜记; pinyin: Lì jìng jì; Pe̍h-ōe-jī: Nāi-kèng-kì, Lē-kèng-kì) is a play written by an unknown author in the Ming dynasty. Tân Saⁿ and Gō͘-niû […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sample Extraction from RLWE to LWE]]></title>
        <id>https://jeremykun.com/?p=118643</id>
        <link href="https://jeremykun.com/2023/02/27/sample-extraction-from-rlwe-to-lwe/"/>
        <updated>2023-02-27T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[In this article I’ll derive a trick used in FHE called sample extraction. In brief, it allows one to partially convert a ciphertext in the Ring Learning With Errors (RLWE) scheme to the Learning With Errors (LWE) scheme. Here are some other articles I’ve written about other FHE building blocks, though they are not prerequisites […]]]></summary>
        <author>
            <name>j2kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Linearized Laplace Approximation for Bayesian Deep Learning]]></title>
        <id>http://arxiv.org/abs/2302.12565</id>
        <link href="http://arxiv.org/abs/2302.12565"/>
        <updated>2023-02-27T07:15:52.156Z</updated>
        <summary type="html"><![CDATA[Luis A. Ortega, Sim\'on Rodr\'iguez Santana, Daniel Hern\'andez-Lobato]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beyond Moments: Robustly Learning Affine Transformations with
  Asymptotically Optimal Error]]></title>
        <id>http://arxiv.org/abs/2302.12289</id>
        <link href="http://arxiv.org/abs/2302.12289"/>
        <updated>2023-02-27T07:15:52.139Z</updated>
        <summary type="html"><![CDATA[He Jia, Pravesh K . Kothari, Santosh S. Vempala]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reward Learning as Doubly Nonparametric Bandits: Optimal Design and
  Scaling Laws]]></title>
        <id>http://arxiv.org/abs/2302.12349</id>
        <link href="http://arxiv.org/abs/2302.12349"/>
        <updated>2023-02-27T07:15:52.115Z</updated>
        <summary type="html"><![CDATA[Kush Bhatia, Wenshuo Guo, Jacob Steinhardt]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice
  Polytopes]]></title>
        <id>http://arxiv.org/abs/2302.12553</id>
        <link href="http://arxiv.org/abs/2302.12553"/>
        <updated>2023-02-27T07:15:52.109Z</updated>
        <summary type="html"><![CDATA[Christian Haase, Christoph Hertrich, Georg Loho]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uncertainty Injection: A Deep Learning Method for Robust Optimization]]></title>
        <id>http://arxiv.org/abs/2302.12304</id>
        <link href="http://arxiv.org/abs/2302.12304"/>
        <updated>2023-02-27T07:15:52.100Z</updated>
        <summary type="html"><![CDATA[Wei Cui, Wei Yu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diophantine riddle]]></title>
        <id>http://xianblog.wordpress.com/?p=52260</id>
        <link href="https://xianblog.wordpress.com/2023/02/27/diophantine-riddle/"/>
        <updated>2023-02-26T23:23:08.000Z</updated>
        <summary type="html"><![CDATA[The weekly riddle from The Riddler is to find solutions to the Diophantine equation c³-c=b²+4 (when b and c are positive integers). First, forget about ChatGPT since it states this is a Pell equation. With a wrong argument. Second, when running a basic R code, using as.double to handle larger integers, the only solution less […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Taiwan Navy recruitment ad language puzzle]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58094</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58094&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=taiwan-navy-recruitment-ad-language-puzzle"/>
        <updated>2023-02-26T20:50:02.000Z</updated>
        <summary type="html"><![CDATA[Photo of a Taiwan Naval Academy recruitment ad in the Taipei MRT which references the One Piece ワンピース manga series from Japan: First some basic information about One Piece, then I'll explain what the Chinese says: One Piece (stylized in all caps) is a Japanese manga series written and illustrated by Eiichiro Oda. It has been serialized in Shueisha's shōnen manga magazine […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diversification of Proto-Austronesian]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58099</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58099&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=diversification-of-proto-austronesian"/>
        <updated>2023-02-26T19:53:15.000Z</updated>
        <summary type="html"><![CDATA[Important archeological news from Tainan: South Taiwan park renovation project paused after archaeological artifacts unearthed  Artifact pieces belonging to neolithic Niuchouzi Culture discovered, date back to 3000-4500 years ago. By Stephanie Chiang, Taiwan News (2/26/23) Finds include "orange-colored pottery made of fine sand-bearing rope patterns, polished hoe-axes, polished adze-chisels, and shell mounds." The nature of […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[surveying homelessness]]></title>
        <id>http://xianblog.wordpress.com/?p=52284</id>
        <link href="https://xianblog.wordpress.com/2023/02/26/surveying-homelessness/"/>
        <updated>2023-02-25T23:23:12.000Z</updated>
        <summary type="html"><![CDATA[A recent NYT article, entitled “582,462 and Counting“, is describing how the USA Federal Administation is running a yearly survey of homeless people. By sending agents and volunteers in the streets and shelters to get an idea of the magnitude of the problem. The figure of 582,462 was the one produced by HUD (the US […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transcription vs. transliteration vs. translation in cartography]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58088</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58088&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=transcription-vs-transliteration-vs-translation-in-cartography"/>
        <updated>2023-02-25T03:49:40.000Z</updated>
        <summary type="html"><![CDATA[In this post, I wanted to do something that I thought would be fairly simple, viz., address the question of the "rectification" of Russian place names in areas proximate to populations speaking Sinitic languages.  This sort of rectification is also a hot topic where Russia borders on Ukraine.  There, however, the task is simpler, because […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bernard l’Hermite [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=52272</id>
        <link href="https://xianblog.wordpress.com/2023/02/25/bernard-lhermite-jatp/"/>
        <updated>2023-02-24T23:23:28.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A vision-language approach for foundational UI understanding]]></title>
        <id>http://ai.googleblog.com/2023/02/a-vision-language-approach-for.html</id>
        <link href="http://ai.googleblog.com/2023/02/a-vision-language-approach-for.html"/>
        <updated>2023-02-24T20:21:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Yang Li, Research Scientist, and Gang Li, Software Engineer, Google Research   
The computational understanding of user interfaces (UI) is a key step towards achieving intelligent UI behaviors. Previously, we investigated various UI modeling tasks, including widget captioning, screen summarization, and command grounding, that address diverse interaction scenarios such as automation and accessibility. We also demonstrated how machine learning can help user experience practitioners improve UI quality by diagnosing tappability confusion and providing insights for improving UI design. These works along with those developed by others in the field have showcased how deep neural networks can potentially transform end user experiences and the interaction design practice.  

With these su…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chelsea Finn - Neural networks make stuff up. What should we do about it?]]></title>
        <id>https://mlfoundations.org/talk/finn/</id>
        <link href="https://mlfoundations.org/talk/finn/"/>
        <updated>2023-02-24T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[When machine learning models are deployed into the world, they inevitably encounter scenarios that differ from their training data, either novel contexts where the appropriate answers may differ or scenarios with new out-of-distribution inputs. Unfortunately, in such situations, deep neural network models make up answers or misunderstand the context, making the models unreliable. Even if a model makes useful predictions for many examples, such unreliability poses considerable risks when these models are interacting with real people and ultimately precludes models from being useful in safety-critical applications. In this talk, I’ll discuss some ways that we might cope with and address the unreliability of neural network models. As an initial coping strategy, I will first discuss a technique for detecting whether some content was generated by a machine learning model, leveraging the probability distribution that the model assigns to different content. Next, I will describe an approach for enabling neural network models to better estimate what they don’t know, such that they can abstain from making predictions on such inputs (i.e. selective classification). I will lastly describe methods for adapting models with small amounts of data to improve their accuracy under distribution shift.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
</feed>