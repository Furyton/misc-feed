<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-06-25T18:20:18.772Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Use chili sparingly]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59391</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59391&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=use-chili-sparingly"/>
        <updated>2023-06-25T04:18:02.000Z</updated>
        <summary type="html"><![CDATA[From AntC: Seen in a very typical (but delicious) corner eatery in downtown¬†Hualien, Taiwan. Surprisingly idiomatic translation: "use sparingly" in Hualien GTranslate isn't so idiomatic; I'm not able to try DeepL ‚Äî any better? I agree with AntC that "use sparingly" is a strikingly fine English expression, one that does not seem possible from a [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phenomenology]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59401</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59401&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=phenomenology"/>
        <updated>2023-06-25T01:54:34.000Z</updated>
        <summary type="html"><![CDATA[Nancy Kathryn Walecki, "Sound as Ever: Gram Parsons and Harvard‚Äôs hand in country rock", Harvard Magazine July-August 2023: During Parsons‚Äôs Burritos era, Thomas left Harvard to write his dissertation in a cabin on Mount Baldy outside Los Angeles. Now more of an older brother to Parsons than a proctor, he would take study breaks with [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=53299</id>
        <link href="https://xianblog.wordpress.com/2023/06/25/a-journal-of-the-conquest-war-famine-and-death-year/"/>
        <updated>2023-06-24T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[Read both following volumes of Peter May‚Äôs Lewis trilogy, The Lewis Man and The Chessmen. The stories remain focussed on the same few characters as in the first volume, with some predictable developments and a rather heavy borrowing to the local history in the shape of a peat-bog mommy or a plane crash. And of [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prigozhin's pronouns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59396</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59396&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=prigozhins-pronouns"/>
        <updated>2023-06-24T14:26:14.000Z</updated>
        <summary type="html"><![CDATA[Just wow. A video has surfaced showing Prigozhin at the Southern Military District HQ in Rostov-on-Don talking to (and HUMILIATING) Deputy Defense Minister Yunus-bek Yevkurov. He threatens to blockade Rostov and head for Moscow! I have extreme trouble understanding Yevkurov and‚Ä¶ pic.twitter.com/jGr9gaLB1i ‚Äî Kevin Rothrock (@KevinRothrock) June 24, 2023 An English translation of the linguistically-relevant [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five old, white men]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59388</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59388&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=five-old-white-men"/>
        <updated>2023-06-24T11:16:19.000Z</updated>
        <summary type="html"><![CDATA[I promised that I would tell the story of how five old, white men persuaded me to begin the study of Asian languages two years after I was out of college.¬† Here it is. When I graduated from Dartmouth in 1965, I joined the Peace Corps for two years in Nepal.¬† Although I contracted fifteen [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the generalizations of global dimensions and singularity categories]]></title>
        <id>http://arxiv.org/abs/2306.09832</id>
        <link href="http://arxiv.org/abs/2306.09832"/>
        <updated>2023-06-24T07:15:01.670Z</updated>
        <summary type="html"><![CDATA[Xiaolei Zhang, Tiwei Zhao, Dingguo Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ÁîüÊàêÊâ©Êï£Ê®°ÂûãÊº´Ë∞àÔºàÂçÅ‰πùÔºâÔºö‰Ωú‰∏∫Êâ©Êï£ODEÁöÑGAN]]></title>
        <id>https://kexue.fm/archives/9662</id>
        <link href="https://kexue.fm/archives/9662"/>
        <updated>2023-06-24T01:38:00.000Z</updated>
        <summary type="html"><![CDATA[Âú®ÊñáÁ´†„ÄäÁîüÊàêÊâ©Êï£Ê®°ÂûãÊº´Ë∞àÔºàÂçÅÂÖ≠ÔºâÔºöWË∑ùÁ¶ª ‚â§ ÂæóÂàÜÂåπÈÖç„Äã‰∏≠ÔºåÊàë‰ª¨Êé®ÂØº‰∫ÜWassersteinË∑ùÁ¶ª‰∏éÊâ©Êï£Ê®°ÂûãÂæóÂàÜÂåπÈÖçÊçüÂ§±‰πãÈó¥ÁöÑ‰∏Ä‰∏™‰∏çÁ≠âÂºèÔºåË°®ÊòéÊâ©Êï£Ê®°ÂûãÁöÑ‰ºòÂåñÁõÆÊ†á‰∏éWGANÁöÑ‰ºòÂåñÁõÆÊ†áÂú®ÊüêÁßçÁ®ãÂ∫¶‰∏äÂÖ∑Êúâ...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[noctureine 2023 [16/6/23, 20h40, 10k, 41‚Äô54‚Äù, 29‚Å∞, 48th/295, 1st M5/11]]]></title>
        <id>http://xianblog.wordpress.com/?p=53258</id>
        <link href="https://xianblog.wordpress.com/2023/06/24/noctureine-2023-2/"/>
        <updated>2023-06-23T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gardening on the path]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59383</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59383&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=gardening-on-the-path"/>
        <updated>2023-06-23T22:01:29.000Z</updated>
        <summary type="html"><![CDATA[The most recent xkcd: Mouseover title: "Arboretum Owner Denied Standing in Garden Path Suit on Grounds Grounds Appealing Appealing" What the Berkeley Neural Parser thinks: (S (PP (IN After) (NP (NN bird) (VBZ strikes))) (NP (NP (NN judge)) (SBAR (WHNP (WP who)) (S (VP (VBD ordered) (NP (NNP olive) (NNP garden) (NNP path) (NN sentence)) [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Preference learning with automated feedback for cache eviction]]></title>
        <id>http://ai.googleblog.com/2023/06/preference-learning-with-automated.html</id>
        <link href="http://ai.googleblog.com/2023/06/preference-learning-with-automated.html"/>
        <updated>2023-06-23T19:24:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Ramki Gummadi, Software Engineer, Google and Kevin Chen, Software Engineer, YouTube





Caching is a ubiquitous idea in computer science that significantly improves the performance of storage and retrieval systems by storing a subset of popular items closer to the client based on request patterns. An important algorithmic piece of cache management is the decision policy used for dynamically updating the set of items being stored, which has been extensively optimized over several decades, resulting in several efficient and robust heuristics. While applying machine learning to cache policies has shown promising results in recent years (e.g., LRB, LHD, storage applications), it remains a challenge to outperform robust heuristics in a way that can generalize reliably beyond benchmar‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Origin of Speeches? or just the collapse of Uruk?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59365</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59365&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-origin-of-speeches-or-just-the-collapse-of-uruk"/>
        <updated>2023-06-23T17:16:45.000Z</updated>
        <summary type="html"><![CDATA[I've wondered for a long time why Biblical inerrantists have a big problem with biological evolution, which contradicts Chapter 1 of Genesis, but not so much with historical linguistics, which contradicts Chapter 11. But in "Linguistic Confusion and the Tower of Babel", National Catholic Register 6/21/2023, Dave Armstrong argues that the usual interpretation of the [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The allure of Latin, the glory of Greek]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59358</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59358&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-allure-of-latin-the-glory-of-greek"/>
        <updated>2023-06-23T13:46:11.000Z</updated>
        <summary type="html"><![CDATA[Beautiful WSJ OpED (6/22/23) by Gerard Gayou, a seminarian of the archdiocese of Washington, who is studying theology at the Pontifical North American College in Rome: The Guiding Light of Latin Grammar The language reminds us of what our words mean and of whom we‚Äôre called to be. ‚Äî‚Äì Nothing bored me more during the [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interpretable Neural-Symbolic Concept Reasoning]]></title>
        <id>http://arxiv.org/abs/2304.14068</id>
        <link href="http://arxiv.org/abs/2304.14068"/>
        <updated>2023-06-23T09:17:07.507Z</updated>
        <summary type="html"><![CDATA[Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Mateo
  Espinosa Zarlenga, Lucie Charlotte Magister, Alberto Tonda, Pietro Lio',
  Frederic Precioso, Mateja Jamnik, Giuseppe Marra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sharp analysis of EM for learning mixtures of pairwise differences]]></title>
        <id>http://arxiv.org/abs/2302.10066</id>
        <link href="http://arxiv.org/abs/2302.10066"/>
        <updated>2023-06-23T07:19:28.276Z</updated>
        <summary type="html"><![CDATA[Abhishek Dhawan, Cheng Mao, Ashwin Pananjady]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the explainable properties of 1-Lipschitz Neural Networks: An Optimal
  Transport Perspective]]></title>
        <id>http://arxiv.org/abs/2206.06854</id>
        <link href="http://arxiv.org/abs/2206.06854"/>
        <updated>2023-06-23T07:19:28.271Z</updated>
        <summary type="html"><![CDATA[Mathieu Serrurier (IRIT, UT), Franck Mamalet (UT), Thomas Fel (UT),
  Louis B\'ethune (UT3, UT, IRIT), Thibaut Boissin (UT)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Path to Autonomous Learners]]></title>
        <id>http://arxiv.org/abs/2211.02403</id>
        <link href="http://arxiv.org/abs/2211.02403"/>
        <updated>2023-06-23T07:19:28.265Z</updated>
        <summary type="html"><![CDATA[Hanna Abi Akl]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Finite-time Lyapunov exponents of deep neural networks]]></title>
        <id>http://arxiv.org/abs/2306.12548</id>
        <link href="http://arxiv.org/abs/2306.12548"/>
        <updated>2023-06-23T07:19:28.245Z</updated>
        <summary type="html"><![CDATA[L. Storm, H. Linander, J. Bec, K. Gustavsson, B. Mehlig]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SQ Lower Bounds for Learning Bounded Covariance GMMs]]></title>
        <id>http://arxiv.org/abs/2306.13057</id>
        <link href="http://arxiv.org/abs/2306.13057"/>
        <updated>2023-06-23T07:19:28.227Z</updated>
        <summary type="html"><![CDATA[Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#3]]]></title>
        <id>http://xianblog.wordpress.com/?p=53355</id>
        <link href="https://xianblog.wordpress.com/2023/06/23/approximation-methods-in-bayesian-analysis-3/"/>
        <updated>2023-06-22T22:23:24.000Z</updated>
        <summary type="html"><![CDATA[My last day (#4) at the workshop, as I had to return to Paris earlier. A rather theoretical morning again, with Morgane Austern on (probabilistic) concentration inequalities on transport distances, far from my comfort zone if lively, Jason Xu on replacing non-convex penalisation factors to distances to the corresponding manifold, which I found most interesting [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SoundStorm: Efficient parallel audio generation]]></title>
        <id>http://ai.googleblog.com/2023/06/soundstorm-efficient-parallel-audio.html</id>
        <link href="http://ai.googleblog.com/2023/06/soundstorm-efficient-parallel-audio.html"/>
        <updated>2023-06-22T18:33:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Zal√°n Borsos, Research Software Engineer, and Marco Tagliasacchi, Senior Staff Research Scientist, Google Research







The recent progress in generative AI unlocked the possibility of creating new content in several different domains, including text, vision and audio. These models often rely on the fact that raw data is first converted to a compressed format as a sequence of tokens. In the case of audio, neural audio codecs (e.g., SoundStream or EnCodec) can efficiently compress waveforms to a compact representation, which can be inverted to reconstruct an approximation of the original audio signal. Such a representation consists of a sequence of discrete audio tokens, capturing the local properties of sounds (e.g., phonemes) and their temporal structure (e.g., prosody). By re‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The legal standing of the serial comma]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59352</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59352&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-legal-standing-of-the-serial-comma"/>
        <updated>2023-06-22T13:30:29.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Mark Cohen] I am wondering if members of this group have had experience with translating the Chinese serial comma or d√πnh√†o È°øÂè∑¬† [„ÄÅ] ("the caesura sign; a slight-pause mark used to set off items in a series; punctuation mark used between parallel words or short phrases; sign of coordination; [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Problem: Learning with Variational Objectives on Measures]]></title>
        <id>http://arxiv.org/abs/2306.11928</id>
        <link href="http://arxiv.org/abs/2306.11928"/>
        <updated>2023-06-22T07:16:05.265Z</updated>
        <summary type="html"><![CDATA[Vivien Cabannes, Carles Domingo-Enrich]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Any Deep ReLU Network is Shallow]]></title>
        <id>http://arxiv.org/abs/2306.11827</id>
        <link href="http://arxiv.org/abs/2306.11827"/>
        <updated>2023-06-22T07:16:05.251Z</updated>
        <summary type="html"><![CDATA[Mattia Jacopo Villani, Nandi Schoots]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayes-optimal Learning of Deep Random Networks of Extensive-width]]></title>
        <id>http://arxiv.org/abs/2302.00375</id>
        <link href="http://arxiv.org/abs/2302.00375"/>
        <updated>2023-06-22T07:16:04.347Z</updated>
        <summary type="html"><![CDATA[Hugo Cui, Florent Krzakala, Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Debiased Machine Learning for Dynamic Treatment Effects and
  General Nested Functionals]]></title>
        <id>http://arxiv.org/abs/2203.13887</id>
        <link href="http://arxiv.org/abs/2203.13887"/>
        <updated>2023-06-22T07:16:04.342Z</updated>
        <summary type="html"><![CDATA[Victor Chernozhukov, Whitney Newey, Rahul Singh, Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal rates of approximation by shallow ReLU$^k$ neural networks and
  applications to nonparametric regression]]></title>
        <id>http://arxiv.org/abs/2304.01561</id>
        <link href="http://arxiv.org/abs/2304.01561"/>
        <updated>2023-06-22T07:16:04.220Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimized PyTorch 2.0 Inference with AWS Graviton processors]]></title>
        <id>https://pytorch.org/blog/optimized-pytorch-w-graviton/</id>
        <link href="https://pytorch.org/blog/optimized-pytorch-w-graviton/"/>
        <updated>2023-06-22T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[New generations of CPUs offer significant performance improvement in machine learning (ML) inference due to specialized built-in instructions. Combined with their flexibility, high speed of development, and low operating cost, these general-purpose processors offer an alternative ML inference solution to other existing hardware solutions.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#2]]]></title>
        <id>http://xianblog.wordpress.com/?p=53342</id>
        <link href="https://xianblog.wordpress.com/2023/06/22/approximation-methods-in-bayesian-analysis-2/"/>
        <updated>2023-06-21T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[A more theoretical Day #2 of the workshop, with Debdeep Pati comparing two representations of Gaussian processes with significantly different efficiencies, and Aad van der Vaart presenting a form of linearisation for a range of inverse problems, Kolyan Ray debiasing Lasso impacts by variational Bayes, although through a somewhat intricate process that distanced the procedure [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: AI for Social Good]]></title>
        <id>http://ai.googleblog.com/2023/06/responsible-ai-at-google-research-ai.html</id>
        <link href="http://ai.googleblog.com/2023/06/responsible-ai-at-google-research-ai.html"/>
        <updated>2023-06-21T20:57:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Jimmy Tobin and Katrin Tomanek, Software Engineers, Google Research, AI for Social Good


Google‚Äôs AI for Social Good team consists of researchers, engineers, volunteers, and others with a shared focus on positive social impact. Our mission is to demonstrate AI‚Äôs societal benefit by enabling real-world value, with projects spanning work in public health, accessibility, crisis response, climate and energy, and nature and society. We believe that the best way to drive positive change in underserved communities is by partnering with change-makers and the organizations they serve.


 


In this blog post we discuss work done by Project Euphonia, a team within AI for Social Good, that aims to improve automatic speech recognition (ASR) for people with disordered speech. For people with‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The world‚Äôs first braiding of non-Abelian anyons]]></title>
        <id>http://ai.googleblog.com/2023/06/the-worlds-first-braiding-of-non.html</id>
        <link href="http://ai.googleblog.com/2023/06/the-worlds-first-braiding-of-non.html"/>
        <updated>2023-06-21T17:29:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Trond Andersen and Yuri Lensky, Research Scientists, Google Quantum AI Team  






Imagine you‚Äôre shown two identical objects and then asked to close your eyes. When you open your eyes, you see the same two objects in the same position. How can you determine if they have been swapped back and forth? Intuition and the laws of quantum mechanics agree: If the objects are truly identical, there is no way to tell. 



While this sounds like common sense, it only applies to our familiar three-dimensional world. Researchers have predicted that for a special type of particle, called an anyon, that is restricted to move only in a two-dimensional (2D) plane, quantum mechanics allows for something quite different. Anyons are indistinguishable from one another and some, non-Abelian anyons, ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On-the-Fly Adaptation of Source Code Models using Meta-Learning]]></title>
        <id>http://arxiv.org/abs/2003.11768</id>
        <link href="http://arxiv.org/abs/2003.11768"/>
        <updated>2023-06-21T01:23:11.749Z</updated>
        <summary type="html"><![CDATA[Disha Shrivastava, Hugo Larochelle, Daniel Tarlow]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Novel Collaborative Self-Supervised Learning Method for Radiomic Data]]></title>
        <id>http://arxiv.org/abs/2302.09807</id>
        <link href="http://arxiv.org/abs/2302.09807"/>
        <updated>2023-06-21T01:23:11.744Z</updated>
        <summary type="html"><![CDATA[Zhiyuan Li, Hailong Li, Anca L. Ralescu, Jonathan R. Dillman, Nehal A.
  Parikh, Lili He]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Does a Deep Learning Model Architecture Impact Its Privacy? A
  Comprehensive Study of Privacy Attacks on CNNs and Transformers]]></title>
        <id>http://arxiv.org/abs/2210.11049</id>
        <link href="http://arxiv.org/abs/2210.11049"/>
        <updated>2023-06-21T01:23:11.454Z</updated>
        <summary type="html"><![CDATA[Guangsheng Zhang, Bo Liu, Huan Tian, Tianqing Zhu, Ming Ding, Wanlei
  Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Principles for Initialization and Architecture Selection in Graph Neural
  Networks with ReLU Activations]]></title>
        <id>http://arxiv.org/abs/2306.11668</id>
        <link href="http://arxiv.org/abs/2306.11668"/>
        <updated>2023-06-21T01:23:11.449Z</updated>
        <summary type="html"><![CDATA[Gage DeZoort, Boris Hanin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Implicit Bias of Batch Normalization in Linear Models and Two-layer
  Linear Convolutional Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.11680</id>
        <link href="http://arxiv.org/abs/2306.11680"/>
        <updated>2023-06-21T01:23:07.429Z</updated>
        <summary type="html"><![CDATA[Yuan Cao, Difan Zou, Yuanzhi Li, Quanquan Gu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[shallow learning]]></title>
        <id>http://xianblog.wordpress.com/?p=53337</id>
        <link href="https://xianblog.wordpress.com/2023/06/21/shallow-learning/"/>
        <updated>2023-06-20T22:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fangy√°n = topolect in DC]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59348</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59348&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=fangyan-topolect-in-dc"/>
        <updated>2023-06-20T20:58:16.000Z</updated>
        <summary type="html"><![CDATA[I'm in Georgetown for a few days to meet with colleagues and do some research.¬† Shortly after I left my hotel and headed down Wisconsin Avenue toward the Potomac for a morning run, I stopped dead in my tracks when I crossed over the canal and saw this: Especially with all the¬†butterflies¬†in the window, I [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Fursty Ferret]]></title>
        <id>http://xianblog.wordpress.com/?p=53009</id>
        <link href="https://xianblog.wordpress.com/2023/06/20/the-fursty-ferret/"/>
        <updated>2023-06-20T18:20:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Topolects and texts]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59286</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59286&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=topolects-and-texts"/>
        <updated>2023-06-20T14:06:53.000Z</updated>
        <summary type="html"><![CDATA[Illuminating new book from Hong Kong University Press edited by Richard VanNess Simmons: Studies in Colloquial Chinese and Its History:¬† Dialect and Text ISBN : 978-988-8754-09-0 The book also has a Chinese title: H√†ny«î k«íuy«î de l√¨sh«ê y√°nji≈´: fƒÅngy√°n h√© w√©nxi√†n Êº¢Ë™ûÂè£Ë™ûÁöÑÊ≠∑Âè≤Á†îÁ©∂ÔºöÊñπË®ÄËàáÊñáÁçª I would prefer to render this into English as: Studies on the History [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tortured phrases, LLMs, and Goodhart's Law]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59339</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59339&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tortured-phrases-llms-and-goodharts-law"/>
        <updated>2023-06-20T13:55:24.000Z</updated>
        <summary type="html"><![CDATA[A few years ago, I began to notice that the scientific and technical papers relentless spammed at me, by academia.edu and similar outfits, were becoming increasingly surrealistic. And I soon learned that the source for such articles was systems for "article spinning" by "rogeting" ‚Äî automatic random subsitution of (usually inappropriate) synonyms. Those techniques were [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RoboCat: A self-improving robotic agent]]></title>
        <id>https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent</id>
        <link href="https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent"/>
        <updated>2023-06-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#1]]]></title>
        <id>http://xianblog.wordpress.com/?p=53331</id>
        <link href="https://xianblog.wordpress.com/2023/06/20/approximation-methods-in-bayesian-analysis-1/"/>
        <updated>2023-06-19T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[Interesting first day, if somewhat intense!, with Sylvia Richardson talking of divide & conquer strategies, which we had recently explored in our work on mixtures with Adrien and Judith. Then Jere Koskela (Warwick) on sufficient conditions for consistent inference on trees like Kingman‚Äôs coalescent. And in the afternoon Julia-Adela Palacios on tree estimation, with novel [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stabilized Neural Differential Equations for Learning Constrained
  Dynamics]]></title>
        <id>http://arxiv.org/abs/2306.09739</id>
        <link href="http://arxiv.org/abs/2306.09739"/>
        <updated>2023-06-19T07:14:46.765Z</updated>
        <summary type="html"><![CDATA[Alistair White, Niki Kilbertus, Maximilian Gelbrecht, Niklas Boers]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resolving the Human Subjects Status of Machine Learning's Crowdworkers]]></title>
        <id>http://arxiv.org/abs/2206.04039</id>
        <link href="http://arxiv.org/abs/2206.04039"/>
        <updated>2023-06-19T07:14:46.761Z</updated>
        <summary type="html"><![CDATA[Divyansh Kaushik, Zachary C. Lipton, Alex John London]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enhancing Activity Prediction Models in Drug Discovery with the Ability
  to Understand Human Language]]></title>
        <id>http://arxiv.org/abs/2303.03363</id>
        <link href="http://arxiv.org/abs/2303.03363"/>
        <updated>2023-06-19T07:14:46.756Z</updated>
        <summary type="html"><![CDATA[Philipp Seidl, Andreu Vall, Sepp Hochreiter, G\"unter Klambauer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Collapsed Inference for Bayesian Deep Learning]]></title>
        <id>http://arxiv.org/abs/2306.09686</id>
        <link href="http://arxiv.org/abs/2306.09686"/>
        <updated>2023-06-19T07:14:46.750Z</updated>
        <summary type="html"><![CDATA[Zhe Zeng, Guy Van den Broeck]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trained Transformers Learn Linear Models In-Context]]></title>
        <id>http://arxiv.org/abs/2306.09927</id>
        <link href="http://arxiv.org/abs/2306.09927"/>
        <updated>2023-06-19T07:14:46.650Z</updated>
        <summary type="html"><![CDATA[Ruiqi Zhang, Spencer Frei, Peter L. Bartlett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[no country for old men [Cormac McCarthy]]]></title>
        <id>http://xianblog.wordpress.com/?p=53250</id>
        <link href="https://xianblog.wordpress.com/2023/06/19/no-country-for-old-men-cormac-mccarthy/"/>
        <updated>2023-06-18T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at CVPR 2023]]></title>
        <id>http://ai.googleblog.com/2023/06/google-at-cvpr-2023.html</id>
        <link href="http://ai.googleblog.com/2023/06/google-at-cvpr-2023.html"/>
        <updated>2023-06-18T18:00:00.014Z</updated>
        <summary type="html"><![CDATA[Posted by Shaina Mehta, Program Manager, Google




This week marks the beginning of the premier annual Computer Vision and Pattern Recognition conference (CVPR 2023), held in-person in Vancouver, BC (with additional virtual content). As a leader in computer vision research and a Platinum Sponsor, Google Research will have a strong presence across CVPR 2023 with 90 papers being presented at the main conference and active involvement in over 40 conference workshops and tutorials.




If you are attending CVPR this year, please stop by our booth to chat with our researchers who are actively exploring the latest techniques for application to various areas of machine perception. Our researchers will also be available to talk about and demo several recent efforts, including on-device ML applica‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Time-averaged quantum annealing for weak processes]]></title>
        <id>http://arxiv.org/abs/2306.06008</id>
        <link href="http://arxiv.org/abs/2306.06008"/>
        <updated>2023-06-18T07:13:07.422Z</updated>
        <summary type="html"><![CDATA[Pierre Naz\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal shortcuts to adiabaticity of finite-time and weak processes]]></title>
        <id>http://arxiv.org/abs/2305.17802</id>
        <link href="http://arxiv.org/abs/2305.17802"/>
        <updated>2023-06-18T07:13:06.921Z</updated>
        <summary type="html"><![CDATA[Pierre Naz\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Saturn < Cronus (ŒöœÅœåŒΩŒøœÇ) ‚â† Chronos (ŒßœÅœåŒΩŒøœÇ)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59190</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59190&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=saturn-cronus-%25ce%25ba%25cf%2581%25cf%258c%25ce%25bd%25ce%25bf%25cf%2582-%25e2%2589%25a0-chronos-%25cf%2587%25cf%2581%25cf%258c%25ce%25bd%25ce%25bf%25cf%2582"/>
        <updated>2023-06-18T04:50:29.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Jichang Lulu, with some minor modifications and additions by VHM] You might have seen this ‚Äî the PRC embassy in Poland has given¬†Badiucao's forthcoming exhibition in Warsaw¬†(coorganised by¬†Sinopsis) some very welcome, completely unexpected publicity by trying to have it shut down. Lots of international reporting: The Guardian,¬†Sydney Morning Herald,¬†&c.,¬†&c. [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[webscussion on Bayesian causality]]></title>
        <id>http://xianblog.wordpress.com/?p=53243</id>
        <link href="https://xianblog.wordpress.com/2023/06/18/webscussion-on-bayesian-causality/"/>
        <updated>2023-06-17T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[Today, I attended (most of) and briefly took part in the discussion webinar run by Bayesian Analysis (the journal) and featuring the paper Causal Inference Under Mis-Specification: Adjustment Based on the Propensity Score by David Stephens, Widemberg Nobre, Erica Moodie, and Alexandra M. Schmidt, for which Pierre Jacob and I contributed a written discussion. I [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Throw a photo" in South Florida English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59266</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59266&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=throw-a-photo-in-south-florida-english"/>
        <updated>2023-06-17T20:45:14.000Z</updated>
        <summary type="html"><![CDATA[Article by Phillip M. Carter in The Conversation (6/12/23): "Linguists have identified a new English dialect that‚Äôs emerging in South Florida" Beginning sentences: ‚ÄúWe got down from the car and went inside.‚Äù ‚ÄúI made the line to pay for groceries.‚Äù ‚ÄúHe made a party to celebrate his son‚Äôs birthday.‚Äù These phrases might sound off to [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ancient eggcorns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59277</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59277&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ancient-eggcorns"/>
        <updated>2023-06-17T13:29:57.000Z</updated>
        <summary type="html"><![CDATA[The word eggcorn was originally proposed in a LLOG post almost 20 years ago ‚Äî "Egg corns: folk etymology, malapropism, mondegreen, ???", 9/23/2003.¬† And the word is now recognized by most current English dictionaries and other relevant sources, which gloss it variously, e.g. ‚Äî the¬† Oxford English Dictionary, ("An alteration of a word or phrase [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Coors Light Bear]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59272</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59272&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=coors-light-bear"/>
        <updated>2023-06-17T09:28:04.000Z</updated>
        <summary type="html"><![CDATA[An NFL policy prohibits plays from endorsing alcoholic beverages. So Coors found a linguistic work-around: Last year's commercial promoted the Coors (Flash) Light: I have some inter-related contractual and cultural questions. Are these commercials really consistent, legally, with a contractual agreement not to promote alcoholic beverages? Is is crucial that there actual merch you can [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[shame!]]></title>
        <id>http://xianblog.wordpress.com/?p=53289</id>
        <link href="https://xianblog.wordpress.com/2023/06/17/53289/"/>
        <updated>2023-06-16T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rivers and lakes:  quackery]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59232</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59232&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rivers-and-lakes-quackery"/>
        <updated>2023-06-16T19:03:16.000Z</updated>
        <summary type="html"><![CDATA[Get ready to go a-wanderin'.¬† I'll take you down to the rivers and lakes, and we shall lose ourselves in them, get lost from the hurlyburly hustlebustle of the mundane world.¬† That's what jiƒÅngh√∫ Ê±üÊπñ ("rivers and lakes") is all about.¬† It's where you go to xiƒÅoy√°o y√≥u ÈÄçÈÅôÈÅä ("wander freely / carefreely / leisurely"). [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Her pension for body-hugging gowns‚Ä¶"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59257</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59257&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=her-pension-for-body-hugging-gowns"/>
        <updated>2023-06-16T12:34:28.000Z</updated>
        <summary type="html"><![CDATA[It's been a while since we discussed a new eggcorn, so here's one, from "Beauty and the bleach", The Vintage Woman¬†2020: Blonde bombshell. A phrase so used frequently in our accumulative vernacular that the significance now wanes. This phrase, once a revelation, was brought to our consciousness by Jean Harlow. The original platinum blonde. Her [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WavPool: A New Block for Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.08734</id>
        <link href="http://arxiv.org/abs/2306.08734"/>
        <updated>2023-06-16T07:13:31.376Z</updated>
        <summary type="html"><![CDATA[Samuel D. McDermott, M. Voetberg, Brian Nord]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phase diagram of Stochastic Gradient Descent in high-dimensional
  two-layer neural networks]]></title>
        <id>http://arxiv.org/abs/2202.00293</id>
        <link href="http://arxiv.org/abs/2202.00293"/>
        <updated>2023-06-16T07:13:30.776Z</updated>
        <summary type="html"><![CDATA[Rodrigo Veiga, Ludovic Stephan, Bruno Loureiro, Florent Krzakala,
  Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nonparametric regression using over-parameterized shallow ReLU neural
  networks]]></title>
        <id>http://arxiv.org/abs/2306.08321</id>
        <link href="http://arxiv.org/abs/2306.08321"/>
        <updated>2023-06-16T07:13:30.771Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unbiased Learning of Deep Generative Models with Structured Discrete
  Representations]]></title>
        <id>http://arxiv.org/abs/2306.08230</id>
        <link href="http://arxiv.org/abs/2306.08230"/>
        <updated>2023-06-16T07:13:30.766Z</updated>
        <summary type="html"><![CDATA[Harry Bendekgey, Gabriel Hope, Erik B. Sudderth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visualizing Deep Neural Networks with Topographic Activation Maps]]></title>
        <id>http://arxiv.org/abs/2204.03528</id>
        <link href="http://arxiv.org/abs/2204.03528"/>
        <updated>2023-06-16T07:13:30.619Z</updated>
        <summary type="html"><![CDATA[Valerie Krug, Raihan Kabir Ratul, Christopher Olson, Sebastian Stober]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[üéâ PyTorch Docathon H1 2023 Wrap-up üéâ]]></title>
        <id>https://pytorch.org/blog/docathon-h1-2023-wrap-up/</id>
        <link href="https://pytorch.org/blog/docathon-h1-2023-wrap-up/"/>
        <updated>2023-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Thank you to all who participated in our first ever PyTorch Docathon, the results have been nothing short of amazing! We want to extend our sincerest gratitude to all the participants who made this event a resounding success. Your passion, talent, and hard work have left an indelible mark on the PyTorch documentation.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ê¢ØÂ∫¶ÊµÅÔºöÊé¢Á¥¢ÈÄöÂæÄÊúÄÂ∞èÂÄº‰πãË∑Ø]]></title>
        <id>https://kexue.fm/archives/9660</id>
        <link href="https://kexue.fm/archives/9660"/>
        <updated>2023-06-16T02:10:00.000Z</updated>
        <summary type="html"><![CDATA[Âú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®‰∏Ä‰∏™Ë¢´Áß∞‰∏∫‚ÄúÊ¢ØÂ∫¶ÊµÅÔºàGradient FlowÔºâ‚ÄùÁöÑÊ¶ÇÂøµ„ÄÇÁÆÄÂçïÊù•ËØ¥ÔºåÊ¢ØÂ∫¶ÊµÅÊòØÂ∞ÜÊàë‰ª¨Âú®Áî®Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï‰∏≠ÂØªÊâæÊúÄÂ∞èÂÄºÁöÑËøáÁ®ã‰∏≠ÁöÑÂêÑ‰∏™ÁÇπËøûÊé•Ëµ∑Êù•ÔºåÂΩ¢Êàê‰∏ÄÊù°ÈöèÔºàËôöÊãüÁöÑÔºâÊó∂Èó¥ÂèòÂåñÁöÑËΩ®ËøπÔºå...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noctureine 2023]]></title>
        <id>http://xianblog.wordpress.com/?p=53100</id>
        <link href="https://xianblog.wordpress.com/2023/06/16/noctureine-2023/"/>
        <updated>2023-06-15T22:23:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Syllabolic"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59235</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59235&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=syllabolic"/>
        <updated>2023-06-15T21:58:09.000Z</updated>
        <summary type="html"><![CDATA[On June 1 in Iowa, Donald Trump gave a speech in which he attacked Ron DeSantis from several angles. One of them was DeSantis' variation in pronunciation of his last name (see "Pronouncing 'DeSantis'", 6/3/2023), which Trump characterized as "changing his name", while introducing a puzzling (but promising?) new linguistic term, "syllabolic": Your browser does [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speed is all you need: On-device acceleration of large diffusion models via GPU-aware optimizations]]></title>
        <id>http://ai.googleblog.com/2023/06/speed-is-all-you-need-on-device.html</id>
        <link href="http://ai.googleblog.com/2023/06/speed-is-all-you-need-on-device.html"/>
        <updated>2023-06-15T20:53:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Juhyun Lee and Raman Sarokin, Software Engineers, Core Systems & Experiences




The proliferation of large diffusion models for image generation has led to a significant increase in model size and inference workloads. On-device ML inference in mobile environments requires meticulous performance optimization and consideration of trade-offs due to resource constraints. Running inference of large diffusion models (LDMs) on-device, driven by the need for cost efficiency and user privacy, presents even greater challenges due to the substantial memory requirements and computational demands of these models.
 

We address this challenge in our work titled ‚ÄúSpeed Is All You Need: On-Device Acceleration of Large Diffusion Models via GPU-Aware Optimizations‚Äù (to be presented at the CVPR 20‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Cantophone and the state]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59228</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59228&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-cantophone-and-the-state"/>
        <updated>2023-06-15T12:19:22.000Z</updated>
        <summary type="html"><![CDATA[Cantonese ‚Äî its nature, its status, its past, present, and future, its place in the realm of Sinitic languages and in the world ‚Äî has been one of the chief foci of Language Log.¬† Consequently, it is my great pleasure to announce the publication of the three-hundred-and-thirty-fourth issue of Sino-Platonic Papers: ‚ÄúThe Concept of the [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classifier Calibration: A survey on how to assess and improve predicted
  class probabilities]]></title>
        <id>http://arxiv.org/abs/2112.10327</id>
        <link href="http://arxiv.org/abs/2112.10327"/>
        <updated>2023-06-15T07:14:30.613Z</updated>
        <summary type="html"><![CDATA[Telmo Silva Filho, Hao Song, Miquel Perello-Nieto, Raul
  Santos-Rodriguez, Meelis Kull, Peter Flach]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[soon off to CIRM]]></title>
        <id>http://xianblog.wordpress.com/?p=53229</id>
        <link href="https://xianblog.wordpress.com/2023/06/15/soon-off-to-cirm/"/>
        <updated>2023-06-14T22:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reconstructing indoor spaces with NeRF]]></title>
        <id>http://ai.googleblog.com/2023/06/reconstructing-indoor-spaces-with-nerf.html</id>
        <link href="http://ai.googleblog.com/2023/06/reconstructing-indoor-spaces-with-nerf.html"/>
        <updated>2023-06-14T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[Marcos Seefelder, Software Engineer, and Daniel Duckworth, Research Software Engineer, Google Research




When choosing a venue, we often find ourselves with questions like the following: Does this restaurant have the right vibe for a date? Is there good outdoor seating? Are there enough screens to watch the game? While photos and videos may partially answer questions like these, they are no substitute for feeling like you‚Äôre there, even when visiting in person isn't an option.



Immersive experiences that are interactive, photorealistic, and multi-dimensional stand to bridge this gap and recreate the feel and vibe of a space, empowering users to naturally and intuitively find the information they need. To help with this, Google Maps launched Immersive View, which uses advances in machin‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Tortured syllables"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59186</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59186&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tortured-syllables"/>
        <updated>2023-06-14T15:16:36.000Z</updated>
        <summary type="html"><![CDATA["Language change (about to be?) in progress" (6/12/2023) linked to media commentary on divergent features of Northeast Philadelphia speech, e.g. "Side effect of the highway collapse: A perfect example of Northeast Philly hoagiemouth", Billy Penn 6/11/2-23. Some of the characterization was extremely evaluative: Philadelphians have perfected torturing vowels like medieval Europe perfected torturing people. Every [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Indigenous languages of Taiwan]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59179</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59179&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=indigenous-languages-of-taiwan"/>
        <updated>2023-06-14T11:35:23.000Z</updated>
        <summary type="html"><![CDATA[How many are there? Taiwan‚Äôs unrecognized indigenous tribes are reviving dead languages to achieve recognition There are currently 16 officially recognized indigenous peoples in Taiwan. The Pingpu ‚Äî which comprise 10 groups on the island‚Äôs lowlands ‚Äî are lobbying to make that number 17, and they‚Äôre doing it by reviving lost languages and culture. By [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identification of Nonlinear Latent Hierarchical Models]]></title>
        <id>http://arxiv.org/abs/2306.07916</id>
        <link href="http://arxiv.org/abs/2306.07916"/>
        <updated>2023-06-14T07:13:58.126Z</updated>
        <summary type="html"><![CDATA[Lingjing Kong, Biwei Huang, Feng Xie, Eric Xing, Yuejie Chi, Kun Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solving the Dirichlet problem for the Monge-Amp\`ere equation using
  neural networks]]></title>
        <id>http://arxiv.org/abs/2110.03310</id>
        <link href="http://arxiv.org/abs/2110.03310"/>
        <updated>2023-06-14T07:13:58.121Z</updated>
        <summary type="html"><![CDATA[Kaj Nystr\"om, Matias Vestberg]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fixed points of arbitrarily deep 1-dimensional neural networks]]></title>
        <id>http://arxiv.org/abs/2303.12814</id>
        <link href="http://arxiv.org/abs/2303.12814"/>
        <updated>2023-06-14T07:13:57.895Z</updated>
        <summary type="html"><![CDATA[Andrew Cook, Andy Hammerlindl, Warwick Tucker]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robustly Learning a Single Neuron via Sharpness]]></title>
        <id>http://arxiv.org/abs/2306.07892</id>
        <link href="http://arxiv.org/abs/2306.07892"/>
        <updated>2023-06-14T07:13:57.890Z</updated>
        <summary type="html"><![CDATA[Puqian Wang, Nikos Zarifis, Ilias Diakonikolas, Jelena Diakonikolas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Trio Neural Model for Dynamic Entity Relatedness Ranking]]></title>
        <id>http://arxiv.org/abs/1808.08316</id>
        <link href="http://arxiv.org/abs/1808.08316"/>
        <updated>2023-06-14T07:13:57.681Z</updated>
        <summary type="html"><![CDATA[Tu Nguyen, Tuan Tran, Wolfgang Nejdl]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[astrostat webinar [IAU-IAA]]]></title>
        <id>http://xianblog.wordpress.com/?p=53218</id>
        <link href="https://xianblog.wordpress.com/2023/06/14/astrostat-webinar-iau-iaa/"/>
        <updated>2023-06-13T22:23:28.000Z</updated>
        <summary type="html"><![CDATA[Next Tuesday, June 13, at 16:00 UTC, I am giving a talk on inferring the number of components in a mixture at the international online IAU-IAA Astrostats and Astroinfo seminar. As pointed out by my Cornell friend Tom Loredo, it is unfortunately clashing with the ISI quadrenial Statistical Challenges in Modern Astronomy meeting help at [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enabling delightful user experiences via predictive models of human attention]]></title>
        <id>http://ai.googleblog.com/2023/06/enabling-delightful-user-experiences.html</id>
        <link href="http://ai.googleblog.com/2023/06/enabling-delightful-user-experiences.html"/>
        <updated>2023-06-13T17:18:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Junfeng He, Senior Research Scientist, and Kai Kohlhoff, Staff Research Scientist, Google Research




People have the remarkable ability to take in a tremendous amount of information (estimated to be ~1010 bits/s entering the retina) and selectively attend to a few task-relevant and interesting regions for further processing (e.g., memory, comprehension, action). Modeling human attention (the result of which is often called a saliency model) has therefore been of interest across the fields of neuroscience, psychology, human-computer interaction (HCI) and computer vision. The ability to predict which regions are likely to attract attention has numerous important applications in areas like graphics, photography, image compression and processing, and the measurement of visual quali‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Victorious Secret]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59183</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59183&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=victorious-secret"/>
        <updated>2023-06-13T10:25:10.000Z</updated>
        <summary type="html"><![CDATA[The next event in the Salon Sanctuary concert series is "Victorious Secret: Love Gamed and Gender Untamed in the Sparkling Courts of the Baroque": Before the bars of gender binaries caged the mainstream operatic imagination, a golden age of fluidity guided the vocal soundscape. Virility declared itself with the castrato‚Äôs clarion high notes, while femininity [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beyond the Imitation Game: Quantifying and extrapolating the
  capabilities of language models]]></title>
        <id>http://arxiv.org/abs/2206.04615</id>
        <link href="http://arxiv.org/abs/2206.04615"/>
        <updated>2023-06-13T08:19:00.775Z</updated>
        <summary type="html"><![CDATA[Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb,
  Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adri\`a
  Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea
  Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv,
  Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda
  Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen,
  Andrea Madotto, Andrea Santilli, Andreas Stuhlm\"uller, Andrew Dai, Andrew
  La, Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong,
  Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash
  Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher
  Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla
  Karaka\c{s}, B. Ryan Roberts, Bao Sheng Loe, Barret Zoph, Bart{\l}omiej
  Bojanowski, Batuhan \"Ozyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin
  Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan
  Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta,
  C\'esar Ferri Ram\'irez, Chandan Singh, Charles Rathkopf, Chenlin Meng,
  Chitta Baral, Chiyu Wu, Chris Callison-Burch, Chris Waites, Christian Voigt,
  Christopher D. Manning, Christopher Potts, Cindy Ramirez, Clara E. Rivera,
  Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien
  Sileo, Dan Garrette, Dan Hendrycks, Dan Kilman, Dan Roth, Daniel Freeman,
  Daniel Khashabi, Daniel Levy, Daniel Mosegu\'i Gonz\'alez, Danielle Perszyk,
  Danny Hernandez, Danqi Chen, Daphne Ippolito, Dar Gilboa, David Dohan, David
  Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis
  Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes, Diganta Misra,
  Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader,
  Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth
  Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodola,]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Energy-Dissipative Evolutionary Deep Operator Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.06281</id>
        <link href="http://arxiv.org/abs/2306.06281"/>
        <updated>2023-06-13T08:19:00.296Z</updated>
        <summary type="html"><![CDATA[Jiahao Zhang, Shiheng Zhang, Jie Shen, Guang Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Learning Priors for Safe Bayesian Optimization]]></title>
        <id>http://arxiv.org/abs/2210.00762</id>
        <link href="http://arxiv.org/abs/2210.00762"/>
        <updated>2023-06-13T08:19:00.280Z</updated>
        <summary type="html"><![CDATA[Jonas Rothfuss, Christopher Koenig, Alisa Rupenyan, Andreas Krause]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intensity Profile Projection: A Framework for Continuous-Time
  Representation Learning for Dynamic Networks]]></title>
        <id>http://arxiv.org/abs/2306.06155</id>
        <link href="http://arxiv.org/abs/2306.06155"/>
        <updated>2023-06-13T08:19:00.275Z</updated>
        <summary type="html"><![CDATA[Alexander Modell, Ian Gallagher, Emma Ceccherini, Nick Whiteley and
  Patrick Rubin-Delanchy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Variational Models with Unrolling and Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2209.12651</id>
        <link href="http://arxiv.org/abs/2209.12651"/>
        <updated>2023-06-13T08:19:00.264Z</updated>
        <summary type="html"><![CDATA[Christoph Brauer, Niklas Breustedt, Timo de Wolff, Dirk A. Lorenz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introduction to Queueing Theory and Stochastic Teletraffic Models]]></title>
        <id>http://arxiv.org/abs/1307.2968</id>
        <link href="http://arxiv.org/abs/1307.2968"/>
        <updated>2023-06-13T07:14:02.706Z</updated>
        <summary type="html"><![CDATA[Moshe Zukerman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Effect of driving on coarsening dynamics in phase-separating systems]]></title>
        <id>http://arxiv.org/abs/1905.13396</id>
        <link href="http://arxiv.org/abs/1905.13396"/>
        <updated>2023-06-13T07:14:02.700Z</updated>
        <summary type="html"><![CDATA[D. Tseluiko, M. Alesemi, T.-S. Lin, U. Thiele]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Converse growth estimates for ODEs with slowly growing solutions]]></title>
        <id>http://arxiv.org/abs/1811.08736</id>
        <link href="http://arxiv.org/abs/1811.08736"/>
        <updated>2023-06-13T07:14:02.683Z</updated>
        <summary type="html"><![CDATA[Janne Gr\"ohn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alexandrov geometry: foundations]]></title>
        <id>http://arxiv.org/abs/1903.08539</id>
        <link href="http://arxiv.org/abs/1903.08539"/>
        <updated>2023-06-13T07:14:02.676Z</updated>
        <summary type="html"><![CDATA[Stephanie Alexander, Vitali Kapovitch, Anton Petrunin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Good News for Polynomial Root-finding]]></title>
        <id>http://arxiv.org/abs/1805.12042</id>
        <link href="http://arxiv.org/abs/1805.12042"/>
        <updated>2023-06-13T07:14:02.670Z</updated>
        <summary type="html"><![CDATA[Victor Y. Pan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is it a rat's head or a duck's neck?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59176</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59176&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=is-it-a-rats-head-or-a-ducks-neck"/>
        <updated>2023-06-13T04:20:49.000Z</updated>
        <summary type="html"><![CDATA[Main dish served as part of a college cafeteria lunch in¬†Nanchang, China: On the left side it says:¬† zh√® b√∫sh√¨ m√°o ma? Ëøô‰∏çÊòØÊØõÂêó "Isn't this hair?" On the right side it reads: ƒÅy√≠ shu≈ç¬†sh√¨ yƒÅr√≤u ÈòøÂß®Ë™™ÊòØÈ¥®ËÇâ "Auntie [i.e., the cafeteria serving lady] says that it's duck meat." The photographs and the captions are from Andrew [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red Sea [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53157</id>
        <link href="https://xianblog.wordpress.com/2023/06/13/red-sea-jatp/"/>
        <updated>2023-06-12T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Old Sinitic "wheat" and Early Middle Sinitic "camel"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59111</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59111&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=old-sinitic-wheat-and-early-middle-sinitic-camel"/>
        <updated>2023-06-12T20:56:56.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Chris Button] OC uvulars tended to condition rounding (e.g OC q- becoming EMC kw-). In the case of  Å-, we sometimes get m- (for a modern-day example, note howÊÉü, which also had a  Å- onset in Old Chinese, gives an m- reflex in Fuzhou Min). The classic example is [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language change (about to be?) in progress]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59145</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59145&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-change-about-to-be-in-progress"/>
        <updated>2023-06-12T11:48:10.000Z</updated>
        <summary type="html"><![CDATA[Current big news around here is the collapse of an elevated section of Interstate 95 due to a tanker truck fire. As Wikipedia explains, I-95 "is the main north‚Äìsouth Interstate Highway on the East Coast of the United States, running from U.S. Route 1 (US 1) in Miami, Florida, north to the Houlton‚ÄìWoodstock Border Crossing [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning]]></title>
        <id>http://arxiv.org/abs/2211.06530</id>
        <link href="http://arxiv.org/abs/2211.06530"/>
        <updated>2023-06-12T07:14:12.350Z</updated>
        <summary type="html"><![CDATA[Christopher A. Choquette-Choo, H. Brendan McMahan, Keith Rush, and
  Abhradeep Thakurta]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Huber-energy measure quantization]]></title>
        <id>http://arxiv.org/abs/2212.08162</id>
        <link href="http://arxiv.org/abs/2212.08162"/>
        <updated>2023-06-12T07:14:11.384Z</updated>
        <summary type="html"><![CDATA[Gabriel Turinici]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Path Neural Networks: Expressive and Accurate Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.05955</id>
        <link href="http://arxiv.org/abs/2306.05955"/>
        <updated>2023-06-12T07:14:11.314Z</updated>
        <summary type="html"><![CDATA[Gaspard Michel, Giannis Nikolentzos, Johannes Lutzeyer, Michalis
  Vazirgiannis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Credal Self-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2205.15239</id>
        <link href="http://arxiv.org/abs/2205.15239"/>
        <updated>2023-06-12T07:14:11.308Z</updated>
        <summary type="html"><![CDATA[Julian Lienen, Caglar Demir, Eyke H\"ullermeier]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Change-Point Detection in Time Series via Deep Learning]]></title>
        <id>http://arxiv.org/abs/2211.03860</id>
        <link href="http://arxiv.org/abs/2211.03860"/>
        <updated>2023-06-12T07:14:11.201Z</updated>
        <summary type="html"><![CDATA[Jie Li, Paul Fearnhead, Piotr Fryzlewicz, Tengyao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[gamin‚Äô the rankin‚Äô]]></title>
        <id>http://xianblog.wordpress.com/?p=53148</id>
        <link href="https://xianblog.wordpress.com/2023/06/12/gamin-the-rankin/"/>
        <updated>2023-06-11T22:23:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ravens on the garden path]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59146</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59146&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ravens-on-the-garden-path"/>
        <updated>2023-06-11T20:38:33.000Z</updated>
        <summary type="html"><![CDATA[I just ran across a particularly impressive garden path sentence in Bernd Heinrich's book RAVENS IN WINTER (p. 268); it took me several tries to get this sentence to parse grammatically: "Even the wolverine is said to do nothing to drive ravens off that land beside it and steal its food." (Of course parsing is [‚Ä¶]]]></summary>
        <author>
            <name>Sally Thomason</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thai to English translation gets injected with Tamil]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59101</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59101&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=thai-to-english-translation-gets-injected-with-tamil"/>
        <updated>2023-06-11T19:39:16.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Charles Belov] I pasted the following Thai, which I got from a YouTube channel, into Google translate. The results were mostly in English, but Google Translate injected some apparent Tamil as well and then just gives up and leaves some of the Thai untranslated. "‡∏ï‡∏•‡∏≠‡∏î‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏¥‡∏á‡∏°‡∏±‡∏ô‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÄ‡πÄ‡∏•‡πâ‡∏ß‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡πÑ‡∏õ‡∏´‡∏°‡∏î ‡πÄ‡πÄ‡∏•‡πâ‡∏ß‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏°‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏°‡∏±‡∏ô‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢ [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quirky speech-to-text, weird diarization]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59108</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59108&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=quirky-asr-weird-diarization"/>
        <updated>2023-06-11T14:28:01.000Z</updated>
        <summary type="html"><![CDATA[From Daniel Deutsch: We had a long drive yesterday, so we listened to a ‚Äúrobot‚Äù reading the entire indictment. It certainly isn‚Äôt flawless, but I was surprised by how good it is, especially when it gets ‚Äúexcited‚Äù while enacting dialogue. Indeed, the text-to-speech quality is quite good ‚Äî though unfortunately they don't tell us which [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apostrophes in Hanyu Pinyin]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59105</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59105&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=apostrophes-in-hanyu-pinyin"/>
        <updated>2023-06-11T12:39:45.000Z</updated>
        <summary type="html"><![CDATA[The most famous instance of the use of an apostrophe in Hanyu Pinyin romanization is in the place name "Xi'an", the capital of Shaanxi (the doubled "a" is another story) Province. Xƒ´'ƒÅn Ë•øÂÆâ ‚Äî two characters signifying "Western Peace" If you don't use an apostrophe to separate the syllables, you end up with the monosyllable [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT has a sense of humor (sort of)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59096</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59096&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-has-a-sense-of-humor-sort-of"/>
        <updated>2023-06-11T01:50:18.000Z</updated>
        <summary type="html"><![CDATA[Benj Edwards has a mirthful article in Ars Technica (6/9/23) Researchers discover that ChatGPT prefers repeating 25 jokes over and over When tested, "Over 90% of 1,008 generated jokes were the same 25 jokes." [includes an AI generated image of "a laughing robot"] On Wednesday, two German researchers, Sophie Jentzsch and Kristian Kersting, released a [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[technical steps]]></title>
        <id>http://xianblog.wordpress.com/?p=53198</id>
        <link href="https://xianblog.wordpress.com/2023/06/11/technical-steps/"/>
        <updated>2023-06-10T22:23:32.000Z</updated>
        <summary type="html"><![CDATA[After procrastinating as much as feasible, I switched at last to (K)Ubuntu 22.04, Jammy Jellyfish, after security updates stopped for the 20.04 version. While this proceeded mostly without hiccups, the upgrade stalled when upgrading Firefox, which I had foolishly left open. When I turned it off and completed the upgrade, this erased all of my [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Steak the First"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59077</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59077&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=steak-the-first"/>
        <updated>2023-06-10T21:32:29.000Z</updated>
        <summary type="html"><![CDATA[Enlightening article by Peter Backhaus in The Japan Times (6/9/23): "Za grammar notes: How to properly handle the 'the' in Japanese" Japanese seems to be able to assimilate any English word, including the ubiquitous definite article "the", which is unlike anything in Japanese itself. If there‚Äôs something like a Murphy‚Äôs Law for syntax, the name [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["The beautiful mind paper boxes"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59074</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59074&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-beautiful-mind-paper-boxes"/>
        <updated>2023-06-10T12:51:43.000Z</updated>
        <summary type="html"><![CDATA[The most recent Trump indictment reproduces this exchange of text messages (p. 11) : Trump Employee 2: We can definitely make it work if we move his papers into the lake room? Trump Employee 1: There is still a little room in the shower where his other stuff is. Is it only his papers he [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InternLM]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59071</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59071&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=internlm"/>
        <updated>2023-06-10T11:46:43.000Z</updated>
        <summary type="html"><![CDATA[As I am about to deliver a keynote address to an international conference on Chinese language pedagogy, I receive news of this new LLM that knocks my socks off: InternLM is a multilingual large language model jointly developed by Shanghai AI Lab and SenseTime (with equal contribution), in collaboration with the Chinese University of Hong [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT does Emily Dickinson writing a recipe for Pad Thai (and haiku too)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59030</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59030&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-does-emily-dickinson-writing-a-recipe-for-pad-thai-and-haiku-too"/>
        <updated>2023-06-10T03:02:36.000Z</updated>
        <summary type="html"><![CDATA[From Scott D. Seligman via Facebook: ¬† ChatGPT is really creeping me out. I asked it for a recipe for Pad Thai in the form of an Emily Dickinson poem. I'm no poetry maven, but the damned thing seems to have the ability to turn a phrase, at least some of the time. Below is [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[statistical modeling with R [book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53183</id>
        <link href="https://xianblog.wordpress.com/2023/06/10/statistical-modeling-with-r-book-review/"/>
        <updated>2023-06-09T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[Statistical Modeling with R (A dual frequentist and Bayesian approach for life scientists) is a recent book written by Pablo Inchausti, from Uruguay. In a highly personal and congenial style (witness the preface), with references to (fiction) books that enticed me to buy them. The book was sent to me by the JASA book editor [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Imagen Editor and EditBench: Advancing and evaluating text-guided image inpainting]]></title>
        <id>http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html</id>
        <link href="http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html"/>
        <updated>2023-06-09T19:09:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Su Wang and Ceslee Montgormery, Research Engineers, Google Research





In the last few years, text-to-image generation research has seen an explosion of breakthroughs (notably, Imagen, Parti, DALL-E 2, etc.) that have naturally permeated into related topics. In particular, text-guided image editing (TGIE) is a practical task that involves editing generated and photographed visuals rather than completely redoing them. Quick, automated, and controllable editing is a convenient solution when recreating visuals would be time-consuming or infeasible (e.g., tweaking objects in vacation photos or perfecting fine-grained details on a cute pup generated from scratch). Further, TGIE represents a substantial opportunity to improve training of foundational models themselves. Multimodal mod‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-owning peeve of the week: Compersion]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59056</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59056&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=self-owning-peeve-of-the-week-compersion"/>
        <updated>2023-06-09T13:27:09.000Z</updated>
        <summary type="html"><![CDATA[Email from Florent Moncomble¬†[links added]: A few months ago, the distinguished member of the Acad√©mie fran√ßaise Alain Finkielkraut was featured in a video where he deplored the loss of ‚Äúa word which used to exist in the [French] language and disappeared from it‚Äù, ie. ‚Äúcompersion‚Äù. Apparently, little does he know that ‚Äúcompersion‚Äù was actually coined [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural
  Language Understanding]]></title>
        <id>http://arxiv.org/abs/2306.04933</id>
        <link href="http://arxiv.org/abs/2306.04933"/>
        <updated>2023-06-09T08:18:07.758Z</updated>
        <summary type="html"><![CDATA[Junda Wu, Tong Yu, Rui Wang, Zhao Song, Ruiyi Zhang, Handong Zhao,
  Chaochao Lu, Shuai Li, Ricardo Henao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Large Language Model Annotations for Valid Downstream Statistical
  Inference in Social Science: Design-Based Semi-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2306.04746</id>
        <link href="http://arxiv.org/abs/2306.04746"/>
        <updated>2023-06-09T08:18:07.753Z</updated>
        <summary type="html"><![CDATA[Naoki Egami, Musashi Jacobs-Harukawa, Brandon M. Stewart, Hanying Wei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multitask Learning and Bandits via Robust Statistics]]></title>
        <id>http://arxiv.org/abs/2112.14233</id>
        <link href="http://arxiv.org/abs/2112.14233"/>
        <updated>2023-06-09T08:18:07.741Z</updated>
        <summary type="html"><![CDATA[Kan Xu, Hamsa Bastani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Polynomial Time and Private Learning of Unbounded Gaussian Mixture
  Models]]></title>
        <id>http://arxiv.org/abs/2303.04288</id>
        <link href="http://arxiv.org/abs/2303.04288"/>
        <updated>2023-06-09T08:18:07.736Z</updated>
        <summary type="html"><![CDATA[Jamil Arbas, Hassan Ashtiani, Christopher Liaw]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Meets Sparse Regularization: A Signal Processing
  Perspective]]></title>
        <id>http://arxiv.org/abs/2301.09554</id>
        <link href="http://arxiv.org/abs/2301.09554"/>
        <updated>2023-06-09T08:18:06.909Z</updated>
        <summary type="html"><![CDATA[Rahul Parhi, Robert D. Nowak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The asymptotics of r(4,t)]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"/>
        <updated>2023-06-09T06:17:30.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved‚Ä¶]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The asymptotics of r(4,t)]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"/>
        <updated>2023-06-09T06:17:30.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved‚Ä¶]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[de-MCM‚Äôd]]></title>
        <id>http://xianblog.wordpress.com/?p=53208</id>
        <link href="https://xianblog.wordpress.com/2023/06/09/de-mcmd/"/>
        <updated>2023-06-08T22:23:02.000Z</updated>
        <summary type="html"><![CDATA[This morning I received a message from the MCM 23 conference organisers that my registration [submitted two months ago] was declined for lack of room! I wonder why the organisers did not opt for broadcasting in a second amphitheater, as was done for ISBA in Edinburgh. Unfortunately, we have attained the maximal capacity of the [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Determining Ramsey numbers using finite geometry]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"/>
        <updated>2023-06-08T19:31:29.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Anurag's Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a‚Ä¶]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Determining Ramsey numbers using finite geometry]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"/>
        <updated>2023-06-08T19:31:29.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Anurag's Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a‚Ä¶]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transliterations aplenty]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59014</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59014&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=transliterations-aplenty"/>
        <updated>2023-06-08T16:50:05.000Z</updated>
        <summary type="html"><![CDATA[From Simon Cartoon: Here's something I just saw at a local bakery in Berkeley, CA. Simon explains: We have English, Spanish, and then French in the last position, no issues there. 3rd position is Mandarin Chinese via pinyin: Who is this for? What is the population of people uncomfortable reading in English, but comfortable reading [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We may finally crack Maths. But should we?]]></title>
        <id>6481b5876965110001df8c10</id>
        <link href="https://www.inference.vc/we-may-finally-crack-maths-but-should-we/"/>
        <updated>2023-06-08T15:58:13.000Z</updated>
        <summary type="html"><![CDATA[Automating mathematical theorem proving has been a long standing goal of artificial intelligence and indeed computer science. It's one of the areas I became very interested in recently. This is because I feel we may have the ingredients needed to make very, very significant progress:

a structured search]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is the logical form of that?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59026</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59026&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=what-is-the-logical-form-of-that"/>
        <updated>2023-06-08T13:36:25.000Z</updated>
        <summary type="html"><![CDATA[This post wanders down a series of rabbit holes, from a couple of dead economists, to a dead philosopher, to a dead Supreme Court justice. It all started with Eric Rahim's obituary in the Guardian, which links to the British Academy's obituary for Piero Sraffa, which includes this passage: He also formed a close friendship [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greco-Sinitic œàŒ¨ŒºŒºŒøœÇ /  ÉÀ†a  m…ëkÃö ("desert")]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59024</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59024&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=greco-sinitic-%25cf%2588%25ce%25ac%25ce%25bc%25ce%25bc%25ce%25bf%25cf%2582-%25ca%2583%25cb%25a0a-mak%25cc%259a-desert"/>
        <updated>2023-06-08T12:39:35.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Chau Wu] The psammo- component of the winning word in this year's Scripps National Spelling Bee, psammophile, is of interest to me because it is a good example of European-Sinitic lexical correspondence. The Ancient Greek word ps√°mmos (œàŒ¨ŒºŒºŒøœÇ) means ‚Äòsand‚Äô.¬† When used together with a definite article (·º° œàŒ¨ŒºŒºŒøœÇ), [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Invariance in Policy Optimisation and Partial Identifiability in Reward
  Learning]]></title>
        <id>http://arxiv.org/abs/2203.07475</id>
        <link href="http://arxiv.org/abs/2203.07475"/>
        <updated>2023-06-08T07:13:38.535Z</updated>
        <summary type="html"><![CDATA[Joar Skalse, Matthew Farrugia-Roberts, Stuart Russell, Alessandro
  Abate, Adam Gleave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformers as Statisticians: Provable In-Context Learning with
  In-Context Algorithm Selection]]></title>
        <id>http://arxiv.org/abs/2306.04637</id>
        <link href="http://arxiv.org/abs/2306.04637"/>
        <updated>2023-06-08T07:13:38.518Z</updated>
        <summary type="html"><![CDATA[Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multimodal Learning Without Labeled Multimodal Data: Guarantees and
  Applications]]></title>
        <id>http://arxiv.org/abs/2306.04539</id>
        <link href="http://arxiv.org/abs/2306.04539"/>
        <updated>2023-06-08T07:13:38.512Z</updated>
        <summary type="html"><![CDATA[Paul Pu Liang, Chun Kai Ling, Yun Cheng, Alex Obolenskiy, Yudong Liu,
  Rohan Pandey, Alex Wilf, Louis-Philippe Morency, Ruslan Salakhutdinov]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics,
  Directional Convergence, and Equilibria]]></title>
        <id>http://arxiv.org/abs/2212.02457</id>
        <link href="http://arxiv.org/abs/2212.02457"/>
        <updated>2023-06-08T07:13:38.507Z</updated>
        <summary type="html"><![CDATA[Tengyuan Liang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PILLAR: How to make semi-private learning more effective]]></title>
        <id>http://arxiv.org/abs/2306.03962</id>
        <link href="http://arxiv.org/abs/2306.03962"/>
        <updated>2023-06-08T07:13:38.500Z</updated>
        <summary type="html"><![CDATA[Francesco Pinto, Yaxi Hu, Fanny Yang, Amartya Sanyal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2023‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºö‚ÄúAIÁîüÊàê‰∏éÂûÇÁõ¥Â§ßËØ≠Ë®ÄÊ®°Âûã‚ÄùËÆ∫ÂùõÈáçÁ£ÖÊù•Ë¢≠ÔºÅ]]></title>
        <id>https://www.52nlp.cn/?p=13474</id>
        <link href="https://www.52nlp.cn/2023%e4%b8%96%e7%95%8c%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%a4%a7%e4%bc%9aai%e7%94%9f%e6%88%90%e4%b8%8e%e5%9e%82%e7%9b%b4%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e8%ae%ba"/>
        <updated>2023-06-08T02:23:31.000Z</updated>
        <summary type="html"><![CDATA[ÂΩìÂâçAIÁîüÊàê‰∏éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊåáÊï∞Á∫ßÂèëÂ±ïÔºå‰∏∫Áõ∏ÂÖ≥‰∫ß‰∏öÈìæÂ∏¶Êù•Êñ∞ÁöÑÂèëÂ±ïÂºïÊìéÔºå‰πü‰∏∫AIËêΩÂú∞Â∫îÁî®Â∏¶Êù•Êñ∞ÁöÑÊÉ≥Ë±°Á©∫Èó¥„ÄÇ2023 [‚Ä¶]]]></summary>
        <author>
            <name>ËææËßÇÊï∞ÊçÆ</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Naive Bayes is all you need ?]]></title>
        <id>https://kexue.fm/archives/9648</id>
        <link href="https://kexue.fm/archives/9648"/>
        <updated>2023-06-08T01:25:00.000Z</updated>
        <summary type="html"><![CDATA[ÂæàÊä±Ê≠âÔºåËµ∑‰∫ÜËøô‰πà‰∏™ÂÖ∑ÊúâÊ†áÈ¢òÂÖöÁâπÂæÅÁöÑÈ¢òÁõÆ„ÄÇÂú®ÂÜôÂÆå„ÄäNBCEÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÊâ©Â±ïLLMÁöÑContextÂ§ÑÁêÜÈïøÂ∫¶„Äã‰πãÂêéÔºåÁ¨îËÄÖÂ∞±ËßâÂæóÊú¥Á¥†Ë¥ùÂè∂ÊñØÔºàNaive BayesÔºâË∑üAttentionÊú∫Âà∂ÊúâÂæàÂ§öÁõ∏Âêå...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[uniform spacings]]></title>
        <id>http://xianblog.wordpress.com/?p=53161</id>
        <link href="https://xianblog.wordpress.com/2023/06/08/uniform-spacings/"/>
        <updated>2023-06-07T22:23:28.000Z</updated>
        <summary type="html"><![CDATA[A riddle on uniform spacings!, namely when considering eight iid Uniform (0,1) variates as visiting times and three further iid Uniform (0,1) variates as server availability times, with unit service time, the question being the probability a server is available for a ninth visiting time, T‚Åπ. Which can be decomposed into four cases: at least [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating speech synthesis in many languages with SQuId]]></title>
        <id>http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html</id>
        <link href="http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html"/>
        <updated>2023-06-07T18:07:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Thibault Sellam, Research Scientist, Google





Previously, we presented the 1,000 languages initiative and the Universal Speech Model with the goal of making speech and language technologies available to billions of users around the world. Part of this commitment involves developing high-quality speech synthesis technologies, which build upon projects such as VDTTS and AudioLM, for users that speak many different languages.






listening tests, during which dozens of annotators listen to the utterances one after the other to determine how natural they sound. While humans are still unbeaten at detecting whether a piece of text sounds natural, this process can be impractical ‚Äî especially in the early stages of research projects, when engineers need rapid feedback to test and re‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aligning Language Models with Preferences through f-divergence
  Minimization]]></title>
        <id>http://arxiv.org/abs/2302.08215</id>
        <link href="http://arxiv.org/abs/2302.08215"/>
        <updated>2023-06-07T07:13:39.489Z</updated>
        <summary type="html"><![CDATA[Dongyoung Go, Tomasz Korbak, Germ\'an Kruszewski, Jos Rozen, Nahyeon
  Ryu, Marc Dymetman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Denise: Deep Robust Principal Component Analysis for Positive
  Semidefinite Matrices]]></title>
        <id>http://arxiv.org/abs/2004.13612</id>
        <link href="http://arxiv.org/abs/2004.13612"/>
        <updated>2023-06-07T07:13:39.484Z</updated>
        <summary type="html"><![CDATA[Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen,
  Josef Teichmann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Orthogonal Statistical Learning]]></title>
        <id>http://arxiv.org/abs/1901.09036</id>
        <link href="http://arxiv.org/abs/1901.09036"/>
        <updated>2023-06-07T07:13:39.478Z</updated>
        <summary type="html"><![CDATA[Dylan J. Foster, Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep neural networks architectures from the perspective of manifold
  learning]]></title>
        <id>http://arxiv.org/abs/2306.03406</id>
        <link href="http://arxiv.org/abs/2306.03406"/>
        <updated>2023-06-07T07:13:39.454Z</updated>
        <summary type="html"><![CDATA[German Magai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Join the PyTorch Foundation: Membership Now Open]]></title>
        <id>https://pytorch.org/blog/join-pytorch/</id>
        <link href="https://pytorch.org/blog/join-pytorch/"/>
        <updated>2023-06-07T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[In September 2022, we welcomed PyTorch to the Linux Foundation from Meta, which formed the PyTorch Foundation with founding members AMD, Amazon Web Services (AWS), Google, Meta, Microsoft, and NVIDIA.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unknown language #15]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59005</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59005&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=unknown-language-15"/>
        <updated>2023-06-07T02:46:22.000Z</updated>
        <summary type="html"><![CDATA[Yuan (? dynasty (1271-1368) jade seal in the Bristol Museum: Know what language this is, or even what it says? Yes? Please get back to me. No? Please retweet it until somebody does. (But be aware, it's stumped some quite clever people who've already been asked, so it isn't obvious) Also, advance apologies if it [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding CPUs can help speed up Numba and NumPy code]]></title>
        <id>https://pythonspeed.com/articles/speeding-up-numba/</id>
        <link href="https://pythonspeed.com/articles/speeding-up-numba/"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[When you need to speed up your NumPy processing‚Äîor just reduce your memory usage‚Äîthe Numba just-in-time compiler is a great tool.
It lets you write Python code that gets compiled at runtime to machine code, allowing you to get the kind of speed improvements you‚Äôd get from languages like C, Fortran, or Rust.
Or at least, that‚Äôs the theory.
In practice, your initial Numba code may be no faster than the NumPy equivalent.
But you can do better, once you have a better understanding of how CPUs work.
And this knowledge will help you more broadly with any compiled language.
In this article we‚Äôll:
Consider a simple image-processing problem.
Try, and initially fail, to speed it up with Numba.
We‚Äôll review just a little bit how modern CPUs are so fast, and the limits of compilers.
Based on our new understanding, we‚Äôll then show how we can tweak our code to run 25√ó faster than our original version.
Read more...]]></summary>
        <author>
            <name>Python‚áíSpeed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimising computer systems with more generalised AI tools]]></title>
        <id>https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools</id>
        <link href="https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Based on reinforcement learning, our AI models AlphaZero and MuZero have achieved superhuman performance winning games. Now, they‚Äôre expanding their capabilities to help optimise resources in data centres and advance video compression ‚Äì and most recently, our specialised version of AlphaZero, called AlphaDev, discovered new algorithms that are already accelerating the software applications at the foundations of our digital society.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AlphaDev discovers faster sorting algorithms]]></title>
        <id>https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms</id>
        <link href="https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In our paper published today in Nature, we introduce AlphaDev, an artificial intelligence (AI) system that uses reinforcement learning to discover enhanced computer science algorithms ‚Äì surpassing those honed by scientists and engineers over decades.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[stack overflow on strike]]></title>
        <id>http://xianblog.wordpress.com/?p=53202</id>
        <link href="https://xianblog.wordpress.com/2023/06/07/stack-overflow-on-strike/"/>
        <updated>2023-06-06T22:23:40.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinitic exclamations in English speech]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58949</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58949&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinitic-exclamations-in-english-speech"/>
        <updated>2023-06-06T17:45:45.000Z</updated>
        <summary type="html"><![CDATA[Listen to Malaysian comedian Nigel Ng (aka "Uncle Roger"), who has had his Weibo and bilibili social media accounts banned due to "violation of relevant regulations": The ban comes one day after Ng uploaded this clip to various social media platforms. pic.twitter.com/8Wwf2aTrfZ ‚Äî Aaron Busch (@tripperhead) May 19, 2023 Under the subject line "Uncle Roger [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual captions: Using large language models to augment video conferences with dynamic visuals]]></title>
        <id>http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html</id>
        <link href="http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html"/>
        <updated>2023-06-06T16:58:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ruofei Du, Research Scientist, and Alex Olwal, Senior Staff Research Scientist, Google Augmented Reality




Recent advances in video conferencing have significantly improved remote video communication through features like live captioning and noise cancellation. However, there are various situations where dynamic visual augmentation would be useful to better convey complex and nuanced information. For example, when discussing what to order at a Japanese restaurant, your friends could share visuals that would help you feel more confident about ordering the ‚ÄúSukiyaki‚Äù. Or when talking about your recent family trip to San Francisco, you may want to show a photo from your personal album.




In ‚ÄúVisual Captions: Augmenting Verbal Communication With On-the-fly Visuals‚Äù, presented at ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LLMs as coders?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58977</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58977&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=llms-as-coders"/>
        <updated>2023-06-06T12:19:14.000Z</updated>
        <summary type="html"><![CDATA[I've recently seen many articles like this one, "You probably don't need to learn to code anymore" (Medium 6/5/2023), arguing that Large Language Models will make human programming (and human programmers) unnecessary. These arguments puzzle me, because my experience with LLMs suggests that they can't be relied on even for very simple programming tasks. After [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Bayesian Active Learning for Accelerating Stochastic Simulation]]></title>
        <id>http://arxiv.org/abs/2106.02770</id>
        <link href="http://arxiv.org/abs/2106.02770"/>
        <updated>2023-06-06T07:14:01.826Z</updated>
        <summary type="html"><![CDATA[Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, Yi-An
  Ma, Rose Yu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alignment with human representations supports robust few-shot learning]]></title>
        <id>http://arxiv.org/abs/2301.11990</id>
        <link href="http://arxiv.org/abs/2301.11990"/>
        <updated>2023-06-06T07:14:01.819Z</updated>
        <summary type="html"><![CDATA[Ilia Sucholutsky, Thomas L. Griffiths]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Emergence of Clean-Priority Learning in Early Stopped Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.02533</id>
        <link href="http://arxiv.org/abs/2306.02533"/>
        <updated>2023-06-06T07:14:01.813Z</updated>
        <summary type="html"><![CDATA[Chaoyue Liu, Amirhesam Abedsoltan, Mikhail Belkin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LibAUC: A Deep Learning Library for X-Risk Optimization]]></title>
        <id>http://arxiv.org/abs/2306.03065</id>
        <link href="http://arxiv.org/abs/2306.03065"/>
        <updated>2023-06-06T07:14:01.438Z</updated>
        <summary type="html"><![CDATA[Zhuoning Yuan, Dixian Zhu, Zi-Hao Qiu, Gang Li, Xuanhui Wang, Tianbao
  Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Linear Causal Representations from Interventions under General
  Nonlinear Mixing]]></title>
        <id>http://arxiv.org/abs/2306.02235</id>
        <link href="http://arxiv.org/abs/2306.02235"/>
        <updated>2023-06-06T07:14:01.143Z</updated>
        <summary type="html"><![CDATA[Simon Buchholz, Goutham Rajendran, Elan Rosenfeld, Bryon Aragam,
  Bernhard Sch\"olkopf, Pradeep Ravikumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinitic semiliteracy]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58917</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58917&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinitic-semiliteracy"/>
        <updated>2023-06-06T04:43:50.000Z</updated>
        <summary type="html"><![CDATA[From¬†a story on CNN on "begpackers" in Asia: The photo is captioned, "Professor Stephen Pratt posed as a begpacker to do fieldwork in Hong Kong." The sign says: q«êng bƒÅngzh√π w«í z√†i qu√°n sh√¨ji√® l«öx√≠ng Ë´ãÂπ´Âä©ÊàëÂú®ÂÖ®‰∏ñÁïåÊóÖË°å "Please help me travel around the world" Despite the fractured grammar (the z√†i Âú®* is especially egregious), all the [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of biang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58888</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58888&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-biang"/>
        <updated>2023-06-06T04:34:16.000Z</updated>
        <summary type="html"><![CDATA[Shop sign in Budapest: Don't be cowed by the quixotic orthography.¬† The noodles are delicious, and you can get them right here in Philadelphia, and many other cities around the world. Selected readings "Biangbiang: authentic Xi'an grub in the heart of Philadelphia's University City" (6/9/22) "A Chinese character that is harder to write than 'biang'" [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[remembering May 35th]]></title>
        <id>http://xianblog.wordpress.com/?p=53194</id>
        <link href="https://xianblog.wordpress.com/2023/06/06/remembering-may-35th/"/>
        <updated>2023-06-05T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The (local) unit of intelligence is FLOPs]]></title>
        <id>http://windowsontheory.org/?p=8630</id>
        <link href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/"/>
        <updated>2023-06-05T18:22:58.000Z</updated>
        <summary type="html"><![CDATA[[Crossposting again on¬†Lesswrong and¬†Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it‚Äôs hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure ‚Ä¶ Continue reading The (local) unit of intelligence is¬†FLOPs]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The (local) unit of intelligence is FLOPs]]></title>
        <id>http://windowsontheory.org/?p=8630</id>
        <link href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/"/>
        <updated>2023-06-05T18:22:58.000Z</updated>
        <summary type="html"><![CDATA[[Crossposting again on¬†Lesswrong and¬†Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it‚Äôs hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure ‚Ä¶ Continue reading The (local) unit of intelligence is¬†FLOPs]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bilingual road signs]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58960</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58960&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bilingual-road-signs"/>
        <updated>2023-06-05T12:15:41.000Z</updated>
        <summary type="html"><![CDATA[‚Ä¶in New Zealand. Phil Pennington, "Analysis: National opposed bilingual road signs, so what does the evidence say?", RNZ 62/2023: Analysis ‚Äì Bilingual road signs send a signal ‚Äì that the country values te reo MƒÅori. But going bilingual was confusing and National would not support it, National's Simeon Brown told voters in blue-ribbon Tauranga recently. [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding the Dynamics of Gaussian-Stein Variational
  Gradient Descent]]></title>
        <id>http://arxiv.org/abs/2305.14076</id>
        <link href="http://arxiv.org/abs/2305.14076"/>
        <updated>2023-06-05T07:13:47.914Z</updated>
        <summary type="html"><![CDATA[Tianle Liu, Promit Ghosal, Krishnakumar Balasubramanian, Natesh S.
  Pillai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linked Deep Gaussian Process Emulation for Model Networks]]></title>
        <id>http://arxiv.org/abs/2306.01212</id>
        <link href="http://arxiv.org/abs/2306.01212"/>
        <updated>2023-06-05T07:13:47.903Z</updated>
        <summary type="html"><![CDATA[Deyu Ming, Daniel Williamson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding Generalization of Macro-AUC in Multi-label
  Learning]]></title>
        <id>http://arxiv.org/abs/2305.05248</id>
        <link href="http://arxiv.org/abs/2305.05248"/>
        <updated>2023-06-05T07:13:47.890Z</updated>
        <summary type="html"><![CDATA[Guoqiang Wu, Chongxuan Li, Yilong Yin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Developing A Visual-Interactive Interface for Electronic Health Record
  Labeling: An Explainable Machine Learning Approach]]></title>
        <id>http://arxiv.org/abs/2209.12778</id>
        <link href="http://arxiv.org/abs/2209.12778"/>
        <updated>2023-06-05T07:13:47.871Z</updated>
        <summary type="html"><![CDATA[Donlapark Ponnoprat, Parichart Pattarapanitchai, Phimphaka Taninpong,
  Suthep Suantai, Natthanaphop Isaradech, Thiraphat Tanphiriyakun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hyperparameter Learning under Data Poisoning: Analysis of the Influence
  of Regularization via Multiobjective Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2306.01613</id>
        <link href="http://arxiv.org/abs/2306.01613"/>
        <updated>2023-06-05T07:13:47.865Z</updated>
        <summary type="html"><![CDATA[Javier Carnerero-Cano, Luis Mu\~noz-Gonz\'alez, Phillippa Spencer,
  Emil C. Lupu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[fusing simulation with data science [18-19 July 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=53177</id>
        <link href="https://xianblog.wordpress.com/2023/06/05/fusing-simulation-with-data-science-18-19-july-2023/"/>
        <updated>2023-06-04T22:23:59.000Z</updated>
        <summary type="html"><![CDATA[In collaboration with the Met Office, my friend and Warwick colleague Rito Dutta is co-organising a two-day workshop in Warwick in July on the use of statistics and machine learning tools in weather prediction. Attendance is free, but registration needed for tea breaks.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greater China Co-Prosperity Sushi and Ramen Kitchen]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58924</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58924&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=greater-china-co-prosperity-sushi-and-ramen-kitchen"/>
        <updated>2023-06-04T17:30:33.000Z</updated>
        <summary type="html"><![CDATA[Shouldn‚Äôt that be Zhonghua Pan-Asian Kitchen Ramen Wok Premium Sushi? pic.twitter.com/tTUaWidjL3 ‚Äî James Millward Á±≥ËèØÂÅ• (@JimMillward) June 4, 2023 The small characters at the top of the sign say: H√†nz√∫ Y√†zh≈çu ch√∫f√°ng Ê±âÊóè‰∫öÊ¥≤Âé®Êàø "Han ethnicity Asian kitchen" The wording in large H√†ny«î Pƒ´nyƒ´n ("Sinitic spelling") is HANZU, the roman letter transcription of the first two [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revelation:  Scythians and Shang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58846</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58846&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=revelation-scythians-and-shang"/>
        <updated>2023-06-04T15:48:03.000Z</updated>
        <summary type="html"><![CDATA[I was stunned when I read the following article in the South China Morning Post, both because it was published in Hong Kong, which is now completely under the censorial control of the People's Republic of China (PRC) / Chinese Communist Party (CCP), and because it raises some disturbing political issues and troubling linguistic problems. [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of inventive pinyin: rua]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58832</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58832&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-inventive-pinyin-rua"/>
        <updated>2023-06-04T15:26:32.000Z</updated>
        <summary type="html"><![CDATA[This exercise video shows a woman repeating the syllable "rua" to describe a move that she makes: Problem is that there's no Sinoglyph (h√†nz√¨¬†Êº¢Â≠ó /¬†Ê±âÂ≠ó) for writing that in Modern Standard Mandarin (MSM), although some might claim that it can be written with¬†this character, ru√≥ Êåº¬†("rub; knead; massage"). According to¬†this table, "rua" is not a [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The rise (and fall?) of shiesties]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58927</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58927&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-rise-and-fall-of-shiesties"/>
        <updated>2023-06-04T10:52:10.000Z</updated>
        <summary type="html"><![CDATA[Last month I learned a new word, shiesty ‚Äî which rhymes with feisty, as if it were written "sheisty" ‚Äî because shiesties have been banned on the local transit system ("SEPTA"): Your browser does not support the audio element. Keith, I'm sure if you walked around Philadelphia, live in Philadelphia, work in Philadelphia, you've seen [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Role Of Social Media On Selected Businesses In Nigeria In The Era Of
  Covid-19 Pandemic]]></title>
        <id>http://arxiv.org/abs/2305.19299</id>
        <link href="http://arxiv.org/abs/2305.19299"/>
        <updated>2023-06-04T07:13:27.273Z</updated>
        <summary type="html"><![CDATA[Cajetan Ihemebiri, Elochukwu Ukwandu, Lizzy Ofusori, Comfort
  Olebara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near-Atomic Scale Perspective on the Oxidation of Ti$_3$C$_2$T$_x$
  MXenes: Insights from Atom Probe Tomography]]></title>
        <id>http://arxiv.org/abs/2305.19822</id>
        <link href="http://arxiv.org/abs/2305.19822"/>
        <updated>2023-06-04T07:13:27.240Z</updated>
        <summary type="html"><![CDATA[Mathias Kr\"amer, Bar Favelukis, Ayman A. El-Zoka, Maxim Sokol, Brian
  A. Rosen, Noam Eliaz, Se-Ho Kim, Baptiste Gault]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual Exploratory Data Analysis of the Covid-19 Pandemic in Nigeria:
  Two Years after the Outbreak]]></title>
        <id>http://arxiv.org/abs/2305.19297</id>
        <link href="http://arxiv.org/abs/2305.19297"/>
        <updated>2023-06-04T07:13:27.228Z</updated>
        <summary type="html"><![CDATA[Ugochukwu Orji, Modesta Ezema, Elochukwu Ukwandu, Chikaodili
  Ugwuishiwu, Ezugwu Obianuju, Malachi Egbugha]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[To what extent can control policies influence the epidemic spreading? --
  A data-driven analysis based on the first wave of COVID-19]]></title>
        <id>http://arxiv.org/abs/2305.19544</id>
        <link href="http://arxiv.org/abs/2305.19544"/>
        <updated>2023-06-04T07:13:27.223Z</updated>
        <summary type="html"><![CDATA[Dongyan Zhang, Wanqi Wen, Wuyue Yang, Liangrong Peng, Changjingn
  Zhuge, Liu Hong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Beacon [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53153</id>
        <link href="https://xianblog.wordpress.com/2023/06/04/the-beacon-jatp/"/>
        <updated>2023-06-03T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dog bites man:  Indian wins spelling bee]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58921</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58921&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dog-bites-man-indian-wins-spelling-bee"/>
        <updated>2023-06-03T20:25:55.000Z</updated>
        <summary type="html"><![CDATA[New old news: "Dev Shah wins 2023 Scripps National Spelling Bee by correctly spelling 'psammophile'"Chris BumbacaUSA TODAY (6/1/23) Another year, same story: The 2023 Scripps National Spelling Bee ended the old-fashioned way. Two competitors left on the stage. No spell-off required. Dev Shah, an eighth-grader from Largo, Florida, spelled "psammophile" correctly to win the 95th [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pronouncing "DeSantis"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58876</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58876&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pronouncing-desantis"/>
        <updated>2023-06-03T14:21:21.000Z</updated>
        <summary type="html"><![CDATA[The question of how to pronounce Ron DeSantis' last name ‚Äî and the observation that the candidate, his wife, and his campaign have made different choices at different times ‚Äî is among the more trivial bits of political flotsam recently washing up on the shores of social and political media. In fact the issue has [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinological formatting]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58874</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58874&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinological-formatting"/>
        <updated>2023-06-03T12:02:31.000Z</updated>
        <summary type="html"><![CDATA[I recently received this book: S≈´n Sƒ´mi«éo, Sabine Wilms.¬† Healing Virtue-Power: Medical Ethics and the Doctor's Dao.¬† Whidbey Island WA:¬† Happy Goat Productions, 2022. ISBN:¬† 978-1-7321571-9-4 website As soon as I started to leaf through the volume, I was struck by its unusual format and usages:¬† every Chinese character is accompanied by Hanyu Pinyin phonetic [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tsunami and megathrust earthquake disaster prevention warnings:
  Real-time monitoring of the genesis processes with Physical Wavelets]]></title>
        <id>http://arxiv.org/abs/2305.13249</id>
        <link href="http://arxiv.org/abs/2305.13249"/>
        <updated>2023-06-03T07:12:38.216Z</updated>
        <summary type="html"><![CDATA[Fumihide Takeda]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diagonalization of Polynomial-Time Deterministic Turing Machines Via
  Nondeterministic Turing Machine]]></title>
        <id>http://arxiv.org/abs/2110.06211</id>
        <link href="http://arxiv.org/abs/2110.06211"/>
        <updated>2023-06-03T07:12:38.210Z</updated>
        <summary type="html"><![CDATA[Tianrong Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[van Dantzig seminar]]></title>
        <id>http://xianblog.wordpress.com/?p=53169</id>
        <link href="https://xianblog.wordpress.com/2023/06/03/van-dantzig-seminar/"/>
        <updated>2023-06-02T22:23:48.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Just < Not the same as it was]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58869</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58869&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=just-not-the-same-as-it-was"/>
        <updated>2023-06-02T22:12:54.000Z</updated>
        <summary type="html"><![CDATA[I listened to this Harry Styles song dozens of times on the radio, and every time I heard him sing "You know it's just the same as it was" over and over: It was only after watching the video and reading the subtitles that I realized he was saying "You know it's not the same [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Austronesian languages of Taiwan]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58855</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58855&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=austronesian-languages-of-taiwan"/>
        <updated>2023-06-02T19:27:48.000Z</updated>
        <summary type="html"><![CDATA[Handbook of Formosan Languages (Online): The Indigenous Languages of Taiwan Editors: Paul Jen-kuei Li, Academia SinicaElizabeth Zeitoun, Academia SinicaRik De Busser, National Taiwan Cheng-Chi University Leiden:¬† Brill, 2023 Outright Purchase: ‚Ç¨ 2249 / US dollars 2495Subscription: ‚Ç¨ 350 / US dollars 390 A print version is forthcoming (September 2023 ; 3 vols, ~ 2200 pp.) [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AVFormer: Injecting vision into frozen speech models for zero-shot AV-ASR]]></title>
        <id>http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html</id>
        <link href="http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html"/>
        <updated>2023-06-02T17:02:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Arsha Nagrani and Paul Hongsuck Seo, Research Scientists, Google Research






Automatic speech recognition (ASR) is a well-established technology that is widely adopted for various applications such as conference calls, streamed video transcription and voice commands. While the challenges for this technology are centered around noisy audio inputs, the visual stream in multimodal videos (e.g., TV, online edited videos) can provide strong cues for improving the robustness of ASR systems ‚Äî this is called audiovisual ASR (AV-ASR).
 

Although lip motion can provide strong signals for speech recognition and is the most common area of focus for AV-ASR, the mouth is often not directly visible in videos in the wild (e.g., due to egocentric viewpoints, face coverings, and low resolution‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Historical speech styles]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58857</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58857&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=historical-speech-styles"/>
        <updated>2023-06-02T11:48:13.000Z</updated>
        <summary type="html"><![CDATA[A recent Dinosaur Comics strip¬†features T-Rex imitating (a certain kind of) speech style from the 1940s: Mouseover title: "to t-rex's mind, and mine as well, all of the past takes place around the 1930s. well sure! and why not?" The next strip: Mouseover title: "you want a gender-neutral way to address a room, well here [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Expressive Power of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.00145</id>
        <link href="http://arxiv.org/abs/2306.00145"/>
        <updated>2023-06-02T07:13:25.962Z</updated>
        <summary type="html"><![CDATA[Jan Holstermann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combining Explicit and Implicit Regularization for Efficient Learning in
  Deep Networks]]></title>
        <id>http://arxiv.org/abs/2306.00342</id>
        <link href="http://arxiv.org/abs/2306.00342"/>
        <updated>2023-06-02T07:13:25.957Z</updated>
        <summary type="html"><![CDATA[Dan Zhao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provably Learning Diverse Features in Multi-View Data with Midpoint
  Mixup]]></title>
        <id>http://arxiv.org/abs/2210.13512</id>
        <link href="http://arxiv.org/abs/2210.13512"/>
        <updated>2023-06-02T07:13:25.952Z</updated>
        <summary type="html"><![CDATA[Muthu Chidambaram, Xiang Wang, Chenwei Wu, Rong Ge]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Revealing the Mystery behind Chain of Thought: a Theoretical
  Perspective]]></title>
        <id>http://arxiv.org/abs/2305.15408</id>
        <link href="http://arxiv.org/abs/2305.15408"/>
        <updated>2023-06-02T07:13:25.946Z</updated>
        <summary type="html"><![CDATA[Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Sensible Adversarial Learning of Deep Neural Networks for Image
  Classification]]></title>
        <id>http://arxiv.org/abs/2205.10457</id>
        <link href="http://arxiv.org/abs/2205.10457"/>
        <updated>2023-06-02T07:13:25.730Z</updated>
        <summary type="html"><![CDATA[Jungeum Kim, Xiao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Galton and Watson voluntarily skipping some generations]]></title>
        <id>http://xianblog.wordpress.com/?p=53139</id>
        <link href="https://xianblog.wordpress.com/2023/06/02/galton-and-watson-voluntarily-skipping-some-generations/"/>
        <updated>2023-06-01T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[A riddle on a form of a Galton-Watson process, starting from a single unit, where no one dies but rather, at each of 100 generations, Dog either opts for a Uniform number œÖ of additional units or increments a counter Œ≥ by this number œÖ, its goal being to optimise Œ≥. The solution proposed by [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Know your relatives in Chinese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58807</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58807&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=know-your-relatives-in-chinese"/>
        <updated>2023-06-01T18:38:21.000Z</updated>
        <summary type="html"><![CDATA[Randy Alexander reports that during a guitar lesson, he asked his student: MƒÅmƒÅ de d√¨di de n«ö√©r sh√¨ bi«éom√®i maÔºü Â¶àÂ¶àÁöÑÂºüÂºüÁöÑÂ•≥ÂÑøÊòØË°®Â¶πÂêóÔºü "Is your mother's younger brother's daughter your younger maternal female cousin?" The student replied: w«íyƒõ b√∫t√†i qƒ´ngch«î dƒõngy√≠xi√† Êàë‰πü‰∏çÂ§™Ê∏ÖÊ•öÁ≠â‰∏Ä‰∏ã "I don't quite know either, wait a minute." Here's a screen shot of the student's [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Retrieval-augmented visual-language pre-training]]></title>
        <id>http://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html</id>
        <link href="http://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html"/>
        <updated>2023-06-01T17:25:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ziniu Hu, Student Researcher, and Alireza Fathi, Research Scientist, Google Research, Perception Team





Large-scale models, such as T5, GPT-3, PaLM, Flamingo and PaLI, have demonstrated the ability to store substantial amounts of knowledge when scaled to tens of billions of parameters and trained on large text and image datasets. These models achieve state-of-the-art results on downstream tasks, such as image captioning, visual question answering and open vocabulary recognition. Despite such achievements, these models require a massive volume of data for training and end up with a tremendous number of parameters (billions in many cases), resulting in significant computational requirements. Moreover, the data used to train these models can become outdated, requiring re-training‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multilingual TV series]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58835</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58835&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=multilingual-tv-series"/>
        <updated>2023-06-01T15:13:03.000Z</updated>
        <summary type="html"><![CDATA[Coby Lubliner called my attention to the Belgian Netflix series "Rough Diamonds." It takes place in Antwerp, so the default language is Dutch (Flemish), but the characters move into Yiddish, English¬†and French with the greatest of ease. The subtitles don't indicate the language spoken in any one scene, except that when [Yiddish] appears what is [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Wordectomy"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58838</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58838&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=wordectomy"/>
        <updated>2023-06-01T13:37:16.000Z</updated>
        <summary type="html"><![CDATA[The medical news site MedPage Today¬†has recently added a daily game page, "Wordectomy", in which a medically-relevant Wikipedia article is presented with all letters blanked out except for punctuation and (some) function words, e.g. The instructions: Welcome to Wordectomy ‚Äî a word game from MedPage Today where you try to determine what medical condition is [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low-rank extended Kalman filtering for online learning of neural
  networks from streaming data]]></title>
        <id>http://arxiv.org/abs/2305.19535</id>
        <link href="http://arxiv.org/abs/2305.19535"/>
        <updated>2023-06-01T07:14:05.921Z</updated>
        <summary type="html"><![CDATA[Peter Chang, Gerardo Dur\`an-Mart\'in, Alexander Y Shestopaloff, Matt
  Jones, Kevin Murphy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Active causal structure learning with advice]]></title>
        <id>http://arxiv.org/abs/2305.19588</id>
        <link href="http://arxiv.org/abs/2305.19588"/>
        <updated>2023-06-01T07:14:05.907Z</updated>
        <summary type="html"><![CDATA[Davin Choo, Themis Gouleakis, Arnab Bhattacharyya]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Estimates for Pairwise Learning with Deep ReLU Networks]]></title>
        <id>http://arxiv.org/abs/2305.19640</id>
        <link href="http://arxiv.org/abs/2305.19640"/>
        <updated>2023-06-01T07:14:05.886Z</updated>
        <summary type="html"><![CDATA[Junyu Zhou, Shuo Huang, Han Feng, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What and How does In-Context Learning Learn? Bayesian Model Averaging,
  Parameterization, and Generalization]]></title>
        <id>http://arxiv.org/abs/2305.19420</id>
        <link href="http://arxiv.org/abs/2305.19420"/>
        <updated>2023-06-01T07:14:05.878Z</updated>
        <summary type="html"><![CDATA[Yufeng Zhang, Fengzhuo Zhang, Zhuoran Yang, Zhaoran Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine learning with tree tensor networks, CP rank constraints, and
  tensor dropout]]></title>
        <id>http://arxiv.org/abs/2305.19440</id>
        <link href="http://arxiv.org/abs/2305.19440"/>
        <updated>2023-06-01T07:14:05.872Z</updated>
        <summary type="html"><![CDATA[Hao Chen, Thomas Barthel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[the alpinist [film review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53126</id>
        <link href="https://xianblog.wordpress.com/2023/06/01/the-alpinist-film-review/"/>
        <updated>2023-05-31T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[Watched (with supplementary oxygen) The Alpinist in the plane to Jeddah. It is a documentary (made by the same filmmakers who filmed the Dawn Wall) about the amazing Canadian alpinist Marc-Andr√© Leclerc, who died in 2018 on the Mendenhall Glacier, Alaska, in an avalanche, after achieving extraordinary complex solo climbs as eg on Mount Robbson, [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Questions and Concerns About Google‚Äôs Quantum Supremacy Claim]]></title>
        <id>http://gilkalai.wordpress.com/?p=24142</id>
        <link href="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/"/>
        <updated>2023-05-31T17:36:59.000Z</updated>
        <summary type="html"><![CDATA[Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.¬† Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Questions and Concerns About Google‚Äôs Quantum Supremacy Claim]]></title>
        <id>http://gilkalai.wordpress.com/?p=24142</id>
        <link href="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/"/>
        <updated>2023-05-31T17:36:59.000Z</updated>
        <summary type="html"><![CDATA[Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.¬† Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large sequence models for software development activities]]></title>
        <id>http://ai.googleblog.com/2023/05/large-sequence-models-for-software.html</id>
        <link href="http://ai.googleblog.com/2023/05/large-sequence-models-for-software.html"/>
        <updated>2023-05-31T17:13:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Petros Maniatis and Daniel Tarlow, Research Scientists, Google




Software isn‚Äôt created in one dramatic step. It improves bit by bit, one little step at a time ‚Äî editing, running unit tests, fixing build errors, addressing code reviews, editing some more, appeasing linters, and fixing more errors ‚Äî until finally it becomes good enough to merge into a code repository. Software engineering isn‚Äôt an isolated process, but a dialogue among human developers, code reviewers, bug reporters, software architects and tools, such as compilers, unit tests, linters and static analyzers. 




Today we describe DIDACT (‚Äã‚ÄãDynamic Integrated Developer ACTivity), which is a methodology for training large machine learning (ML) models for software development. The novelty of DIDACT is that it uses ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ÂÖ≥‰∫éNBCEÊñπÊ≥ïÁöÑ‰∏Ä‰∫õË°•ÂÖÖËØ¥ÊòéÂíåÂàÜÊûê]]></title>
        <id>https://kexue.fm/archives/9632</id>
        <link href="https://kexue.fm/archives/9632"/>
        <updated>2023-05-31T07:38:00.000Z</updated>
        <summary type="html"><![CDATA[‰∏äÂë®Âú®„ÄäNBCEÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÊâ©Â±ïLLMÁöÑContextÂ§ÑÁêÜÈïøÂ∫¶„Äã‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊú¥Á¥†Ë¥ùÂè∂ÊñØÊù•Êâ©Â±ïLLMÁöÑContextÈïøÂ∫¶ÁöÑÊñπÊ°àNBCEÔºàNaive Bayes-based Conte...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the minimax optimality and superiority of deep neural network
  learning over sparse parameter spaces]]></title>
        <id>http://arxiv.org/abs/1905.09195</id>
        <link href="http://arxiv.org/abs/1905.09195"/>
        <updated>2023-05-31T07:13:39.538Z</updated>
        <summary type="html"><![CDATA[Satoshi Hayakawa, Taiji Suzuki]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prediction Error-based Classification for Class-Incremental Learning]]></title>
        <id>http://arxiv.org/abs/2305.18806</id>
        <link href="http://arxiv.org/abs/2305.18806"/>
        <updated>2023-05-31T07:13:39.532Z</updated>
        <summary type="html"><![CDATA[Micha{\l} Zaj\k{a}c, Tinne Tuytelaars, Gido M. van de Ven]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal Approximation Property of Hamiltonian Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.12147</id>
        <link href="http://arxiv.org/abs/2303.12147"/>
        <updated>2023-05-31T07:13:39.527Z</updated>
        <summary type="html"><![CDATA[Muhammad Zakwan, Massimiliano d'Angelo, Giancarlo Ferrari-Trecate]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Prediction with Large Language Models for Multi-Choice
  Question Answering]]></title>
        <id>http://arxiv.org/abs/2305.18404</id>
        <link href="http://arxiv.org/abs/2305.18404"/>
        <updated>2023-05-31T07:13:39.521Z</updated>
        <summary type="html"><![CDATA[Bhawesh Kumar, Charlie Lu, Gauri Gupta, Anil Palepu, David Bellamy,
  Ramesh Raskar, Andrew Beam]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generating with Confidence: Uncertainty Quantification for Black-box
  Large Language Models]]></title>
        <id>http://arxiv.org/abs/2305.19187</id>
        <link href="http://arxiv.org/abs/2305.19187"/>
        <updated>2023-05-31T07:13:39.504Z</updated>
        <summary type="html"><![CDATA[Zhen Lin, Shubhendu Trivedi, Jimeng Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[optimal importance sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53120</id>
        <link href="https://xianblog.wordpress.com/2023/05/31/optimal-importance-sampling/"/>
        <updated>2023-05-30T22:23:27.000Z</updated>
        <summary type="html"><![CDATA[In Stein Œ†-Importance Sampling, Congye Wang et al. (mostly from Newcastle, UK) build an MCMC scheme with invariant distribution Œ† targeting a distribution P, showing that the optimal solution (in terms of a discrepancy) differs from P when the chain is Stein-sampled, e..g. via kernel discrepancies. In terms of densities, the solution is the correction [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mortal Komputation: On Hinton's argument for superhuman AI.]]></title>
        <id>64724f2336605b0001f5e7fa</id>
        <link href="https://www.inference.vc/mortal-computation-hintons/"/>
        <updated>2023-05-30T13:48:52.000Z</updated>
        <summary type="html"><![CDATA[Last week in Cambridge was Hinton bonanza. He visited the university town where he was once an undergraduate in experimental psychology, and gave a series of back-to-back talks, Q&A sessions, interviews, dinners, etc. He was stopped on the street by random passers-by who recognised him from the lecture,]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The contextual lasso: Sparse linear models via deep neural networks]]></title>
        <id>http://arxiv.org/abs/2302.00878</id>
        <link href="http://arxiv.org/abs/2302.00878"/>
        <updated>2023-05-30T07:13:25.154Z</updated>
        <summary type="html"><![CDATA[Ryan Thompson, Amir Dezfouli, Robert Kohn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization Error Bounds for Deep Neural Networks Trained by SGD]]></title>
        <id>http://arxiv.org/abs/2206.03299</id>
        <link href="http://arxiv.org/abs/2206.03299"/>
        <updated>2023-05-30T07:13:24.424Z</updated>
        <summary type="html"><![CDATA[Mingze Wang, Chao Ma]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Two-Layer Neural Networks, One (Giant) Step at a Time]]></title>
        <id>http://arxiv.org/abs/2305.18270</id>
        <link href="http://arxiv.org/abs/2305.18270"/>
        <updated>2023-05-30T07:13:23.287Z</updated>
        <summary type="html"><![CDATA[Yatin Dandi, Florent Krzakala, Bruno Loureiro, Luca Pesce, Ludovic
  Stephan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Implicit Bias of Gradient Descent for Mean Squared Error Regression with
  Two-Layer Wide Neural Networks]]></title>
        <id>http://arxiv.org/abs/2006.07356</id>
        <link href="http://arxiv.org/abs/2006.07356"/>
        <updated>2023-05-30T07:13:23.096Z</updated>
        <summary type="html"><![CDATA[Hui Jin, Guido Mont\'ufar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reward Collapse in Aligning Large Language Models]]></title>
        <id>http://arxiv.org/abs/2305.17608</id>
        <link href="http://arxiv.org/abs/2305.17608"/>
        <updated>2023-05-30T07:13:22.873Z</updated>
        <summary type="html"><![CDATA[Ziang Song, Tianle Cai, Jason D. Lee, Weijie J. Su]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.]]></title>
        <id>http://gilkalai.wordpress.com/?p=23932</id>
        <link href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/"/>
        <updated>2023-05-30T05:38:33.000Z</updated>
        <summary type="html"><![CDATA[(Click to enlarge.) Plan for this post: Prologue: ‚ÄúCan we sleep soundly at night?‚Äù Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.]]></title>
        <id>http://gilkalai.wordpress.com/?p=23932</id>
        <link href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/"/>
        <updated>2023-05-30T05:38:33.000Z</updated>
        <summary type="html"><![CDATA[(Click to enlarge.) Plan for this post: Prologue: ‚ÄúCan we sleep soundly at night?‚Äù Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[reciprocal importance sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53111</id>
        <link href="https://xianblog.wordpress.com/2023/05/30/reciprocal-importance-sampling/"/>
        <updated>2023-05-29T22:23:39.000Z</updated>
        <summary type="html"><![CDATA[In a recent arXival, Metodiev et al. (including my friend Adrian Raftery, who is spending the academic year in Paris) proposed a new version of reciprocal importance sampling, expanding the proposal we made with Darren Wraith (2009) of using a Uniform over an HPD region. It is called THAMES, hence the picture (of London, not [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Manifold Regularization for Memory-Efficient Training of Deep Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.17119</id>
        <link href="http://arxiv.org/abs/2305.17119"/>
        <updated>2023-05-29T07:14:17.605Z</updated>
        <summary type="html"><![CDATA[Shadi Sartipi, Edgar A. Bernal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vecchia Gaussian Process Ensembles on Internal Representations of Deep
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.17063</id>
        <link href="http://arxiv.org/abs/2305.17063"/>
        <updated>2023-05-29T07:14:17.597Z</updated>
        <summary type="html"><![CDATA[Felix Jimenez, Matthias Katzfuss]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Language Models as Tool Makers]]></title>
        <id>http://arxiv.org/abs/2305.17126</id>
        <link href="http://arxiv.org/abs/2305.17126"/>
        <updated>2023-05-29T07:14:16.379Z</updated>
        <summary type="html"><![CDATA[Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Influence of Learning Rule on Representation Dynamics in Wide Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2210.02157</id>
        <link href="http://arxiv.org/abs/2210.02157"/>
        <updated>2023-05-29T07:14:16.372Z</updated>
        <summary type="html"><![CDATA[Blake Bordelon, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Architecture Search for Parameter-Efficient Fine-tuning of Large
  Pre-trained Language Models]]></title>
        <id>http://arxiv.org/abs/2305.16597</id>
        <link href="http://arxiv.org/abs/2305.16597"/>
        <updated>2023-05-29T07:14:16.356Z</updated>
        <summary type="html"><![CDATA[Neal Lawton, Anoop Kumar, Govind Thattai, Aram Galstyan, Greg Ver
  Steeg]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Model-Based Clustering, Classification, and Density Estimation Using mclust in R [not a book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53104</id>
        <link href="https://xianblog.wordpress.com/2023/05/29/model-based-clustering-classification-and-density-estimation-using-mclust-in-r-not-a-book-review/"/>
        <updated>2023-05-28T22:23:16.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Vatnik" ‚Äî ethnic or political slur?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58816</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58816&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=vatnik-ethnic-or-political-slur"/>
        <updated>2023-05-28T13:31:58.000Z</updated>
        <summary type="html"><![CDATA[Adam Taylor, Anastacia Galouchka & Heidi Levine, "Ukrainians fighting outside Bakhmut see Russian mercenaries withdrawing", Washington Post 5/282023: ‚ÄúThe Wagner guys have left and the [regular Russians] have come in,‚Äù said a 26-year-old commander who asked to be identified by his call sign, Chichen. He used an anti-Russian ethnic slur to refer to the troops [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chickee cakes]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58803</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58803&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chickee-cakes"/>
        <updated>2023-05-28T03:27:05.000Z</updated>
        <summary type="html"><![CDATA[Taken at a restaurant in¬†Hangzhou: The big Chinese characters say: Cant. gai1zai2 beng2¬† MSM¬† jƒ´z«éi b«êng È∏°‰ªîÈ•º "phoenix cookie" This is a type of chewy biscuit made with lard, originating in¬†Guangzhou¬†/ Canton.¬† (source)¬† Its original name was¬†Cant. siu2fung6¬†beng2¬†¬†MSM¬†xi«éof√®ng b«êng¬†Â∞èÈ≥≥È§Ö¬†("little phoenix cake"). Here are some¬†recipes for "phoenix cookies".¬† I noticed plenty of fat and sesame, peanuts, [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Natural nested sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53091</id>
        <link href="https://xianblog.wordpress.com/2023/05/28/natural-nested-sampling/"/>
        <updated>2023-05-27T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[‚ÄúThe nested sampling algorithm solves otherwise challenging, high-dimensional integrals by evolving a collection of live points through parameter space. The algorithm was immediately adopted in cosmology because it partially overcomes three of the major difficulties in Markov chain Monte Carlo, the algorithm traditionally used for Bayesian computation. Nested sampling simultaneously returns results for model comparison [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
</feed>