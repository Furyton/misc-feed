<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-11-10T13:18:15.897Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA["…oscillated in his words"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61197</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61197&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=oscillated-in-his-words"/>
        <updated>2023-11-10T13:14:17.000Z</updated>
        <summary type="html"><![CDATA[Ken Bensinger, "Ramaswamy Seemed to Call Zelensky a Nazi. His Campaign Says That’s Not What He Meant." NYT 11/8/2023: A spokeswoman for Mr. Ramaswamy, Tricia McLaughlin, said that he had not called Mr. Zelensky a Nazi. Instead, Ms. McLaughlin said, he was referring to an event in September in which Mr. Zelensky visited Canada’s Parliament […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adrian’s defence]]></title>
        <id>http://xianblog.wordpress.com/?p=54431</id>
        <link href="https://xianblog.wordpress.com/2023/11/10/adrians-defence/"/>
        <updated>2023-11-10T08:08:36.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Class-Incremental Learning with Generative Classifiers]]></title>
        <id>http://arxiv.org/abs/2104.10093</id>
        <link href="http://arxiv.org/abs/2104.10093"/>
        <updated>2023-11-10T03:15:28.293Z</updated>
        <summary type="html"><![CDATA[Gido M. van de Ven, Zhe Li, Andreas S. Tolias]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical process monitoring of artificial neural networks]]></title>
        <id>http://arxiv.org/abs/2209.07436</id>
        <link href="http://arxiv.org/abs/2209.07436"/>
        <updated>2023-11-10T03:15:28.275Z</updated>
        <summary type="html"><![CDATA[Anna Malinovskaya, Pavlo Mozharovskyi, Philipp Otto]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uncertainty Wrapper in the medical domain: Establishing transparent
  uncertainty quantification for opaque machine learning models in practice]]></title>
        <id>http://arxiv.org/abs/2311.05245</id>
        <link href="http://arxiv.org/abs/2311.05245"/>
        <updated>2023-11-10T03:15:28.270Z</updated>
        <summary type="html"><![CDATA[Lisa J\"ockel, Michael Kl\"as, Georg Popp, Nadja Hilger, Stephan
  Fricke]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Compression of Overparameterized Deep Models through
  Low-Dimensional Learning Dynamics]]></title>
        <id>http://arxiv.org/abs/2311.05061</id>
        <link href="http://arxiv.org/abs/2311.05061"/>
        <updated>2023-11-10T03:15:28.209Z</updated>
        <summary type="html"><![CDATA[Soo Min Kwon, Zekai Zhang, Dogyoon Song, Laura Balzano, Qing Qu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-learning of semi-supervised learning from tasks with heterogeneous
  attribute spaces]]></title>
        <id>http://arxiv.org/abs/2311.05088</id>
        <link href="http://arxiv.org/abs/2311.05088"/>
        <updated>2023-11-10T03:15:28.173Z</updated>
        <summary type="html"><![CDATA[Tomoharu Iwata, Atsutoshi Kumagai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Novemberly MCMC]]></title>
        <id>http://xianblog.wordpress.com/?p=54414</id>
        <link href="https://xianblog.wordpress.com/2023/11/10/novemberly-mcmc/"/>
        <updated>2023-11-09T23:23:05.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hype over AI and Classical Chinese / Literary Sinitic]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61190</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61190&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hype-over-ai-and-classical-chinese-literary-sinitic"/>
        <updated>2023-11-09T23:09:40.000Z</updated>
        <summary type="html"><![CDATA[From the get-go, I'm dubious about any claims that current AI can fully and accurately translate Classical Chinese / Literary Sinitic (CC/LS) into Modern Standard Mandarin (MSM), much less English or other language, on a practical, functional basis.  Since the following article is from one of China's official propaganda "news" outlets (China Daily [CD]), the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: Context in AI Research (CAIR)]]></title>
        <id>http://blog.research.google/2023/11/responsible-ai-at-google-research.html</id>
        <link href="http://blog.research.google/2023/11/responsible-ai-at-google-research.html"/>
        <updated>2023-11-09T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Katherine Heller, Research Scientist, Google Research, on behalf of the CAIR Team




Artificial intelligence (AI) and related machine learning (ML) technologies are increasingly influential in the world around us, making it imperative that we consider the potential impacts on society and individuals in all aspects of the technology that we create. To these ends, the Context in AI Research (CAIR) team develops novel AI methods in the context of the entire AI pipeline: from data to end-user feedback. The pipeline for building an AI system typically starts with data collection, followed by designing a model to run on that data, deployment of the model in the real world, and lastly, compiling and incorporation of human feedback. Originating in the health space, and now expanded to a…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Overcoming leakage on error-corrected quantum processors]]></title>
        <id>http://blog.research.google/2023/11/overcoming-leakage-on-error-corrected.html</id>
        <link href="http://blog.research.google/2023/11/overcoming-leakage-on-error-corrected.html"/>
        <updated>2023-11-09T19:20:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Kevin Miao and Matt McEwen, Research Scientists, Quantum AI Team




The qubits that make up Google quantum devices are delicate and noisy, so it’s necessary to incorporate error correction procedures that identify and account for qubit errors on the way to building a useful quantum computer. Two of the most prevalent error mechanisms are bit-flip errors (where the energy state of the qubit changes) and phase-flip errors (where the phase of the encoded quantum information changes). Quantum error correction (QEC) promises to address and mitigate these two prominent errors. However, there is an assortment of other error mechanisms that challenges the effectiveness of QEC.



While we want qubits to behave as ideal two-level systems with no loss mechanisms, this is not the case in r…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VQ一下Key，Transformer的复杂度就变成线性了]]></title>
        <id>https://kexue.fm/archives/9844</id>
        <link href="https://kexue.fm/archives/9844"/>
        <updated>2023-11-09T13:10:00.000Z</updated>
        <summary type="html"><![CDATA[Efficient Transformer，泛指一切致力于降低Transformer的二次复杂度的工作，开始特指针对Attention的改进，后来更一般的思路，如傅立叶变换、线性RNN等，也被归...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spectral Evolution and Invariance in Linear-width Neural Networks]]></title>
        <id>http://arxiv.org/abs/2211.06506</id>
        <link href="http://arxiv.org/abs/2211.06506"/>
        <updated>2023-11-09T03:15:35.908Z</updated>
        <summary type="html"><![CDATA[Zhichao Wang, Andrew Engel, Anand Sarwate, Ioana Dumitriu, Tony Chiang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Linear Gaussian Polytree Models with Interventions]]></title>
        <id>http://arxiv.org/abs/2311.04636</id>
        <link href="http://arxiv.org/abs/2311.04636"/>
        <updated>2023-11-09T03:15:35.846Z</updated>
        <summary type="html"><![CDATA[D. Tramontano, L. Waldmann, M. Drton, E. Duarte]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Source Domain Adaptation through Dataset Dictionary Learning in
  Wasserstein Space]]></title>
        <id>http://arxiv.org/abs/2307.14953</id>
        <link href="http://arxiv.org/abs/2307.14953"/>
        <updated>2023-11-09T03:15:35.829Z</updated>
        <summary type="html"><![CDATA[Eduardo Fernandes Montesuma, Fred Ngol\`e Mboula, Antoine Souloumiac]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Certified Data Removal from Machine Learning Models]]></title>
        <id>http://arxiv.org/abs/1911.03030</id>
        <link href="http://arxiv.org/abs/1911.03030"/>
        <updated>2023-11-09T03:15:35.795Z</updated>
        <summary type="html"><![CDATA[Chuan Guo, Tom Goldstein, Awni Hannun, Laurens van der Maaten]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Few-Annotation Learning in Computer Vision: Application to Image
  Classification and Object Detection tasks]]></title>
        <id>http://arxiv.org/abs/2311.04888</id>
        <link href="http://arxiv.org/abs/2311.04888"/>
        <updated>2023-11-09T03:15:35.755Z</updated>
        <summary type="html"><![CDATA[Quentin Bouniot]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[20/11 1pm-2pm: Statistics Seminar - Graphical Models of Intelligent Cause]]></title>
        <id>8a17841b8adb7895018adfd6ce0c4ad1</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b8adb7895018adfd6ce0b4ad0"/>
        <updated>2023-11-09T00:23:09.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 20 Nov '23

	
Where: Stats Common Room

	
Abstract: Graphical models are now widely used to express underlying mechanisms which drive and explain how such mechanisms work. In particular Bayesian Networks and more recently Chain Event Graphs have been used to produce probabilistic predictive models of processes. Such graphs are chosen to be consistent with elicited natural explanations of how and why things happen the way they do in a given domain. Causal algebras are then specified which use this elicited information to determine predictions of what might happen were the system be subjected to various controls.

But how could we extend this work so that it might apply to produce predictive models of what might happen when the decision maker believes that his controls might be resisted? In this talk I will argue that standard causal models then need to be generalised to embed a decision maker's beliefs of the intent capability and the information a resistant adversary might have about the intervention after it has been made. After reviewing recent advances in general forms of Bayesian dynamic causal models I will describe how - using a special form of Adversarial Risk Analysis - we are developing new intelligent algorithms to produce such predictions. The talk will be illustrated throughout by examples of various adversarial threats currently being analysed within the UK.]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[19/02 1pm-2pm: Statistics Seminar - TBD]]></title>
        <id>8a17841b8ba96181018bb1757be51f94</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a1785d88adb7b44018adfff90924f46"/>
        <updated>2023-11-09T00:22:28.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 19 Feb '24

	
Where: Stats Common Room

	
Abstract: TBD]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[22/01 1pm-2pm: Stats Seminar - TBD]]></title>
        <id>8a1785d88ba96480018bb1744fff6836</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a1785d78adb7884018adffec409135c"/>
        <updated>2023-11-09T00:21:11.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 22 Jan '24

	
Where: Stats Common Room

	
Abstract: TBD]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[08/01 1pm-2pm: Statistics Seminar - TBD]]></title>
        <id>8a17841a8ba96485018bb17348124fdf</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841a8ba96485018bb171545c4fdc"/>
        <updated>2023-11-09T00:20:04.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 08 Jan '24

	
Where: Statistics common room

	
Abstract: TBD]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[04/12 1pm-2pm: Statistics Seminar - TBD]]></title>
        <id>8a17841a8adb7b43018adfd7774d1148</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841a8adb7b43018adfd7774d1147"/>
        <updated>2023-11-09T00:16:38.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 04 Dec '23

	
Where: Stats Common Room

	
Abstract:TBD]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[francescoverdose [Jorge does Massilia]]]></title>
        <id>http://xianblog.wordpress.com/?p=54107</id>
        <link href="https://xianblog.wordpress.com/2023/11/09/francescoverdose-jorge-does-massilia/"/>
        <updated>2023-11-08T23:23:51.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[English language flap in Korea]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61183</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61183&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=english-language-flap-in-korea"/>
        <updated>2023-11-08T22:50:32.000Z</updated>
        <summary type="html"><![CDATA[From the Korea Times (11/6/23): Ihn says he was 'very disappointed' after ex-leader Lee spoke to him in English (Yonhap) Before you read the article, it's unlikely that you could begin to surmise what the commotion is all about. The American Korean chief of the ruling People Power Party (PPP)'s innovation committee said Monday he […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT Meets Elchanan Mossel’s Dice Problem]]></title>
        <id>http://gilkalai.wordpress.com/?p=24878</id>
        <link href="https://gilkalai.wordpress.com/2023/11/08/chatgpt-meets-elchanan-mossels-dice-problem/"/>
        <updated>2023-11-08T10:42:44.000Z</updated>
        <summary type="html"><![CDATA[One of the greatest hits of this blog was Elchanan Mossel’s dice problem, asked here and answered here. Here is how chatGPT (the free version) handles the problem. You throw a die until you get 6. What is the expected … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT Meets Elchanan Mossel’s Dice Problem]]></title>
        <id>http://gilkalai.wordpress.com/?p=24878</id>
        <link href="https://gilkalai.wordpress.com/2023/11/08/chatgpt-meets-elchanan-mossels-dice-problem/"/>
        <updated>2023-11-08T10:42:44.000Z</updated>
        <summary type="html"><![CDATA[One of the greatest hits of this blog was Elchanan Mossel’s dice problem, asked here and answered here. Here is how chatGPT (the free version) handles the problem. You throw a die until you get 6. What is the expected … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Comparing Causal Frameworks: Potential Outcomes, Structural Models,
  Graphs, and Abstractions]]></title>
        <id>http://arxiv.org/abs/2306.14351</id>
        <link href="http://arxiv.org/abs/2306.14351"/>
        <updated>2023-11-08T04:17:34.898Z</updated>
        <summary type="html"><![CDATA[Duligur Ibeling, Thomas Icard]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean
  Field Neural Networks]]></title>
        <id>http://arxiv.org/abs/2304.03408</id>
        <link href="http://arxiv.org/abs/2304.03408"/>
        <updated>2023-11-08T04:17:34.894Z</updated>
        <summary type="html"><![CDATA[Blake Bordelon, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Linear Representation Hypothesis and the Geometry of Large Language
  Models]]></title>
        <id>http://arxiv.org/abs/2311.03658</id>
        <link href="http://arxiv.org/abs/2311.03658"/>
        <updated>2023-11-08T04:17:34.801Z</updated>
        <summary type="html"><![CDATA[Kiho Park, Yo Joong Choe, Victor Veitch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimizing Solution-Samplers for Combinatorial Problems: The Landscape
  of Policy-Gradient Methods]]></title>
        <id>http://arxiv.org/abs/2310.05309</id>
        <link href="http://arxiv.org/abs/2310.05309"/>
        <updated>2023-11-08T04:17:34.792Z</updated>
        <summary type="html"><![CDATA[Constantine Caramanis, Dimitris Fotakis, Alkis Kalavasis, Vasilis
  Kontonis, Christos Tzamos]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Outliers with Opposing Signals Have an Outsized Effect on Neural Network
  Optimization]]></title>
        <id>http://arxiv.org/abs/2311.04163</id>
        <link href="http://arxiv.org/abs/2311.04163"/>
        <updated>2023-11-08T04:17:34.785Z</updated>
        <summary type="html"><![CDATA[Elan Rosenfeld, Andrej Risteski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year [minus two fingers]]]></title>
        <id>http://xianblog.wordpress.com/?p=54220</id>
        <link href="https://xianblog.wordpress.com/2023/11/08/a-journal-of-the-conquest-war-famine-and-death-year-minus-two-fingers/"/>
        <updated>2023-11-07T23:23:02.000Z</updated>
        <summary type="html"><![CDATA[Read The House of Shattered Wings, by Aliette de Bodard, which involves a character with two fingers eventually missing. A British Science Fiction Association Award and for once a rather impressive horror story taking place in an alternative 1900’s Paris partly destroyed by a war between Houses run by fallen angels. With connections with French […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alternating updates for efficient transformers]]></title>
        <id>http://blog.research.google/2023/11/alternating-updates-for-efficient.html</id>
        <link href="http://blog.research.google/2023/11/alternating-updates-for-efficient.html"/>
        <updated>2023-11-07T20:34:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Xin Wang, Software Engineer, and Nishanth Dikkala, Research Scientist, Google Research




Contemporary deep learning models have been remarkably successful in many domains, ranging from natural language to computer vision. Transformer neural networks (transformers) are a popular deep learning architecture that today comprise the foundation for most tasks in natural language processing and also are starting to extend to applications in other domains, such as computer vision, robotics, and autonomous driving. Moreover, they form the backbone of all the current state-of-the-art language models.
 

Increasing scale in Transformer networks has led to improved performance and the emergence of behavior not present in smaller networks. However, this increase in scale often comes with pr…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mao and Chinese Character Reform: Revisionist History on CCTV]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61179</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61179&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mao-and-chinese-character-reform-revisionist-history-on-cctv"/>
        <updated>2023-11-07T20:05:34.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by David Moser] Just when you thought CCP propaganda couldn’t get more absurd, China Central Television (CCTV) has aired a short TV series in which Confucius and Karl Marx actually meet up for comradely chat about ideology. In typical fantasy time-travel style, Marx simply appears miraculously at the Yuelu Academy […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch compile to speed up inference on Llama 2]]></title>
        <id>https://pytorch.org/blog/pytorch-compile-to-speed-up-inference/</id>
        <link href="https://pytorch.org/blog/pytorch-compile-to-speed-up-inference/"/>
        <updated>2023-11-07T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[In this blog, we discuss how to improve the inference latencies of the Llama 2 family of models using PyTorch native optimizations such as native fast kernels, compile transformations from torch compile, and tensor parallel for distributed inference. Our approach results in 29ms/token latency for single user requests on the 70B LLaMa model (as measured on 8 A100 GPUs). We are excited to share our findings with the community and make our code available here.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low Tensor Rank Learning of Neural Dynamics]]></title>
        <id>http://arxiv.org/abs/2308.11567</id>
        <link href="http://arxiv.org/abs/2308.11567"/>
        <updated>2023-11-07T03:15:36.190Z</updated>
        <summary type="html"><![CDATA[Arthur Pellegrino, N Alex Cayco-Gajic, Angus Chadwick]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Estimation and inference for transfer learning with high-dimensional
  quantile regression]]></title>
        <id>http://arxiv.org/abs/2211.14578</id>
        <link href="http://arxiv.org/abs/2211.14578"/>
        <updated>2023-11-07T03:15:36.180Z</updated>
        <summary type="html"><![CDATA[Jiayu Huang, Mingqiu Wang, Yuanshan Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Revealing the Mystery behind Chain of Thought: A Theoretical
  Perspective]]></title>
        <id>http://arxiv.org/abs/2305.15408</id>
        <link href="http://arxiv.org/abs/2305.15408"/>
        <updated>2023-11-07T03:15:36.157Z</updated>
        <summary type="html"><![CDATA[Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Theory for Emergence of Complex Skills in Language Models]]></title>
        <id>http://arxiv.org/abs/2307.15936</id>
        <link href="http://arxiv.org/abs/2307.15936"/>
        <updated>2023-11-07T03:15:36.137Z</updated>
        <summary type="html"><![CDATA[Sanjeev Arora, Anirudh Goyal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Architecture Matters: Uncovering Implicit Mechanisms in Graph
  Contrastive Learning]]></title>
        <id>http://arxiv.org/abs/2311.02687</id>
        <link href="http://arxiv.org/abs/2311.02687"/>
        <updated>2023-11-07T03:15:36.106Z</updated>
        <summary type="html"><![CDATA[Xiaojun Guo, Yifei Wang, Zeming Wei, Yisen Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian inference from the ground up [no book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=54094</id>
        <link href="https://xianblog.wordpress.com/2023/11/07/54094/"/>
        <updated>2023-11-06T23:23:18.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rectilinear rectitude]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61173</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61173&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rectilinear-rectitude"/>
        <updated>2023-11-06T12:48:34.000Z</updated>
        <summary type="html"><![CDATA[An alternative name for M Hànzì / J Kanji / K Hanja / C hon3 zi6 漢字 ("sinoglyph; Chinese character") is fāngkuàizì 方塊字 ("square shaped character").  I learned that the very first year of my Chinese language studies more than half a century ago.  From kindergarten and elementary school on up, Chinese children learn to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We need an immediate humanitarian ceasefire in Gaza]]></title>
        <id>http://xianblog.wordpress.com/?p=54409</id>
        <link href="https://xianblog.wordpress.com/2023/11/06/we-need-an-immediate-humanitarian-ceasefire-in-gaza/"/>
        <updated>2023-11-06T10:00:49.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High-Performance Llama 2 Training and Inference with PyTorch/XLA on Cloud TPUs]]></title>
        <id>https://pytorch.org/blog/high-performance-llama-2/</id>
        <link href="https://pytorch.org/blog/high-performance-llama-2/"/>
        <updated>2023-11-06T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[In a landscape where AI innovation is accelerating at an unprecedented pace, Meta’s Llama family of open sourced large language models (LLMs) stands out as a notable breakthrough. Llama marked a significant step forward for LLMs, demonstrating the power of pre-trained architectures for a wide range of applications. Llama 2 further pushed the boundaries of scale and capabilities, inspiring advancements in language understanding, generation, and beyond.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian learning of feature spaces for multitasks problems]]></title>
        <id>http://arxiv.org/abs/2209.03028</id>
        <link href="http://arxiv.org/abs/2209.03028"/>
        <updated>2023-11-06T03:15:41.747Z</updated>
        <summary type="html"><![CDATA[Carlos Sevilla-Salcedo, Ascensi\'on Gallardo-Antol\'in, Vanessa
  G\'omez-Verdejo, Emilio Parrado-Hern\'andez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning nonparametric latent causal graphs with unknown interventions]]></title>
        <id>http://arxiv.org/abs/2306.02899</id>
        <link href="http://arxiv.org/abs/2306.02899"/>
        <updated>2023-11-06T03:15:41.666Z</updated>
        <summary type="html"><![CDATA[Yibo Jiang, Bryon Aragam]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Obtaining Explainable Classification Models using Distributionally
  Robust Optimization]]></title>
        <id>http://arxiv.org/abs/2311.01994</id>
        <link href="http://arxiv.org/abs/2311.01994"/>
        <updated>2023-11-06T03:15:41.640Z</updated>
        <summary type="html"><![CDATA[Sanjeeb Dash, Soumyadip Ghosh, Joao Goncalves, Mark S. Squillante]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SortNet: Learning To Rank By a Neural-Based Sorting Algorithm]]></title>
        <id>http://arxiv.org/abs/2311.01864</id>
        <link href="http://arxiv.org/abs/2311.01864"/>
        <updated>2023-11-06T03:15:41.604Z</updated>
        <summary type="html"><![CDATA[Leonardo Rigutini, Tiziano Papini, Marco Maggini, Franco Scarselli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How a student becomes a teacher: learning and forgetting through
  Spectral methods]]></title>
        <id>http://arxiv.org/abs/2310.12612</id>
        <link href="http://arxiv.org/abs/2310.12612"/>
        <updated>2023-11-06T03:15:41.591Z</updated>
        <summary type="html"><![CDATA[Lorenzo Giambagli, Lorenzo Buffoni, Lorenzo Chicchi, Duccio Fanelli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speculations Concerning the First Ultraintelligent Machine [not a book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=54087</id>
        <link href="https://xianblog.wordpress.com/2023/11/06/speculations-concerning-the-first-ultraintelligent-machine-not-a-book-review/"/>
        <updated>2023-11-05T23:23:51.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Really weird sinographs, part 4:  hyena]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61168</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61168&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=really-weird-sinographs-part-4-hyena"/>
        <updated>2023-11-05T15:10:03.000Z</updated>
        <summary type="html"><![CDATA[In "LOL, ROTFL, IJBO" (11/2/23), all the talk of laughter made me think of the epitome of that particular animal behavior, the hyena.  Of all creatures on earth, the hyena is one of the most curious.  Can you imagine going through life laughing at everything, especially when life is so full of tragedy? Listen:  here, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Covent’ska [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53444</id>
        <link href="https://xianblog.wordpress.com/2023/11/05/coventska-jatp/"/>
        <updated>2023-11-04T23:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Maximum likelihood estimation of autoregressive model parameters]]></title>
        <id>https://parsiad.ca/blog/2023/maximum_likelihood_estimation_of_autoregressive_model_parameters/</id>
        <link href="https://parsiad.ca/blog/2023/maximum_likelihood_estimation_of_autoregressive_model_parameters/"/>
        <updated>2023-11-04T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Got wheels]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61154</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61154&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=got-wheels"/>
        <updated>2023-11-04T16:17:44.000Z</updated>
        <summary type="html"><![CDATA[Sign on a truck in Hong Kong: It says: Lún lún lún輪倫侖lit. "wheel — Lon(don) / kinship / relationship / logic / order / match / peer — (Kun)lun / [alternate form of the previous character, hence having its sound and all of its meanings]" lún 輪 is the Chinese glyph / word for "wheel". […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Marsset]]></title>
        <id>http://xianblog.wordpress.com/?p=54040</id>
        <link href="https://xianblog.wordpress.com/2023/11/04/marsset/"/>
        <updated>2023-11-03T23:22:50.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The changing accents of British English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61128</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61128&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-changing-accents-of-british-english"/>
        <updated>2023-11-03T20:49:23.000Z</updated>
        <summary type="html"><![CDATA[King’s English and Cockney replaced by three new accents, study finds Britons depart from overtly class-based post-war speech epitomised by either clipped vowels or working-class dialects By Charles Hymas, The Telegraph, Home Affairs Editor 30 October 2023 • 6:33pm I vaguely recall an earlier study from about ten years ago that came to similar conclusions (including the emergence of […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Best of both worlds: Achieving scalability and quality in text clustering]]></title>
        <id>http://blog.research.google/2023/11/best-of-both-worlds-achieving.html</id>
        <link href="http://blog.research.google/2023/11/best-of-both-worlds-achieving.html"/>
        <updated>2023-11-03T18:23:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Sara Ahmadian and Mehran Kazemi, Research Scientists, Google Research




Clustering is a fundamental, ubiquitous problem in data mining and unsupervised machine learning, where the goal is to group together similar items. The standard forms of clustering are metric clustering and graph clustering. In metric clustering, a given metric space defines distances between data points, which are grouped together based on their separation. In graph clustering, a given graph connects similar data points through edges, and the clustering process groups data points together based on the connections between them. Both clustering forms are particularly useful for large corpora where class labels can’t be defined. Examples of such corpora are the ever-growing digital text collections of variou…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prince of pronunciation]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61141</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61141&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=prince-of-pronunciation"/>
        <updated>2023-11-03T16:57:44.000Z</updated>
        <summary type="html"><![CDATA[Many people have the (mis)perception that the French (mis)pronounce all languages with a heavy accent.  It turns out that the gold standard for correct pronunciation of borrowed words is a French gentilhomme /ʒɑ̃.ti.jɔm/. How to Pronounce the Trickiest English Words: Ask This Frenchman Millions of Americans, the curious and the insecure, consult Julien Miquel for […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Carsen Stringer - Unsupervised pretraining in biological neural networks]]></title>
        <id>https://mlfoundations.org/talk/carsen/</id>
        <link href="https://mlfoundations.org/talk/carsen/"/>
        <updated>2023-11-03T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Representation learning in neural networks may be implemented with supervised or unsupervised algorithms, distinguished by the presence or absence of reward feedback. Both types of learning are highly effective in artificial neural networks. In biological systems, task learning has been shown to modify sensory neural representations, but it is not known if these changes are due to supervised or unsupervised learning. Here we recorded populations of up to 70,000 neurons simultaneously from primary visual cortex (V1) and higher visual areas (HVA), while animals learned multiple tasks as well as during unrewarded exposure to the same stimuli. We found that most neural changes in task mice were replicated in the mice with unrewarded exposure. These changes were concentrated in the medial HVAs after mice learned to discriminate visual textures from two different classes. In contrast, the changes were widespread across visual areas after mice learned to discriminate between two exemplars of the same visual class. In both tasks, neural representations of the most recently learned exemplar generalized to new exemplars of the same visual category and the behavior of the mice generalized according to the same rule. These specific neural changes were replicated in mice with unrewarded exposure, suggesting that unsupervised learning plays a major role in visual learning. In task mice only, we found a neural population in anterior HVAs encoding a ramping reward prediction signal, potentially involved in the supervised learning. Our neural results predict that unsupervised pretraining may accelerate subsequent task learning, a prediction which we validated with behavioral training experiments.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI insults]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61148</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61148&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-insults"/>
        <updated>2023-11-03T11:26:59.000Z</updated>
        <summary type="html"><![CDATA[No, not what you get by asking GPT-4 for insults — for that, see below… This is the SMBC comic from a few days ago: Mouseover title: "You catastrophic forgetter! You opaque box! You absolute Chinese room!" The aftercomic: GPT-4's response to the prompt "Give me some really good insults": While I understand the desire […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anonymous Learning via Look-Alike Clustering: A Precise Analysis of
  Model Generalization]]></title>
        <id>http://arxiv.org/abs/2310.04015</id>
        <link href="http://arxiv.org/abs/2310.04015"/>
        <updated>2023-11-03T02:22:45.380Z</updated>
        <summary type="html"><![CDATA[Adel Javanmard, Vahab Mirrokni]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inversion of Bayesian Networks]]></title>
        <id>http://arxiv.org/abs/2212.10649</id>
        <link href="http://arxiv.org/abs/2212.10649"/>
        <updated>2023-11-03T02:22:45.373Z</updated>
        <summary type="html"><![CDATA[Jesse van Oostrum, Peter van Hintum, Nihat Ay]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Long Story Short: Omitted Variable Bias in Causal Machine Learning]]></title>
        <id>http://arxiv.org/abs/2112.13398</id>
        <link href="http://arxiv.org/abs/2112.13398"/>
        <updated>2023-11-03T02:22:45.366Z</updated>
        <summary type="html"><![CDATA[Victor Chernozhukov, Carlos Cinelli, Whitney Newey, Amit Sharma,
  Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Learning Gaussian Multi-index Models with Gradient Flow]]></title>
        <id>http://arxiv.org/abs/2310.19793</id>
        <link href="http://arxiv.org/abs/2310.19793"/>
        <updated>2023-11-03T02:22:45.342Z</updated>
        <summary type="html"><![CDATA[Alberto Bietti, Joan Bruna, Loucas Pillaud-Vivien]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Detection of Interacting Variables for Generalized Linear Models via
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2209.08030</id>
        <link href="http://arxiv.org/abs/2209.08030"/>
        <updated>2023-11-03T02:22:41.601Z</updated>
        <summary type="html"><![CDATA[Yevhen Havrylenko, Julia Heger]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Eeeech… [X validated]]]></title>
        <id>http://xianblog.wordpress.com/?p=53666</id>
        <link href="https://xianblog.wordpress.com/2023/11/03/eeeech-x-validated/"/>
        <updated>2023-11-02T23:23:32.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Crispy Rs"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61145</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61145&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=crispy-rs"/>
        <updated>2023-11-02T23:18:50.000Z</updated>
        <summary type="html"><![CDATA[Dan Nosowitz, "The ‘Crispy R’ and Why R Is the Weirdest Letter", Atlas Obscura 11/2/2023: The crispy R is a phenomenon that some linguists had noticed, but which had gone largely unstudied—until the phrase “crispy R” was bestowed on it by Brian Michael Firkus, better known as Trixie Mattel, the winner of the third season […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zero-shot adaptive prompting of large language models]]></title>
        <id>http://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html</id>
        <link href="http://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html"/>
        <updated>2023-11-02T22:01:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Xingchen Wan, Student Researcher, and Ruoxi Sun, Research Scientist, Cloud AI Team




Recent advances in large language models (LLMs) are very promising as reflected in their capability for general problem-solving in few-shot and zero-shot setups, even without explicit training on these tasks. This is impressive because in the few-shot setup, LLMs are presented with only a few question-answer demonstrations prior to being given a test question. Even more challenging is the zero-shot setup, where the LLM is directly prompted with the test question only. 




Even though the few-shot setup has dramatically reduced the amount of data required to adapt a model for a specific use-case, there are still cases where generating sample prompts can be challenging. For example, handcrafting…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LOL, ROTFL, IJBOL]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61137</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61137&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=lol-rotfl-ijbol"/>
        <updated>2023-11-02T09:23:43.000Z</updated>
        <summary type="html"><![CDATA[As Laura Morland said to me in a p.c., I am a "Swiftie" (I admit it, even though I'm a Penn prof), but there are plenty of things about pop culture that I do not know, including IJBOL. What Is IJBOL? A Korean word? A new boy band? This new acronym is replacing LOL and […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerating Inference on x86-64 Machines with oneDNN Graph]]></title>
        <id>https://pytorch.org/blog/accelerating-inference/</id>
        <link href="https://pytorch.org/blog/accelerating-inference/"/>
        <updated>2023-11-02T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Supported in PyTorch 2.0 as a beta feature, oneDNN Graph leverages aggressive fusion patterns to accelerate inference on x86-64 machines, especially Intel® Xeon® Scalable processors.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Online learning in bandits with predicted context]]></title>
        <id>http://arxiv.org/abs/2307.13916</id>
        <link href="http://arxiv.org/abs/2307.13916"/>
        <updated>2023-11-02T05:14:05.276Z</updated>
        <summary type="html"><![CDATA[Yongyi Guo, Ziping Xu, Susan Murphy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Learning Adversarial Bandit Algorithms]]></title>
        <id>http://arxiv.org/abs/2307.02295</id>
        <link href="http://arxiv.org/abs/2307.02295"/>
        <updated>2023-11-02T02:21:18.815Z</updated>
        <summary type="html"><![CDATA[Mikhail Khodak, Ilya Osadchiy, Keegan Harris, Maria-Florina Balcan,
  Kfir Y. Levy, Ron Meir, Zhiwei Steven Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Concept Algebra for (Score-Based) Text-Controlled Generative Models]]></title>
        <id>http://arxiv.org/abs/2302.03693</id>
        <link href="http://arxiv.org/abs/2302.03693"/>
        <updated>2023-11-02T02:21:18.711Z</updated>
        <summary type="html"><![CDATA[Zihao Wang, Lin Gui, Jeffrey Negrea, Victor Veitch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Learning Necessary and Sufficient Causal Graphs]]></title>
        <id>http://arxiv.org/abs/2301.12389</id>
        <link href="http://arxiv.org/abs/2301.12389"/>
        <updated>2023-11-02T02:21:18.708Z</updated>
        <summary type="html"><![CDATA[Hengrui Cai, Yixin Wang, Michael Jordan, Rui Song]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Likelihood-Free Frequentist Inference: Bridging Classical Statistics and
  Machine Learning in Simulator-Based Inference]]></title>
        <id>http://arxiv.org/abs/2107.03920</id>
        <link href="http://arxiv.org/abs/2107.03920"/>
        <updated>2023-11-02T02:21:18.478Z</updated>
        <summary type="html"><![CDATA[Niccol\`o Dalmasso, Luca Masserano, David Zhao, Rafael Izbicki, Ann B.
  Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Corruption-robust exploration in episodic reinforcement learning]]></title>
        <id>http://arxiv.org/abs/1911.08689</id>
        <link href="http://arxiv.org/abs/1911.08689"/>
        <updated>2023-11-02T02:21:18.473Z</updated>
        <summary type="html"><![CDATA[Thodoris Lykouris, Max Simchowitz, Aleksandrs Slivkins, Wen Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Warwick Stats recruits]]></title>
        <id>http://xianblog.wordpress.com/?p=54323</id>
        <link href="https://xianblog.wordpress.com/2023/11/02/warwick-stats-recruits/"/>
        <updated>2023-11-01T23:23:57.000Z</updated>
        <summary type="html"><![CDATA[The Department of Statistics at the University of Warwick is recruiting: Assistant Professor, Statistics (3 positions in Applied, Methodological or Theoretical Statistics ) Assistant Professor, Computational Statistics or Machine Learning (2 positions) Associate Professor (1 position, any area within the Department) Applicants should have evidence or promise of world-class research excellence and ability to deliver […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MetNet-3: A state-of-the-art neural weather model available in Google products]]></title>
        <id>http://blog.research.google/2023/11/metnet-3-state-of-art-neural-weather.html</id>
        <link href="http://blog.research.google/2023/11/metnet-3-state-of-art-neural-weather.html"/>
        <updated>2023-11-01T17:30:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Samier Merchant, Google Research, and Nal Kalchbrenner, Google DeepMind






Forecasting weather variables such as precipitation, temperature, and wind is key to numerous aspects of society, from daily planning and transportation to energy production. As we continue to see more extreme weather events such as floods, droughts, and heat waves, accurate forecasts can be essential to preparing for and mitigating their effects. The first 24 hours into the future are especially important as they are both highly predictable and actionable, which can help people make informed decisions in a timely manner and stay safe. 
 

Today we present a new weather model called MetNet-3, developed by Google Research and Google DeepMind. Building on the earlier MetNet and MetNet-2 models, MetNet-3 p…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Lowering through LLVM]]></title>
        <id>https://jeremykun.com/?p=120196</id>
        <link href="https://jeremykun.com/2023/11/01/mlir-lowering-through-llvm/"/>
        <updated>2023-11-01T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents In the last article we lowered our custom poly dialect to standard MLIR dialects. In this article we’ll continue lowering it to LLVM IR, exporting it out of MLIR to LLVM, and then compiling to x86 machine code. The code for this article is in this pull request, and as usual the commits are organized to […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Emigrate" no longer an option]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61134</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61134&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=emigrate-no-longer-an-option"/>
        <updated>2023-11-01T13:42:45.000Z</updated>
        <summary type="html"><![CDATA[As things seem to be spinning out of control in the PRC (generals, bankers, politicians being disappeared left and right; foreign ministers evaporating; a former president being levitated out of his seat at the 29th National Congress; a much-admired premier being heart attacked…), people are increasingly desperate to get out.  We saw this already in […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stronger Privacy Amplification by Shuffling for R\'enyi and Approximate
  Differential Privacy]]></title>
        <id>http://arxiv.org/abs/2208.04591</id>
        <link href="http://arxiv.org/abs/2208.04591"/>
        <updated>2023-11-01T01:08:48.285Z</updated>
        <summary type="html"><![CDATA[Vitaly Feldman, Audra McMillan, Kunal Talwar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revisiting Parameter Sharing in Multi-Agent Deep Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2005.13625</id>
        <link href="http://arxiv.org/abs/2005.13625"/>
        <updated>2023-11-01T01:08:48.281Z</updated>
        <summary type="html"><![CDATA[J. K. Terry, Nathaniel Grammel, Sanghyun Son, Benjamin Black, Aakriti
  Agrawal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Double logistic regression approach to biased positive-unlabeled data]]></title>
        <id>http://arxiv.org/abs/2209.07787</id>
        <link href="http://arxiv.org/abs/2209.07787"/>
        <updated>2023-11-01T01:08:48.276Z</updated>
        <summary type="html"><![CDATA[Konrad Furma\'nczyk, Jan Mielniczuk, Wojciech Rejchel and
  Pawe{\l} Teisseyre]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A general class of surrogate functions for stable and efficient
  reinforcement learning]]></title>
        <id>http://arxiv.org/abs/2108.05828</id>
        <link href="http://arxiv.org/abs/2108.05828"/>
        <updated>2023-11-01T01:08:48.270Z</updated>
        <summary type="html"><![CDATA[Sharan Vaswani, Olivier Bachem, Simone Totaro, Robert Mueller, Shivam
  Garg, Matthieu Geist, Marlos C. Machado, Pablo Samuel Castro, Nicolas Le Roux]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse PCA With Multiple Components]]></title>
        <id>http://arxiv.org/abs/2209.14790</id>
        <link href="http://arxiv.org/abs/2209.14790"/>
        <updated>2023-11-01T01:08:48.265Z</updated>
        <summary type="html"><![CDATA[Ryan Cory-Wright, Jean Pauphilet]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[j’adôre la bagnole [not!]]]></title>
        <id>http://xianblog.wordpress.com/?p=54165</id>
        <link href="https://xianblog.wordpress.com/2023/11/01/jadore-la-bagnole-not/"/>
        <updated>2023-10-31T23:23:22.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Richard Montgomery presents: A proof of the Ryser-Brualdi-Stein conjecture for large even n]]></title>
        <id>http://gilkalai.wordpress.com/?p=24829</id>
        <link href="https://gilkalai.wordpress.com/2023/11/01/richard-montgomery-presents-a-proof-of-the-ryser-brualdi-stein-conjecture-for-large-even-n/"/>
        <updated>2023-10-31T21:40:14.000Z</updated>
        <summary type="html"><![CDATA[Fresh from the ArXiv A proof of the Ryser-Brualdi-Stein conjecture for large even n by Richard Montgomery A Latin square of order n is an n by n grid filled using n symbols so that each symbol appears exactly once … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Richard Montgomery presents: A proof of the Ryser-Brualdi-Stein conjecture for large even n]]></title>
        <id>http://gilkalai.wordpress.com/?p=24829</id>
        <link href="https://gilkalai.wordpress.com/2023/11/01/richard-montgomery-presents-a-proof-of-the-ryser-brualdi-stein-conjecture-for-large-even-n/"/>
        <updated>2023-10-31T21:40:14.000Z</updated>
        <summary type="html"><![CDATA[Fresh from the ArXiv A proof of the Ryser-Brualdi-Stein conjecture for large even n by Richard Montgomery A Latin square of order n is an n by n grid filled using n symbols so that each symbol appears exactly once … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speak Mandarin, not Cantonese, even in Macau]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61124</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61124&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=speak-mandarin-not-cantonese-even-in-macau"/>
        <updated>2023-10-31T21:34:00.000Z</updated>
        <summary type="html"><![CDATA[Eason Chan rebukes Chinese fans demanding he speak Mandarin at Macau concert 'I love speaking whatever way and language I want,' says Chan By Keoni Everington, Taiwan News (2023/10/20) Well, it looks as though we are having a clash of languages — Mandarin vs. Cantonese — right in the heartland of Cantonese. TAIPEI (Taiwan News) […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adventures in Supersingularland]]></title>
        <id>http://arxiv.org/abs/1909.07779</id>
        <link href="http://arxiv.org/abs/1909.07779"/>
        <updated>2023-10-31T17:13:50.069Z</updated>
        <summary type="html"><![CDATA[Sarah Arpin, Catalina Camacho-Navarro, Kristin Lauter, Joelle Lim,
  Kristina Nelson, Travis Scholl, Jana Sot\'akov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Diffusion of Recurrent Innovations]]></title>
        <id>http://arxiv.org/abs/2101.05094</id>
        <link href="http://arxiv.org/abs/2101.05094"/>
        <updated>2023-10-31T17:13:50.042Z</updated>
        <summary type="html"><![CDATA[Fuqi Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Unified Framework for Generalizing the Gromov-Hausdorff Metric]]></title>
        <id>http://arxiv.org/abs/1812.03760</id>
        <link href="http://arxiv.org/abs/1812.03760"/>
        <updated>2023-10-31T17:13:50.020Z</updated>
        <summary type="html"><![CDATA[Ali Khezeli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Equistarable graphs and counterexamples to three conjectures on
  equistable graphs]]></title>
        <id>http://arxiv.org/abs/1407.1670</id>
        <link href="http://arxiv.org/abs/1407.1670"/>
        <updated>2023-10-31T17:13:49.989Z</updated>
        <summary type="html"><![CDATA[Martin Milani\v{c}, Nicolas Trotignon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Selling a Single Item with Negative Externalities]]></title>
        <id>http://arxiv.org/abs/1902.10008</id>
        <link href="http://arxiv.org/abs/1902.10008"/>
        <updated>2023-10-31T17:13:49.981Z</updated>
        <summary type="html"><![CDATA[Tithi Chattopadhyay, Nick Feamster, Matheus V. X. Ferreira and
  Danny Yuxing Huang, S. Matthew Weinberg]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A glimpse of the next generation of AlphaFold]]></title>
        <id>https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/</id>
        <link href="https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/"/>
        <updated>2023-10-31T13:00:00.000Z</updated>
        <summary type="html"><![CDATA[Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[20/11 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841b8adb7895018adfd6ce0c4ad1</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-10-31T09:55:48.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 20 Nov '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Congrats, Dr. Robert!]]></title>
        <id>http://xianblog.wordpress.com/?p=54356</id>
        <link href="https://xianblog.wordpress.com/2023/10/31/congrats-dr-robert/"/>
        <updated>2023-10-31T09:31:50.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[“四舍五入”之FSQ：简单得令人尴尬的VQ-VAE替代品]]></title>
        <id>https://kexue.fm/archives/9826</id>
        <link href="https://kexue.fm/archives/9826"/>
        <updated>2023-10-31T08:33:00.000Z</updated>
        <summary type="html"><![CDATA[正如“XXX is all you need”一样，有不少论文都以“简单得令人尴尬”命名（An Embarrassingly Simple XXX），但在笔者看来，这些论文大多数都是噱头多于实力...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AMD Extends Support for Pytorch Machine Learning Development nn Select RDNA™ 3 GPUs with ROCm™ 5.7]]></title>
        <id>https://pytorch.org/blog/amd-extends-support-for-pt-ml/</id>
        <link href="https://pytorch.org/blog/amd-extends-support-for-pt-ml/"/>
        <updated>2023-10-31T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Researchers and developers working with Machine Learning (ML) models and algorithms using PyTorch can now use AMD ROCm 5.7 on Ubuntu® Linux® to tap into the parallel computing power of the Radeon™ RX 7900 XTX and the Radeon™ PRO W7900 graphics cards which are based on the AMD RDNA™ 3 GPU architecture.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially Private Statistical Inference through $\beta$-Divergence
  One Posterior Sampling]]></title>
        <id>http://arxiv.org/abs/2307.05194</id>
        <link href="http://arxiv.org/abs/2307.05194"/>
        <updated>2023-10-31T02:22:20.140Z</updated>
        <summary type="html"><![CDATA[Jack Jewson, Sahra Ghalebikesabi, Chris Holmes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Benefits of Policy Learning from Human Preferences in
  Contextual Bandit Problems]]></title>
        <id>http://arxiv.org/abs/2307.12975</id>
        <link href="http://arxiv.org/abs/2307.12975"/>
        <updated>2023-10-31T02:22:20.139Z</updated>
        <summary type="html"><![CDATA[Xiang Ji, Huazheng Wang, Minshuo Chen, Tuo Zhao, Mengdi Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Characterization and Learning of Causal Graphs with Small Conditioning
  Sets]]></title>
        <id>http://arxiv.org/abs/2301.09028</id>
        <link href="http://arxiv.org/abs/2301.09028"/>
        <updated>2023-10-31T02:22:20.138Z</updated>
        <summary type="html"><![CDATA[Murat Kocaoglu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MMD-FUSE: Learning and Combining Kernels for Two-Sample Testing Without
  Data Splitting]]></title>
        <id>http://arxiv.org/abs/2306.08777</id>
        <link href="http://arxiv.org/abs/2306.08777"/>
        <updated>2023-10-31T02:22:20.138Z</updated>
        <summary type="html"><![CDATA[Felix Biggs, Antonin Schrab, Arthur Gretton]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InstanT: Semi-supervised Learning with Instance-dependent Thresholds]]></title>
        <id>http://arxiv.org/abs/2310.18910</id>
        <link href="http://arxiv.org/abs/2310.18910"/>
        <updated>2023-10-31T02:22:20.137Z</updated>
        <summary type="html"><![CDATA[Muyang Li, Runze Wu, Haoyu Liu, Jun Yu, Xun Yang, Bo Han, Tongliang
  Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Tomato sauce" in Cantonese, with a trigger warning]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61115</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61115&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tomato-sauce-in-cantonese-with-a-trigger-warning"/>
        <updated>2023-10-30T17:20:25.000Z</updated>
        <summary type="html"><![CDATA[Aside from the popular folk etymology that the word came to English from the Cantonese keh jup (茄汁 ke2 zap1, literally meaning "tomato sauce" in Cantonese), there are many serious competing etymological theories about the origins of the word "ketchup (catsup)".  The main types are Amoy (Minnan, Fujian / Hokkien), Malay, and Euro-Arabic.  (source).  I will […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Stability Principle for Learning under Non-Stationarity]]></title>
        <id>http://arxiv.org/abs/2310.18304</id>
        <link href="http://arxiv.org/abs/2310.18304"/>
        <updated>2023-10-30T03:15:38.214Z</updated>
        <summary type="html"><![CDATA[Chengpiao Huang, Kaizheng Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semantic HELM: A Human-Readable Memory for Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2306.09312</id>
        <link href="http://arxiv.org/abs/2306.09312"/>
        <updated>2023-10-30T03:15:36.517Z</updated>
        <summary type="html"><![CDATA[Fabian Paischer, Thomas Adler, Markus Hofmarcher, Sepp Hochreiter]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian sparsification for deep neural networks with Bayesian model
  reduction]]></title>
        <id>http://arxiv.org/abs/2309.12095</id>
        <link href="http://arxiv.org/abs/2309.12095"/>
        <updated>2023-10-30T03:15:36.396Z</updated>
        <summary type="html"><![CDATA[Dimitrije Markovi\'c, Karl J. Friston, Stefan J. Kiebel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pitons du Carbet [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=54312</id>
        <link href="https://xianblog.wordpress.com/2023/10/30/pitons-du-carbet-jatp/"/>
        <updated>2023-10-29T23:23:55.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flash mob / drive]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61112</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61112&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=flash-mob-drive"/>
        <updated>2023-10-29T20:35:40.000Z</updated>
        <summary type="html"><![CDATA[Placed on the countertop of the coffee corner in the dining hall at Lingnan University in Hong Kong: The English is an adequate translation of the Chinese, so I won't transcribe and romanize the latter.  I only wish to point out a striking neologism and ask two pertinent questions. The neologism is kuàishǎn 快閃 ("flash mob"), […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complementary water]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61105</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61105&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=complementary-water"/>
        <updated>2023-10-29T20:30:33.000Z</updated>
        <summary type="html"><![CDATA[François Lang saw this sign at the local farmers market: François asked the men at the booth what their water complements, but they did'nt get it. Meanwhile, François introduced me to the Dihydrogen Monoxide Research Division (DHMO), whose roots go back to the early 80s. Selected readings "Complimentary Internet in the lobby" (10/26/09) "Dihydrogen Monoxide" (3/15/04)]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[56 行代码用 Python 实现一个 Flex/Lex]]></title>
        <id>https://www.skywind.me/blog/?p=2761</id>
        <link href="https://www.skywind.me/blog/archives/2761"/>
        <updated>2023-10-29T17:03:00.000Z</updated>
        <summary type="html"><![CDATA[作为 Yacc/Bison 的好搭档 Lex/Flex 是一个很方便的工具，可以通过写几行规则就能生成一个新的词法分析器，大到给你的 parser 提供 token 流，小到解析一个配置文件，都很有帮助；而用 Python 实现一个支持自定义规则的类 Flex/Lex 词法分析器只需要短短 56 行代码，简单拷贝粘贴到你的代码里，让你的代码具备基于可定制规则的词法分析功能。 原理很简单，熟读 Python 文档的同学应该看过 regex module 帮助页面最下面有段程序： def tokenize(code): keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'} token_specification = [ ('NUMBER', r'\d+(\.\d*)?'), # Integer or decimal number ('ASSIGN', r':='), # Assignment operator ('END', r';'), # Statement terminator ('ID', r'[A-Za-z]+'), # […]
The post 56 行代码用 Python 实现一个 Flex/Lex appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[apply international humanitarian law, including the principle of proportionality and distinction]]></title>
        <id>http://xianblog.wordpress.com/?p=54341</id>
        <link href="https://xianblog.wordpress.com/2023/10/29/apply-international-humanitarian-law-including-the-principle-of-proportionality-and-distinction/"/>
        <updated>2023-10-29T15:46:26.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI and slang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61098</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61098&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-and-slang"/>
        <updated>2023-10-29T14:00:56.000Z</updated>
        <summary type="html"><![CDATA[As someone who is particularly fond of and sensitive to vernacular (I didn't say "vulgar"), I knew it was only a matter of time before this came up. Why AI Doesn’t Get SlangAnd why that’s a good thing By Caleb MadisonThe Atlantic (October 28, 2023 ——– Slang is born in the margins. In its early […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Middle Sinitic in Indological Transcription]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61092</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61092&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=middle-sinitic-in-indological-transcription"/>
        <updated>2023-10-29T01:06:43.000Z</updated>
        <summary type="html"><![CDATA[A fascinating, valuable new proposal from Nathan Hill: "An Indological transcription of Middle Chinese" Cahiers de Linguistique Asie Orientale, 52 (2023), 40-50. Abstract Because most Sino-Tibetan languages with a literary tradition use Indic derived scripts and those that do not are each sui generis, there are advantages to transcribing these languages also along Indic lines. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[assistant professor opening at UBC Stats]]></title>
        <id>http://xianblog.wordpress.com/?p=54318</id>
        <link href="https://xianblog.wordpress.com/2023/10/29/assistant-professor-opening-at-ubc-stats/"/>
        <updated>2023-10-28T22:23:20.000Z</updated>
        <summary type="html"><![CDATA[A new position in Statistics at UBC, Vancouver. Details available there. And deadline on 15 November.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sanaaq, the first novel written in Inuktitut syllabics in Canada]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61088</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61088&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sanaaq-the-first-novel-written-in-inuktitut-syllabics-in-canada"/>
        <updated>2023-10-28T13:08:41.000Z</updated>
        <summary type="html"><![CDATA[Long, richly illustrated, highly biographical article in CBC (10/8/23): Writing the story of a changing North In the 1950s, Mitiarjuk Nappaaluk began Sanaaq, which would end up becoming the first novel written in Inuktitut. Her words continue to inform our understanding of Inuit life. By Pauline Holdsworth   Shortly after receiving notice that the Norwegian […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CB-HVTNet: A channel-boosted hybrid vision transformer network for
  lymphocyte assessment in histopathological images]]></title>
        <id>http://arxiv.org/abs/2305.09211</id>
        <link href="http://arxiv.org/abs/2305.09211"/>
        <updated>2023-10-28T02:18:38.982Z</updated>
        <summary type="html"><![CDATA[Momina Liaqat Ali, Zunaira Rauf, Asifullah Khan, Anabia Sohail, Rafi
  Ullah, Jeonghwan Gwak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[off to Luminy [Autumn school in Bayesian statistics]]]></title>
        <id>http://xianblog.wordpress.com/?p=54309</id>
        <link href="https://xianblog.wordpress.com/2023/10/28/off-to-luminy-autumn-school-in-bayesian-statistics-2/"/>
        <updated>2023-10-27T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Audioplethysmography for cardiac monitoring with hearable devices]]></title>
        <id>http://blog.research.google/2023/10/audioplethysmography-for-cardiac.html</id>
        <link href="http://blog.research.google/2023/10/audioplethysmography-for-cardiac.html"/>
        <updated>2023-10-27T20:22:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Xiaoran "Van" Fan, Experimental Scientist, and Trausti Thormundsson, Director, Google





The market for true wireless stereo (TWS) active noise canceling (ANC) hearables (headphones and earbuds) has been soaring in recent years, and the global shipment volume will nearly double that of smart wristbands and watches in 2023. The on-head time for hearables has extended significantly due to the recent advances in ANC, transparency mode, and artificial intelligence. Users frequently wear hearables not just for music listening, but also for exercising, focusing, or simply mood adjustment. However, hearable health is still mostly uncharted territory for the consumer market. 



In “APG: Audioplethysmography for Cardiac Monitoring in Hearables,” presented at MobiCom 2023, we introduce …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Harvard, we have a problem]]></title>
        <id>http://windowsontheory.org/?p=8717</id>
        <link href="https://windowsontheory.org/2023/10/27/harvard-we-have-a-problem/"/>
        <updated>2023-10-27T16:10:53.000Z</updated>
        <summary type="html"><![CDATA[[I was hoping for this piece to be posted as an op-ed in the Crimson, since I really want to reach students that are well-intentioned but may not realize they are harmful. However, it was rejected and so I am posting this here] The events of October 7th, 2023, hit many Israeli-Americans personally. My immediate … Continue reading Harvard, we have a problem]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Harvard, we have a problem]]></title>
        <id>http://windowsontheory.org/?p=8717</id>
        <link href="https://windowsontheory.org/2023/10/27/harvard-we-have-a-problem/"/>
        <updated>2023-10-27T16:10:53.000Z</updated>
        <summary type="html"><![CDATA[[I was hoping for this piece to be posted as an op-ed in the Crimson, since I really want to reach students that are well-intentioned but may not realize they are harmful. However, it was rejected and so I am posting this here] The events of October 7th, 2023, hit many Israeli-Americans personally. My immediate … Continue reading Harvard, we have a problem]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Midori]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61085</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61085&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=midori"/>
        <updated>2023-10-27T12:51:03.000Z</updated>
        <summary type="html"><![CDATA[Michael Watts just wrote this comment on another post, and I thought it was interesting enough to deserve a post of its own: I've been wondering about a claim that appears on wiktionary. The entry for the Japanese word "midori", spelled 緑 or in older form 綠, states that the word is from Old Japanese, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Petition by CS & Math Laureates: Freedom for kidnapped children]]></title>
        <id>http://windowsontheory.org/?p=8704</id>
        <link href="https://windowsontheory.org/2023/10/27/petition-by-cs-math-laureates-freedom-for-kidnapped-children/"/>
        <updated>2023-10-27T05:57:01.000Z</updated>
        <summary type="html"><![CDATA[[Guest post by Shafi Goldwasser, PDF version below] On the morning of Saturday, October 7, 2023, Hamas launched an attack near the Israel/Gaza border. In villages and towns near the border they went from door-to-door annihilating whole families. They killed children in front of their parents and siblings. They abused women. In a music concert … Continue reading Petition by CS & Math Laureates: Freedom for kidnapped children]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Petition by CS & Math Laureates: Freedom for kidnapped children]]></title>
        <id>http://windowsontheory.org/?p=8704</id>
        <link href="https://windowsontheory.org/2023/10/27/petition-by-cs-math-laureates-freedom-for-kidnapped-children/"/>
        <updated>2023-10-27T05:57:01.000Z</updated>
        <summary type="html"><![CDATA[[Guest post by Shafi Goldwasser, PDF version below] On the morning of Saturday, October 7, 2023, Hamas launched an attack near the Israel/Gaza border. In villages and towns near the border they went from door-to-door annihilating whole families. They killed children in front of their parents and siblings. They abused women. In a music concert … Continue reading Petition by CS & Math Laureates: Freedom for kidnapped children]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Characterizing the Implicit Bias of Regularized SGD in Rank Minimization]]></title>
        <id>http://arxiv.org/abs/2206.05794</id>
        <link href="http://arxiv.org/abs/2206.05794"/>
        <updated>2023-10-27T02:20:24.824Z</updated>
        <summary type="html"><![CDATA[Tomer Galanti, Zachary S. Siegel, Aparna Gupte, Tomaso Poggio]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Few-Shot Learning through Multi-task Representation Learning
  Theory]]></title>
        <id>http://arxiv.org/abs/2010.01992</id>
        <link href="http://arxiv.org/abs/2010.01992"/>
        <updated>2023-10-27T02:20:24.802Z</updated>
        <summary type="html"><![CDATA[Quentin Bouniot, Ievgen Redko, Romaric Audigier, Ang\'elique Loesch,
  Amaury Habrard]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Squared Neural Families: A New Class of Tractable Density Models]]></title>
        <id>http://arxiv.org/abs/2305.13552</id>
        <link href="http://arxiv.org/abs/2305.13552"/>
        <updated>2023-10-27T02:20:21.689Z</updated>
        <summary type="html"><![CDATA[Russell Tsuchida, Cheng Soon Ong, Dino Sejdinovic]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mind the spikes: Benign overfitting of kernels and neural networks in
  fixed dimension]]></title>
        <id>http://arxiv.org/abs/2305.14077</id>
        <link href="http://arxiv.org/abs/2305.14077"/>
        <updated>2023-10-27T02:20:20.792Z</updated>
        <summary type="html"><![CDATA[Moritz Haas, David Holzm\"uller, Ulrike von Luxburg, Ingo Steinwart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Neural Collapse Perspective on Feature Evolution in Graph Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2307.01951</id>
        <link href="http://arxiv.org/abs/2307.01951"/>
        <updated>2023-10-27T02:20:16.040Z</updated>
        <summary type="html"><![CDATA[Vignesh Kothapalli, Tom Tirer, Joan Bruna]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[downtown Fort-de-France [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=54292</id>
        <link href="https://xianblog.wordpress.com/2023/10/27/downtown-fort-de-france-jatp/"/>
        <updated>2023-10-26T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Supporting benchmarks for AI safety with MLCommons]]></title>
        <id>http://blog.research.google/2023/10/supporting-benchmarks-for-ai-safety.html</id>
        <link href="http://blog.research.google/2023/10/supporting-benchmarks-for-ai-safety.html"/>
        <updated>2023-10-26T18:01:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Anoop Sinha, Technology and Society, and Marian Croak, Google Research, Responsible AI and Human Centered Technology team





Standard benchmarks are agreed upon ways of measuring important product qualities, and they exist in many fields. Some standard benchmarks measure safety: for example, when a car manufacturer touts a “five-star overall safety rating,” they’re citing a benchmark. Standard benchmarks already exist in machine learning (ML) and AI technologies: for instance, the MLCommons Association operates the MLPerf benchmarks that measure the speed of cutting edge AI hardware such as Google’s TPUs. However, though there has been significant work done on AI safety, there are as yet no similar standard benchmarks for AI safety.
 

We are excited to support a new effort by …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spoken question answering and speech continuation using a spectrogram-powered LLM]]></title>
        <id>http://blog.research.google/2023/10/spoken-question-answering-and-speech.html</id>
        <link href="http://blog.research.google/2023/10/spoken-question-answering-and-speech.html"/>
        <updated>2023-10-26T15:57:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Eliya Nachmani, Research Scientist, and Alon Levkovitch, Student Researcher, Google Research




The goal of natural language processing (NLP) is to develop computational models that can understand and generate natural language. By capturing the statistical patterns and structures of text-based natural language, language models can predict and generate coherent and meaningful sequences of words. Enabled by the increasing use of the highly successful Transformer model architecture and with training on large amounts of text (with proportionate compute and model size), large language models (LLMs) have demonstrated remarkable success in NLP tasks. 

 


However, modeling spoken human language remains a challenging frontier. Spoken dialog systems have conventionally been built as a c…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The sound of ancient Iranian languages]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61079</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61079&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-sound-of-ancient-iranian-languages"/>
        <updated>2023-10-26T15:40:19.000Z</updated>
        <summary type="html"><![CDATA[From Hiroshi Kumamoto: Old Iranian Languages Proto-Iranian Old Persian Avestan Middle Persian Parthian Sogdian Alanian Khotanese Bactrian Khwarezmian The Sound of the Sogdian language (Numbers, Words & Sample Text) The Sound of the Khwarezmian language (Numbers, Words & Sample Text) Sound of ANCIENT east iranic (Tajik) languages (Sogdian, Saka Khotanese, Bactrian & Khwārezmian) EASTERN IRANIC […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via
  Mixed-Effect Models and Hierarchical Clustering]]></title>
        <id>http://arxiv.org/abs/2308.06399</id>
        <link href="http://arxiv.org/abs/2308.06399"/>
        <updated>2023-10-26T02:20:16.183Z</updated>
        <summary type="html"><![CDATA[Lorenzo Valleggi, Marco Scutari, Federico Mattia Stefanini]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From Tempered to Benign Overfitting in ReLU Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.15141</id>
        <link href="http://arxiv.org/abs/2305.15141"/>
        <updated>2023-10-26T02:20:04.097Z</updated>
        <summary type="html"><![CDATA[Guy Kornowski, Gilad Yehudai, Ohad Shamir]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Discrete Diffusion Language Modeling by Estimating the Ratios of the
  Data Distribution]]></title>
        <id>http://arxiv.org/abs/2310.16834</id>
        <link href="http://arxiv.org/abs/2310.16834"/>
        <updated>2023-10-26T02:20:03.787Z</updated>
        <summary type="html"><![CDATA[Aaron Lou, Chenlin Meng, Stefano Ermon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beyond IID weights: sparse and low-rank deep Neural Networks are also
  Gaussian Processes]]></title>
        <id>http://arxiv.org/abs/2310.16597</id>
        <link href="http://arxiv.org/abs/2310.16597"/>
        <updated>2023-10-26T02:20:03.740Z</updated>
        <summary type="html"><![CDATA[Thiziri Nait-Saada, Alireza Naderi, Jared Tanner]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Optimization of Deep Learning via Jacobian Matrix and
  Lipschitz Constant]]></title>
        <id>http://arxiv.org/abs/2306.09338</id>
        <link href="http://arxiv.org/abs/2306.09338"/>
        <updated>2023-10-26T02:20:03.039Z</updated>
        <summary type="html"><![CDATA[Xianbiao Qi, Jianan Wang, Lei Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[bibliothèque Schœlcher [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=54282</id>
        <link href="https://xianblog.wordpress.com/2023/10/26/bibliotheque-schoelcher-jatp/"/>
        <updated>2023-10-25T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Looking back at wildfire research in 2023]]></title>
        <id>http://blog.research.google/2023/10/looking-back-at-wildfire-research-in.html</id>
        <link href="http://blog.research.google/2023/10/looking-back-at-wildfire-research-in.html"/>
        <updated>2023-10-25T22:10:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Yi-Fan Chen, Software Engineer, and Carla Bromberg, Program Lead, Google Research

Wildfires are becoming larger and affecting more and more communities around the world, often resulting in large-scale devastation. Just this year, communities have experienced catastrophic wildfires in Greece, Maui, and Canada to name a few. While the underlying causes leading to such an increase are complex — including changing climate patterns, forest management practices, land use development policies and many more — it is clear that the advancement of technologies can help to address the new challenges.
 
At Google Research, we’ve been investing in a number of climate adaptation efforts, including the application of machine learning (ML) to aid in wildfire prevention and provide information to…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Swedish dictionary:  140 years in the making]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61073</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61073&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=swedish-dictionary-140-years-in-the-making"/>
        <updated>2023-10-25T20:40:14.000Z</updated>
        <summary type="html"><![CDATA[Patience pays off: Official Swedish dictionary completed after 140 years One hundred and thirty-seven full-time employees have worked on Swedish Academy Dictionary over the years since 1883 Agence France-Presse in StockholmWed 25 Oct 2023 ———- The definitive record of the Swedish language has been completed after 140 years, with the dictionary’s final volume sent to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Grammar checking at Google Search scale]]></title>
        <id>http://blog.research.google/2023/10/grammar-checking-at-google-search-scale.html</id>
        <link href="http://blog.research.google/2023/10/grammar-checking-at-google-search-scale.html"/>
        <updated>2023-10-25T17:45:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Eric Malmi, Senior Research Scientist, and Jakub Adamek, Senior Software Engineer, Google, Bard Team





Many people with questions about grammar turn to Google Search for guidance. While existing features, such as “Did you mean”, already handle simple typo corrections, more complex grammatical error correction (GEC) is beyond their scope. What makes the development of new Google Search features challenging is that they must have high precision and recall while outputting results quickly.



The conventional approach to GEC is to treat it as a translation problem and use autoregressive Transformer models to decode the response token-by-token, conditioning on the previously generated tokens. However, although Transformer models have proven to be effective at GEC, they aren’t part…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What Algorithms can Transformers Learn? A Study in Length Generalization]]></title>
        <id>http://arxiv.org/abs/2310.16028</id>
        <link href="http://arxiv.org/abs/2310.16028"/>
        <updated>2023-10-25T03:15:49.117Z</updated>
        <summary type="html"><![CDATA[Hattie Zhou, Arwen Bradley, Etai Littwin, Noam Razin, Omid Saremi,
  Josh Susskind, Samy Bengio, Preetum Nakkiran]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Denoising Low-Rank Data Under Distribution Shift: Double Descent and
  Data Augmentation]]></title>
        <id>http://arxiv.org/abs/2305.17297</id>
        <link href="http://arxiv.org/abs/2305.17297"/>
        <updated>2023-10-25T03:15:49.093Z</updated>
        <summary type="html"><![CDATA[Chinmaya Kausik, Kashvi Srivastava, Rishi Sonthalia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Amortised Inference in Neural Networks for Small-Scale Probabilistic
  Meta-Learning]]></title>
        <id>http://arxiv.org/abs/2310.15786</id>
        <link href="http://arxiv.org/abs/2310.15786"/>
        <updated>2023-10-25T03:15:49.014Z</updated>
        <summary type="html"><![CDATA[Matthew Ashman, Tommy Rochussen, Adrian Weller]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What's Left? Concept Grounding with Logic-Enhanced Foundation Models]]></title>
        <id>http://arxiv.org/abs/2310.16035</id>
        <link href="http://arxiv.org/abs/2310.16035"/>
        <updated>2023-10-25T03:15:48.991Z</updated>
        <summary type="html"><![CDATA[Joy Hsu, Jiayuan Mao, Joshua B. Tenenbaum, Jiajun Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Sound of Ancient Languages, parts 1 and 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61045</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61045&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-sound-of-ancient-languages-parts-1-and-2"/>
        <updated>2023-10-25T01:08:55.000Z</updated>
        <summary type="html"><![CDATA[0:00 Etruscan  0:39 Sumerian  1:25 Ancient Greek  2:24 Urartian 3:24 Avestan  3:50 Egyptian  4:41 Akkadian  5:34 Sanskrit 6:33 Hittite  7:31 Latin  8:28 Phoenician  9:14 End 0:00 Proto Indo European 0:30 Sabaic  1:00 Sanskrit  1:30 Aramaic 2:00 Sumerian 2:30 Old Chinese 3:00 Ge`ez 3:30 Gothic language And here are two shorts Old Norse Old English I […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adversarial Attacks on LLMs]]></title>
        <id>https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/</id>
        <link href="https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/"/>
        <updated>2023-10-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.
A large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space.]]></summary>
        <author>
            <name>Lil'Log</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[so long, and thanks for all the quests]]></title>
        <id>http://xianblog.wordpress.com/?p=53865</id>
        <link href="https://xianblog.wordpress.com/2023/10/25/so-long-and-thanks-for-all-the-quests/"/>
        <updated>2023-10-24T22:23:37.000Z</updated>
        <summary type="html"><![CDATA[The Riddler, which I have followed for many years, has been discontinued by FiveThirtyEight, but its producer, Zach Wissner-Gross, has launched a personal website to keep considering a weekly mathematical puzzle. The Fiddler on the Proof! Expect thus more ‘Og entries in this category!]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is the maximum number of Tverberg’s partitions?]]></title>
        <id>http://gilkalai.wordpress.com/?p=24764</id>
        <link href="https://gilkalai.wordpress.com/2023/10/24/what-is-the-maximum-number-of-tverbergs-partitions/"/>
        <updated>2023-10-24T07:44:49.000Z</updated>
        <summary type="html"><![CDATA[The problem presented in this post was discussed in my recent lecture “New types of order types” in the workshop on discrete convexity and geometry in Budapest, a few weeks ago. The lecture described various results and questions including the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is the maximum number of Tverberg’s partitions?]]></title>
        <id>http://gilkalai.wordpress.com/?p=24764</id>
        <link href="https://gilkalai.wordpress.com/2023/10/24/what-is-the-maximum-number-of-tverbergs-partitions/"/>
        <updated>2023-10-24T07:44:49.000Z</updated>
        <summary type="html"><![CDATA[The problem presented in this post was discussed in my recent lecture “New types of order types” in the workshop on discrete convexity and geometry in Budapest, a few weeks ago. The lecture described various results and questions including the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fundamental Limits of Membership Inference Attacks on Machine Learning
  Models]]></title>
        <id>http://arxiv.org/abs/2310.13786</id>
        <link href="http://arxiv.org/abs/2310.13786"/>
        <updated>2023-10-24T03:16:45.979Z</updated>
        <summary type="html"><![CDATA[Eric Aubinais, Elisabeth Gassiat, Pablo Piantanida]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Extended Deep Adaptive Input Normalization for Preprocessing Time Series
  Data for Neural Networks]]></title>
        <id>http://arxiv.org/abs/2310.14720</id>
        <link href="http://arxiv.org/abs/2310.14720"/>
        <updated>2023-10-24T03:16:45.750Z</updated>
        <summary type="html"><![CDATA[Marcus A. K. September, Francesco Sanna Passino, Leonie Goldmann,
  Anton Hinel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unifying O(3) Equivariant Neural Networks Design with Tensor-Network
  Formalism]]></title>
        <id>http://arxiv.org/abs/2211.07482</id>
        <link href="http://arxiv.org/abs/2211.07482"/>
        <updated>2023-10-24T03:16:21.336Z</updated>
        <summary type="html"><![CDATA[Zimu Li, Zihan Pengmei, Han Zheng, Erik Thiede, Junyu Liu, Risi
  Kondor]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Rigorous Link between Deep Ensembles and (Variational) Bayesian
  Methods]]></title>
        <id>http://arxiv.org/abs/2305.15027</id>
        <link href="http://arxiv.org/abs/2305.15027"/>
        <updated>2023-10-24T03:16:21.329Z</updated>
        <summary type="html"><![CDATA[Veit David Wild, Sahra Ghalebikesabi, Dino Sejdinovic, Jeremias
  Knoblauch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning the Visualness of Text Using Large Vision-Language Models]]></title>
        <id>http://arxiv.org/abs/2305.10434</id>
        <link href="http://arxiv.org/abs/2305.10434"/>
        <updated>2023-10-24T03:16:21.310Z</updated>
        <summary type="html"><![CDATA[Gaurav Verma, Ryan A. Rossi, Christopher Tensmeyer, Jiuxiang Gu, Ani
  Nenkova]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[sequential meetings in Edinburgh]]></title>
        <id>http://xianblog.wordpress.com/?p=54265</id>
        <link href="https://xianblog.wordpress.com/2023/10/24/sequential-meetings-in-edinburgh/"/>
        <updated>2023-10-23T22:23:53.000Z</updated>
        <summary type="html"><![CDATA[There will be not one but two consecutive events in Edinburgh next May²⁴ on sequential Monte Carlo methods! Both hosted by the fantastic International Centre for Mathematical Sciences (ICMS) in Edinburgh Olde Town. Within the Bayes Centre. And running distance to Arthur’s Seat. (Reminding me of my first ICMS workshop in 2001 run with Mike […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Dialect Conversion]]></title>
        <id>https://jeremykun.com/?p=120066</id>
        <link href="https://jeremykun.com/2023/10/23/mlir-dialect-conversion/"/>
        <updated>2023-10-23T13:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents In previous articles we defined a dialect, and wrote various passes to optimize and canonicalize a program using that dialect. However, one of the main tenets of MLIR is “incremental lowering,” the idea that there are lots of levels of IR granularity, and you incrementally lower different parts of the IR, only discarding information […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepFDR: A Deep Learning-based False Discovery Rate Control Method for
  Neuroimaging Data]]></title>
        <id>http://arxiv.org/abs/2310.13349</id>
        <link href="http://arxiv.org/abs/2310.13349"/>
        <updated>2023-10-23T03:15:48.494Z</updated>
        <summary type="html"><![CDATA[Taehyo Kim, Hai Shu, Qiran Jia, Mony de Leon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trained Transformers Learn Linear Models In-Context]]></title>
        <id>http://arxiv.org/abs/2306.09927</id>
        <link href="http://arxiv.org/abs/2306.09927"/>
        <updated>2023-10-23T03:15:48.488Z</updated>
        <summary type="html"><![CDATA[Ruiqi Zhang, Spencer Frei, Peter L. Bartlett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random Matrix Analysis to Balance between Supervised and Unsupervised
  Learning under the Low Density Separation Assumption]]></title>
        <id>http://arxiv.org/abs/2310.13434</id>
        <link href="http://arxiv.org/abs/2310.13434"/>
        <updated>2023-10-23T03:15:48.434Z</updated>
        <summary type="html"><![CDATA[Vasilii Feofanov, Malik Tiomoko, Aladin Virmaux]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding Sycophancy in Language Models]]></title>
        <id>http://arxiv.org/abs/2310.13548</id>
        <link href="http://arxiv.org/abs/2310.13548"/>
        <updated>2023-10-23T03:15:48.302Z</updated>
        <summary type="html"><![CDATA[Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda
  Askell, Samuel R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds,
  Scott R. Johnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal
  Ndousse, Oliver Rausch, Nicholas Schiefer, Da Yan, Miranda Zhang, Ethan Perez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-learning of Physics-informed Neural Networks for Efficiently
  Solving Newly Given PDEs]]></title>
        <id>http://arxiv.org/abs/2310.13270</id>
        <link href="http://arxiv.org/abs/2310.13270"/>
        <updated>2023-10-23T03:15:48.283Z</updated>
        <summary type="html"><![CDATA[Tomoharu Iwata, Yusuke Tanaka, Naonori Ueda]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[back to the future [no need!]]]></title>
        <id>http://xianblog.wordpress.com/?p=54126</id>
        <link href="https://xianblog.wordpress.com/2023/10/23/back-to-the-future-no-need/"/>
        <updated>2023-10-22T22:23:53.000Z</updated>
        <summary type="html"><![CDATA[A news entry in Nature of 25 Sept 23 is reporting on the grim period of Earth, 250 millions year away! By that time, continents will have drifted back, reunited into a new Pangaea supercontinent, Pangaea Ultima, which is likely to form around the equator, producing a deadly place where most life will go extinct. […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Frater studiorum: Tsu-Lin Mei (1933-2023)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61041</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61041&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=frater-studiorum-tsu-lin-mei-1933-2023"/>
        <updated>2023-10-22T20:19:13.000Z</updated>
        <summary type="html"><![CDATA[It is with deep sadness that I report the passing on October 14, 2023 of Tsu-Lin Mei, professor of Chinese historical linguistics at Cornell University.  Tsu-Lin was born on February 14, 1933 at the Peking Union Medical College Hospital in Beijing. He received his B.A. from Oberlin College in 1954, his M.A. (in Mathematics) from Harvard […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[从梯度最大化看Attention的Scale操作]]></title>
        <id>https://kexue.fm/archives/9812</id>
        <link href="https://kexue.fm/archives/9812"/>
        <updated>2023-10-22T09:35:00.000Z</updated>
        <summary type="html"><![CDATA[我们知道，Scaled-Dot Product Attention的Scale因子是$\frac{1}{\sqrt{d}}$，其中$d$是$\boldsymbol{q},\boldsymbol{...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[帧同步游戏中使用 Run-Ahead 隐藏输入延迟]]></title>
        <id>https://www.skywind.me/blog/?p=2746</id>
        <link href="https://www.skywind.me/blog/archives/2746"/>
        <updated>2023-10-22T03:05:00.000Z</updated>
        <summary type="html"><![CDATA[帧同步可以轻松解决高互动的联网游戏（如格斗，RTS 等）的同步问题，但该方案对延迟很敏感，现在一般省内服务器延迟差不多 10-15ms （1帧），跨省一般 40ms （2-3 帧），在此情况下，使用 Run-Ahead 机制可以有效的掩盖延迟的体感，让用玩家立马看到自己的操作反馈。 该机制有很多其他名字比如：预测回滚（prediction and rollback），或者时间曲力（time warp），名字取的天花乱坠的，很多文章也只是云里雾里说一半天，结果还没说清楚，所以本文打算最简短的句子说清楚这个概念，并给出可以实际操作的实现步骤。 我觉得用 Run-Ahead 这个质朴的名字更容易说明这个算法背后的思想：提前运行，这个概念不光用在游戏同步里，也早已用在游戏模拟器中，为了便于理解，先说一下模拟器中的情况（更简单）。 RetroArch 使用 Run-Ahead 隐藏输入延迟，一般需要设置一下 Run-Ahead 的帧数，比如 0 是关闭，1 是提前运行一帧，2 是提前运行两帧，一般设置用 1，一般不会超过 2 ，设置太高游戏表现会很奇怪： 运行时 RetroArch 为每帧保存快照，假定的是用户输入有持续性，那么运行时当前帧使用上一帧用户的输入作为本帧输入（假设 runahead 设置为 1），然后接着往下运行，如果用户新输入来了，一律把它算作当前帧-1 的输入，然后再去对比历史如果和上一帧所尝试假定的输入一致就继续，否则快照回退到上一帧，重新用新的输入去运行，然后再快进到当前帧。 通常手柄或键盘都有 5ms 左右的输入延迟（部分设备如 switch 的 pro 手柄延迟高达 15ms），再加上操作系统处理的延迟，投递到模拟器进程里，从按下到真正开始处理也许也差不多 1 帧的时间了，RetroArch 用这个功能，也只有用户真实输入和预测输入不一致时才会触发，由于间隔很短，所以即使纠正也难看出来，最终在模拟器上达到了物理设备一样的超低延迟体验。 理解了模拟器的 Run-Ahead 实现，其实在帧同步里的原理也就差不多了，无外乎是用远程的旧输入，搭配本地刚采集到的新输入，作为预测帧的输入值，产生新帧，不匹配了再回滚。 帧同步里引入类似 Run-Ahead 的机制，要求游戏最近所有状态都可以被快速保存、复制和恢复，实现有很多种，你可以用状态的反复前进、后退来实现，但是 BUG 率太高了，这里给出一个更简易的实现方式： […]
The post 帧同步游戏中使用 Run-Ahead 隐藏输入延迟 appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Your work has been cited! [who is U?!]]]></title>
        <id>http://xianblog.wordpress.com/?p=53626</id>
        <link href="https://xianblog.wordpress.com/2023/10/22/your-work-has-been-cited-who-is-u/"/>
        <updated>2023-10-21T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Calling all linguists"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61043</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61043&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=calling-all-linguists"/>
        <updated>2023-10-21T20:15:43.000Z</updated>
        <summary type="html"><![CDATA[Kevin Drum, "Calling all linguists", 10/20/2023: You know what I'd like? I'd like a qualified linguist with a good ear to listen to a Joe Biden speech and report back. A couple of weeks ago I spent some time doing this, and Biden's problem is that his speech really does sound a little slurred at […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five Riddles כמה חידות]]></title>
        <id>http://gilkalai.wordpress.com/?p=24747</id>
        <link href="https://gilkalai.wordpress.com/2023/10/21/five-riddles-%d7%9b%d7%9e%d7%94-%d7%97%d7%99%d7%93%d7%95%d7%aa/"/>
        <updated>2023-10-21T18:58:13.000Z</updated>
        <summary type="html"><![CDATA[Here are five riddles. I learned them from Maya Bar-Hillel. Can you solve them? (We had several earlier posts with riddles, such as Two Math Riddles; Greg’s Dinosaurs Riddle; and The Ultimate Riddle. ) Two old friends are standing together … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five Riddles כמה חידות]]></title>
        <id>http://gilkalai.wordpress.com/?p=24747</id>
        <link href="https://gilkalai.wordpress.com/2023/10/21/five-riddles-%d7%9b%d7%9e%d7%94-%d7%97%d7%99%d7%93%d7%95%d7%aa/"/>
        <updated>2023-10-21T18:58:13.000Z</updated>
        <summary type="html"><![CDATA[Here are five riddles. I learned them from Maya Bar-Hillel. Can you solve them? (We had several earlier posts with riddles, such as Two Math Riddles; Greg’s Dinosaurs Riddle; and The Ultimate Riddle. ) Two old friends are standing together … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[More AI shenanigans]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61032</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61032&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=more-ai-shenanigans"/>
        <updated>2023-10-21T10:55:45.000Z</updated>
        <summary type="html"><![CDATA[Since When Does Eric Adams Speak Spanish, Yiddish and Mandarin? He doesn’t. But New York City is using artificial intelligence to send robocalls featuring the mayor’s voice in many languages. By Emma G. Fitzsimmons and Jeffery C. Mays, NYT (Oct. 20, 2023) The calls to New Yorkers have a familiar ring to them. They all […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bidirectional Temporal Diffusion Model for Temporally Consistent Human
  Animation]]></title>
        <id>http://arxiv.org/abs/2307.00574</id>
        <link href="http://arxiv.org/abs/2307.00574"/>
        <updated>2023-10-21T02:18:57.873Z</updated>
        <summary type="html"><![CDATA[Tserendorj Adiya, Sanghun Kim, Jung Eun Lee, Jae Shin Yoon, Hwasup
  Lim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=54022</id>
        <link href="https://xianblog.wordpress.com/2023/10/21/a-journal-of-the-conquest-war-famine-and-death-year-5/"/>
        <updated>2023-10-20T22:23:47.000Z</updated>
        <summary type="html"><![CDATA[Read Jen Williams’ The Winnowing Flame trilogy, induced by two British Fantasy Awards associated with the first two volumes. This is quite a disappointing series, the more one goes through the story. At the start, while I found the story rather simplistic in its world building and in repeating the all-too-common pattern of a very […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Answering billions of reporting queries each day with low latency]]></title>
        <id>http://blog.research.google/2023/10/answering-billions-of-reporting-queries.html</id>
        <link href="http://blog.research.google/2023/10/answering-billions-of-reporting-queries.html"/>
        <updated>2023-10-20T17:07:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Jagan Sankaranarayanan, Senior Staff Software Engineer, and Indrajit Roy, Head of Napa Product, Google




Google Ads infrastructure runs on an internal data warehouse called Napa. Billions of reporting queries, which power critical dashboards used by advertising clients to measure campaign performance, run on tables stored in Napa. These tables contain records of ads performance that are keyed using particular customers and the campaign identifiers with which they are associated. Keys are tokens that are used both to associate an ads record with a particular client and campaign (e.g., customer_id, campaign_id) and for efficient retrieval. A record contains dozens of keys, so clients use reporting queries to specify keys needed to filter the data to understand ads performance (e.…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pinyin vs. English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61028</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61028&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pinyin-vs-english"/>
        <updated>2023-10-20T11:37:44.000Z</updated>
        <summary type="html"><![CDATA[I knew that in the future it would come to this.  More than forty years ago, I predicted that one day China would have to make a choice between Hanyu Pinyin and English when it comes to phonetic writing.  As we say in Mandarin, "guǒrán 果然" ("as expected / it turns out")…. It seems that […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Discriminative to Kernel Density Networks for Calibrated Inference]]></title>
        <id>http://arxiv.org/abs/2201.13001</id>
        <link href="http://arxiv.org/abs/2201.13001"/>
        <updated>2023-10-20T02:21:10.392Z</updated>
        <summary type="html"><![CDATA[Jayanta Dey, Will LeVine, Haoyin Xu, Ashwin De Silva, Tyler M. Tomita,
  Ali Geisa, Tiffany Chu, Jacob Desman, Joshua T. Vogelstein]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Piecewise Deterministic Markov Processes for Bayesian Neural Networks]]></title>
        <id>http://arxiv.org/abs/2302.08724</id>
        <link href="http://arxiv.org/abs/2302.08724"/>
        <updated>2023-10-20T02:21:10.375Z</updated>
        <summary type="html"><![CDATA[Ethan Goan, Dimitri Perrin, Kerrie Mengersen, Clinton Fookes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics-informed neural networks in the recreation of hydrodynamic
  simulations from dark matter]]></title>
        <id>http://arxiv.org/abs/2303.14090</id>
        <link href="http://arxiv.org/abs/2303.14090"/>
        <updated>2023-10-20T02:21:10.371Z</updated>
        <summary type="html"><![CDATA[Zhenyu Dai, Ben Moews, Ricardo Vilalta, Romeel Dave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Seeking the Truth Beyond the Data. An Unsupervised Machine Learning
  Approach]]></title>
        <id>http://arxiv.org/abs/2207.06949</id>
        <link href="http://arxiv.org/abs/2207.06949"/>
        <updated>2023-10-20T02:21:10.366Z</updated>
        <summary type="html"><![CDATA[Dimitrios Saligkaras, Vasileios E. Papageorgiou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[URL: A Representation Learning Benchmark for Transferable Uncertainty
  Estimates]]></title>
        <id>http://arxiv.org/abs/2307.03810</id>
        <link href="http://arxiv.org/abs/2307.03810"/>
        <updated>2023-10-20T02:21:10.361Z</updated>
        <summary type="html"><![CDATA[Michael Kirchhof, B\'alint Mucs\'anyi, Seong Joon Oh and
  Enkelejda Kasneci]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arrowleaf Cellars [pinot noir]]]></title>
        <id>http://xianblog.wordpress.com/?p=53943</id>
        <link href="https://xianblog.wordpress.com/2023/10/20/arrowleaf-cellars-pinot-noir/"/>
        <updated>2023-10-19T22:23:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI and the law, part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61019</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61019&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-and-the-law-part-2"/>
        <updated>2023-10-19T19:52:35.000Z</updated>
        <summary type="html"><![CDATA[Here we go again, but this time on a grander and more dramatic scale: Pras Michel of Fugees seeks new trial, contends former attorney used AI for closing argument The hip-hop artist convicted on campaign finance and foreign influence charges seeks to set aside the jury’s guilty verdicts. By Josh Bernstein, Politico (1016/23) Notice the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[English learners can now practice speaking on Search]]></title>
        <id>http://blog.research.google/2023/10/google-search-can-now-help-with-english-speaking-practice.html</id>
        <link href="http://blog.research.google/2023/10/google-search-can-now-help-with-english-speaking-practice.html"/>
        <updated>2023-10-19T16:24:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Christian Plagemann, Director, and Katya Cox, Product Manager, Google Research




Learning a language can open up new opportunities in a person’s life. It can help people connect with those from different cultures, travel the world, and advance their career. English alone is estimated to have 1.5 billion learners worldwide. Yet proficiency in a new language is difficult to achieve, and many learners cite a lack of opportunity to practice speaking actively and receiving actionable feedback as a barrier to learning.




We are excited to announce a new feature of Google Search that helps people practice speaking and improve their language skills. Within the next few days, Android users in Argentina, Colombia, India (Hindi), Indonesia, Mexico, and Venezuela can get even more langua…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating social and ethical risks from generative AI]]></title>
        <id>https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/</id>
        <link href="https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/"/>
        <updated>2023-10-19T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subject-specific Deep Neural Networks for Count Data with
  High-cardinality Categorical Features]]></title>
        <id>http://arxiv.org/abs/2310.11654</id>
        <link href="http://arxiv.org/abs/2310.11654"/>
        <updated>2023-10-19T03:15:18.882Z</updated>
        <summary type="html"><![CDATA[Hangbin Lee, Il Do Ha, Changha Hwang, Youngjo Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Flow Networks in Continual Learning]]></title>
        <id>http://arxiv.org/abs/2310.12001</id>
        <link href="http://arxiv.org/abs/2310.12001"/>
        <updated>2023-10-19T03:15:18.839Z</updated>
        <summary type="html"><![CDATA[Mateusz Pyla, Kamil Deja, Bart{\l}omiej Twardowski, Tomasz Trzci\'nski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Online Learning with Offline Datasets for Infinite Horizon
  MDPs: A Bayesian Approach]]></title>
        <id>http://arxiv.org/abs/2310.11531</id>
        <link href="http://arxiv.org/abs/2310.11531"/>
        <updated>2023-10-19T03:15:18.821Z</updated>
        <summary type="html"><![CDATA[Dengwang Tang, Rahul Jain, Botao Hao, Zheng Wen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A General Theoretical Paradigm to Understand Learning from Human
  Preferences]]></title>
        <id>http://arxiv.org/abs/2310.12036</id>
        <link href="http://arxiv.org/abs/2310.12036"/>
        <updated>2023-10-19T03:15:18.809Z</updated>
        <summary type="html"><![CDATA[Mohammad Gheshlaghi Azar, Mark Rowland, Bilal Piot, Daniel
  Guo, Daniele Calandriello, Michal Valko, R\'emi Munos]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SQ Lower Bounds for Learning Mixtures of Linear Classifiers]]></title>
        <id>http://arxiv.org/abs/2310.11876</id>
        <link href="http://arxiv.org/abs/2310.11876"/>
        <updated>2023-10-19T03:15:18.794Z</updated>
        <summary type="html"><![CDATA[Ilias Diakonikolas, Daniel M. Kane, Yuxin Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating social and ethical risks from generative AI]]></title>
        <id>https://www.deepmind.com/blog/evaluating-social-and-ethical-risks-from-generative-ai</id>
        <link href="https://www.deepmind.com/blog/evaluating-social-and-ethical-risks-from-generative-ai"/>
        <updated>2023-10-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Generative AI systems are already being used to write books, create graphic designs, assist medical practitioners, and are becoming increasingly capable. To ensure these systems are developed and deployed responsibly requires carefully evaluating the potential ethical and social risks they may pose.In our paper, we propose a three-layered framework for evaluating the social and ethical risks of AI systems. This framework includes evaluations of AI system capability, human interaction, and systemic impacts.We also map the current state of safety evaluations and find three main gaps: context, specific risks, and multimodality. To help close these gaps, we call for repurposing existing evaluation methods for generative AI and for implementing a comprehensive approach to evaluation, as in our case study on misinformation. This approach integrates findings like how likely the AI system is to provide factually incorrect information, with insights on how people use that system, and in what context. Multi-layered evaluations can draw conclusions beyond model capability and indicate whether harm — in this case, misinformation — actually occurs and spreads. To make any technology work as intended, both social and technical challenges must be solved. So to better assess AI system safety, these different layers of context must be taken into account. Here, we build upon earlier research identifying the potential risks of large-scale language models, such as privacy leaks, job automation, misinformation, and more — and introduce a way of comprehensively evaluating these risks going forward.]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[minimize harm to civilians and civilian objects and refrain from unlawful attacks or the collective punishment of civilians [reposted from Amnesty International]]]></title>
        <id>http://xianblog.wordpress.com/?p=54260</id>
        <link href="https://xianblog.wordpress.com/2023/10/19/minimize-harm-to-civilians-and-civilian-objects-and-refrain-from-unlawful-attacks-or-the-collective-punishment-of-civilians-reposted-from-amnesty-international/"/>
        <updated>2023-10-18T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sad Update]]></title>
        <id>http://gilkalai.wordpress.com/?p=24719</id>
        <link href="https://gilkalai.wordpress.com/2023/10/19/sad-update/"/>
        <updated>2023-10-18T21:07:25.000Z</updated>
        <summary type="html"><![CDATA[Dear all, as you probably know, Israel was gravely attacked on Saturday, October, 7 2023 by Hamas terrorists coming from the Gaza streak. More than a thousand civilians including many children and babies were murdered and more than a hundred … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sad Update]]></title>
        <id>http://gilkalai.wordpress.com/?p=24719</id>
        <link href="https://gilkalai.wordpress.com/2023/10/19/sad-update/"/>
        <updated>2023-10-18T21:07:25.000Z</updated>
        <summary type="html"><![CDATA[Dear all, as you probably know, Israel was gravely attacked on Saturday, October, 7 2023 by Hamas terrorists coming from the Gaza streak. More than a thousand civilians including many children and babies were murdered and more than a hundred … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Measurement-induced entanglement phase transitions in a quantum circuit]]></title>
        <id>http://blog.research.google/2023/10/measurement-induced-entanglement-phase.html</id>
        <link href="http://blog.research.google/2023/10/measurement-induced-entanglement-phase.html"/>
        <updated>2023-10-18T21:05:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Jesse Hoke, Student Researcher, and Pedram Roushan, Senior Research Scientist, Quantum AI Team




Quantum mechanics allows many phenomena that are classically impossible: a quantum particle can exist in a superposition of two states simultaneously or be entangled with another particle, such that anything you do to one seems to instantaneously also affect the other, regardless of the space between them. But perhaps no aspect of quantum theory is as striking as the act of measurement. In classical mechanics, a measurement need not affect the system being studied. But a measurement on a quantum system can profoundly influence its behavior. For example, when a quantum bit of information, called a qubit, that is in a superposition of both “0” and “1” is measured, its state will sudde…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flip over when you finish]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61014</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61014&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=flip-over-when-you-finish"/>
        <updated>2023-10-18T20:13:36.000Z</updated>
        <summary type="html"><![CDATA[From shaing tai, via a group on Facebook, photograph taken at the New Otani Inn in Tokyo: Treating the lines one at a time, from top to bottom, except for the English lines, which are left to speak for themselves: Shokuji chū desu 食事中です (I am) in the process of eating (lit., "in the middle of […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards the Fundamental Limits of Knowledge Transfer over Finite Domains]]></title>
        <id>http://arxiv.org/abs/2310.07838</id>
        <link href="http://arxiv.org/abs/2310.07838"/>
        <updated>2023-10-18T02:22:11.932Z</updated>
        <summary type="html"><![CDATA[Qingyue Zhao, Banghua Zhu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding deep neural networks through the lens of their
  non-linearity]]></title>
        <id>http://arxiv.org/abs/2310.11439</id>
        <link href="http://arxiv.org/abs/2310.11439"/>
        <updated>2023-10-18T02:22:11.738Z</updated>
        <summary type="html"><![CDATA[Quentin Bouniot, Ievgen Redko, Anton Mallasto, Charlotte Laclau, Karol
  Arndt, Oliver Struckmeier, Markus Heinonen, Ville Kyrki, Samuel Kaski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wide Neural Networks as Gaussian Processes: Lessons from Deep
  Equilibrium Models]]></title>
        <id>http://arxiv.org/abs/2310.10767</id>
        <link href="http://arxiv.org/abs/2310.10767"/>
        <updated>2023-10-18T02:22:11.720Z</updated>
        <summary type="html"><![CDATA[Tianxiang Gao, Xiaokai Huo, Hailiang Liu, Hongyang Gao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Densely Connected $G$-invariant Deep Neural Networks with Signed
  Permutation Representations]]></title>
        <id>http://arxiv.org/abs/2303.04614</id>
        <link href="http://arxiv.org/abs/2303.04614"/>
        <updated>2023-10-18T02:21:54.835Z</updated>
        <summary type="html"><![CDATA[Devanshu Agrawal, James Ostrowski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Language Models Are Latent Variable Models: Explaining and Finding
  Good Demonstrations for In-Context Learning]]></title>
        <id>http://arxiv.org/abs/2301.11916</id>
        <link href="http://arxiv.org/abs/2301.11916"/>
        <updated>2023-10-18T02:21:54.828Z</updated>
        <summary type="html"><![CDATA[Xinyi Wang, Wanrong Zhu, Michael Saxon, Mark Steyvers, William Yang
  Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When should you upgrade to Python 3.12?]]></title>
        <id>https://pythonspeed.com/articles/upgrade-python-3.12/</id>
        <link href="https://pythonspeed.com/articles/upgrade-python-3.12/"/>
        <updated>2023-10-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Python 3.12 is out now–but should you switch to it immediately?
And if you shouldn’t upgrade just yet, when should you?
Immediately after the release, you may not want to upgrade just yet.
But from December 2023 and onwards, upgrading is definitely worth trying.
To understand why, we need to consider Python packaging, the software development process, and take a look at the history of past releases.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up Cython with SIMD]]></title>
        <id>https://pythonspeed.com/articles/faster-cython-simd/</id>
        <link href="https://pythonspeed.com/articles/faster-cython-simd/"/>
        <updated>2023-10-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Cython allows you to write compiled extensions for Python, by translating Python-y code to C or C++.
Often you’ll use it to speed up your software, and it’s especially useful for implementing small data science or scientific computing algorithms.
But what happens when Cython is too slow?
Often there’s still speed improvements you can do.
In a previous article we focused on examples of optimizing your code to take advantage of things like instruction-level parallelism.
In this article, we’ll focus on another CPU feature, Single Instruction Multiple Data or SIMD, specifically in the context of Cython.
As well see, in some situations using SIMD can happen with only minimal changes to your code.
Parts of this article are excerpted from a book I’m working on that will help teach you how to optimize low-level code, the kind of code you’d write with Cython, C, or Rust.
The goal is to help data scientists and scientists who normally write Python to understand how to make their compiled code faster.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wok talk: enlarging the scope]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60996</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60996&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=wok-talk-enlarging-the-scope"/>
        <updated>2023-10-17T23:07:17.000Z</updated>
        <summary type="html"><![CDATA[Following up on "Wok talk: a real-life retronym!" (10/16/23), Jim Millward remarks: My wife (Punjabi background) and her family call the "wok-shaped pan" they use for cooking vegetable or meat dishes "kurai" (that's my phoneticization–it could be aspirated or unaspirated k / g, I'm not good at hearing the difference).  I've seen these and we've […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[off to Martinique [#2]]]></title>
        <id>http://xianblog.wordpress.com/?p=54132</id>
        <link href="https://xianblog.wordpress.com/2023/10/18/off-to-martinique-2/"/>
        <updated>2023-10-17T22:23:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Goal Representations for Instruction Following]]></title>
        <id>http://bair.berkeley.edu/blog/2023/10/17/grif/</id>
        <link href="http://bair.berkeley.edu/blog/2023/10/17/grif/"/>
        <updated>2023-10-17T14:35:00.000Z</updated>
        <summary type="html"><![CDATA[Goal Representations for Instruction Following



Figure title. Figure caption. This image is centered and set to 50%
page width. -->


A longstanding goal of the field of robot learning has been to create generalist agents that can perform tasks for humans. Natural language has the potential to be an easy-to-use interface for humans to specify arbitrary tasks, but it is difficult to train robots to follow language instructions. Approaches like language-conditioned behavioral cloning (LCBC) train policies to directly imitate expert actions conditioned on language, but require humans to annotate all training trajectories and generalize poorly across scenes and behaviors. Meanwhile, recent goal-conditioned approaches perform much better at general manipulation tasks, but do not enable easy t…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Compound pejoratives]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60998</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60998&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=compound-pejoratives"/>
        <updated>2023-10-17T12:45:28.000Z</updated>
        <summary type="html"><![CDATA[[This has been drifting down my too-long to-blog list for almost 16 months — but better late than never, I guess, and the world could use some pejorative-flavored humor…]  Colin Morris, "Compound pejoratives on Reddit – from buttface to wankpuffin", 6/28/2022: I collected lists of around 70 prefixes and 70 suffixes (collectively, “affixes”) that can […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Compiling NumPy code into C++ or CUDA via torch.compile]]></title>
        <id>https://pytorch.org/blog/compiling-numpy-code/</id>
        <link href="https://pytorch.org/blog/compiling-numpy-code/"/>
        <updated>2023-10-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Quansight engineers have implemented support for tracing through NumPy code via torch.compile in PyTorch 2.1. This feature leverages PyTorch’s compiler to generate efficient fused vectorized code without having to modify your original NumPy code. Even more, it also allows for executing NumPy code on CUDA just by running it through torch.compile under torch.device("cuda")!]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Huawei Joins the PyTorch Foundation as a Premier Member]]></title>
        <id>https://pytorch.org/blog/huawei-joins-pytorch/</id>
        <link href="https://pytorch.org/blog/huawei-joins-pytorch/"/>
        <updated>2023-10-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today, the PyTorch Foundation, a neutral home for the deep learning community to collaborate on the open source PyTorch framework and ecosystem, announced that Huawei has joined as a premier member.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lightning AI Joins the PyTorch Foundation as a Premier Member]]></title>
        <id>https://pytorch.org/blog/lightning-ai-joins-pytorch/</id>
        <link href="https://pytorch.org/blog/lightning-ai-joins-pytorch/"/>
        <updated>2023-10-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[The PyTorch Foundation, a neutral home for the deep learning community to collaborate on the open source PyTorch framework and ecosystem, is announcing today that Lightning AI has joined as a premier member.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch Edge: Enabling On-Device Inference Across Mobile and Edge Devices with ExecuTorch]]></title>
        <id>https://pytorch.org/blog/pytorch-edge/</id>
        <link href="https://pytorch.org/blog/pytorch-edge/"/>
        <updated>2023-10-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Other contributors: Dave Bort, Kimish Patel, Mergen Nachin, Orion Reblitz-Richardson, Andrew Caples]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wok talk: a real-life retronym!]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60948</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60948&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=wok-talk-a-real-life-retronym"/>
        <updated>2023-10-17T03:27:13.000Z</updated>
        <summary type="html"><![CDATA[From François Lang: Since you're a Sinologist, I thought you might be amused by a retronym that I had to coin.   My wife (59 YO) was born and grew up in Beijing, and came to the US in the 80s to do her PhD at Cornell. Since she's Chinese, the only stovetop cooking vessel […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Deep learning model of upstream and downstream brain regions Based
  on Memory Generation-Consolidation-Loss, Synaptic Strength Rebalance and
  mnemonic spiral]]></title>
        <id>http://arxiv.org/abs/2203.11740</id>
        <link href="http://arxiv.org/abs/2203.11740"/>
        <updated>2023-10-17T03:15:25.030Z</updated>
        <summary type="html"><![CDATA[Jun-Bo Tao, Bai-Qing Sun, Wei-Dong Zhu, Shi-You Qu, Ling-Kun Chen,
  Jia-Qiang Li, Guo-Qi Li, Chong Wu, Yu Xiong, Jiaxuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding]]></title>
        <id>http://arxiv.org/abs/2305.14196</id>
        <link href="http://arxiv.org/abs/2305.14196"/>
        <updated>2023-10-17T03:15:25.011Z</updated>
        <summary type="html"><![CDATA[Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, Omer
  Levy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The CoT Collection: Improving Zero-shot and Few-shot Learning of
  Language Models via Chain-of-Thought Fine-Tuning]]></title>
        <id>http://arxiv.org/abs/2305.14045</id>
        <link href="http://arxiv.org/abs/2305.14045"/>
        <updated>2023-10-17T03:15:24.986Z</updated>
        <summary type="html"><![CDATA[Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye,
  Jamin Shin, Minjoon Seo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Med-HALT: Medical Domain Hallucination Test for Large Language Models]]></title>
        <id>http://arxiv.org/abs/2307.15343</id>
        <link href="http://arxiv.org/abs/2307.15343"/>
        <updated>2023-10-17T03:15:24.913Z</updated>
        <summary type="html"><![CDATA[Ankit Pal, Logesh Kumar Umapathi, Malaikannan Sankarasubbu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring the Power of Graph Neural Networks in Solving Linear
  Optimization Problems]]></title>
        <id>http://arxiv.org/abs/2310.10603</id>
        <link href="http://arxiv.org/abs/2310.10603"/>
        <updated>2023-10-17T03:15:24.903Z</updated>
        <summary type="html"><![CDATA[Chendi Qian, Didier Ch\'etelat, Christopher Morris]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In the paper there is y instead of x]]></title>
        <id>http://xianblog.wordpress.com/?p=54199</id>
        <link href="https://xianblog.wordpress.com/2023/10/17/in-the-paper-there-is-y-instead-of-x/"/>
        <updated>2023-10-16T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving traffic evacuations: A case study]]></title>
        <id>http://blog.research.google/2023/10/improving-traffic-evacuations-case-study.html</id>
        <link href="http://blog.research.google/2023/10/improving-traffic-evacuations-case-study.html"/>
        <updated>2023-10-16T17:12:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Damien Pierce, Software Engineer, and John Anderson, Senior Research Director, Google Research




Some cities or communities develop an evacuation plan to be used in case of an emergency. There are a number of reasons why city officials might enact their plan, a primary one being a natural disaster, such as a tornado, flood, or wildfire. An evacuation plan can help the community more effectively respond to an emergency, and so could help save lives. However, it can be difficult for a city to evaluate such a plan because it is not practical to have an entire town or city rehearse a full blown evacuation. For example, Mill Valley, a city in northern California, created a wildfire evacuation plan but lacked an estimate for how long the evacuation would take.


Today we describe a c…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Read vs. spontaneous speech]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60956</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60956&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=read-vs-spontaneous-speech"/>
        <updated>2023-10-16T12:07:52.000Z</updated>
        <summary type="html"><![CDATA[Across the many disciplines that analyze language, there's surprisingly little focus on the properties of natural, spontaneous speech, as opposed to read (or memorized and performed) speech. But of course that dichotomy is an oversimplification — there are many linguistic registers, many ways to read each of the many styles of text, and even more […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rethinking the Role of PPO in RLHF]]></title>
        <id>http://bair.berkeley.edu/blog/2023/10/16/p3o/</id>
        <link href="http://bair.berkeley.edu/blog/2023/10/16/p3o/"/>
        <updated>2023-10-16T09:00:00.000Z</updated>
        <summary type="html"><![CDATA[Rethinking the Role of PPO in RLHF

TL;DR: In RLHF, there’s tension between the reward learning phase, which uses human preference in the form of comparisons, and the RL fine-tuning phase, which optimizes a single, non-comparative reward. What if we performed RL in a comparative way?
Figure 1:
 This diagram illustrates the difference between reinforcement learning from absolute feedback and relative feedback. By incorporating a new component - pairwise policy gradient, we can unify the reward modeling stage and RL stage, enabling direct updates based on pairwise responses.



Large Language Models (LLMs) have powered increasingly capable virtual assistants, such as GPT-4, Claude-2, Bard and Bing Chat. These systems can respond to complex user queries, write code, and even produce poetry. T…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[随机分词再探：从Viterbi Sampling到完美采样算法]]></title>
        <id>https://kexue.fm/archives/9811</id>
        <link href="https://kexue.fm/archives/9811"/>
        <updated>2023-10-16T08:16:00.000Z</updated>
        <summary type="html"><![CDATA[在文章《随机分词浅探：从Viterbi Decoding到Viterbi Sampling》中，笔者提出了一种名为“Viterbi Sampling”的随机分词算法，它只是在求最优解的Viter...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adam-family Methods with Decoupled Weight Decay in Deep Learning]]></title>
        <id>http://arxiv.org/abs/2310.08858</id>
        <link href="http://arxiv.org/abs/2310.08858"/>
        <updated>2023-10-16T02:23:54.304Z</updated>
        <summary type="html"><![CDATA[Kuangyu Ding, Nachuan Xiao, Kim-Chuan Toh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks]]></title>
        <id>http://arxiv.org/abs/2310.03684</id>
        <link href="http://arxiv.org/abs/2310.03684"/>
        <updated>2023-10-16T02:23:54.219Z</updated>
        <summary type="html"><![CDATA[Alexander Robey, Eric Wong, Hamed Hassani, George J. Pappas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subspace Adaptation Prior for Few-Shot Learning]]></title>
        <id>http://arxiv.org/abs/2310.09028</id>
        <link href="http://arxiv.org/abs/2310.09028"/>
        <updated>2023-10-16T02:23:54.214Z</updated>
        <summary type="html"><![CDATA[Mike Huisman, Aske Plaat, Jan N. van Rijn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep
  Models]]></title>
        <id>http://arxiv.org/abs/2310.09250</id>
        <link href="http://arxiv.org/abs/2310.09250"/>
        <updated>2023-10-16T02:23:54.099Z</updated>
        <summary type="html"><![CDATA[Lin Chen, Michal Lukasik, Wittawat Jitkrittum, Chong You, Sanjiv Kumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complementary Domain Adaptation and Generalization for Unsupervised
  Continual Domain Shift Learning]]></title>
        <id>http://arxiv.org/abs/2303.15833</id>
        <link href="http://arxiv.org/abs/2303.15833"/>
        <updated>2023-10-16T02:23:54.093Z</updated>
        <summary type="html"><![CDATA[Wonguk Cho, Jinha Park, Taesup Kim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pacific [far]Northwest]]></title>
        <id>http://xianblog.wordpress.com/?p=53847</id>
        <link href="https://xianblog.wordpress.com/2023/10/16/pacific-farnorthwest/"/>
        <updated>2023-10-15T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[The last week of our BCations was spent in Prince Rupert, 54⁰18’W, on Kaien Island, almost the northernest coastal spot before Alaska. (Although Stewart, 55⁰56’W, may qualify.) With a much more oceanic [and cooler] weather than in farther south, still warm enough to swim in the ocean. And an interesting airport since it sits on […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hypercorrect Mandarin tones]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60937</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60937&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hypercorrect-mandarin-tones"/>
        <updated>2023-10-15T14:55:13.000Z</updated>
        <summary type="html"><![CDATA[Here are two examples.  The first is the (in)famous one about the "Lion-Eating Poet in the Stone Den": This is supposed to show that tones and characters are sine quibus non for intelligibility in Sinitic, except that nobody — but nobody — talks like this.  Without a character script, it's gibberish, and most Chinese throughout […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Eat their young"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60932</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60932&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=eat-their-young"/>
        <updated>2023-10-15T13:21:49.000Z</updated>
        <summary type="html"><![CDATA[In "Trump Short-Circuits in New Video as Concerns Grow Over Cognitive Decline", Meidas Touch 10/14/2023, Brett Meiselas presents the apparent mis-use of an idiom as evidence of neurodegeneration: A new video posted by Donald Trump to his social media account is the latest in a series of clips of the former president that have raised […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI and the law]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60925</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60925&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-and-the-law"/>
        <updated>2023-10-15T13:10:59.000Z</updated>
        <summary type="html"><![CDATA[Article in LAist (10/12/230; This Prolific LA Eviction Law Firm Was Caught Faking Cases In Court. Did They Misuse AI? Dennis Block runs what he says is California’s “leading eviction law firm.” A judge said legal citations submitted in Block's name for a recent case were fake. Six legal experts told LAist the errors likely […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arnak Dalalyan at the RSS Journal Webinar]]></title>
        <id>http://xianblog.wordpress.com/?p=54209</id>
        <link href="https://xianblog.wordpress.com/2023/10/15/arnak-dalalyan-at-the-rss-journal-webinar/"/>
        <updated>2023-10-14T22:23:37.000Z</updated>
        <summary type="html"><![CDATA[My friend and CREST colleague Arnak Dalalyan will (re)present [online] a Read Paper at the RSS on 31 October with my friends Hani Doss and Alain Durmus as discussants: ‘Theoretical Guarantees for Approximate Sampling and Log-Concave Densities’ Arnak Dalalyan ENSAE Paris, France Sampling from various kinds of distributions is an issue of paramount importance in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Socks, a matching game based on an additive combinatorics problem]]></title>
        <id>https://jeremykun.com/?p=120042</id>
        <link href="https://jeremykun.com/2023/10/14/socks-a-matching-game-based-on-an-additive-combinatorics-problem/"/>
        <updated>2023-10-14T13:00:00.000Z</updated>
        <summary type="html"><![CDATA[Can you find a set of cards among these six, such that the socks on the chosen cards can be grouped into matching pairs? (Duplicate pairs of the same sock are OK) This is the objective of the game Socks, a card game originally designed by Anna Varvak, a math professor at Soka University of […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SwinCross: Cross-modal Swin Transformer for Head-and-Neck Tumor
  Segmentation in PET/CT Images]]></title>
        <id>http://arxiv.org/abs/2302.03861</id>
        <link href="http://arxiv.org/abs/2302.03861"/>
        <updated>2023-10-14T02:18:49.684Z</updated>
        <summary type="html"><![CDATA[Gary Y. Li, Junyu Chen, Se-In Jang, Kuang Gong, Quanzheng Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hubert Reeves (1932-2023)]]></title>
        <id>http://xianblog.wordpress.com/?p=54253</id>
        <link href="https://xianblog.wordpress.com/2023/10/14/hubert-reeves-1932-2023/"/>
        <updated>2023-10-13T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Batch calibration: Rethinking calibration for in-context learning and prompt engineering]]></title>
        <id>http://blog.research.google/2023/10/batch-calibration-rethinking.html</id>
        <link href="http://blog.research.google/2023/10/batch-calibration-rethinking.html"/>
        <updated>2023-10-13T18:01:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Han Zhou, Student Researcher, and Subhrajit Roy, Senior Research Scientist, Google Research





Prompting large language models (LLMs) has become an efficient learning paradigm for adapting LLMs to a new task by conditioning on human-designed instructions. The remarkable in-context learning (ICL) ability of LLMs also leads to efficient few-shot learners that can generalize from few-shot input-label pairs. However, the predictions of LLMs are highly sensitive and even biased to the choice of templates, label spaces (such as yes/no, true/false, correct/incorrect), and demonstration examples, resulting in unexpected performance degradation and barriers for pursuing robust LLM applications. To address this problem, calibration methods have been developed to mitigate the effects of t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Emmanuel Abbe - Logic Reasoning and Generalization on the Unseen]]></title>
        <id>https://mlfoundations.org/talk/abbe/</id>
        <link href="https://mlfoundations.org/talk/abbe/"/>
        <updated>2023-10-13T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Transformers have become the dominant neural network architecture in deep learning. While they are state of the art in language and vision tasks, their performance is less convincing in so-called “reasoning” tasks. In this talk, we consider the “generalization on the unseen (GOTU)" objective to test the reasoning capabilities of neural networks, primarily Transformers on Boolean/logic tasks. We first give experimental results showing that such networks have a strong “minimal degree bias" - they tend to find specific interpolators having low degree, in agreement with the “leap complexity” picture derived for classic generalization. Using basic concepts from Boolean Fourier analysis and algebraic geometry, we then characterize such minimal degree profile interpolators and prove two theorems about the convergence of (S)GD to such interpolators on basic architectures. Since the minimal degree profile is not desirable in many reasoning tasks, we discuss various methods to correct this bias and improve consequently the reasoning capabilities. Based primarily on joint works with S. Bengio, A. Lotfi, K. Rizk and E. Adsera-Boix, T. Misiakiewicz.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Autoarticulation]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60917</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60917&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=autoarticulation"/>
        <updated>2023-10-13T11:43:35.000Z</updated>
        <summary type="html"><![CDATA[As Language Log readers are undoubtedly aware, I am prey to mondegreens, earworms, and other imaginary auditory oddities.  Lately, the last half year or so, I've been occasionally subject to what, faute de mieux, I've taken to calling "autoarticulation", modeled after "autosuggestion". It doesn't last very long, doesn't repeat on an endless loop, and is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EMO：基于最优传输思想设计的分类损失函数]]></title>
        <id>https://kexue.fm/archives/9797</id>
        <link href="https://kexue.fm/archives/9797"/>
        <updated>2023-10-13T09:06:00.000Z</updated>
        <summary type="html"><![CDATA[众所周知，分类任务的标准损失是交叉熵（Cross Entropy，等价于最大似然MLE，即Maximum Likelihood Estimation），它有着简单高效的特点，但在某些场景下也暴露...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flash-Decoding for long-context inference]]></title>
        <id>https://pytorch.org/blog/flash-decoding/</id>
        <link href="https://pytorch.org/blog/flash-decoding/"/>
        <updated>2023-10-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially Private Non-convex Learning for Multi-layer Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2310.08425</id>
        <link href="http://arxiv.org/abs/2310.08425"/>
        <updated>2023-10-13T02:24:56.147Z</updated>
        <summary type="html"><![CDATA[Hanpu Shen, Cheng-Long Wang, Zihang Xiang, Yiming Ying, Di
  Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement]]></title>
        <id>http://arxiv.org/abs/2310.07831</id>
        <link href="http://arxiv.org/abs/2310.07831"/>
        <updated>2023-10-13T02:24:56.142Z</updated>
        <summary type="html"><![CDATA[Aaron Defazio, Ashok Cutkosky, Harsh Mehta, Konstantin
  Mishchenko]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Theory of Non-Linear Feature Learning with One Gradient Step in
  Two-Layer Neural Networks]]></title>
        <id>http://arxiv.org/abs/2310.07891</id>
        <link href="http://arxiv.org/abs/2310.07891"/>
        <updated>2023-10-13T02:24:56.138Z</updated>
        <summary type="html"><![CDATA[Behrad Moniri, Donghwan Lee, Hamed Hassani, Edgar Dobriban]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Feature Learning and Generalization in Deep Networks with Orthogonal
  Weights]]></title>
        <id>http://arxiv.org/abs/2310.07765</id>
        <link href="http://arxiv.org/abs/2310.07765"/>
        <updated>2023-10-13T02:24:56.133Z</updated>
        <summary type="html"><![CDATA[Hannah Day, Yonatan Kahn, Daniel A. Roberts]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformers as Decision Makers: Provable In-Context Reinforcement
  Learning via Supervised Pretraining]]></title>
        <id>http://arxiv.org/abs/2310.08566</id>
        <link href="http://arxiv.org/abs/2310.08566"/>
        <updated>2023-10-13T02:24:53.412Z</updated>
        <summary type="html"><![CDATA[Licong Lin, Yu Bai, Song Mei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[preserving civilian lives is essential [reposted Guardian editorial]]]></title>
        <id>http://xianblog.wordpress.com/?p=54238</id>
        <link href="https://xianblog.wordpress.com/2023/10/13/preserving-civilian-lives-is-essential-reposted-guardian-editorial/"/>
        <updated>2023-10-12T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Developing industrial use cases for physical simulation on future error-corrected quantum computers]]></title>
        <id>http://blog.research.google/2023/10/developing-industrial-use-cases-for.html</id>
        <link href="http://blog.research.google/2023/10/developing-industrial-use-cases-for.html"/>
        <updated>2023-10-12T20:56:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Nicholas Rubin, Senior Research Scientist, and Ryan Babbush, Head of Quantum Algorithms, Quantum AI Team





If you’ve paid attention to the quantum computing space, you’ve heard the claim that in the future, quantum computers will solve certain problems exponentially more efficiently than classical computers can. They have the potential to transform many industries, from pharmaceuticals to energy.



For the most part, these claims have rested on arguments about the asymptotic scaling of algorithms as the problem size approaches infinity, but this tells us very little about the practical performance of quantum computers for finite-sized problems. We want to be more concrete: Exactly which problems are quantum computers more suited to tackle than their classical counterparts, an…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ox Demolition]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60911</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60911&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ox-demolition"/>
        <updated>2023-10-12T12:47:04.000Z</updated>
        <summary type="html"><![CDATA[From AntC: The black Chinese writing on a yellow background says: tuòhuāng niú jiànzhù qīngchāi gōnsī 拓荒牛建筑清拆公司 "bull / ox /bovine for opening up / reclaiming (waste)land for agriculture construction and demolition company" AntC, who sent this photograph to me, also included the following remarks: In my neighbourhood there’s a straggling cluster of Chinese/Asian businesses […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Machine Learning Approach for Modelling Parking Duration in Urban
  Land-use]]></title>
        <id>http://arxiv.org/abs/2008.01674</id>
        <link href="http://arxiv.org/abs/2008.01674"/>
        <updated>2023-10-12T02:19:40.575Z</updated>
        <summary type="html"><![CDATA[Janak Parmar, Pritikana Das, Sanjaykumar Dave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Change-Point Detection in Time Series via Deep Learning]]></title>
        <id>http://arxiv.org/abs/2211.03860</id>
        <link href="http://arxiv.org/abs/2211.03860"/>
        <updated>2023-10-12T02:19:40.545Z</updated>
        <summary type="html"><![CDATA[Jie Li, Paul Fearnhead, Piotr Fryzlewicz, Tengyao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Equivariant Transfer Learning from Pretrained Models]]></title>
        <id>http://arxiv.org/abs/2305.09900</id>
        <link href="http://arxiv.org/abs/2305.09900"/>
        <updated>2023-10-12T02:19:40.521Z</updated>
        <summary type="html"><![CDATA[Sourya Basu, Pulkit Katdare, Prasanna Sattigeri, Vijil
  Chenthamarakshan, Katherine Driggs-Campbell, Payel Das, Lav R. Varshney]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge Rumination for Pre-trained Language Models]]></title>
        <id>http://arxiv.org/abs/2305.08732</id>
        <link href="http://arxiv.org/abs/2305.08732"/>
        <updated>2023-10-12T02:19:40.468Z</updated>
        <summary type="html"><![CDATA[Yunzhi Yao, Peng Wang, Shengyu Mao, Chuanqi Tan, Fei Huang, Huajun
  Chen, Ningyu Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Double-Descent in Reinforcement Learning with LSTD and Random
  Features]]></title>
        <id>http://arxiv.org/abs/2310.05518</id>
        <link href="http://arxiv.org/abs/2310.05518"/>
        <updated>2023-10-12T02:19:40.400Z</updated>
        <summary type="html"><![CDATA[David Brellmann, Elo\"ise Berthier, David Filliat, Goran Frehse]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
</feed>