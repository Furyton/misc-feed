<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-07-14T15:16:50.938Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Is there no / any longer a reason / need to learn a foreign language?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59666</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59666&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=is-there-no-any-longer-a-reason-need-to-learn-a-foreign-language"/>
        <updated>2023-07-14T10:47:27.000Z</updated>
        <summary type="html"><![CDATA[Or, to put it another way, in the words of Douglas Hofstadter, Learn a Foreign Language Before It’s Too Late AI translators may seem wondrous but they also erode a major part of what it is to be human. The Atlantic (7/13/23) Hofstadter recounts how he spent years of painstaking, hard labor learning more than […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[当生成模型肆虐：互联网将有“疯牛病”之忧？]]></title>
        <id>https://kexue.fm/archives/9687</id>
        <link href="https://kexue.fm/archives/9687"/>
        <updated>2023-07-14T09:30:00.000Z</updated>
        <summary type="html"><![CDATA[众所周知，不管是文本还是视觉领域，各种生成模型正在以无法阻挡的势头“肆虐”互联网。虽然大家都明白，实现真正的通用人工智能（AGI）还有很长的路要走，但这并没有阻止人们越来越频繁地利用生成模型来创...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Emergent Neural Network Mechanisms for Generalization to Objects in
  Novel Orientations]]></title>
        <id>http://arxiv.org/abs/2109.13445</id>
        <link href="http://arxiv.org/abs/2109.13445"/>
        <updated>2023-07-14T07:15:10.868Z</updated>
        <summary type="html"><![CDATA[Avi Cooper, Xavier Boix, Daniel Harari, Spandan Madan, Hanspeter
  Pfister, Tomotake Sasaki, Pawan Sinha]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convergence of Message Passing Graph Neural Networks with Generic
  Aggregation On Large Random Graphs]]></title>
        <id>http://arxiv.org/abs/2304.11140</id>
        <link href="http://arxiv.org/abs/2304.11140"/>
        <updated>2023-07-14T07:15:10.860Z</updated>
        <summary type="html"><![CDATA[Matthieu Cordonnier, Nicolas Keriven, Nicolas Tremblay, Samuel Vaiter]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cramer Type Distances for Learning Gaussian Mixture Models by Gradient
  Descent]]></title>
        <id>http://arxiv.org/abs/2307.06753</id>
        <link href="http://arxiv.org/abs/2307.06753"/>
        <updated>2023-07-14T07:15:10.679Z</updated>
        <summary type="html"><![CDATA[Ruichong Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Neural Networks for Semiparametric Frailty Models via H-likelihood]]></title>
        <id>http://arxiv.org/abs/2307.06581</id>
        <link href="http://arxiv.org/abs/2307.06581"/>
        <updated>2023-07-14T07:15:10.012Z</updated>
        <summary type="html"><![CDATA[Hangbin Lee, IL DO HA, Youngjo Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[达观曹植大模型正式对外公测！专注于长文本、多语言、垂直化发展]]></title>
        <id>https://www.52nlp.cn/?p=13492</id>
        <link href="https://www.52nlp.cn/%e8%be%be%e8%a7%82%e6%9b%b9%e6%a4%8d%e5%a4%a7%e6%a8%a1%e5%9e%8b%e6%ad%a3%e5%bc%8f%e5%af%b9%e5%a4%96%e5%85%ac%e6%b5%8b%ef%bc%81%e4%b8%93%e6%b3%a8%e4%ba%8e%e9%95%bf%e6%96%87%e6%9c%ac%e3%80%81%e5%a4%9a-2"/>
        <updated>2023-07-14T03:37:50.000Z</updated>
        <summary type="html"><![CDATA[大模型时代到来，国内出现“百模大战”的局面。达观数据自23年3月宣布研发大语言模型以来，一直积极探索大语言模型 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Éric turns 60]]></title>
        <id>http://xianblog.wordpress.com/?p=53449</id>
        <link href="https://xianblog.wordpress.com/2023/07/14/eric-turns-60/"/>
        <updated>2023-07-13T22:05:25.000Z</updated>
        <summary type="html"><![CDATA[Conférence en l’honneur d’Eric Moulines 13-14 sept. 2023 IHP Paris (France) There will be a conference / Festschrift held for the 60th birthday of Eric Moulines [longtime friend, coauthor, ERC Synergy co-PI, whom I almost killed when missing a catch on Dent Parrachée!] at Institut Henri Poincaré, Paris, on 13 and 14 September 2023. Registration […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Symbol tuning improves in-context learning in language models]]></title>
        <id>http://ai.googleblog.com/2023/07/symbol-tuning-improves-in-context.html</id>
        <link href="http://ai.googleblog.com/2023/07/symbol-tuning-improves-in-context.html"/>
        <updated>2023-07-13T21:01:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Jerry Wei, Student Researcher, and Denny Zhou, Principal Scientist, Google Research





A key feature of human intelligence is that humans can learn to perform new tasks by reasoning using only a few examples. Scaling up language models has unlocked a range of new applications and paradigms in machine learning, including the ability to perform challenging reasoning tasks via in-context learning. Language models, however, are still sensitive to the way that prompts are given, indicating that they are not reasoning in a robust manner. For instance, language models often require heavy prompt engineering or phrasing tasks as instructions, and they exhibit unexpected behaviors such as performance on tasks being unaffected even when shown incorrect labels.


In “Symbol tuning improves…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Python源码剖析：深度探索Cpython对象-达观数据]]></title>
        <id>https://www.52nlp.cn/?p=13490</id>
        <link href="https://www.52nlp.cn/python%e6%ba%90%e7%a0%81%e5%89%96%e6%9e%90%ef%bc%9a%e6%b7%b1%e5%ba%a6%e6%8e%a2%e7%b4%a2cpython%e5%af%b9%e8%b1%a1-%e8%be%be%e8%a7%82%e6%95%b0%e6%8d%ae"/>
        <updated>2023-07-13T09:37:19.000Z</updated>
        <summary type="html"><![CDATA[CPython 是 Python 社区的标准，其他版本的 Python，比如 pypy，都会遵行 CPytho […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[达观曹植大模型正式对外公测！专注于长文本、多语言、垂直化发展]]></title>
        <id>https://www.52nlp.cn/?p=13488</id>
        <link href="https://www.52nlp.cn/%e8%be%be%e8%a7%82%e6%9b%b9%e6%a4%8d%e5%a4%a7%e6%a8%a1%e5%9e%8b%e6%ad%a3%e5%bc%8f%e5%af%b9%e5%a4%96%e5%85%ac%e6%b5%8b%ef%bc%81%e4%b8%93%e6%b3%a8%e4%ba%8e%e9%95%bf%e6%96%87%e6%9c%ac%e3%80%81%e5%a4%9a"/>
        <updated>2023-07-13T09:35:57.000Z</updated>
        <summary type="html"><![CDATA[大模型时代到来，国内出现“百模大战”的局面。达观数据自23年3月宣布研发大语言模型以来，一直积极探索大语言模型 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[一文详解新一代高效前端构建工具VITE-达观数据]]></title>
        <id>https://www.52nlp.cn/?p=13486</id>
        <link href="https://www.52nlp.cn/%e4%b8%80%e6%96%87%e8%af%a6%e8%a7%a3%e6%96%b0%e4%b8%80%e4%bb%a3%e9%ab%98%e6%95%88%e5%89%8d%e7%ab%af%e6%9e%84%e5%bb%ba%e5%b7%a5%e5%85%b7vite-%e8%be%be%e8%a7%82%e6%95%b0%e6%8d%ae"/>
        <updated>2023-07-13T09:34:15.000Z</updated>
        <summary type="html"><![CDATA[Vite 是一个快速、简单且高效的前端构建工具，它的出现为前端开发者带来了新的构建体验。在本文中，我们将探讨  […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning for Survival Analysis: A Review]]></title>
        <id>http://arxiv.org/abs/2305.14961</id>
        <link href="http://arxiv.org/abs/2305.14961"/>
        <updated>2023-07-13T07:15:20.980Z</updated>
        <summary type="html"><![CDATA[Simon Wiegrebe, Philipp Kopper, Raphael Sonabend, Bernd Bischl, and
  Andreas Bender]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Functional PCA and Deep Neural Networks-based Bayesian Inverse
  Uncertainty Quantification with Transient Experimental Data]]></title>
        <id>http://arxiv.org/abs/2307.05592</id>
        <link href="http://arxiv.org/abs/2307.05592"/>
        <updated>2023-07-13T07:15:20.974Z</updated>
        <summary type="html"><![CDATA[Ziyu Xie, Mahmoud Yaseen, Xu Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Active Subspaces and Discovering Important Features with
  Gaussian Radial Basis Functions Neural Networks]]></title>
        <id>http://arxiv.org/abs/2307.05639</id>
        <link href="http://arxiv.org/abs/2307.05639"/>
        <updated>2023-07-13T07:15:20.960Z</updated>
        <summary type="html"><![CDATA[Danny D'Agostino, Ilija Ilievski, Christine Annette Shoemaker]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Deep Learning Method for Comparing Bayesian Hierarchical Models]]></title>
        <id>http://arxiv.org/abs/2301.11873</id>
        <link href="http://arxiv.org/abs/2301.11873"/>
        <updated>2023-07-13T07:15:20.953Z</updated>
        <summary type="html"><![CDATA[Lasse Elsem\"uller, Martin Schnuerch, Paul-Christian B\"urkner, Stefan
  T. Radev]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep
  Learning]]></title>
        <id>http://arxiv.org/abs/2307.05772</id>
        <link href="http://arxiv.org/abs/2307.05772"/>
        <updated>2023-07-13T07:15:20.947Z</updated>
        <summary type="html"><![CDATA[Shireen Kudukkil Manchingal, Muhammad Mubashar, Kaizheng Wang, Keivan
  Shariatmadar, Fabio Cuzzolin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The alphabet in Kazakhstan — which one?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59654</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59654&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-alphabet-in-kazakhstan-which-one"/>
        <updated>2023-07-13T01:56:12.000Z</updated>
        <summary type="html"><![CDATA[They were already talking about this when I was in Kazakhstan twenty years ago. The ABC of alphabet reform in Kazakhstan Moving from Cyrillic-based to modified Latin script will distance the central Asian state symbolically from Russia By Tony Barber, Financial Times (7/3/23) —— It took only a few hours after my arrival in Astana, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nesnesitelná lehkost bytí]]></title>
        <id>http://xianblog.wordpress.com/?p=53499</id>
        <link href="https://xianblog.wordpress.com/2023/07/13/nesnesitelna-lehkost-byti/"/>
        <updated>2023-07-12T22:23:43.000Z</updated>
        <summary type="html"><![CDATA[Just heard that Milan Kundera, Czech-French author of The Unbearable Lightness of Being and other fantastic books had passed away on Tuesday in Paris. I still remember from the mid 1980’s the deep impression this book left on me, both as a bitter-sweet love story with the Prague Spring and its aftermath as its background, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A High-Dimensional Diameter Problem for Polytopes]]></title>
        <id>http://gilkalai.wordpress.com/?p=24636</id>
        <link href="https://gilkalai.wordpress.com/2023/07/12/a-high-dimensional-diameter-problems-for-polytopes/"/>
        <updated>2023-07-12T20:06:46.000Z</updated>
        <summary type="html"><![CDATA[Avi Wigderson is here for a year and it was a good opportunity to go back together to the question of diameter of polytopes. The diameter problem for polytopes is to determine the behavior of the maximum diameter of the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A High-Dimensional Diameter Problem for Polytopes]]></title>
        <id>http://gilkalai.wordpress.com/?p=24636</id>
        <link href="https://gilkalai.wordpress.com/2023/07/12/a-high-dimensional-diameter-problems-for-polytopes/"/>
        <updated>2023-07-12T20:06:46.000Z</updated>
        <summary type="html"><![CDATA[Avi Wigderson is here for a year and it was a good opportunity to go back together to the question of diameter of polytopes. The diameter problem for polytopes is to determine the behavior of the maximum diameter of the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Selective Sampling and Imitation Learning via Online Regression]]></title>
        <id>http://arxiv.org/abs/2307.04998</id>
        <link href="http://arxiv.org/abs/2307.04998"/>
        <updated>2023-07-12T07:15:23.615Z</updated>
        <summary type="html"><![CDATA[Ayush Sekhari, Karthik Sridharan, Wen Sun, Runzhe Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reconstructing Kernel-based Machine Learning Force Fields with
  Super-linear Convergence]]></title>
        <id>http://arxiv.org/abs/2212.12737</id>
        <link href="http://arxiv.org/abs/2212.12737"/>
        <updated>2023-07-12T07:15:22.611Z</updated>
        <summary type="html"><![CDATA[Stefan Bl\"ucher, Klaus-Robert M\"uller, Stefan Chmiela]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially Private Statistical Inference through $\beta$-Divergence
  One Posterior Sampling]]></title>
        <id>http://arxiv.org/abs/2307.05194</id>
        <link href="http://arxiv.org/abs/2307.05194"/>
        <updated>2023-07-12T07:15:22.605Z</updated>
        <summary type="html"><![CDATA[Jack Jewson, Sahra Ghalebikesabi, Chris Holmes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Used to be a bun]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59639</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59639&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=used-to-be-a-bun"/>
        <updated>2023-07-12T04:59:29.000Z</updated>
        <summary type="html"><![CDATA[Dunhuang (see here and here) is turning out to be a Chinglish goldmine.  Maybe that's because it's so far out in the remote, desolate, desert northwest. The Chinese label says: hóngdòu xiǎo ruǎnbāo 紅豆小軟包 "red bean small soft bun" The printing is nice. Selected readings "Somking" (7/7/23) "More savory Chinglish from Dunhuang" (7/9/23) "Baozi: The stuffed, steamed bun […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spellbound]]></title>
        <id>http://xianblog.wordpress.com/?p=53438</id>
        <link href="https://xianblog.wordpress.com/2023/07/12/spellbound/"/>
        <updated>2023-07-11T22:23:01.000Z</updated>
        <summary type="html"><![CDATA[Reading in Le Monde the news that Siouxie had sung at the Eurockéennes de Belfort reminded of her first albums that I played endlessly. With The Banshees and a certain Robert Smith as an occasional guitarist… Highly innovative punk rock announcing the New Wave and mesmerising voice.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The etiology of a self-inflicted earworm]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59651</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59651&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-etiology-of-a-self-inflicted-earworm"/>
        <updated>2023-07-11T18:01:40.000Z</updated>
        <summary type="html"><![CDATA[I am prone / prey to earworms.  Sometimes when I'm seriously affected / infected by one, it takes me weeks to get rid of the scourge, and I have to resort to all sorts of devices and deceptions to disinfect them from the space between my ears and the auditory cortex inside the lateral sulcus […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An open-source gymnasium for machine learning assisted computer architecture design]]></title>
        <id>http://ai.googleblog.com/2023/07/an-open-source-gymnasium-for-computer.html</id>
        <link href="http://ai.googleblog.com/2023/07/an-open-source-gymnasium-for-computer.html"/>
        <updated>2023-07-11T17:00:00.005Z</updated>
        <summary type="html"><![CDATA[Posted by Amir Yazdanbakhsh, Research Scientist, and Vijay Janapa Reddi, Visiting Researcher, Google Research




Computer Architecture research has a long history of developing simulators and tools to evaluate and shape the design of computer systems. For example, the SimpleScalar simulator was introduced in the late 1990s and allowed researchers to explore various microarchitectural ideas. Computer architecture simulators and tools, such as gem5, DRAMSys, and many more have played a significant role in advancing computer architecture research. Since then, these shared resources and infrastructure have benefited industry and academia and have enabled researchers to systematically build on each other's work, leading to significant advances in the field. 



Nonetheless, computer architectu…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The growing supinity of Chinese youth]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59648</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59648&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-growing-supinity-of-chinese-youth"/>
        <updated>2023-07-11T11:22:15.000Z</updated>
        <summary type="html"><![CDATA["Lying flat", "Buddha whatever", "Kong Yijiism", "involution" — China today has so many memes for opting out.  Helen Gao explains the reasons for their profusion: How China’s Education System Trapped a Generation Young people have been trained into competition and hopelessness. Foreign Policy (6/22/23) —– From 2003 to 2005, I was a student at rendafuzhong […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Prediction with Large Language Models for Multi-Choice
  Question Answering]]></title>
        <id>http://arxiv.org/abs/2305.18404</id>
        <link href="http://arxiv.org/abs/2305.18404"/>
        <updated>2023-07-11T07:15:38.013Z</updated>
        <summary type="html"><![CDATA[Bhawesh Kumar, Charlie Lu, Gauri Gupta, Anil Palepu, David Bellamy,
  Ramesh Raskar, Andrew Beam]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning-Rate-Free Learning by D-Adaptation]]></title>
        <id>http://arxiv.org/abs/2301.07733</id>
        <link href="http://arxiv.org/abs/2301.07733"/>
        <updated>2023-07-11T07:15:38.007Z</updated>
        <summary type="html"><![CDATA[Aaron Defazio, Konstantin Mishchenko]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DORA: Exploring Outlier Representations in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2206.04530</id>
        <link href="http://arxiv.org/abs/2206.04530"/>
        <updated>2023-07-11T07:15:38.000Z</updated>
        <summary type="html"><![CDATA[Kirill Bykov, Mayukh Deb, Dennis Grinwald, Klaus-Robert M\"uller,
  Marina M.-C. H\"ohne]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Learners for Realizable Regression: PAC Learning and Online
  Learning]]></title>
        <id>http://arxiv.org/abs/2307.03848</id>
        <link href="http://arxiv.org/abs/2307.03848"/>
        <updated>2023-07-11T07:15:37.994Z</updated>
        <summary type="html"><![CDATA[Idan Attias, Steve Hanneke, Alkis Kalavasis, Amin Karbasi, Grigoris
  Velegkas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[URL: A Representation Learning Benchmark for Transferable Uncertainty
  Estimates]]></title>
        <id>http://arxiv.org/abs/2307.03810</id>
        <link href="http://arxiv.org/abs/2307.03810"/>
        <updated>2023-07-11T07:15:37.984Z</updated>
        <summary type="html"><![CDATA[Michael Kirchhof, B\'alint Mucs\'anyi, Seong Joon Oh and
  Enkelejda Kasneci]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring institutions for global AI governance]]></title>
        <id>https://www.deepmind.com/blog/exploring-institutions-for-global-ai-governance</id>
        <link href="https://www.deepmind.com/blog/exploring-institutions-for-global-ai-governance"/>
        <updated>2023-07-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI. Growing awareness of the global impact of advanced artificial intelligence (AI) has inspired public discussions about the need for international governance structures to help manage opportunities and mitigate risks involved. Many discussions have drawn on analogies with the ICAO (International Civil Aviation Organization) in civil aviation; CERN (European Organization for Nuclear Research) in particle physics; IAEA (International Atomic Energy Agency) in nuclear technology, and intergovernmental and multi-stakeholder organisations in many other domains. And yet, while analogies can be a useful start, the technologies emerging from AI will be unlike aviation, particle physics, or nuclear technology. To succeed with AI governance, we need to better understand: what specific benefits and risks we need to manage internationally, what governance functions those benefits and risks require, what organisations can best provide those functions.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=53416</id>
        <link href="https://xianblog.wordpress.com/2023/07/11/a-journal-of-the-conquest-war-famine-and-death-year-2/"/>
        <updated>2023-07-10T22:23:57.000Z</updated>
        <summary type="html"><![CDATA[Read Les chiens et la charrue (Le cycle de Syffe, tome 3 ) by Patrick K. Dewdney, which came out after a long hiatus (esp. when missing the parution in September 2021!). It thus proved hard to remember the complex structure of this universe, as well as the names of characters from the earlier volumes. […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Asking ChatGPT: If the regime of the state of Israel would become dictatorial give five reasons why this may endanger the world.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24628</id>
        <link href="https://gilkalai.wordpress.com/2023/07/11/asking-chatgpt-if-the-regime-of-the-state-of-israel-would-become-dictatorial-give-five-reasons-why-this-may-endanger-the-world/"/>
        <updated>2023-07-10T22:06:46.000Z</updated>
        <summary type="html"><![CDATA[Regional Instability: Israel is situated in a highly volatile region, and any shift towards a dictatorial regime could potentially exacerbate existing conflicts and tensions. A dictatorial government in Israel may pursue aggressive policies, leading to increased regional instability and potential … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Asking ChatGPT: If the regime of the state of Israel would become dictatorial give five reasons why this may endanger the world.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24628</id>
        <link href="https://gilkalai.wordpress.com/2023/07/11/asking-chatgpt-if-the-regime-of-the-state-of-israel-would-become-dictatorial-give-five-reasons-why-this-may-endanger-the-world/"/>
        <updated>2023-07-10T22:06:46.000Z</updated>
        <summary type="html"><![CDATA[Regional Instability: Israel is situated in a highly volatile region, and any shift towards a dictatorial regime could potentially exacerbate existing conflicts and tensions. A dictatorial government in Israel may pursue aggressive policies, leading to increased regional instability and potential … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two’s Complement and Group Theory]]></title>
        <id>https://jeremykun.com/?p=119571</id>
        <link href="https://jeremykun.com/2023/07/10/twos-complement-and-group-theory/"/>
        <updated>2023-07-10T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Before I discovered math, I was a first year undergrad computer science student taking Electrical Engineering 101. The first topic I learned was what bits and boolean gates are, and the second was the two’s complement representation of a negative n-bit integer. At the time two’s complement seemed to me like a bizarre quirk of […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at ACL 2023]]></title>
        <id>http://ai.googleblog.com/2023/07/google-at-acl-2023.html</id>
        <link href="http://ai.googleblog.com/2023/07/google-at-acl-2023.html"/>
        <updated>2023-07-10T13:02:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Malaya Jules, Program Manager, Google




  This week, the 61st annual meeting of the Association for Computational Linguistics (ACL), a premier conference covering a broad spectrum of research areas that are concerned with computational approaches to natural language, is taking place online.


  As a leader in natural language processing and understanding, and a Diamond Level sponsor of ACL 2023, Google will showcase the latest research in the field with over 50 publications, and active involvement in a variety of workshops and tutorials.
bold).
 

Board and Organizing Committee
Dan Garrette

Workshop chairs include: Annie Louis

Publication chairs include: Lei Shu

Program Committee includes: Vinodkumar Prabhakaran, Najoung Kim, Markus Freitag


 

Spotlight papers
NusaCrowd: O…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Stepwise Nature of <br> Self-Supervised Learning]]></title>
        <id>http://bair.berkeley.edu/blog/2023/07/10/stepwise-ssl/</id>
        <link href="http://bair.berkeley.edu/blog/2023/07/10/stepwise-ssl/"/>
        <updated>2023-07-10T09:00:00.000Z</updated>
        <summary type="html"><![CDATA[Figure 1: stepwise behavior in self-supervised learning. When training common SSL algorithms, we find that the loss descends in a stepwise fashion (top left) and the learned embeddings iteratively increase in dimensionality (bottom left). Direct visualization of embeddings (right; top three PCA directions shown) confirms that embeddings are initially collapsed to a point, which then expands to a 1D manifold, a 2D manifold, and beyond concurrently with steps in the loss.

It is widely believed that deep learning’s stunning success is due in part to its ability to discover and extract useful representations of complex data. Self-supervised learning (SSL) has emerged as a leading framework for learning these representations for images directly from unlabeled data, similar to how LLMs learn re…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Black-Box Batch Active Learning for Regression]]></title>
        <id>http://arxiv.org/abs/2302.08981</id>
        <link href="http://arxiv.org/abs/2302.08981"/>
        <updated>2023-07-10T07:16:12.822Z</updated>
        <summary type="html"><![CDATA[Andreas Kirsch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MALIBO: Meta-learning for Likelihood-free Bayesian Optimization]]></title>
        <id>http://arxiv.org/abs/2307.03565</id>
        <link href="http://arxiv.org/abs/2307.03565"/>
        <updated>2023-07-10T07:16:12.528Z</updated>
        <summary type="html"><![CDATA[Jiarong Pan, Stefan Falkner, Felix Berkenkamp, Joaquin Vanschoren]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Backward Feature Correction: How Deep Learning Performs Deep
  (Hierarchical) Learning]]></title>
        <id>http://arxiv.org/abs/2001.04413</id>
        <link href="http://arxiv.org/abs/2001.04413"/>
        <updated>2023-07-10T07:16:12.521Z</updated>
        <summary type="html"><![CDATA[Zeyuan Allen-Zhu, Yuanzhi Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multiclass Online Learning and Uniform Convergence]]></title>
        <id>http://arxiv.org/abs/2303.17716</id>
        <link href="http://arxiv.org/abs/2303.17716"/>
        <updated>2023-07-10T07:16:12.506Z</updated>
        <summary type="html"><![CDATA[Steve Hanneke, Shay Moran, Vinod Raman, Unique Subedi, Ambuj Tewari]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Theory of Distribution Regression with Neural Networks]]></title>
        <id>http://arxiv.org/abs/2307.03487</id>
        <link href="http://arxiv.org/abs/2307.03487"/>
        <updated>2023-07-10T07:16:12.490Z</updated>
        <summary type="html"><![CDATA[Zhongjie Shi, Zhan Yu, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to Accelerate PyTorch Geometric on Intel® CPUs]]></title>
        <id>https://pytorch.org/blog/how-to-accelerate/</id>
        <link href="https://pytorch.org/blog/how-to-accelerate/"/>
        <updated>2023-07-10T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Overview]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A lupine crash blossom from the Netherlands]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59632</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59632&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-lupine-crash-blossom-from-the-netherlands"/>
        <updated>2023-07-10T03:00:20.000Z</updated>
        <summary type="html"><![CDATA[Headline from NL Times (9 July 2023): "Sheep farmer injured after wolf attack in Wapse, ordered to be shot." Poor sheep farmer; our condolences to his family. Selected readings "Vocalizations of wolves and justices" (2/17/23) "Year of the ovicaprid" (2/15/15) [Thanks to Jonathan Silk]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[More savory Chinglish from Dunhuang:]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59622</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59622&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=more-savory-chinglish-from-dunhuang"/>
        <updated>2023-07-10T02:26:05.000Z</updated>
        <summary type="html"><![CDATA[More savory Chinglish from Dunhuang: lāo zhī qiāncéng dù 捞汁千层肚 "thousand-layered tripe scooped from broth" gàn bàn shùnfēng ěr 干拌顺风耳 "dry mixed clairaudient (pig) ears" N.B.:  When Chinese eat the ears of an animal, it's usually those of pigs.  To prettify the pigs' ears, they style them "clairaudient".  No mention of chili sauce in the Chinese. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The easiest way to speed up Python with Rust]]></title>
        <id>https://pythonspeed.com/articles/easiest-rust-python/</id>
        <link href="https://pythonspeed.com/articles/easiest-rust-python/"/>
        <updated>2023-07-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[If you want to speed up some existing Python code, writing a compiled extension in Rust can be an excellent choice:
In many situations, Rust code can run much faster than Python.
Rust prevents most of the memory-management bugs that often occur in C, C++, and Cython code.
There is a growing ecosystem of third-party Rust packages available, and unlike C and C++ it also has a built-in package manager and build system.
However, if you just want to prototype a Rust extension, packaging and integration boilerplate can get in the way: every extra bit of friction prevents you from just doing the experiment of whether or not Rust will help.
This is where rustimport comes in, a library that makes standalone Rust files easily importable in Python (currently only on Linux and macOS).
In this article we’ll cover:
How to use rustimport to quickly try out your Rust code.
The most common performance mistake Rust beginners make, and how to avoid it.
Some gotchas when using rustimport.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ban on cluster bombs]]></title>
        <id>http://xianblog.wordpress.com/?p=53481</id>
        <link href="https://xianblog.wordpress.com/2023/07/10/ban-on-cluster-bombs/"/>
        <updated>2023-07-09T22:23:38.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Old Sinitic "rice", with an added note on "leopard"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59629</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59629&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=old-sinitic-rice-with-an-added-note-on-leopard"/>
        <updated>2023-07-09T11:38:23.000Z</updated>
        <summary type="html"><![CDATA[We've had extensive discussions about the Old Sinitic reconstruction of the Sinitic word for "wheat".  Although we've been circling around it for quite some time now, we haven't yet nailed it down securely, but we're close.  While we're still occupied with "wheat", Martin Schwartz sends in this terse, seemingly cryptic, but extremely interesting information about […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Three principles for modernizing an undergraduate regression analysis
  course]]></title>
        <id>http://arxiv.org/abs/2205.11026</id>
        <link href="http://arxiv.org/abs/2205.11026"/>
        <updated>2023-07-09T07:14:24.887Z</updated>
        <summary type="html"><![CDATA[Maria Tackett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unstable higher Toda brackets III]]></title>
        <id>http://arxiv.org/abs/2201.05255</id>
        <link href="http://arxiv.org/abs/2201.05255"/>
        <updated>2023-07-09T07:14:24.882Z</updated>
        <summary type="html"><![CDATA[Hideaki Ooshima, Katsumi Oshima]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[poem about a crow [Victoria Amelina, 1986-2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=53433</id>
        <link href="https://xianblog.wordpress.com/2023/07/09/poem-about-a-crow-victoria-amelina-1986-2023/"/>
        <updated>2023-07-08T22:23:15.000Z</updated>
        <summary type="html"><![CDATA[Poem About a Crow In a barren springtime field Stands a woman dressed in black Crying her sisters’ names Like a bird in the empty sky She’ll cry them all out of herself The one that flew away too soon The one that had begged to die The one that couldn’t stop death The one […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Somking]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59618</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59618&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=somking"/>
        <updated>2023-07-08T04:50:13.000Z</updated>
        <summary type="html"><![CDATA[Sign at Dunhuang, at the western end of the Gansu Corridor in northwestern China, where I did my doctoral research more than half a century ago (there were no signs like this in those days): The sign says: qǐng wù xīyān 请勿吸烟 "Please do not smoke" Easiest Chinglish I ever had to figure out. Selected readings *Chinese 'No […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[another fine…]]></title>
        <id>http://xianblog.wordpress.com/?p=53375</id>
        <link href="https://xianblog.wordpress.com/2023/07/08/another-fine/"/>
        <updated>2023-07-07T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformers as Statisticians: Provable In-Context Learning with
  In-Context Algorithm Selection]]></title>
        <id>http://arxiv.org/abs/2306.04637</id>
        <link href="http://arxiv.org/abs/2306.04637"/>
        <updated>2023-07-07T21:14:12.881Z</updated>
        <summary type="html"><![CDATA[Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modular visual question answering via code generation]]></title>
        <id>http://ai.googleblog.com/2023/07/modular-visual-question-answering-via.html</id>
        <link href="http://ai.googleblog.com/2023/07/modular-visual-question-answering-via.html"/>
        <updated>2023-07-07T18:01:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Sanjay Subramanian, PhD student, UC Berkeley, and Arsha Nagrani, Research Scientist, Google Research, Perception Team




Visual question answering (VQA) is a machine learning task that requires a model to answer a question about an image or a set of images. Conventional VQA approaches need a large amount of labeled training data consisting of thousands of human-annotated question-answer pairs associated with images. In recent years, advances in large-scale pre-training have led to the development of VQA methods that perform well with fewer than fifty training examples (few-shot) and without any human-annotated VQA training data (zero-shot). However, there is still a significant performance gap between these methods and state-of-the-art fully supervised VQA methods, such as MaMMU…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ptahhatp's proverbs]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59587</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59587&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ptahhatps-proverbs"/>
        <updated>2023-07-07T15:57:05.000Z</updated>
        <summary type="html"><![CDATA[From the Wall Street Journal ‘The Oldest Book in the World’ Review: Also Sprach Ptahhatp A set of maxims attributed to an adviser of an Egyptian pharaoh may be the world’s earliest surviving work of philosophy. By Dominic Green July 6, 2023 6:20 pm ET What have we?  Philosophy in the Age of the Pyramids?  […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The LLM-detection boom]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59607</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59607&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-llm-detection-boom"/>
        <updated>2023-07-07T12:49:58.000Z</updated>
        <summary type="html"><![CDATA[Joe Marshall, "As AI cheating booms, so does the industry detecting it: ‘We couldn’t keep up with demand’", The Guardian 7/5/2023: Since its release last November, ChatGPT has shaken the education world. The chatbot and other sophisticated AI tools are reportedly being used everywhere from college essays to high school art projects. A recent survey […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepOnto: A Python Package for Ontology Engineering with Deep Learning]]></title>
        <id>http://arxiv.org/abs/2307.03067</id>
        <link href="http://arxiv.org/abs/2307.03067"/>
        <updated>2023-07-07T07:15:13.946Z</updated>
        <summary type="html"><![CDATA[Yuan He, Jiaoyan Chen, Hang Dong, Ian Horrocks, Carlo Allocca, Taehun
  Kim, Brahmananda Sapkota]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit
  for Purpose?]]></title>
        <id>http://arxiv.org/abs/2307.02732</id>
        <link href="http://arxiv.org/abs/2307.02732"/>
        <updated>2023-07-07T07:15:13.939Z</updated>
        <summary type="html"><![CDATA[Lu\'isa Shimabucoro, Timothy Hospedales, Henry Gouk]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical-Computational Tradeoffs in Mixed Sparse Linear Regression]]></title>
        <id>http://arxiv.org/abs/2303.02118</id>
        <link href="http://arxiv.org/abs/2303.02118"/>
        <updated>2023-07-07T07:15:13.931Z</updated>
        <summary type="html"><![CDATA[Gabriel Arpino, Ramji Venkataramanan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Low-Dimensional Nonlinear Structures from High-Dimensional
  Noisy Data: An Integral Operator Approach]]></title>
        <id>http://arxiv.org/abs/2203.00126</id>
        <link href="http://arxiv.org/abs/2203.00126"/>
        <updated>2023-07-07T07:15:13.910Z</updated>
        <summary type="html"><![CDATA[Xiucai Ding, Rong Ma]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Boatswain]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59573</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59573&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=boatswain"/>
        <updated>2023-07-07T05:59:14.000Z</updated>
        <summary type="html"><![CDATA[This picture troubled me: (source) It seems that the person at the right side of the photograph is saluting with his left hand.  I wondered whether that is permissible in the armed forces? I asked Captain James Fanell, a retired high-ranking naval officer in the Pacific Fleet, how to explain the saluting behavior of this […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Welcome to MCM 2025]]></title>
        <id>http://xianblog.wordpress.com/?p=53400</id>
        <link href="https://xianblog.wordpress.com/2023/07/07/welcome-to-mcm-2025/"/>
        <updated>2023-07-06T22:23:06.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language as a (nonviolent) weapon]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59590</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59590&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-as-a-nonviolent-weapon"/>
        <updated>2023-07-06T20:38:48.000Z</updated>
        <summary type="html"><![CDATA[From the movie "Jak rozpętałem drugą wojnę światową" (How I Unleashed World War II): The initial Q&A: Your browser does not support the audio element. Q: Name und Vorname? A: Grzegorz Brzęczyszczykiewicz. Waveform, spectrogram, F0 track: Just the answer: Your browser does not support the audio element. "Birthplace" Q&A, at the end of the scene: […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pic2Word: Mapping pictures to words for zero-shot composed image retrieval]]></title>
        <id>http://ai.googleblog.com/2023/07/pic2word-mapping-pictures-to-words-for.html</id>
        <link href="http://ai.googleblog.com/2023/07/pic2word-mapping-pictures-to-words-for.html"/>
        <updated>2023-07-06T19:50:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Kuniaki Saito, Student Researcher, Google Research, Cloud AI Team, and Kihyuk Sohn, Research Scientist, Google Research





Image retrieval plays a crucial role in search engines. Typically, their users rely on either image or text as a query to retrieve a desired target image. However, text-based retrieval has its limitations, as describing the target image accurately using words can be challenging. For instance, when searching for a fashion item, users may want an item whose specific attribute, e.g., the color of a logo or the logo itself, is different from what they find in a website. Yet searching for the item in an existing search engine is not trivial since precisely describing the fashion item by text can be challenging. To address this fact, composed image retrieval (CIR…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Impressive speech in Taiwanese by Australian representative]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59528</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59528&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=impressive-speech-in-taiwanese-by-australian-representative"/>
        <updated>2023-07-06T12:45:47.000Z</updated>
        <summary type="html"><![CDATA[Over the last three years, I have seen first-hand Taiwan’s rich diversity and resilience and experienced the warmth, friendship, support and hospitality of the Taiwanese people. As I prepare to return to my hometown #Melbourne in the coming weeks, see my message in Taiwanese: pic.twitter.com/oSZ1hKp6Jx — Jenny Bloomfield (@AusOfficeTPE) July 4, 2023 With subtitles in […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Progress]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59531</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59531&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=progress"/>
        <updated>2023-07-06T10:34:58.000Z</updated>
        <summary type="html"><![CDATA[The next-most-recent xkcd: Mouseover title: "Slowly progressing from 'how do protons behave in relativistic collisions?' to 'what the heck are protons even doing when they're just sitting there?'" This progression accords with most of my professional experience — for one example, see my 2018 paper "Towards Progress in Theories of Language Sound Structure", in Brentari […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer升级之路：10、RoPE是一种β进制编码]]></title>
        <id>https://kexue.fm/archives/9675</id>
        <link href="https://kexue.fm/archives/9675"/>
        <updated>2023-07-06T03:53:00.000Z</updated>
        <summary type="html"><![CDATA[对关心如何扩展LLM的Context长度的读者来说，上周无疑是激动人心的一周，开源社区接连不断地出现令人振奋的成果。首先，网友@kaiokendev在他的项目SuperHOT中实验了“位置线性内...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Comparison of Machine Learning Methods for Data with High-Cardinality
  Categorical Variables]]></title>
        <id>http://arxiv.org/abs/2307.02071</id>
        <link href="http://arxiv.org/abs/2307.02071"/>
        <updated>2023-07-06T01:43:31.042Z</updated>
        <summary type="html"><![CDATA[Fabio Sigrist]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Learning Adversarial Bandit Algorithms]]></title>
        <id>http://arxiv.org/abs/2307.02295</id>
        <link href="http://arxiv.org/abs/2307.02295"/>
        <updated>2023-07-06T01:43:31.038Z</updated>
        <summary type="html"><![CDATA[Mikhail Khodak, Ilya Osadchiy, Keegan Harris, Maria-Florina Balcan,
  Kfir Y. Levy, Ron Meir, Zhiwei Steven Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Neural Collapse Perspective on Feature Evolution in Graph Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2307.01951</id>
        <link href="http://arxiv.org/abs/2307.01951"/>
        <updated>2023-07-06T01:43:30.940Z</updated>
        <summary type="html"><![CDATA[Vignesh Kothapalli, Tom Tirer, Joan Bruna]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Learning for Simple Regret Minimization]]></title>
        <id>http://arxiv.org/abs/2202.12888</id>
        <link href="http://arxiv.org/abs/2202.12888"/>
        <updated>2023-07-06T01:43:28.199Z</updated>
        <summary type="html"><![CDATA[Mohammadjavad Azizi, Branislav Kveton, Mohammad Ghavamzadeh, Sumeet
  Katariya]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Deep Neural Networks Learn Compositional Data: The Random Hierarchy
  Model]]></title>
        <id>http://arxiv.org/abs/2307.02129</id>
        <link href="http://arxiv.org/abs/2307.02129"/>
        <updated>2023-07-06T01:43:28.194Z</updated>
        <summary type="html"><![CDATA[Leonardo Petrini, Francesco Cagnetta, Umberto M. Tomasini, Alessandro
  Favero, Matthieu Wyart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI without human oversight]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59501</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59501&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-without-human-oversight"/>
        <updated>2023-07-05T23:00:52.000Z</updated>
        <summary type="html"><![CDATA[Despite the panic over AI we're seeing in many sectors of society, including academia, the juggernaut rolls on, seeming set to crush everything in its way: "EU gives more power to AI translation machines" The European Commission has launched a pilot project to translate some press releases without any human oversight. POLITICO (6/15/23) First paragraphs: […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[IMS Carver Award 2023]]></title>
        <id>http://xianblog.wordpress.com/?p=53394</id>
        <link href="https://xianblog.wordpress.com/2023/07/06/ims-carver-award-2023/"/>
        <updated>2023-07-05T22:23:15.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alan Turing's revenge?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59521</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59521&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=alan-turings-revenge"/>
        <updated>2023-07-05T20:15:50.000Z</updated>
        <summary type="html"><![CDATA[Ilia Shumailov et al., "The Curse of Recursion: Training on Generated Data Makes Models Forget", 5/31/2023: What will happen to GPT-{n} once LLMs contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[It's impossible to detect LLM-created text]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59512</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59512&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=its-impossible-to-detect-llm-created-text"/>
        <updated>2023-07-05T13:01:21.000Z</updated>
        <summary type="html"><![CDATA[Last year, I expressed considerable skepticism about the prospects for accurate detection of text generated by Large Language Models ("Detecting LLM-created essays?", 12/20/2022). Since then, many new systems claiming to detect LLM outputs have emerged, notably Turnitin's "AI writing detector". In a recent post on AI Weirdness ("Don't use AI detectors for anything important", 6/30/2023), […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My garden path of the day]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59507</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59507&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=my-garden-path-of-the-day"/>
        <updated>2023-07-05T11:30:40.000Z</updated>
        <summary type="html"><![CDATA["Alligator Kills 69-Year-Old Woman in South Carolina", NYT 7/4/2023: A 69-year-old woman was attacked and killed by an alligator on Tuesday as she was walking her dog in her neighborhood in Hilton Head Island, S.C., the authorities said. The Beaufort County Sheriff’s Office said it was the second fatal alligator attack in the county in […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Communism" in Korean]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59497</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59497&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=communism-in-korean"/>
        <updated>2023-07-05T09:49:50.000Z</updated>
        <summary type="html"><![CDATA[As I have demonstrated here, communism is still very much a thing in North Korea, and apparently under the leadership of Kim Jung Un increasingly more so. Now, the word for "communism" in the Korean of South Korea is gongsanjuui 공산주의 (共産主義), which simply adopts the Chinese gòngchǎn zhǔyì 共産主義. Since that usage goes against […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ageein’ dogz]]></title>
        <id>http://xianblog.wordpress.com/?p=53387</id>
        <link href="https://xianblog.wordpress.com/2023/07/05/ageein-dogz/"/>
        <updated>2023-07-04T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[While eating a quick lunch in the CEREMADE common room, I came across an older Nature paper of 3 Feb 2022 on the Dog Aging Project, a longitudinal study of domestic dogs. Describing the goal and design of the project rather than its yet to come findings. The population is made of self-nominated (US) dog […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transitive "blink"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59494</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59494&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=transitive-blink"/>
        <updated>2023-07-04T11:14:19.000Z</updated>
        <summary type="html"><![CDATA[Reader Scott Mauldin asks: I am curious about a unique usage I read in SCOTUS Justice Ketanji Jackson's dissent to the recent cases on affirmative action. She says  “This contention blinks both history and reality in ways too numerous to count.” To me, the usage of "blink" as an transitive verb to mean [I assume] […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Hidden Markov Models When the Locations of Missing Observations
  are Unknown]]></title>
        <id>http://arxiv.org/abs/2203.06527</id>
        <link href="http://arxiv.org/abs/2203.06527"/>
        <updated>2023-07-04T07:15:58.780Z</updated>
        <summary type="html"><![CDATA[Binyamin Perets, Mark Kozdoba, Shie Mannor]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Morse Neural Networks for Uncertainty Quantification]]></title>
        <id>http://arxiv.org/abs/2307.00667</id>
        <link href="http://arxiv.org/abs/2307.00667"/>
        <updated>2023-07-04T07:15:58.775Z</updated>
        <summary type="html"><![CDATA[Benoit Dherin, Huiyi Hu, Jie Ren, Michael W. Dusenberry, Balaji
  Lakshminarayanan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Worth of knowledge in deep learning]]></title>
        <id>http://arxiv.org/abs/2307.00712</id>
        <link href="http://arxiv.org/abs/2307.00712"/>
        <updated>2023-07-04T07:15:58.770Z</updated>
        <summary type="html"><![CDATA[Hao Xu, Yuntian Chen, Dongxiao Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified Transfer Learning Models for High-Dimensional Linear Regression]]></title>
        <id>http://arxiv.org/abs/2307.00238</id>
        <link href="http://arxiv.org/abs/2307.00238"/>
        <updated>2023-07-04T07:15:58.760Z</updated>
        <summary type="html"><![CDATA[Shuo Shuo Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ISB’agoya [28 June – 3 July 2026]]]></title>
        <id>http://xianblog.wordpress.com/?p=53383</id>
        <link href="https://xianblog.wordpress.com/2023/07/04/isbagoya-28-june-3-july-2026/"/>
        <updated>2023-07-03T22:23:24.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In North Korea, it's a dire crime to speak like a South Korean, part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59489</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59489&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=in-north-korea-its-a-dire-crime-to-speak-like-a-south-korean-part-2"/>
        <updated>2023-07-03T15:10:28.000Z</updated>
        <summary type="html"><![CDATA[This is a language war that has been going on for years, and there will never be an end to it, so long as there is a communist North Korea and a democratic South Korea.  It is as deadly as a shooting war, because people die for using the language of the enemy.  I'm not […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why Shallow Networks Struggle with Approximating and Learning High
  Frequency: A Numerical Study]]></title>
        <id>http://arxiv.org/abs/2306.17301</id>
        <link href="http://arxiv.org/abs/2306.17301"/>
        <updated>2023-07-03T07:15:41.725Z</updated>
        <summary type="html"><![CDATA[Shijun Zhang, Hongkai Zhao, Yimin Zhong, Haomin Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Characteristic Activation Value Analysis for Improved ReLU
  Network Feature Learning]]></title>
        <id>http://arxiv.org/abs/2305.15912</id>
        <link href="http://arxiv.org/abs/2305.15912"/>
        <updated>2023-07-03T07:15:41.720Z</updated>
        <summary type="html"><![CDATA[Wenlin Chen, Hong Ge]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Limits of Model Selection under Transfer Learning]]></title>
        <id>http://arxiv.org/abs/2305.00152</id>
        <link href="http://arxiv.org/abs/2305.00152"/>
        <updated>2023-07-03T07:15:41.705Z</updated>
        <summary type="html"><![CDATA[Steve Hanneke, Samory Kpotufe, Yasaman Mahdaviyeh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive
  Noise Models]]></title>
        <id>http://arxiv.org/abs/2306.17361</id>
        <link href="http://arxiv.org/abs/2306.17361"/>
        <updated>2023-07-03T07:15:41.700Z</updated>
        <summary type="html"><![CDATA[Tianyu Chen, Kevin Bello, Bryon Aragam, Pradeep Ravikumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uncertainty Estimation by Fisher Information-based Evidential Deep
  Learning]]></title>
        <id>http://arxiv.org/abs/2303.02045</id>
        <link href="http://arxiv.org/abs/2303.02045"/>
        <updated>2023-07-03T07:15:40.186Z</updated>
        <summary type="html"><![CDATA[Danruo Deng, Guangyong Chen, Yang Yu, Furui Liu, Pheng-Ann Heng]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[in absurdum]]></title>
        <id>http://xianblog.wordpress.com/?p=53391</id>
        <link href="https://xianblog.wordpress.com/2023/07/03/in-absurdum/"/>
        <updated>2023-07-02T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[“Il conduisait sans permis mais c’est un non sujet, vous avez vu comme moi que le gouvernement comptait faire passer l’âge du permis à 17 ans, alors bon…” J. Cambla, lawyer. A few cars (and a bike!) were set on fire and a supermarket was looted just a block from home, on Thursday night, in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Xi Jinping's faux classicism]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59485</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59485&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=xi-jinpings-faux-classicism"/>
        <updated>2023-07-02T17:32:06.000Z</updated>
        <summary type="html"><![CDATA[This new article in The Economist (6/29/23) has a familiar ring to it: To understand Xi Jinping, it helps to be steeped in the classics China’s leader has invented a phrase—and an image Take four Chinese characters, all of them in everyday use. Put them in a certain order and, lo, they become a phrase […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[нет войнe]]></title>
        <id>http://xianblog.wordpress.com/?p=53312</id>
        <link href="https://xianblog.wordpress.com/2023/07/02/%d0%bd%d0%b5-%d0%b2%d0%be%d0%b9%d0%bde/"/>
        <updated>2023-07-01T22:23:48.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Antakshari recitation in India]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59476</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59476&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=antakshari-recitation-in-india"/>
        <updated>2023-07-01T13:10:15.000Z</updated>
        <summary type="html"><![CDATA[This is part of a long series of Language Log posts in which we pondered the phenomenal memorization skills of persons of Indian heritage (see "Selected readings" below). So you know what's happening in the following astonishing video, let me begin by giving a basic definition, etymology, and explication of what happens in this intricate […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[统计月读（2023 年 5-6 月）]]></title>
        <id>https://cosx.org/2023/07/monthly/</id>
        <link href="https://cosx.org/2023/07/monthly/"/>
        <updated>2023-07-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[推荐语：一些活跃的线上研讨会网站：Online Causal Inference Seminar是因果推断的研讨会，每周二晚上有研讨会，2020春季到现在已经举办了几十期报]]></summary>
        <author>
            <name>统计之都</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[36 heures à Paris]]></title>
        <id>http://xianblog.wordpress.com/?p=53363</id>
        <link href="https://xianblog.wordpress.com/2023/07/01/36-heures-a-paris/"/>
        <updated>2023-06-30T22:23:16.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The spiny terminological conundrum of ekhidna and ekhinos]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59471</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59471&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-spiny-terminological-conundrum-of-ekhidna-and-ekhinos"/>
        <updated>2023-06-30T19:15:51.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Stewart Nicol] Greek particles I am a zoologist and comparative physiologist who has worked extensively on the monotremes, the platypus and the echidna. I have been putting together some notes on the naming of the these animals. After originally being placed in the genus Myrmecophaga with the other, totally unrelated, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alex Cohen, Cosmin Pohoata, and Dmitrii Zakharov Improved the Upper Bound for the Heilbronn triangle problem!]]></title>
        <id>http://gilkalai.wordpress.com/?p=24605</id>
        <link href="https://gilkalai.wordpress.com/2023/06/30/alex-cohen-cosmin-pohoata-and-dmitrii-zakharov-improved-the-upper-bound-for-the-heilbronn-triangle-problem/"/>
        <updated>2023-06-30T07:51:31.000Z</updated>
        <summary type="html"><![CDATA[A new upper bound for the Heilbronn triangle problem was proved by Alex Cohen, Cosmin Pohoata, and Dmitrii Zakharov. Congratulations! The paper is A new upper bound for the Heilbronn triangle problem Abstract: For sufficiently large n, we show that … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alex Cohen, Cosmin Pohoata, and Dmitrii Zakharov Improved the Upper Bound for the Heilbronn triangle problem!]]></title>
        <id>http://gilkalai.wordpress.com/?p=24605</id>
        <link href="https://gilkalai.wordpress.com/2023/06/30/alex-cohen-cosmin-pohoata-and-dmitrii-zakharov-improved-the-upper-bound-for-the-heilbronn-triangle-problem/"/>
        <updated>2023-06-30T07:51:31.000Z</updated>
        <summary type="html"><![CDATA[A new upper bound for the Heilbronn triangle problem was proved by Alex Cohen, Cosmin Pohoata, and Dmitrii Zakharov. Congratulations! The paper is A new upper bound for the Heilbronn triangle problem Abstract: For sufficiently large n, we show that … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Concept-Oriented Deep Learning with Large Language Models]]></title>
        <id>http://arxiv.org/abs/2306.17089</id>
        <link href="http://arxiv.org/abs/2306.17089"/>
        <updated>2023-06-30T07:14:48.986Z</updated>
        <summary type="html"><![CDATA[Daniel T. Chang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Graph Neural Networks with Generalized Geometric
  Scattering Transforms]]></title>
        <id>http://arxiv.org/abs/1911.06253</id>
        <link href="http://arxiv.org/abs/1911.06253"/>
        <updated>2023-06-30T07:14:48.969Z</updated>
        <summary type="html"><![CDATA[Michael Perlmutter, Alexander Tong, Feng Gao, Guy Wolf and
  Matthew Hirn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Joint Multi-view Unsupervised Feature Selection and Graph Learning]]></title>
        <id>http://arxiv.org/abs/2204.08247</id>
        <link href="http://arxiv.org/abs/2204.08247"/>
        <updated>2023-06-30T07:14:48.936Z</updated>
        <summary type="html"><![CDATA[Si-Guo Fang, Dong Huang, Chang-Dong Wang, Yong Tang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Advantage of Curriculum Learning on Parity Targets with Mixed
  Inputs]]></title>
        <id>http://arxiv.org/abs/2306.16921</id>
        <link href="http://arxiv.org/abs/2306.16921"/>
        <updated>2023-06-30T07:14:48.911Z</updated>
        <summary type="html"><![CDATA[Emmanuel Abbe, Elisabetta Cornacchia, Aryo Lotfi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural networks can detect model-free static arbitrage strategies]]></title>
        <id>http://arxiv.org/abs/2306.16422</id>
        <link href="http://arxiv.org/abs/2306.16422"/>
        <updated>2023-06-30T07:14:48.865Z</updated>
        <summary type="html"><![CDATA[Ariel Neufeld, Julian Sester]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[short trip to a theocracy]]></title>
        <id>http://xianblog.wordpress.com/?p=53134</id>
        <link href="https://xianblog.wordpress.com/2023/06/30/trip-to-a-theocracy/"/>
        <updated>2023-06-29T22:23:20.000Z</updated>
        <summary type="html"><![CDATA[Besides attending a workshop on my research themes and meeting researchers from that field, a supplementary incentive for attending Stochastic Numerics and Statistical Learning was to catch a glimpse of Saudi Arabia and its idiosyncrasies.  While this is far from my first time visiting a Muslim theocracy, remembering a most enlightening (if penniless) backpacking trip […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing the first Machine Unlearning Challenge]]></title>
        <id>http://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html</id>
        <link href="http://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html"/>
        <updated>2023-06-29T21:08:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Fabian Pedregosa and Eleni Triantafillou, Research Scientists, Google





Deep learning has recently driven tremendous progress in a wide array of applications, ranging from realistic image generation and impressive retrieval systems to language models that can hold human-like conversations. While this progress is very exciting, the widespread use of deep neural network models requires caution: as guided by Google’s AI Principles, we seek to develop AI technologies responsibly by understanding and mitigating potential risks, such as the propagation and amplification of unfair biases and protecting user privacy.
 

Fully erasing the influence of the data requested to be deleted is challenging since, aside from simply deleting it from databases where it’s stored, it also requires …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On-device diffusion plugins for conditioned text-to-image generation]]></title>
        <id>http://ai.googleblog.com/2023/06/on-device-diffusion-plugins-for.html</id>
        <link href="http://ai.googleblog.com/2023/06/on-device-diffusion-plugins-for.html"/>
        <updated>2023-06-29T19:10:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Yang Zhao and Tingbo Hou, Software Engineers, Core ML




In recent years, diffusion models have shown great success in text-to-image generation, achieving high image quality, improved inference performance, and expanding our creative inspiration. Nevertheless, it is still challenging to efficiently control the generation, especially with conditions that are difficult to describe with text.



Today, we announce MediaPipe diffusion plugins, which enable controllable text-to-image generation to be run on-device. Expanding upon our prior work on GPU inference for on-device large generative models, we introduce new low-cost solutions for controllable text-to-image generation that can be plugged into existing diffusion models and their Low-Rank Adaptation (LoRA) variants. 




Text-t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The AI threat:  keep calm and carry on]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59453</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59453&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-ai-threat-keep-calm-and-carry-on"/>
        <updated>2023-06-29T18:36:01.000Z</updated>
        <summary type="html"><![CDATA[Three weekends ago, I delivered a keynote here: New Directions in Chinese Language Education in the 21st Century The Eighth International Conference on Teaching Chinese as a Second Language Swarthmore College, June 9-10, 2023 ———– Abbreviations:     AI — Artificial Intelligence     DT — Digital Technology     IT — Information Technology     DH — Digital […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cooperative creation with Generative AI]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59461</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59461&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=cooperative-creation-with-generative-ai"/>
        <updated>2023-06-29T13:59:05.000Z</updated>
        <summary type="html"><![CDATA[A couple of weeks ago, John Hansen tried "an experiment to see if I could successfully combine random and seemingly unconnected topics into one poem", and reported the results on Medium. This experiment was quickly reproduced by Adrian CDTPPW, Block Wife, and Robert G. Longpré. The structure was Choose three random words (No AI involved […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generating 3D Molecular Conformers via Equivariant Coarse-Graining and Aggregated Attention]]></title>
        <id>http://bair.berkeley.edu/blog/2023/06/29/coarsenconf/</id>
        <link href="http://bair.berkeley.edu/blog/2023/06/29/coarsenconf/"/>
        <updated>2023-06-29T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[-->

Figure 1: CoarsenConf architecture.

(I) The encoder $q_\phi(z| X, \mathcal{R})$ takes the fine-grained (FG) ground truth conformer $X$, RDKit approximate conformer $\mathcal{R}$ , and coarse-grained (CG) conformer $\mathcal{C}$ as inputs (derived from $X$ and a predefined CG strategy), and outputs a variable-length equivariant CG representation via equivariant message passing and point convolutions.
(II) Equivariant MLPs are applied to learn the mean and log variance of both the posterior and prior distributions.
(III) The posterior (training) or prior (inference) is sampled and fed into the Channel Selection module, where an attention layer is used to learn the optimal pathway from CG to FG structure.
(IV) Given the FG latent vector and the RDKit approximation, the decoder $p_\theta…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified machine learning: Classification with simultaneous observed and
  unobserved novelty detection]]></title>
        <id>http://arxiv.org/abs/2002.01368</id>
        <link href="http://arxiv.org/abs/2002.01368"/>
        <updated>2023-06-29T07:15:37.367Z</updated>
        <summary type="html"><![CDATA[Emile R. Engelbrecht, Johan A. du Preez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incorporating Prior Knowledge into Neural Networks through an Implicit
  Composite Kernel]]></title>
        <id>http://arxiv.org/abs/2205.07384</id>
        <link href="http://arxiv.org/abs/2205.07384"/>
        <updated>2023-06-29T07:15:36.141Z</updated>
        <summary type="html"><![CDATA[Ziyang Jiang, Tongshu Zheng, Yiling Liu, David Carlson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BayesFlow: Amortized Bayesian Workflows With Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.16015</id>
        <link href="http://arxiv.org/abs/2306.16015"/>
        <updated>2023-06-29T07:15:35.502Z</updated>
        <summary type="html"><![CDATA[Stefan T Radev, Marvin Schmitt, Lukas Schumacher, Lasse
  Elsem\"uller, Valentin Pratz, Yannik Sch\"alte, Ullrich K\"othe and
  Paul-Christian B\"urkner]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimizing LibTorch-based inference engine memory usage and thread-pooling]]></title>
        <id>https://pytorch.org/blog/optimizing-libtorch/</id>
        <link href="https://pytorch.org/blog/optimizing-libtorch/"/>
        <updated>2023-06-29T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Outline]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Metaphors for AI, and why I don’t like them]]></title>
        <id>http://windowsontheory.org/?p=8635</id>
        <link href="https://windowsontheory.org/2023/06/28/metaphors-for-ai-and-why-i-dont-like-them/"/>
        <updated>2023-06-28T22:46:34.000Z</updated>
        <summary type="html"><![CDATA[Photo from National Photo Company Collection; see also (Sobel, 2017) [Cross posted in lesswrong and windows on theory see here for my prior writings] “computer, n. /kəmˈpjuːtə/. One who computes; a calculator, reckoner; specifically a person employed to make calculations in an observatory, in surveying, etc”, Oxford English Dictionary “There is no reason why mental as well as bodily labor should … Continue reading Metaphors for AI, and why I don’t like them]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Metaphors for AI, and why I don’t like them]]></title>
        <id>http://windowsontheory.org/?p=8635</id>
        <link href="https://windowsontheory.org/2023/06/28/metaphors-for-ai-and-why-i-dont-like-them/"/>
        <updated>2023-06-28T22:46:34.000Z</updated>
        <summary type="html"><![CDATA[Photo from National Photo Company Collection; see also (Sobel, 2017) [Cross posted in lesswrong and windows on theory see here for my prior writings] “computer, n. /kəmˈpjuːtə/. One who computes; a calculator, reckoner; specifically a person employed to make calculations in an observatory, in surveying, etc”, Oxford English Dictionary “There is no reason why mental as well as bodily labor should … Continue reading Metaphors for AI, and why I don’t like them]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[nAIture]]></title>
        <id>http://xianblog.wordpress.com/?p=53324</id>
        <link href="https://xianblog.wordpress.com/2023/06/29/naiture/"/>
        <updated>2023-06-28T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[Plenty of AI related entries in Nature this week (8 June 2023): Why Nature will not allow the use of generative AI in images and videos (until they cannot spot them) AI intensifies fight against paper mills (as a further hindrance rather than an ally) AI learns to write sorting software on its own, through […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flash sale]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59433</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59433&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=flash-sale"/>
        <updated>2023-06-28T22:06:15.000Z</updated>
        <summary type="html"><![CDATA[Ben Zimmer spotted this interesting street sign in the New York Times photo essay, "DMs from New York City" (June 26, 2023). The Chinese says: suǒyǒu shāngpǐn所有商品"all merchandise" qīnghuò清货"clearance / liquidation of goods" jǐnjí chǔlǐ紧急处理"[must / will be] dealt with / handled urgently" It is true that chǔlǐ 处理 often, if not usually, means "process" […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Today I learned  a new word]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59447</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59447&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=today-i-learned-a-new-word"/>
        <updated>2023-06-28T17:46:06.000Z</updated>
        <summary type="html"><![CDATA[The new-to-me word: assembloid. It occurred in the second (of 20!) bullet points that the blurb for a new publication, Brain Organoid & Systems Neuroscience Journal, lists under the heading Specific areas of interest include, but are not limited to: Brain organogenesis and Neuronal cultures Methods for generating brain assembloids The rest of the list: […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Touring the Turing Test again]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59428</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59428&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=touring-the-turing-test-again"/>
        <updated>2023-06-28T12:28:06.000Z</updated>
        <summary type="html"><![CDATA[The buzz about Large Language Models has re-ignited interest Alan Turing's famous 1950 article "Computing Machinery and Intelligence". Two interesting recent discussions: Jessica Riskin, "A Sort of Buzzing Inside My Head", NYRB 6/25/2023, and Mustafa Suleyman, "The Coming Wave: Technology, Power, and the Twenty-first Century's Greatest Dilemma", Random House 9/5/2023. Suleyman's book won't be released until […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tasting History]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59425</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59425&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tasting-history"/>
        <updated>2023-06-28T10:10:37.000Z</updated>
        <summary type="html"><![CDATA[That's the name of a viral YouTube channel that I had never heard of, and now a popular book that Barbara Phillips Long called to my attention: My son gave me a copy of Tasting History, by Max Miller, which takes very old recipes and gives modern approximations of them. The book is handsomely printed, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LeanDojo: Theorem Proving with Retrieval-Augmented Language Models]]></title>
        <id>http://arxiv.org/abs/2306.15626</id>
        <link href="http://arxiv.org/abs/2306.15626"/>
        <updated>2023-06-28T07:16:00.831Z</updated>
        <summary type="html"><![CDATA[Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chalamala, Peiyang Song,
  Shixing Yu, Saad Godil, Ryan Prenger, Anima Anandkumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal inference is (almost) free for neural networks trained with
  early stopping]]></title>
        <id>http://arxiv.org/abs/2301.11556</id>
        <link href="http://arxiv.org/abs/2301.11556"/>
        <updated>2023-06-28T07:16:00.803Z</updated>
        <summary type="html"><![CDATA[Ziyi Liang, Yanfei Zhou, Matteo Sesia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Neural Networks for Rank-Consistent Ordinal Regression Based On
  Conditional Probabilities]]></title>
        <id>http://arxiv.org/abs/2111.08851</id>
        <link href="http://arxiv.org/abs/2111.08851"/>
        <updated>2023-06-28T07:15:56.500Z</updated>
        <summary type="html"><![CDATA[Xintong Shi, Wenzhi Cao, Sebastian Raschka]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Kernel Learning of Dynamical Models from High-Dimensional Noisy
  Data]]></title>
        <id>http://arxiv.org/abs/2208.12975</id>
        <link href="http://arxiv.org/abs/2208.12975"/>
        <updated>2023-06-28T07:15:56.445Z</updated>
        <summary type="html"><![CDATA[Nicol\`o Botteghi, Mengwu Guo, Christoph Brune]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Neural Networks as Infinite Tree-Structured Probabilistic Graphical
  Models]]></title>
        <id>http://arxiv.org/abs/2305.17583</id>
        <link href="http://arxiv.org/abs/2305.17583"/>
        <updated>2023-06-28T07:15:56.438Z</updated>
        <summary type="html"><![CDATA[Boyao Li, Alexandar J. Thomson, Matthew M. Engelhard, David Page]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Path to Achieve Ultra-Low Inference Latency With LLaMA 65B]]></title>
        <id>https://pytorch.org/blog/path-achieve-low-inference-latency/</id>
        <link href="https://pytorch.org/blog/path-achieve-low-inference-latency/"/>
        <updated>2023-06-28T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Background &amp; State of the Art]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[生成扩散模型漫谈（二十）：从ReFlow到WGAN-GP]]></title>
        <id>https://kexue.fm/archives/9668</id>
        <link href="https://kexue.fm/archives/9668"/>
        <updated>2023-06-28T01:48:00.000Z</updated>
        <summary type="html"><![CDATA[上一篇文章《生成扩散模型漫谈（十九）：作为扩散ODE的GAN》中，我们介绍了如何将GAN理解为在另一个时间维度上的扩散ODE，简而言之，GAN实际上就是将扩散模型中样本的运动转化为生成器参数的运...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[re-MCM’d]]></title>
        <id>http://xianblog.wordpress.com/?p=53368</id>
        <link href="https://xianblog.wordpress.com/2023/06/28/re-mcmd/"/>
        <updated>2023-06-27T22:23:05.000Z</updated>
        <summary type="html"><![CDATA[When I entered the classroom on the Jussieu campus where the Monday morning session on PDMP was taking place, some friends told me a badge was waiting for me at the registration desk of MCM 2023! Most surprisingly since I had received a deregistration message a few weeks earlier. Great PDMP session with non-reversible tempering […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unifying image-caption and image-classification datasets with prefix conditioning]]></title>
        <id>http://ai.googleblog.com/2023/06/unifying-image-caption-and-image.html</id>
        <link href="http://ai.googleblog.com/2023/06/unifying-image-caption-and-image.html"/>
        <updated>2023-06-27T21:19:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Kuniaki Saito, Student Researcher, Cloud AI Team, and Kihyuk Sohn, Research Scientist, Perception Team




Pre-training visual language (VL) models on web-scale image-caption datasets has recently emerged as a powerful alternative to traditional pre-training on image classification data. Image-caption datasets are considered to be more “open-domain” because they contain broader scene types and vocabulary words, which result in models with strong performance in few- and zero-shot recognition tasks. However, images with fine-grained class descriptions can be rare, and the class distribution can be imbalanced since image-caption datasets do not go through manual curation. By contrast, large-scale classification datasets, such as ImageNet, are often curated and can thus provide fine-…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near Optimal Heteroscedastic Regression with Symbiotic Learning]]></title>
        <id>http://arxiv.org/abs/2306.14288</id>
        <link href="http://arxiv.org/abs/2306.14288"/>
        <updated>2023-06-27T07:15:43.389Z</updated>
        <summary type="html"><![CDATA[Dheeraj Baby, Aniket Das, Dheeraj Nagaraj, Praneeth
  Netrapalli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Trustworthy Explanation: On Causal Rationalization]]></title>
        <id>http://arxiv.org/abs/2306.14115</id>
        <link href="http://arxiv.org/abs/2306.14115"/>
        <updated>2023-06-27T07:15:43.383Z</updated>
        <summary type="html"><![CDATA[Wenbo Zhang, Tong Wu, Yunlong Wang, Yong Cai, Hengrui Cai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representation Ensembling for Synergistic Lifelong Learning with
  Quasilinear Complexity]]></title>
        <id>http://arxiv.org/abs/2004.12908</id>
        <link href="http://arxiv.org/abs/2004.12908"/>
        <updated>2023-06-27T07:15:43.377Z</updated>
        <summary type="html"><![CDATA[Joshua T. Vogelstein, Jayanta Dey, Hayden S. Helm, Will LeVine, Ronak
  D. Mehta, Tyler M. Tomita, Haoyin Xu, Ali Geisa, Qingyang Wang, Gido M. van
  de Ven, Chenyu Gao, Weiwei Yang, Bryan Tower, Jonathan Larson, Christopher M.
  White, Carey E. Priebe]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representation Transfer Learning via Multiple Pre-trained models for
  Linear Regression]]></title>
        <id>http://arxiv.org/abs/2305.16440</id>
        <link href="http://arxiv.org/abs/2305.16440"/>
        <updated>2023-06-27T07:15:43.371Z</updated>
        <summary type="html"><![CDATA[Navjot Singh, Suhas Diggavi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The scatology and physiology of push and pull]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59422</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59422&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-scatology-and-physiology-of-push-and-pull"/>
        <updated>2023-06-27T00:11:13.000Z</updated>
        <summary type="html"><![CDATA[Having just written about "Drainage issues" (6/25/23), with a graphic depiction of what causes the problem with the drainage system in question, I am emboldened finally to answer a question that one of my graduate students has been asking about for several years.  Namely, why do Chinese say "pull poo / shit / excrement" (lāshǐ […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When NumPy is too slow]]></title>
        <id>https://pythonspeed.com/articles/numpy-is-slow/</id>
        <link href="https://pythonspeed.com/articles/numpy-is-slow/"/>
        <updated>2023-06-27T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[If you’re doing numeric calculations, NumPy is a lot faster than than plain Python—but sometimes that’s not enough.
What should you do when your NumPy-based code is too slow?
Your first thought might be parallelism, but that should probably be the last thing you consider.
There are many speedups you can do before parallelism becomes helpful, from algorithmic improvements to working around NumPy’s architectural limitations.
Let’s see why NumPy can be slow, and then some solutions to help speed up your code even more.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Xing the 100k milestone]]></title>
        <id>http://xianblog.wordpress.com/?p=53264</id>
        <link href="https://xianblog.wordpress.com/2023/06/27/xing-the-100k-milestone/"/>
        <updated>2023-06-26T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI for Akkadian]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59411</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59411&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-for-akkadian"/>
        <updated>2023-06-26T11:12:00.000Z</updated>
        <summary type="html"><![CDATA[Article by Melanie Lidman in The Times of Israel (6/17/23): Groundbreaking AI project translates 5,000-year-old cuneiform at push of a button ‘Google Translate’-like program for Akkadian cuneiform will enable tens of thousands of digitized but unread tablets to be translated to English. Accuracy is debatable. Opening and key paragraphs: Cuneiform is the oldest known form […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convergence of First-Order Methods for Constrained Nonconvex
  Optimization with Dependent Data]]></title>
        <id>http://arxiv.org/abs/2203.15797</id>
        <link href="http://arxiv.org/abs/2203.15797"/>
        <updated>2023-06-26T09:17:23.822Z</updated>
        <summary type="html"><![CDATA[Ahmet Alacaoglu, Hanbaek Lyu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMART: An Open Source Data Labeling Platform for Supervised Learning]]></title>
        <id>http://arxiv.org/abs/1812.06591</id>
        <link href="http://arxiv.org/abs/1812.06591"/>
        <updated>2023-06-26T07:16:33.172Z</updated>
        <summary type="html"><![CDATA[Rob Chew, Michael Wenger, Caroline Kery, Jason Nance, Keith Richards,
  Emily Hadley, Peter Baumgartner]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Precise Asymptotic Generalization for Multiclass Classification with
  Overparameterized Linear Models]]></title>
        <id>http://arxiv.org/abs/2306.13255</id>
        <link href="http://arxiv.org/abs/2306.13255"/>
        <updated>2023-06-26T07:16:33.165Z</updated>
        <summary type="html"><![CDATA[David X. Wu, Anant Sahai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Compression with Bayesian Implicit Neural Representations]]></title>
        <id>http://arxiv.org/abs/2305.19185</id>
        <link href="http://arxiv.org/abs/2305.19185"/>
        <updated>2023-06-26T07:16:33.144Z</updated>
        <summary type="html"><![CDATA[Zongyu Guo, Gergely Flamich, Jiajun He, Zhibo Chen, Jos\'e Miguel
  Hern\'andez-Lobato]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximate Causal Effect Identification under Weak Confounding]]></title>
        <id>http://arxiv.org/abs/2306.13242</id>
        <link href="http://arxiv.org/abs/2306.13242"/>
        <updated>2023-06-26T07:16:33.135Z</updated>
        <summary type="html"><![CDATA[Ziwei Jiang, Lai Wei, Murat Kocaoglu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding quantum machine learning also requires rethinking
  generalization]]></title>
        <id>http://arxiv.org/abs/2306.13461</id>
        <link href="http://arxiv.org/abs/2306.13461"/>
        <updated>2023-06-26T07:16:33.055Z</updated>
        <summary type="html"><![CDATA[Elies Gil-Fuster, Jens Eisert, Carlos Bravo-Prieto]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BobWords on eggcorn]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59418</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59418&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bobwords-on-eggcorn"/>
        <updated>2023-06-25T23:38:50.000Z</updated>
        <summary type="html"><![CDATA[RobWords for June 24, 2023: The word eggcorn was originally proposed in "Egg corns: folk etymology, malapropism, mondegreen, ???", 9/23/2003, and most recently discussed in "Ancient Eggcorns", 6/17/2023.]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[definitely wrong]]></title>
        <id>http://xianblog.wordpress.com/?p=53237</id>
        <link href="https://xianblog.wordpress.com/2023/06/26/definitely-wrong/"/>
        <updated>2023-06-25T22:23:54.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-wheat food]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59369</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59369&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=non-wheat-food"/>
        <updated>2023-06-25T21:06:08.000Z</updated>
        <summary type="html"><![CDATA[From John Rohsenow: qǐng wù zài běn cāntīng nèi jìnshí fēi Màiduōlè shípǐn huò yǐnliào 请勿在本餐厅内进食非麦多乐食品或饮料 "Please do not consume non-Madola food or drink in this restaurant" Pretty straightforward, eh?  Except that we have to explain that Madola (Màiduōlè 麦多乐 [lit., "wheat-much-music"]) is probably a local (fast) food brand trying to emulate McDonald's (Màidāngláo 麦当劳).  Madola […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Drainage issues]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59405</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59405&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=drainage-issues"/>
        <updated>2023-06-25T21:02:42.000Z</updated>
        <summary type="html"><![CDATA[Photograph taken in Hong Kong: The Chinese says: qúwù wèntí gù zhǐ néng zuò xiǎojiě   jìngqǐng hézuò渠務問題故只能作小解  敬請合作"Since there are drainage problems, can only be used for urination.  Your cooperation is respectfully requested."   BTW: GT:  "The drainage problem can only be explained briefly, please cooperate." Baidu Fanyi:  "Due to drainage issues, we can […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Use chili sparingly]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59391</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59391&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=use-chili-sparingly"/>
        <updated>2023-06-25T04:18:02.000Z</updated>
        <summary type="html"><![CDATA[From AntC: Seen in a very typical (but delicious) corner eatery in downtown Hualien, Taiwan. Surprisingly idiomatic translation: "use sparingly" in Hualien GTranslate isn't so idiomatic; I'm not able to try DeepL — any better? I agree with AntC that "use sparingly" is a strikingly fine English expression, one that does not seem possible from a […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phenomenology]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59401</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59401&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=phenomenology"/>
        <updated>2023-06-25T01:54:34.000Z</updated>
        <summary type="html"><![CDATA[Nancy Kathryn Walecki, "Sound as Ever: Gram Parsons and Harvard’s hand in country rock", Harvard Magazine July-August 2023: During Parsons’s Burritos era, Thomas left Harvard to write his dissertation in a cabin on Mount Baldy outside Los Angeles. Now more of an older brother to Parsons than a proctor, he would take study breaks with […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=53299</id>
        <link href="https://xianblog.wordpress.com/2023/06/25/a-journal-of-the-conquest-war-famine-and-death-year/"/>
        <updated>2023-06-24T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[Read both following volumes of Peter May’s Lewis trilogy, The Lewis Man and The Chessmen. The stories remain focussed on the same few characters as in the first volume, with some predictable developments and a rather heavy borrowing to the local history in the shape of a peat-bog mommy or a plane crash. And of […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prigozhin's pronouns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59396</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59396&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=prigozhins-pronouns"/>
        <updated>2023-06-24T14:26:14.000Z</updated>
        <summary type="html"><![CDATA[Just wow. A video has surfaced showing Prigozhin at the Southern Military District HQ in Rostov-on-Don talking to (and HUMILIATING) Deputy Defense Minister Yunus-bek Yevkurov. He threatens to blockade Rostov and head for Moscow! I have extreme trouble understanding Yevkurov and… pic.twitter.com/jGr9gaLB1i — Kevin Rothrock (@KevinRothrock) June 24, 2023 An English translation of the linguistically-relevant […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five old, white men]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59388</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59388&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=five-old-white-men"/>
        <updated>2023-06-24T11:16:19.000Z</updated>
        <summary type="html"><![CDATA[I promised that I would tell the story of how five old, white men persuaded me to begin the study of Asian languages two years after I was out of college.  Here it is. When I graduated from Dartmouth in 1965, I joined the Peace Corps for two years in Nepal.  Although I contracted fifteen […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the generalizations of global dimensions and singularity categories]]></title>
        <id>http://arxiv.org/abs/2306.09832</id>
        <link href="http://arxiv.org/abs/2306.09832"/>
        <updated>2023-06-24T07:15:01.670Z</updated>
        <summary type="html"><![CDATA[Xiaolei Zhang, Tiwei Zhao, Dingguo Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[生成扩散模型漫谈（十九）：作为扩散ODE的GAN]]></title>
        <id>https://kexue.fm/archives/9662</id>
        <link href="https://kexue.fm/archives/9662"/>
        <updated>2023-06-24T01:38:00.000Z</updated>
        <summary type="html"><![CDATA[在文章《生成扩散模型漫谈（十六）：W距离 ≤ 得分匹配》中，我们推导了Wasserstein距离与扩散模型得分匹配损失之间的一个不等式，表明扩散模型的优化目标与WGAN的优化目标在某种程度上具有...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[noctureine 2023 [16/6/23, 20h40, 10k, 41’54”, 29⁰, 48th/295, 1st M5/11]]]></title>
        <id>http://xianblog.wordpress.com/?p=53258</id>
        <link href="https://xianblog.wordpress.com/2023/06/24/noctureine-2023-2/"/>
        <updated>2023-06-23T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gardening on the path]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59383</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59383&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=gardening-on-the-path"/>
        <updated>2023-06-23T22:01:29.000Z</updated>
        <summary type="html"><![CDATA[The most recent xkcd: Mouseover title: "Arboretum Owner Denied Standing in Garden Path Suit on Grounds Grounds Appealing Appealing" What the Berkeley Neural Parser thinks: (S (PP (IN After) (NP (NN bird) (VBZ strikes))) (NP (NP (NN judge)) (SBAR (WHNP (WP who)) (S (VP (VBD ordered) (NP (NNP olive) (NNP garden) (NNP path) (NN sentence)) […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Preference learning with automated feedback for cache eviction]]></title>
        <id>http://ai.googleblog.com/2023/06/preference-learning-with-automated.html</id>
        <link href="http://ai.googleblog.com/2023/06/preference-learning-with-automated.html"/>
        <updated>2023-06-23T19:24:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Ramki Gummadi, Software Engineer, Google and Kevin Chen, Software Engineer, YouTube





Caching is a ubiquitous idea in computer science that significantly improves the performance of storage and retrieval systems by storing a subset of popular items closer to the client based on request patterns. An important algorithmic piece of cache management is the decision policy used for dynamically updating the set of items being stored, which has been extensively optimized over several decades, resulting in several efficient and robust heuristics. While applying machine learning to cache policies has shown promising results in recent years (e.g., LRB, LHD, storage applications), it remains a challenge to outperform robust heuristics in a way that can generalize reliably beyond benchmar…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Origin of Speeches? or just the collapse of Uruk?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59365</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59365&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-origin-of-speeches-or-just-the-collapse-of-uruk"/>
        <updated>2023-06-23T17:16:45.000Z</updated>
        <summary type="html"><![CDATA[I've wondered for a long time why Biblical inerrantists have a big problem with biological evolution, which contradicts Chapter 1 of Genesis, but not so much with historical linguistics, which contradicts Chapter 11. But in "Linguistic Confusion and the Tower of Babel", National Catholic Register 6/21/2023, Dave Armstrong argues that the usual interpretation of the […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The allure of Latin, the glory of Greek]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59358</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59358&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-allure-of-latin-the-glory-of-greek"/>
        <updated>2023-06-23T13:46:11.000Z</updated>
        <summary type="html"><![CDATA[Beautiful WSJ OpED (6/22/23) by Gerard Gayou, a seminarian of the archdiocese of Washington, who is studying theology at the Pontifical North American College in Rome: The Guiding Light of Latin Grammar The language reminds us of what our words mean and of whom we’re called to be. —– Nothing bored me more during the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interpretable Neural-Symbolic Concept Reasoning]]></title>
        <id>http://arxiv.org/abs/2304.14068</id>
        <link href="http://arxiv.org/abs/2304.14068"/>
        <updated>2023-06-23T09:17:07.507Z</updated>
        <summary type="html"><![CDATA[Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Mateo
  Espinosa Zarlenga, Lucie Charlotte Magister, Alberto Tonda, Pietro Lio',
  Frederic Precioso, Mateja Jamnik, Giuseppe Marra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sharp analysis of EM for learning mixtures of pairwise differences]]></title>
        <id>http://arxiv.org/abs/2302.10066</id>
        <link href="http://arxiv.org/abs/2302.10066"/>
        <updated>2023-06-23T07:19:28.276Z</updated>
        <summary type="html"><![CDATA[Abhishek Dhawan, Cheng Mao, Ashwin Pananjady]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the explainable properties of 1-Lipschitz Neural Networks: An Optimal
  Transport Perspective]]></title>
        <id>http://arxiv.org/abs/2206.06854</id>
        <link href="http://arxiv.org/abs/2206.06854"/>
        <updated>2023-06-23T07:19:28.271Z</updated>
        <summary type="html"><![CDATA[Mathieu Serrurier (IRIT, UT), Franck Mamalet (UT), Thomas Fel (UT),
  Louis B\'ethune (UT3, UT, IRIT), Thibaut Boissin (UT)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Path to Autonomous Learners]]></title>
        <id>http://arxiv.org/abs/2211.02403</id>
        <link href="http://arxiv.org/abs/2211.02403"/>
        <updated>2023-06-23T07:19:28.265Z</updated>
        <summary type="html"><![CDATA[Hanna Abi Akl]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Finite-time Lyapunov exponents of deep neural networks]]></title>
        <id>http://arxiv.org/abs/2306.12548</id>
        <link href="http://arxiv.org/abs/2306.12548"/>
        <updated>2023-06-23T07:19:28.245Z</updated>
        <summary type="html"><![CDATA[L. Storm, H. Linander, J. Bec, K. Gustavsson, B. Mehlig]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SQ Lower Bounds for Learning Bounded Covariance GMMs]]></title>
        <id>http://arxiv.org/abs/2306.13057</id>
        <link href="http://arxiv.org/abs/2306.13057"/>
        <updated>2023-06-23T07:19:28.227Z</updated>
        <summary type="html"><![CDATA[Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LLM Powered Autonomous Agents]]></title>
        <id>https://lilianweng.github.io/posts/2023-06-23-agent/</id>
        <link href="https://lilianweng.github.io/posts/2023-06-23-agent/"/>
        <updated>2023-06-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.
Agent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:]]></summary>
        <author>
            <name>Lil'Log</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#3]]]></title>
        <id>http://xianblog.wordpress.com/?p=53355</id>
        <link href="https://xianblog.wordpress.com/2023/06/23/approximation-methods-in-bayesian-analysis-3/"/>
        <updated>2023-06-22T22:23:24.000Z</updated>
        <summary type="html"><![CDATA[My last day (#4) at the workshop, as I had to return to Paris earlier. A rather theoretical morning again, with Morgane Austern on (probabilistic) concentration inequalities on transport distances, far from my comfort zone if lively, Jason Xu on replacing non-convex penalisation factors to distances to the corresponding manifold, which I found most interesting […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SoundStorm: Efficient parallel audio generation]]></title>
        <id>http://ai.googleblog.com/2023/06/soundstorm-efficient-parallel-audio.html</id>
        <link href="http://ai.googleblog.com/2023/06/soundstorm-efficient-parallel-audio.html"/>
        <updated>2023-06-22T18:33:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Zalán Borsos, Research Software Engineer, and Marco Tagliasacchi, Senior Staff Research Scientist, Google Research







The recent progress in generative AI unlocked the possibility of creating new content in several different domains, including text, vision and audio. These models often rely on the fact that raw data is first converted to a compressed format as a sequence of tokens. In the case of audio, neural audio codecs (e.g., SoundStream or EnCodec) can efficiently compress waveforms to a compact representation, which can be inverted to reconstruct an approximation of the original audio signal. Such a representation consists of a sequence of discrete audio tokens, capturing the local properties of sounds (e.g., phonemes) and their temporal structure (e.g., prosody). By re…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The legal standing of the serial comma]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59352</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59352&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-legal-standing-of-the-serial-comma"/>
        <updated>2023-06-22T13:30:29.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Mark Cohen] I am wondering if members of this group have had experience with translating the Chinese serial comma or dùnhào 顿号  [、] ("the caesura sign; a slight-pause mark used to set off items in a series; punctuation mark used between parallel words or short phrases; sign of coordination; […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Problem: Learning with Variational Objectives on Measures]]></title>
        <id>http://arxiv.org/abs/2306.11928</id>
        <link href="http://arxiv.org/abs/2306.11928"/>
        <updated>2023-06-22T07:16:05.265Z</updated>
        <summary type="html"><![CDATA[Vivien Cabannes, Carles Domingo-Enrich]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Any Deep ReLU Network is Shallow]]></title>
        <id>http://arxiv.org/abs/2306.11827</id>
        <link href="http://arxiv.org/abs/2306.11827"/>
        <updated>2023-06-22T07:16:05.251Z</updated>
        <summary type="html"><![CDATA[Mattia Jacopo Villani, Nandi Schoots]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayes-optimal Learning of Deep Random Networks of Extensive-width]]></title>
        <id>http://arxiv.org/abs/2302.00375</id>
        <link href="http://arxiv.org/abs/2302.00375"/>
        <updated>2023-06-22T07:16:04.347Z</updated>
        <summary type="html"><![CDATA[Hugo Cui, Florent Krzakala, Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Debiased Machine Learning for Dynamic Treatment Effects and
  General Nested Functionals]]></title>
        <id>http://arxiv.org/abs/2203.13887</id>
        <link href="http://arxiv.org/abs/2203.13887"/>
        <updated>2023-06-22T07:16:04.342Z</updated>
        <summary type="html"><![CDATA[Victor Chernozhukov, Whitney Newey, Rahul Singh, Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal rates of approximation by shallow ReLU$^k$ neural networks and
  applications to nonparametric regression]]></title>
        <id>http://arxiv.org/abs/2304.01561</id>
        <link href="http://arxiv.org/abs/2304.01561"/>
        <updated>2023-06-22T07:16:04.220Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimized PyTorch 2.0 Inference with AWS Graviton processors]]></title>
        <id>https://pytorch.org/blog/optimized-pytorch-w-graviton/</id>
        <link href="https://pytorch.org/blog/optimized-pytorch-w-graviton/"/>
        <updated>2023-06-22T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[New generations of CPUs offer significant performance improvement in machine learning (ML) inference due to specialized built-in instructions. Combined with their flexibility, high speed of development, and low operating cost, these general-purpose processors offer an alternative ML inference solution to other existing hardware solutions.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#2]]]></title>
        <id>http://xianblog.wordpress.com/?p=53342</id>
        <link href="https://xianblog.wordpress.com/2023/06/22/approximation-methods-in-bayesian-analysis-2/"/>
        <updated>2023-06-21T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[A more theoretical Day #2 of the workshop, with Debdeep Pati comparing two representations of Gaussian processes with significantly different efficiencies, and Aad van der Vaart presenting a form of linearisation for a range of inverse problems, Kolyan Ray debiasing Lasso impacts by variational Bayes, although through a somewhat intricate process that distanced the procedure […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: AI for Social Good]]></title>
        <id>http://ai.googleblog.com/2023/06/responsible-ai-at-google-research-ai.html</id>
        <link href="http://ai.googleblog.com/2023/06/responsible-ai-at-google-research-ai.html"/>
        <updated>2023-06-21T20:57:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Jimmy Tobin and Katrin Tomanek, Software Engineers, Google Research, AI for Social Good


Google’s AI for Social Good team consists of researchers, engineers, volunteers, and others with a shared focus on positive social impact. Our mission is to demonstrate AI’s societal benefit by enabling real-world value, with projects spanning work in public health, accessibility, crisis response, climate and energy, and nature and society. We believe that the best way to drive positive change in underserved communities is by partnering with change-makers and the organizations they serve.


 


In this blog post we discuss work done by Project Euphonia, a team within AI for Social Good, that aims to improve automatic speech recognition (ASR) for people with disordered speech. For people with…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The world’s first braiding of non-Abelian anyons]]></title>
        <id>http://ai.googleblog.com/2023/06/the-worlds-first-braiding-of-non.html</id>
        <link href="http://ai.googleblog.com/2023/06/the-worlds-first-braiding-of-non.html"/>
        <updated>2023-06-21T17:29:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Trond Andersen and Yuri Lensky, Research Scientists, Google Quantum AI Team  






Imagine you’re shown two identical objects and then asked to close your eyes. When you open your eyes, you see the same two objects in the same position. How can you determine if they have been swapped back and forth? Intuition and the laws of quantum mechanics agree: If the objects are truly identical, there is no way to tell. 



While this sounds like common sense, it only applies to our familiar three-dimensional world. Researchers have predicted that for a special type of particle, called an anyon, that is restricted to move only in a two-dimensional (2D) plane, quantum mechanics allows for something quite different. Anyons are indistinguishable from one another and some, non-Abelian anyons, …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On-the-Fly Adaptation of Source Code Models using Meta-Learning]]></title>
        <id>http://arxiv.org/abs/2003.11768</id>
        <link href="http://arxiv.org/abs/2003.11768"/>
        <updated>2023-06-21T01:23:11.749Z</updated>
        <summary type="html"><![CDATA[Disha Shrivastava, Hugo Larochelle, Daniel Tarlow]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Novel Collaborative Self-Supervised Learning Method for Radiomic Data]]></title>
        <id>http://arxiv.org/abs/2302.09807</id>
        <link href="http://arxiv.org/abs/2302.09807"/>
        <updated>2023-06-21T01:23:11.744Z</updated>
        <summary type="html"><![CDATA[Zhiyuan Li, Hailong Li, Anca L. Ralescu, Jonathan R. Dillman, Nehal A.
  Parikh, Lili He]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Does a Deep Learning Model Architecture Impact Its Privacy? A
  Comprehensive Study of Privacy Attacks on CNNs and Transformers]]></title>
        <id>http://arxiv.org/abs/2210.11049</id>
        <link href="http://arxiv.org/abs/2210.11049"/>
        <updated>2023-06-21T01:23:11.454Z</updated>
        <summary type="html"><![CDATA[Guangsheng Zhang, Bo Liu, Huan Tian, Tianqing Zhu, Ming Ding, Wanlei
  Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Principles for Initialization and Architecture Selection in Graph Neural
  Networks with ReLU Activations]]></title>
        <id>http://arxiv.org/abs/2306.11668</id>
        <link href="http://arxiv.org/abs/2306.11668"/>
        <updated>2023-06-21T01:23:11.449Z</updated>
        <summary type="html"><![CDATA[Gage DeZoort, Boris Hanin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Implicit Bias of Batch Normalization in Linear Models and Two-layer
  Linear Convolutional Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.11680</id>
        <link href="http://arxiv.org/abs/2306.11680"/>
        <updated>2023-06-21T01:23:07.429Z</updated>
        <summary type="html"><![CDATA[Yuan Cao, Difan Zou, Yuanzhi Li, Quanquan Gu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[shallow learning]]></title>
        <id>http://xianblog.wordpress.com/?p=53337</id>
        <link href="https://xianblog.wordpress.com/2023/06/21/shallow-learning/"/>
        <updated>2023-06-20T22:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fangyán = topolect in DC]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59348</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59348&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=fangyan-topolect-in-dc"/>
        <updated>2023-06-20T20:58:16.000Z</updated>
        <summary type="html"><![CDATA[I'm in Georgetown for a few days to meet with colleagues and do some research.  Shortly after I left my hotel and headed down Wisconsin Avenue toward the Potomac for a morning run, I stopped dead in my tracks when I crossed over the canal and saw this: Especially with all the butterflies in the window, I […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Fursty Ferret]]></title>
        <id>http://xianblog.wordpress.com/?p=53009</id>
        <link href="https://xianblog.wordpress.com/2023/06/20/the-fursty-ferret/"/>
        <updated>2023-06-20T18:20:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Topolects and texts]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59286</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59286&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=topolects-and-texts"/>
        <updated>2023-06-20T14:06:53.000Z</updated>
        <summary type="html"><![CDATA[Illuminating new book from Hong Kong University Press edited by Richard VanNess Simmons: Studies in Colloquial Chinese and Its History:  Dialect and Text ISBN : 978-988-8754-09-0 The book also has a Chinese title: Hànyǔ kǒuyǔ de lìshǐ yánjiū: fāngyán hé wénxiàn 漢語口語的歷史研究：方言與文獻 I would prefer to render this into English as: Studies on the History […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tortured phrases, LLMs, and Goodhart's Law]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59339</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59339&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tortured-phrases-llms-and-goodharts-law"/>
        <updated>2023-06-20T13:55:24.000Z</updated>
        <summary type="html"><![CDATA[A few years ago, I began to notice that the scientific and technical papers relentless spammed at me, by academia.edu and similar outfits, were becoming increasingly surrealistic. And I soon learned that the source for such articles was systems for "article spinning" by "rogeting" — automatic random subsitution of (usually inappropriate) synonyms. Those techniques were […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RoboCat: A self-improving robotic agent]]></title>
        <id>https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent</id>
        <link href="https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent"/>
        <updated>2023-06-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Robots are quickly becoming part of our everyday lives, but they’re often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data. Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#1]]]></title>
        <id>http://xianblog.wordpress.com/?p=53331</id>
        <link href="https://xianblog.wordpress.com/2023/06/20/approximation-methods-in-bayesian-analysis-1/"/>
        <updated>2023-06-19T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[Interesting first day, if somewhat intense!, with Sylvia Richardson talking of divide & conquer strategies, which we had recently explored in our work on mixtures with Adrien and Judith. Then Jere Koskela (Warwick) on sufficient conditions for consistent inference on trees like Kingman’s coalescent. And in the afternoon Julia-Adela Palacios on tree estimation, with novel […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stabilized Neural Differential Equations for Learning Constrained
  Dynamics]]></title>
        <id>http://arxiv.org/abs/2306.09739</id>
        <link href="http://arxiv.org/abs/2306.09739"/>
        <updated>2023-06-19T07:14:46.765Z</updated>
        <summary type="html"><![CDATA[Alistair White, Niki Kilbertus, Maximilian Gelbrecht, Niklas Boers]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resolving the Human Subjects Status of Machine Learning's Crowdworkers]]></title>
        <id>http://arxiv.org/abs/2206.04039</id>
        <link href="http://arxiv.org/abs/2206.04039"/>
        <updated>2023-06-19T07:14:46.761Z</updated>
        <summary type="html"><![CDATA[Divyansh Kaushik, Zachary C. Lipton, Alex John London]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enhancing Activity Prediction Models in Drug Discovery with the Ability
  to Understand Human Language]]></title>
        <id>http://arxiv.org/abs/2303.03363</id>
        <link href="http://arxiv.org/abs/2303.03363"/>
        <updated>2023-06-19T07:14:46.756Z</updated>
        <summary type="html"><![CDATA[Philipp Seidl, Andreu Vall, Sepp Hochreiter, G\"unter Klambauer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Collapsed Inference for Bayesian Deep Learning]]></title>
        <id>http://arxiv.org/abs/2306.09686</id>
        <link href="http://arxiv.org/abs/2306.09686"/>
        <updated>2023-06-19T07:14:46.750Z</updated>
        <summary type="html"><![CDATA[Zhe Zeng, Guy Van den Broeck]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trained Transformers Learn Linear Models In-Context]]></title>
        <id>http://arxiv.org/abs/2306.09927</id>
        <link href="http://arxiv.org/abs/2306.09927"/>
        <updated>2023-06-19T07:14:46.650Z</updated>
        <summary type="html"><![CDATA[Ruiqi Zhang, Spencer Frei, Peter L. Bartlett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[no country for old men [Cormac McCarthy]]]></title>
        <id>http://xianblog.wordpress.com/?p=53250</id>
        <link href="https://xianblog.wordpress.com/2023/06/19/no-country-for-old-men-cormac-mccarthy/"/>
        <updated>2023-06-18T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at CVPR 2023]]></title>
        <id>http://ai.googleblog.com/2023/06/google-at-cvpr-2023.html</id>
        <link href="http://ai.googleblog.com/2023/06/google-at-cvpr-2023.html"/>
        <updated>2023-06-18T18:00:00.014Z</updated>
        <summary type="html"><![CDATA[Posted by Shaina Mehta, Program Manager, Google




This week marks the beginning of the premier annual Computer Vision and Pattern Recognition conference (CVPR 2023), held in-person in Vancouver, BC (with additional virtual content). As a leader in computer vision research and a Platinum Sponsor, Google Research will have a strong presence across CVPR 2023 with 90 papers being presented at the main conference and active involvement in over 40 conference workshops and tutorials.




If you are attending CVPR this year, please stop by our booth to chat with our researchers who are actively exploring the latest techniques for application to various areas of machine perception. Our researchers will also be available to talk about and demo several recent efforts, including on-device ML applica…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Time-averaged quantum annealing for weak processes]]></title>
        <id>http://arxiv.org/abs/2306.06008</id>
        <link href="http://arxiv.org/abs/2306.06008"/>
        <updated>2023-06-18T07:13:07.422Z</updated>
        <summary type="html"><![CDATA[Pierre Naz\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal shortcuts to adiabaticity of finite-time and weak processes]]></title>
        <id>http://arxiv.org/abs/2305.17802</id>
        <link href="http://arxiv.org/abs/2305.17802"/>
        <updated>2023-06-18T07:13:06.921Z</updated>
        <summary type="html"><![CDATA[Pierre Naz\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Saturn < Cronus (Κρόνος) ≠ Chronos (Χρόνος)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59190</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59190&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=saturn-cronus-%25ce%25ba%25cf%2581%25cf%258c%25ce%25bd%25ce%25bf%25cf%2582-%25e2%2589%25a0-chronos-%25cf%2587%25cf%2581%25cf%258c%25ce%25bd%25ce%25bf%25cf%2582"/>
        <updated>2023-06-18T04:50:29.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Jichang Lulu, with some minor modifications and additions by VHM] You might have seen this — the PRC embassy in Poland has given Badiucao's forthcoming exhibition in Warsaw (coorganised by Sinopsis) some very welcome, completely unexpected publicity by trying to have it shut down. Lots of international reporting: The Guardian, Sydney Morning Herald, &c., &c. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[webscussion on Bayesian causality]]></title>
        <id>http://xianblog.wordpress.com/?p=53243</id>
        <link href="https://xianblog.wordpress.com/2023/06/18/webscussion-on-bayesian-causality/"/>
        <updated>2023-06-17T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[Today, I attended (most of) and briefly took part in the discussion webinar run by Bayesian Analysis (the journal) and featuring the paper Causal Inference Under Mis-Specification: Adjustment Based on the Propensity Score by David Stephens, Widemberg Nobre, Erica Moodie, and Alexandra M. Schmidt, for which Pierre Jacob and I contributed a written discussion. I […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Throw a photo" in South Florida English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59266</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59266&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=throw-a-photo-in-south-florida-english"/>
        <updated>2023-06-17T20:45:14.000Z</updated>
        <summary type="html"><![CDATA[Article by Phillip M. Carter in The Conversation (6/12/23): "Linguists have identified a new English dialect that’s emerging in South Florida" Beginning sentences: “We got down from the car and went inside.” “I made the line to pay for groceries.” “He made a party to celebrate his son’s birthday.” These phrases might sound off to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ancient eggcorns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59277</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59277&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ancient-eggcorns"/>
        <updated>2023-06-17T13:29:57.000Z</updated>
        <summary type="html"><![CDATA[The word eggcorn was originally proposed in a LLOG post almost 20 years ago — "Egg corns: folk etymology, malapropism, mondegreen, ???", 9/23/2003.  And the word is now recognized by most current English dictionaries and other relevant sources, which gloss it variously, e.g. — the  Oxford English Dictionary, ("An alteration of a word or phrase […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Coors Light Bear]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59272</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59272&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=coors-light-bear"/>
        <updated>2023-06-17T09:28:04.000Z</updated>
        <summary type="html"><![CDATA[An NFL policy prohibits plays from endorsing alcoholic beverages. So Coors found a linguistic work-around: Last year's commercial promoted the Coors (Flash) Light: I have some inter-related contractual and cultural questions. Are these commercials really consistent, legally, with a contractual agreement not to promote alcoholic beverages? Is is crucial that there actual merch you can […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[shame!]]></title>
        <id>http://xianblog.wordpress.com/?p=53289</id>
        <link href="https://xianblog.wordpress.com/2023/06/17/53289/"/>
        <updated>2023-06-16T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rivers and lakes:  quackery]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59232</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59232&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rivers-and-lakes-quackery"/>
        <updated>2023-06-16T19:03:16.000Z</updated>
        <summary type="html"><![CDATA[Get ready to go a-wanderin'.  I'll take you down to the rivers and lakes, and we shall lose ourselves in them, get lost from the hurlyburly hustlebustle of the mundane world.  That's what jiānghú 江湖 ("rivers and lakes") is all about.  It's where you go to xiāoyáo yóu 逍遙遊 ("wander freely / carefreely / leisurely"). […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Her pension for body-hugging gowns…"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59257</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59257&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=her-pension-for-body-hugging-gowns"/>
        <updated>2023-06-16T12:34:28.000Z</updated>
        <summary type="html"><![CDATA[It's been a while since we discussed a new eggcorn, so here's one, from "Beauty and the bleach", The Vintage Woman 2020: Blonde bombshell. A phrase so used frequently in our accumulative vernacular that the significance now wanes. This phrase, once a revelation, was brought to our consciousness by Jean Harlow. The original platinum blonde. Her […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WavPool: A New Block for Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.08734</id>
        <link href="http://arxiv.org/abs/2306.08734"/>
        <updated>2023-06-16T07:13:31.376Z</updated>
        <summary type="html"><![CDATA[Samuel D. McDermott, M. Voetberg, Brian Nord]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phase diagram of Stochastic Gradient Descent in high-dimensional
  two-layer neural networks]]></title>
        <id>http://arxiv.org/abs/2202.00293</id>
        <link href="http://arxiv.org/abs/2202.00293"/>
        <updated>2023-06-16T07:13:30.776Z</updated>
        <summary type="html"><![CDATA[Rodrigo Veiga, Ludovic Stephan, Bruno Loureiro, Florent Krzakala,
  Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nonparametric regression using over-parameterized shallow ReLU neural
  networks]]></title>
        <id>http://arxiv.org/abs/2306.08321</id>
        <link href="http://arxiv.org/abs/2306.08321"/>
        <updated>2023-06-16T07:13:30.771Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unbiased Learning of Deep Generative Models with Structured Discrete
  Representations]]></title>
        <id>http://arxiv.org/abs/2306.08230</id>
        <link href="http://arxiv.org/abs/2306.08230"/>
        <updated>2023-06-16T07:13:30.766Z</updated>
        <summary type="html"><![CDATA[Harry Bendekgey, Gabriel Hope, Erik B. Sudderth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visualizing Deep Neural Networks with Topographic Activation Maps]]></title>
        <id>http://arxiv.org/abs/2204.03528</id>
        <link href="http://arxiv.org/abs/2204.03528"/>
        <updated>2023-06-16T07:13:30.619Z</updated>
        <summary type="html"><![CDATA[Valerie Krug, Raihan Kabir Ratul, Christopher Olson, Sebastian Stober]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[🎉 PyTorch Docathon H1 2023 Wrap-up 🎉]]></title>
        <id>https://pytorch.org/blog/docathon-h1-2023-wrap-up/</id>
        <link href="https://pytorch.org/blog/docathon-h1-2023-wrap-up/"/>
        <updated>2023-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Thank you to all who participated in our first ever PyTorch Docathon, the results have been nothing short of amazing! We want to extend our sincerest gratitude to all the participants who made this event a resounding success. Your passion, talent, and hard work have left an indelible mark on the PyTorch documentation.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[梯度流：探索通往最小值之路]]></title>
        <id>https://kexue.fm/archives/9660</id>
        <link href="https://kexue.fm/archives/9660"/>
        <updated>2023-06-16T02:10:00.000Z</updated>
        <summary type="html"><![CDATA[在这篇文章中，我们将探讨一个被称为“梯度流（Gradient Flow）”的概念。简单来说，梯度流是将我们在用梯度下降法中寻找最小值的过程中的各个点连接起来，形成一条随（虚拟的）时间变化的轨迹，...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noctureine 2023]]></title>
        <id>http://xianblog.wordpress.com/?p=53100</id>
        <link href="https://xianblog.wordpress.com/2023/06/16/noctureine-2023/"/>
        <updated>2023-06-15T22:23:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Syllabolic"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59235</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59235&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=syllabolic"/>
        <updated>2023-06-15T21:58:09.000Z</updated>
        <summary type="html"><![CDATA[On June 1 in Iowa, Donald Trump gave a speech in which he attacked Ron DeSantis from several angles. One of them was DeSantis' variation in pronunciation of his last name (see "Pronouncing 'DeSantis'", 6/3/2023), which Trump characterized as "changing his name", while introducing a puzzling (but promising?) new linguistic term, "syllabolic": Your browser does […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speed is all you need: On-device acceleration of large diffusion models via GPU-aware optimizations]]></title>
        <id>http://ai.googleblog.com/2023/06/speed-is-all-you-need-on-device.html</id>
        <link href="http://ai.googleblog.com/2023/06/speed-is-all-you-need-on-device.html"/>
        <updated>2023-06-15T20:53:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Juhyun Lee and Raman Sarokin, Software Engineers, Core Systems & Experiences




The proliferation of large diffusion models for image generation has led to a significant increase in model size and inference workloads. On-device ML inference in mobile environments requires meticulous performance optimization and consideration of trade-offs due to resource constraints. Running inference of large diffusion models (LDMs) on-device, driven by the need for cost efficiency and user privacy, presents even greater challenges due to the substantial memory requirements and computational demands of these models.
 

We address this challenge in our work titled “Speed Is All You Need: On-Device Acceleration of Large Diffusion Models via GPU-Aware Optimizations” (to be presented at the CVPR 20…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Cantophone and the state]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59228</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59228&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-cantophone-and-the-state"/>
        <updated>2023-06-15T12:19:22.000Z</updated>
        <summary type="html"><![CDATA[Cantonese — its nature, its status, its past, present, and future, its place in the realm of Sinitic languages and in the world — has been one of the chief foci of Language Log.  Consequently, it is my great pleasure to announce the publication of the three-hundred-and-thirty-fourth issue of Sino-Platonic Papers: “The Concept of the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classifier Calibration: A survey on how to assess and improve predicted
  class probabilities]]></title>
        <id>http://arxiv.org/abs/2112.10327</id>
        <link href="http://arxiv.org/abs/2112.10327"/>
        <updated>2023-06-15T07:14:30.613Z</updated>
        <summary type="html"><![CDATA[Telmo Silva Filho, Hao Song, Miquel Perello-Nieto, Raul
  Santos-Rodriguez, Meelis Kull, Peter Flach]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
</feed>