<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-07-01T20:15:58.178Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Antakshari recitation in India]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59476</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59476&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=antakshari-recitation-in-india"/>
        <updated>2023-07-01T13:10:15.000Z</updated>
        <summary type="html"><![CDATA[This is part of a long series of Language Log posts in which we pondered the phenomenal memorization skills of persons of Indian heritage (see "Selected readings" below). So you know what's happening in the following astonishing video, let me begin by giving a basic definition, etymology, and explication of what happens in this intricate […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[36 heures à Paris]]></title>
        <id>http://xianblog.wordpress.com/?p=53363</id>
        <link href="https://xianblog.wordpress.com/2023/07/01/36-heures-a-paris/"/>
        <updated>2023-06-30T22:23:16.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The spiny terminological conundrum of ekhidna and ekhinos]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59471</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59471&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-spiny-terminological-conundrum-of-ekhidna-and-ekhinos"/>
        <updated>2023-06-30T19:15:51.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Stewart Nicol] Greek particles I am a zoologist and comparative physiologist who has worked extensively on the monotremes, the platypus and the echidna. I have been putting together some notes on the naming of the these animals. After originally being placed in the genus Myrmecophaga with the other, totally unrelated, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alex Cohen, Cosmin Pohoata, and Dmitrii Zakharov Improved the Upper Bound for the Heilbronn triangle problem!]]></title>
        <id>http://gilkalai.wordpress.com/?p=24605</id>
        <link href="https://gilkalai.wordpress.com/2023/06/30/alex-cohen-cosmin-pohoata-and-dmitrii-zakharov-improved-the-upper-bound-for-the-heilbronn-triangle-problem/"/>
        <updated>2023-06-30T07:51:31.000Z</updated>
        <summary type="html"><![CDATA[A new upper bound for the Heilbronn triangle problem was proved by Alex Cohen, Cosmin Pohoata, and Dmitrii Zakharov. Congratulations! The paper is A new upper bound for the Heilbronn triangle problem Abstract: For sufficiently large n, we show that … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alex Cohen, Cosmin Pohoata, and Dmitrii Zakharov Improved the Upper Bound for the Heilbronn triangle problem!]]></title>
        <id>http://gilkalai.wordpress.com/?p=24605</id>
        <link href="https://gilkalai.wordpress.com/2023/06/30/alex-cohen-cosmin-pohoata-and-dmitrii-zakharov-improved-the-upper-bound-for-the-heilbronn-triangle-problem/"/>
        <updated>2023-06-30T07:51:31.000Z</updated>
        <summary type="html"><![CDATA[A new upper bound for the Heilbronn triangle problem was proved by Alex Cohen, Cosmin Pohoata, and Dmitrii Zakharov. Congratulations! The paper is A new upper bound for the Heilbronn triangle problem Abstract: For sufficiently large n, we show that … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Concept-Oriented Deep Learning with Large Language Models]]></title>
        <id>http://arxiv.org/abs/2306.17089</id>
        <link href="http://arxiv.org/abs/2306.17089"/>
        <updated>2023-06-30T07:14:48.986Z</updated>
        <summary type="html"><![CDATA[Daniel T. Chang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Graph Neural Networks with Generalized Geometric
  Scattering Transforms]]></title>
        <id>http://arxiv.org/abs/1911.06253</id>
        <link href="http://arxiv.org/abs/1911.06253"/>
        <updated>2023-06-30T07:14:48.969Z</updated>
        <summary type="html"><![CDATA[Michael Perlmutter, Alexander Tong, Feng Gao, Guy Wolf and
  Matthew Hirn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Joint Multi-view Unsupervised Feature Selection and Graph Learning]]></title>
        <id>http://arxiv.org/abs/2204.08247</id>
        <link href="http://arxiv.org/abs/2204.08247"/>
        <updated>2023-06-30T07:14:48.936Z</updated>
        <summary type="html"><![CDATA[Si-Guo Fang, Dong Huang, Chang-Dong Wang, Yong Tang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Advantage of Curriculum Learning on Parity Targets with Mixed
  Inputs]]></title>
        <id>http://arxiv.org/abs/2306.16921</id>
        <link href="http://arxiv.org/abs/2306.16921"/>
        <updated>2023-06-30T07:14:48.911Z</updated>
        <summary type="html"><![CDATA[Emmanuel Abbe, Elisabetta Cornacchia, Aryo Lotfi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural networks can detect model-free static arbitrage strategies]]></title>
        <id>http://arxiv.org/abs/2306.16422</id>
        <link href="http://arxiv.org/abs/2306.16422"/>
        <updated>2023-06-30T07:14:48.865Z</updated>
        <summary type="html"><![CDATA[Ariel Neufeld, Julian Sester]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[short trip to a theocracy]]></title>
        <id>http://xianblog.wordpress.com/?p=53134</id>
        <link href="https://xianblog.wordpress.com/2023/06/30/trip-to-a-theocracy/"/>
        <updated>2023-06-29T22:23:20.000Z</updated>
        <summary type="html"><![CDATA[Besides attending a workshop on my research themes and meeting researchers from that field, a supplementary incentive for attending Stochastic Numerics and Statistical Learning was to catch a glimpse of Saudi Arabia and its idiosyncrasies.  While this is far from my first time visiting a Muslim theocracy, remembering a most enlightening (if penniless) backpacking trip […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing the first Machine Unlearning Challenge]]></title>
        <id>http://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html</id>
        <link href="http://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html"/>
        <updated>2023-06-29T21:08:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Fabian Pedregosa and Eleni Triantafillou, Research Scientists, Google





Deep learning has recently driven tremendous progress in a wide array of applications, ranging from realistic image generation and impressive retrieval systems to language models that can hold human-like conversations. While this progress is very exciting, the widespread use of deep neural network models requires caution: as guided by Google’s AI Principles, we seek to develop AI technologies responsibly by understanding and mitigating potential risks, such as the propagation and amplification of unfair biases and protecting user privacy.
 

Fully erasing the influence of the data requested to be deleted is challenging since, aside from simply deleting it from databases where it’s stored, it also requires …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On-device diffusion plugins for conditioned text-to-image generation]]></title>
        <id>http://ai.googleblog.com/2023/06/on-device-diffusion-plugins-for.html</id>
        <link href="http://ai.googleblog.com/2023/06/on-device-diffusion-plugins-for.html"/>
        <updated>2023-06-29T19:10:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Yang Zhao and Tingbo Hou, Software Engineers, Core ML




In recent years, diffusion models have shown great success in text-to-image generation, achieving high image quality, improved inference performance, and expanding our creative inspiration. Nevertheless, it is still challenging to efficiently control the generation, especially with conditions that are difficult to describe with text.



Today, we announce MediaPipe diffusion plugins, which enable controllable text-to-image generation to be run on-device. Expanding upon our prior work on GPU inference for on-device large generative models, we introduce new low-cost solutions for controllable text-to-image generation that can be plugged into existing diffusion models and their Low-Rank Adaptation (LoRA) variants. 




Text-t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The AI threat:  keep calm and carry on]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59453</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59453&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-ai-threat-keep-calm-and-carry-on"/>
        <updated>2023-06-29T18:36:01.000Z</updated>
        <summary type="html"><![CDATA[Three weekends ago, I delivered a keynote here: New Directions in Chinese Language Education in the 21st Century The Eighth International Conference on Teaching Chinese as a Second Language Swarthmore College, June 9-10, 2023 ———– Abbreviations:     AI — Artificial Intelligence     DT — Digital Technology     IT — Information Technology     DH — Digital […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cooperative creation with Generative AI]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59461</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59461&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=cooperative-creation-with-generative-ai"/>
        <updated>2023-06-29T13:59:05.000Z</updated>
        <summary type="html"><![CDATA[A couple of weeks ago, John Hansen tried "an experiment to see if I could successfully combine random and seemingly unconnected topics into one poem", and reported the results on Medium. This experiment was quickly reproduced by Adrian CDTPPW, Block Wife, and Robert G. Longpré. The structure was Choose three random words (No AI involved […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generating 3D Molecular Conformers via Equivariant Coarse-Graining and Aggregated Attention]]></title>
        <id>http://bair.berkeley.edu/blog/2023/06/29/coarsenconf/</id>
        <link href="http://bair.berkeley.edu/blog/2023/06/29/coarsenconf/"/>
        <updated>2023-06-29T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[-->

Figure 1: CoarsenConf architecture.

(I) The encoder $q_\phi(z| X, \mathcal{R})$ takes the fine-grained (FG) ground truth conformer $X$, RDKit approximate conformer $\mathcal{R}$ , and coarse-grained (CG) conformer $\mathcal{C}$ as inputs (derived from $X$ and a predefined CG strategy), and outputs a variable-length equivariant CG representation via equivariant message passing and point convolutions.
(II) Equivariant MLPs are applied to learn the mean and log variance of both the posterior and prior distributions.
(III) The posterior (training) or prior (inference) is sampled and fed into the Channel Selection module, where an attention layer is used to learn the optimal pathway from CG to FG structure.
(IV) Given the FG latent vector and the RDKit approximation, the decoder $p_\theta…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified machine learning: Classification with simultaneous observed and
  unobserved novelty detection]]></title>
        <id>http://arxiv.org/abs/2002.01368</id>
        <link href="http://arxiv.org/abs/2002.01368"/>
        <updated>2023-06-29T07:15:37.367Z</updated>
        <summary type="html"><![CDATA[Emile R. Engelbrecht, Johan A. du Preez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incorporating Prior Knowledge into Neural Networks through an Implicit
  Composite Kernel]]></title>
        <id>http://arxiv.org/abs/2205.07384</id>
        <link href="http://arxiv.org/abs/2205.07384"/>
        <updated>2023-06-29T07:15:36.141Z</updated>
        <summary type="html"><![CDATA[Ziyang Jiang, Tongshu Zheng, Yiling Liu, David Carlson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BayesFlow: Amortized Bayesian Workflows With Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.16015</id>
        <link href="http://arxiv.org/abs/2306.16015"/>
        <updated>2023-06-29T07:15:35.502Z</updated>
        <summary type="html"><![CDATA[Stefan T Radev, Marvin Schmitt, Lukas Schumacher, Lasse
  Elsem\"uller, Valentin Pratz, Yannik Sch\"alte, Ullrich K\"othe and
  Paul-Christian B\"urkner]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimizing LibTorch-based inference engine memory usage and thread-pooling]]></title>
        <id>https://pytorch.org/blog/optimizing-libtorch/</id>
        <link href="https://pytorch.org/blog/optimizing-libtorch/"/>
        <updated>2023-06-29T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Outline]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Metaphors for AI, and why I don’t like them]]></title>
        <id>http://windowsontheory.org/?p=8635</id>
        <link href="https://windowsontheory.org/2023/06/28/metaphors-for-ai-and-why-i-dont-like-them/"/>
        <updated>2023-06-28T22:46:34.000Z</updated>
        <summary type="html"><![CDATA[Photo from National Photo Company Collection; see also (Sobel, 2017) [Cross posted in lesswrong and windows on theory see here for my prior writings] “computer, n. /kəmˈpjuːtə/. One who computes; a calculator, reckoner; specifically a person employed to make calculations in an observatory, in surveying, etc”, Oxford English Dictionary “There is no reason why mental as well as bodily labor should … Continue reading Metaphors for AI, and why I don’t like them]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Metaphors for AI, and why I don’t like them]]></title>
        <id>http://windowsontheory.org/?p=8635</id>
        <link href="https://windowsontheory.org/2023/06/28/metaphors-for-ai-and-why-i-dont-like-them/"/>
        <updated>2023-06-28T22:46:34.000Z</updated>
        <summary type="html"><![CDATA[Photo from National Photo Company Collection; see also (Sobel, 2017) [Cross posted in lesswrong and windows on theory see here for my prior writings] “computer, n. /kəmˈpjuːtə/. One who computes; a calculator, reckoner; specifically a person employed to make calculations in an observatory, in surveying, etc”, Oxford English Dictionary “There is no reason why mental as well as bodily labor should … Continue reading Metaphors for AI, and why I don’t like them]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[nAIture]]></title>
        <id>http://xianblog.wordpress.com/?p=53324</id>
        <link href="https://xianblog.wordpress.com/2023/06/29/naiture/"/>
        <updated>2023-06-28T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[Plenty of AI related entries in Nature this week (8 June 2023): Why Nature will not allow the use of generative AI in images and videos (until they cannot spot them) AI intensifies fight against paper mills (as a further hindrance rather than an ally) AI learns to write sorting software on its own, through […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flash sale]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59433</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59433&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=flash-sale"/>
        <updated>2023-06-28T22:06:15.000Z</updated>
        <summary type="html"><![CDATA[Ben Zimmer spotted this interesting street sign in the New York Times photo essay, "DMs from New York City" (June 26, 2023). The Chinese says: suǒyǒu shāngpǐn所有商品"all merchandise" qīnghuò清货"clearance / liquidation of goods" jǐnjí chǔlǐ紧急处理"[must / will be] dealt with / handled urgently" It is true that chǔlǐ 处理 often, if not usually, means "process" […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Today I learned  a new word]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59447</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59447&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=today-i-learned-a-new-word"/>
        <updated>2023-06-28T17:46:06.000Z</updated>
        <summary type="html"><![CDATA[The new-to-me word: assembloid. It occurred in the second (of 20!) bullet points that the blurb for a new publication, Brain Organoid & Systems Neuroscience Journal, lists under the heading Specific areas of interest include, but are not limited to: Brain organogenesis and Neuronal cultures Methods for generating brain assembloids The rest of the list: […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Touring the Turing Test again]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59428</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59428&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=touring-the-turing-test-again"/>
        <updated>2023-06-28T12:28:06.000Z</updated>
        <summary type="html"><![CDATA[The buzz about Large Language Models has re-ignited interest Alan Turing's famous 1950 article "Computing Machinery and Intelligence". Two interesting recent discussions: Jessica Riskin, "A Sort of Buzzing Inside My Head", NYRB 6/25/2023, and Mustafa Suleyman, "The Coming Wave: Technology, Power, and the Twenty-first Century's Greatest Dilemma", Random House 9/5/2023. Suleyman's book won't be released until […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tasting History]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59425</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59425&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tasting-history"/>
        <updated>2023-06-28T10:10:37.000Z</updated>
        <summary type="html"><![CDATA[That's the name of a viral YouTube channel that I had never heard of, and now a popular book that Barbara Phillips Long called to my attention: My son gave me a copy of Tasting History, by Max Miller, which takes very old recipes and gives modern approximations of them. The book is handsomely printed, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LeanDojo: Theorem Proving with Retrieval-Augmented Language Models]]></title>
        <id>http://arxiv.org/abs/2306.15626</id>
        <link href="http://arxiv.org/abs/2306.15626"/>
        <updated>2023-06-28T07:16:00.831Z</updated>
        <summary type="html"><![CDATA[Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chalamala, Peiyang Song,
  Shixing Yu, Saad Godil, Ryan Prenger, Anima Anandkumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal inference is (almost) free for neural networks trained with
  early stopping]]></title>
        <id>http://arxiv.org/abs/2301.11556</id>
        <link href="http://arxiv.org/abs/2301.11556"/>
        <updated>2023-06-28T07:16:00.803Z</updated>
        <summary type="html"><![CDATA[Ziyi Liang, Yanfei Zhou, Matteo Sesia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Neural Networks for Rank-Consistent Ordinal Regression Based On
  Conditional Probabilities]]></title>
        <id>http://arxiv.org/abs/2111.08851</id>
        <link href="http://arxiv.org/abs/2111.08851"/>
        <updated>2023-06-28T07:15:56.500Z</updated>
        <summary type="html"><![CDATA[Xintong Shi, Wenzhi Cao, Sebastian Raschka]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Kernel Learning of Dynamical Models from High-Dimensional Noisy
  Data]]></title>
        <id>http://arxiv.org/abs/2208.12975</id>
        <link href="http://arxiv.org/abs/2208.12975"/>
        <updated>2023-06-28T07:15:56.445Z</updated>
        <summary type="html"><![CDATA[Nicol\`o Botteghi, Mengwu Guo, Christoph Brune]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Neural Networks as Infinite Tree-Structured Probabilistic Graphical
  Models]]></title>
        <id>http://arxiv.org/abs/2305.17583</id>
        <link href="http://arxiv.org/abs/2305.17583"/>
        <updated>2023-06-28T07:15:56.438Z</updated>
        <summary type="html"><![CDATA[Boyao Li, Alexandar J. Thomson, Matthew M. Engelhard, David Page]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Path to Achieve Ultra-Low Inference Latency With LLaMA 65B]]></title>
        <id>https://pytorch.org/blog/path-achieve-low-inference-latency/</id>
        <link href="https://pytorch.org/blog/path-achieve-low-inference-latency/"/>
        <updated>2023-06-28T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Background &amp; State of the Art]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[生成扩散模型漫谈（二十）：从ReFlow到WGAN-GP]]></title>
        <id>https://kexue.fm/archives/9668</id>
        <link href="https://kexue.fm/archives/9668"/>
        <updated>2023-06-28T01:48:00.000Z</updated>
        <summary type="html"><![CDATA[上一篇文章《生成扩散模型漫谈（十九）：作为扩散ODE的GAN》中，我们介绍了如何将GAN理解为在另一个时间维度上的扩散ODE，简而言之，GAN实际上就是将扩散模型中样本的运动转化为生成器参数的运...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[re-MCM’d]]></title>
        <id>http://xianblog.wordpress.com/?p=53368</id>
        <link href="https://xianblog.wordpress.com/2023/06/28/re-mcmd/"/>
        <updated>2023-06-27T22:23:05.000Z</updated>
        <summary type="html"><![CDATA[When I entered the classroom on the Jussieu campus where the Monday morning session on PDMP was taking place, some friends told me a badge was waiting for me at the registration desk of MCM 2023! Most surprisingly since I had received a deregistration message a few weeks earlier. Great PDMP session with non-reversible tempering […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unifying image-caption and image-classification datasets with prefix conditioning]]></title>
        <id>http://ai.googleblog.com/2023/06/unifying-image-caption-and-image.html</id>
        <link href="http://ai.googleblog.com/2023/06/unifying-image-caption-and-image.html"/>
        <updated>2023-06-27T21:19:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Kuniaki Saito, Student Researcher, Cloud AI Team, and Kihyuk Sohn, Research Scientist, Perception Team




Pre-training visual language (VL) models on web-scale image-caption datasets has recently emerged as a powerful alternative to traditional pre-training on image classification data. Image-caption datasets are considered to be more “open-domain” because they contain broader scene types and vocabulary words, which result in models with strong performance in few- and zero-shot recognition tasks. However, images with fine-grained class descriptions can be rare, and the class distribution can be imbalanced since image-caption datasets do not go through manual curation. By contrast, large-scale classification datasets, such as ImageNet, are often curated and can thus provide fine-…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near Optimal Heteroscedastic Regression with Symbiotic Learning]]></title>
        <id>http://arxiv.org/abs/2306.14288</id>
        <link href="http://arxiv.org/abs/2306.14288"/>
        <updated>2023-06-27T07:15:43.389Z</updated>
        <summary type="html"><![CDATA[Dheeraj Baby, Aniket Das, Dheeraj Nagaraj, Praneeth
  Netrapalli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Trustworthy Explanation: On Causal Rationalization]]></title>
        <id>http://arxiv.org/abs/2306.14115</id>
        <link href="http://arxiv.org/abs/2306.14115"/>
        <updated>2023-06-27T07:15:43.383Z</updated>
        <summary type="html"><![CDATA[Wenbo Zhang, Tong Wu, Yunlong Wang, Yong Cai, Hengrui Cai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representation Ensembling for Synergistic Lifelong Learning with
  Quasilinear Complexity]]></title>
        <id>http://arxiv.org/abs/2004.12908</id>
        <link href="http://arxiv.org/abs/2004.12908"/>
        <updated>2023-06-27T07:15:43.377Z</updated>
        <summary type="html"><![CDATA[Joshua T. Vogelstein, Jayanta Dey, Hayden S. Helm, Will LeVine, Ronak
  D. Mehta, Tyler M. Tomita, Haoyin Xu, Ali Geisa, Qingyang Wang, Gido M. van
  de Ven, Chenyu Gao, Weiwei Yang, Bryan Tower, Jonathan Larson, Christopher M.
  White, Carey E. Priebe]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representation Transfer Learning via Multiple Pre-trained models for
  Linear Regression]]></title>
        <id>http://arxiv.org/abs/2305.16440</id>
        <link href="http://arxiv.org/abs/2305.16440"/>
        <updated>2023-06-27T07:15:43.371Z</updated>
        <summary type="html"><![CDATA[Navjot Singh, Suhas Diggavi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The scatology and physiology of push and pull]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59422</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59422&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-scatology-and-physiology-of-push-and-pull"/>
        <updated>2023-06-27T00:11:13.000Z</updated>
        <summary type="html"><![CDATA[Having just written about "Drainage issues" (6/25/23), with a graphic depiction of what causes the problem with the drainage system in question, I am emboldened finally to answer a question that one of my graduate students has been asking about for several years.  Namely, why do Chinese say "pull poo / shit / excrement" (lāshǐ […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When NumPy is too slow]]></title>
        <id>https://pythonspeed.com/articles/numpy-is-slow/</id>
        <link href="https://pythonspeed.com/articles/numpy-is-slow/"/>
        <updated>2023-06-27T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[If you’re doing numeric calculations, NumPy is a lot faster than than plain Python—but sometimes that’s not enough.
What should you do when your NumPy-based code is too slow?
Your first thought might be parallelism, but that should probably be the last thing you consider.
There are many speedups you can do before parallelism becomes helpful, from algorithmic improvements to working around NumPy’s architectural limitations.
Let’s see why NumPy can be slow, and then some solutions to help speed up your code even more.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Xing the 100k milestone]]></title>
        <id>http://xianblog.wordpress.com/?p=53264</id>
        <link href="https://xianblog.wordpress.com/2023/06/27/xing-the-100k-milestone/"/>
        <updated>2023-06-26T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI for Akkadian]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59411</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59411&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-for-akkadian"/>
        <updated>2023-06-26T11:12:00.000Z</updated>
        <summary type="html"><![CDATA[Article by Melanie Lidman in The Times of Israel (6/17/23): Groundbreaking AI project translates 5,000-year-old cuneiform at push of a button ‘Google Translate’-like program for Akkadian cuneiform will enable tens of thousands of digitized but unread tablets to be translated to English. Accuracy is debatable. Opening and key paragraphs: Cuneiform is the oldest known form […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convergence of First-Order Methods for Constrained Nonconvex
  Optimization with Dependent Data]]></title>
        <id>http://arxiv.org/abs/2203.15797</id>
        <link href="http://arxiv.org/abs/2203.15797"/>
        <updated>2023-06-26T09:17:23.822Z</updated>
        <summary type="html"><![CDATA[Ahmet Alacaoglu, Hanbaek Lyu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMART: An Open Source Data Labeling Platform for Supervised Learning]]></title>
        <id>http://arxiv.org/abs/1812.06591</id>
        <link href="http://arxiv.org/abs/1812.06591"/>
        <updated>2023-06-26T07:16:33.172Z</updated>
        <summary type="html"><![CDATA[Rob Chew, Michael Wenger, Caroline Kery, Jason Nance, Keith Richards,
  Emily Hadley, Peter Baumgartner]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Precise Asymptotic Generalization for Multiclass Classification with
  Overparameterized Linear Models]]></title>
        <id>http://arxiv.org/abs/2306.13255</id>
        <link href="http://arxiv.org/abs/2306.13255"/>
        <updated>2023-06-26T07:16:33.165Z</updated>
        <summary type="html"><![CDATA[David X. Wu, Anant Sahai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Compression with Bayesian Implicit Neural Representations]]></title>
        <id>http://arxiv.org/abs/2305.19185</id>
        <link href="http://arxiv.org/abs/2305.19185"/>
        <updated>2023-06-26T07:16:33.144Z</updated>
        <summary type="html"><![CDATA[Zongyu Guo, Gergely Flamich, Jiajun He, Zhibo Chen, Jos\'e Miguel
  Hern\'andez-Lobato]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximate Causal Effect Identification under Weak Confounding]]></title>
        <id>http://arxiv.org/abs/2306.13242</id>
        <link href="http://arxiv.org/abs/2306.13242"/>
        <updated>2023-06-26T07:16:33.135Z</updated>
        <summary type="html"><![CDATA[Ziwei Jiang, Lai Wei, Murat Kocaoglu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding quantum machine learning also requires rethinking
  generalization]]></title>
        <id>http://arxiv.org/abs/2306.13461</id>
        <link href="http://arxiv.org/abs/2306.13461"/>
        <updated>2023-06-26T07:16:33.055Z</updated>
        <summary type="html"><![CDATA[Elies Gil-Fuster, Jens Eisert, Carlos Bravo-Prieto]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BobWords on eggcorn]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59418</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59418&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bobwords-on-eggcorn"/>
        <updated>2023-06-25T23:38:50.000Z</updated>
        <summary type="html"><![CDATA[RobWords for June 24, 2023: The word eggcorn was originally proposed in "Egg corns: folk etymology, malapropism, mondegreen, ???", 9/23/2003, and most recently discussed in "Ancient Eggcorns", 6/17/2023.]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[definitely wrong]]></title>
        <id>http://xianblog.wordpress.com/?p=53237</id>
        <link href="https://xianblog.wordpress.com/2023/06/26/definitely-wrong/"/>
        <updated>2023-06-25T22:23:54.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-wheat food]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59369</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59369&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=non-wheat-food"/>
        <updated>2023-06-25T21:06:08.000Z</updated>
        <summary type="html"><![CDATA[From John Rohsenow: qǐng wù zài běn cāntīng nèi jìnshí fēi Màiduōlè shípǐn huò yǐnliào 请勿在本餐厅内进食非麦多乐食品或饮料 "Please do not consume non-Madola food or drink in this restaurant" Pretty straightforward, eh?  Except that we have to explain that Madola (Màiduōlè 麦多乐 [lit., "wheat-much-music"]) is probably a local (fast) food brand trying to emulate McDonald's (Màidāngláo 麦当劳).  Madola […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Drainage issues]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59405</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59405&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=drainage-issues"/>
        <updated>2023-06-25T21:02:42.000Z</updated>
        <summary type="html"><![CDATA[Photograph taken in Hong Kong: The Chinese says: qúwù wèntí gù zhǐ néng zuò xiǎojiě   jìngqǐng hézuò渠務問題故只能作小解  敬請合作"Since there are drainage problems, can only be used for urination.  Your cooperation is respectfully requested."   BTW: GT:  "The drainage problem can only be explained briefly, please cooperate." Baidu Fanyi:  "Due to drainage issues, we can […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Use chili sparingly]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59391</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59391&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=use-chili-sparingly"/>
        <updated>2023-06-25T04:18:02.000Z</updated>
        <summary type="html"><![CDATA[From AntC: Seen in a very typical (but delicious) corner eatery in downtown Hualien, Taiwan. Surprisingly idiomatic translation: "use sparingly" in Hualien GTranslate isn't so idiomatic; I'm not able to try DeepL — any better? I agree with AntC that "use sparingly" is a strikingly fine English expression, one that does not seem possible from a […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phenomenology]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59401</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59401&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=phenomenology"/>
        <updated>2023-06-25T01:54:34.000Z</updated>
        <summary type="html"><![CDATA[Nancy Kathryn Walecki, "Sound as Ever: Gram Parsons and Harvard’s hand in country rock", Harvard Magazine July-August 2023: During Parsons’s Burritos era, Thomas left Harvard to write his dissertation in a cabin on Mount Baldy outside Los Angeles. Now more of an older brother to Parsons than a proctor, he would take study breaks with […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=53299</id>
        <link href="https://xianblog.wordpress.com/2023/06/25/a-journal-of-the-conquest-war-famine-and-death-year/"/>
        <updated>2023-06-24T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[Read both following volumes of Peter May’s Lewis trilogy, The Lewis Man and The Chessmen. The stories remain focussed on the same few characters as in the first volume, with some predictable developments and a rather heavy borrowing to the local history in the shape of a peat-bog mommy or a plane crash. And of […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prigozhin's pronouns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59396</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59396&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=prigozhins-pronouns"/>
        <updated>2023-06-24T14:26:14.000Z</updated>
        <summary type="html"><![CDATA[Just wow. A video has surfaced showing Prigozhin at the Southern Military District HQ in Rostov-on-Don talking to (and HUMILIATING) Deputy Defense Minister Yunus-bek Yevkurov. He threatens to blockade Rostov and head for Moscow! I have extreme trouble understanding Yevkurov and… pic.twitter.com/jGr9gaLB1i — Kevin Rothrock (@KevinRothrock) June 24, 2023 An English translation of the linguistically-relevant […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five old, white men]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59388</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59388&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=five-old-white-men"/>
        <updated>2023-06-24T11:16:19.000Z</updated>
        <summary type="html"><![CDATA[I promised that I would tell the story of how five old, white men persuaded me to begin the study of Asian languages two years after I was out of college.  Here it is. When I graduated from Dartmouth in 1965, I joined the Peace Corps for two years in Nepal.  Although I contracted fifteen […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the generalizations of global dimensions and singularity categories]]></title>
        <id>http://arxiv.org/abs/2306.09832</id>
        <link href="http://arxiv.org/abs/2306.09832"/>
        <updated>2023-06-24T07:15:01.670Z</updated>
        <summary type="html"><![CDATA[Xiaolei Zhang, Tiwei Zhao, Dingguo Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[生成扩散模型漫谈（十九）：作为扩散ODE的GAN]]></title>
        <id>https://kexue.fm/archives/9662</id>
        <link href="https://kexue.fm/archives/9662"/>
        <updated>2023-06-24T01:38:00.000Z</updated>
        <summary type="html"><![CDATA[在文章《生成扩散模型漫谈（十六）：W距离 ≤ 得分匹配》中，我们推导了Wasserstein距离与扩散模型得分匹配损失之间的一个不等式，表明扩散模型的优化目标与WGAN的优化目标在某种程度上具有...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[noctureine 2023 [16/6/23, 20h40, 10k, 41’54”, 29⁰, 48th/295, 1st M5/11]]]></title>
        <id>http://xianblog.wordpress.com/?p=53258</id>
        <link href="https://xianblog.wordpress.com/2023/06/24/noctureine-2023-2/"/>
        <updated>2023-06-23T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gardening on the path]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59383</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59383&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=gardening-on-the-path"/>
        <updated>2023-06-23T22:01:29.000Z</updated>
        <summary type="html"><![CDATA[The most recent xkcd: Mouseover title: "Arboretum Owner Denied Standing in Garden Path Suit on Grounds Grounds Appealing Appealing" What the Berkeley Neural Parser thinks: (S (PP (IN After) (NP (NN bird) (VBZ strikes))) (NP (NP (NN judge)) (SBAR (WHNP (WP who)) (S (VP (VBD ordered) (NP (NNP olive) (NNP garden) (NNP path) (NN sentence)) […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Preference learning with automated feedback for cache eviction]]></title>
        <id>http://ai.googleblog.com/2023/06/preference-learning-with-automated.html</id>
        <link href="http://ai.googleblog.com/2023/06/preference-learning-with-automated.html"/>
        <updated>2023-06-23T19:24:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Ramki Gummadi, Software Engineer, Google and Kevin Chen, Software Engineer, YouTube





Caching is a ubiquitous idea in computer science that significantly improves the performance of storage and retrieval systems by storing a subset of popular items closer to the client based on request patterns. An important algorithmic piece of cache management is the decision policy used for dynamically updating the set of items being stored, which has been extensively optimized over several decades, resulting in several efficient and robust heuristics. While applying machine learning to cache policies has shown promising results in recent years (e.g., LRB, LHD, storage applications), it remains a challenge to outperform robust heuristics in a way that can generalize reliably beyond benchmar…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Origin of Speeches? or just the collapse of Uruk?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59365</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59365&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-origin-of-speeches-or-just-the-collapse-of-uruk"/>
        <updated>2023-06-23T17:16:45.000Z</updated>
        <summary type="html"><![CDATA[I've wondered for a long time why Biblical inerrantists have a big problem with biological evolution, which contradicts Chapter 1 of Genesis, but not so much with historical linguistics, which contradicts Chapter 11. But in "Linguistic Confusion and the Tower of Babel", National Catholic Register 6/21/2023, Dave Armstrong argues that the usual interpretation of the […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The allure of Latin, the glory of Greek]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59358</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59358&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-allure-of-latin-the-glory-of-greek"/>
        <updated>2023-06-23T13:46:11.000Z</updated>
        <summary type="html"><![CDATA[Beautiful WSJ OpED (6/22/23) by Gerard Gayou, a seminarian of the archdiocese of Washington, who is studying theology at the Pontifical North American College in Rome: The Guiding Light of Latin Grammar The language reminds us of what our words mean and of whom we’re called to be. —– Nothing bored me more during the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interpretable Neural-Symbolic Concept Reasoning]]></title>
        <id>http://arxiv.org/abs/2304.14068</id>
        <link href="http://arxiv.org/abs/2304.14068"/>
        <updated>2023-06-23T09:17:07.507Z</updated>
        <summary type="html"><![CDATA[Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Mateo
  Espinosa Zarlenga, Lucie Charlotte Magister, Alberto Tonda, Pietro Lio',
  Frederic Precioso, Mateja Jamnik, Giuseppe Marra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sharp analysis of EM for learning mixtures of pairwise differences]]></title>
        <id>http://arxiv.org/abs/2302.10066</id>
        <link href="http://arxiv.org/abs/2302.10066"/>
        <updated>2023-06-23T07:19:28.276Z</updated>
        <summary type="html"><![CDATA[Abhishek Dhawan, Cheng Mao, Ashwin Pananjady]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the explainable properties of 1-Lipschitz Neural Networks: An Optimal
  Transport Perspective]]></title>
        <id>http://arxiv.org/abs/2206.06854</id>
        <link href="http://arxiv.org/abs/2206.06854"/>
        <updated>2023-06-23T07:19:28.271Z</updated>
        <summary type="html"><![CDATA[Mathieu Serrurier (IRIT, UT), Franck Mamalet (UT), Thomas Fel (UT),
  Louis B\'ethune (UT3, UT, IRIT), Thibaut Boissin (UT)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Path to Autonomous Learners]]></title>
        <id>http://arxiv.org/abs/2211.02403</id>
        <link href="http://arxiv.org/abs/2211.02403"/>
        <updated>2023-06-23T07:19:28.265Z</updated>
        <summary type="html"><![CDATA[Hanna Abi Akl]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Finite-time Lyapunov exponents of deep neural networks]]></title>
        <id>http://arxiv.org/abs/2306.12548</id>
        <link href="http://arxiv.org/abs/2306.12548"/>
        <updated>2023-06-23T07:19:28.245Z</updated>
        <summary type="html"><![CDATA[L. Storm, H. Linander, J. Bec, K. Gustavsson, B. Mehlig]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SQ Lower Bounds for Learning Bounded Covariance GMMs]]></title>
        <id>http://arxiv.org/abs/2306.13057</id>
        <link href="http://arxiv.org/abs/2306.13057"/>
        <updated>2023-06-23T07:19:28.227Z</updated>
        <summary type="html"><![CDATA[Ilias Diakonikolas, Daniel M. Kane, Thanasis Pittas, Nikos Zarifis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LLM Powered Autonomous Agents]]></title>
        <id>https://lilianweng.github.io/posts/2023-06-23-agent/</id>
        <link href="https://lilianweng.github.io/posts/2023-06-23-agent/"/>
        <updated>2023-06-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.
Agent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:]]></summary>
        <author>
            <name>Lil'Log</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#3]]]></title>
        <id>http://xianblog.wordpress.com/?p=53355</id>
        <link href="https://xianblog.wordpress.com/2023/06/23/approximation-methods-in-bayesian-analysis-3/"/>
        <updated>2023-06-22T22:23:24.000Z</updated>
        <summary type="html"><![CDATA[My last day (#4) at the workshop, as I had to return to Paris earlier. A rather theoretical morning again, with Morgane Austern on (probabilistic) concentration inequalities on transport distances, far from my comfort zone if lively, Jason Xu on replacing non-convex penalisation factors to distances to the corresponding manifold, which I found most interesting […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SoundStorm: Efficient parallel audio generation]]></title>
        <id>http://ai.googleblog.com/2023/06/soundstorm-efficient-parallel-audio.html</id>
        <link href="http://ai.googleblog.com/2023/06/soundstorm-efficient-parallel-audio.html"/>
        <updated>2023-06-22T18:33:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Zalán Borsos, Research Software Engineer, and Marco Tagliasacchi, Senior Staff Research Scientist, Google Research







The recent progress in generative AI unlocked the possibility of creating new content in several different domains, including text, vision and audio. These models often rely on the fact that raw data is first converted to a compressed format as a sequence of tokens. In the case of audio, neural audio codecs (e.g., SoundStream or EnCodec) can efficiently compress waveforms to a compact representation, which can be inverted to reconstruct an approximation of the original audio signal. Such a representation consists of a sequence of discrete audio tokens, capturing the local properties of sounds (e.g., phonemes) and their temporal structure (e.g., prosody). By re…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The legal standing of the serial comma]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59352</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59352&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-legal-standing-of-the-serial-comma"/>
        <updated>2023-06-22T13:30:29.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Mark Cohen] I am wondering if members of this group have had experience with translating the Chinese serial comma or dùnhào 顿号  [、] ("the caesura sign; a slight-pause mark used to set off items in a series; punctuation mark used between parallel words or short phrases; sign of coordination; […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Problem: Learning with Variational Objectives on Measures]]></title>
        <id>http://arxiv.org/abs/2306.11928</id>
        <link href="http://arxiv.org/abs/2306.11928"/>
        <updated>2023-06-22T07:16:05.265Z</updated>
        <summary type="html"><![CDATA[Vivien Cabannes, Carles Domingo-Enrich]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Any Deep ReLU Network is Shallow]]></title>
        <id>http://arxiv.org/abs/2306.11827</id>
        <link href="http://arxiv.org/abs/2306.11827"/>
        <updated>2023-06-22T07:16:05.251Z</updated>
        <summary type="html"><![CDATA[Mattia Jacopo Villani, Nandi Schoots]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayes-optimal Learning of Deep Random Networks of Extensive-width]]></title>
        <id>http://arxiv.org/abs/2302.00375</id>
        <link href="http://arxiv.org/abs/2302.00375"/>
        <updated>2023-06-22T07:16:04.347Z</updated>
        <summary type="html"><![CDATA[Hugo Cui, Florent Krzakala, Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Debiased Machine Learning for Dynamic Treatment Effects and
  General Nested Functionals]]></title>
        <id>http://arxiv.org/abs/2203.13887</id>
        <link href="http://arxiv.org/abs/2203.13887"/>
        <updated>2023-06-22T07:16:04.342Z</updated>
        <summary type="html"><![CDATA[Victor Chernozhukov, Whitney Newey, Rahul Singh, Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal rates of approximation by shallow ReLU$^k$ neural networks and
  applications to nonparametric regression]]></title>
        <id>http://arxiv.org/abs/2304.01561</id>
        <link href="http://arxiv.org/abs/2304.01561"/>
        <updated>2023-06-22T07:16:04.220Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimized PyTorch 2.0 Inference with AWS Graviton processors]]></title>
        <id>https://pytorch.org/blog/optimized-pytorch-w-graviton/</id>
        <link href="https://pytorch.org/blog/optimized-pytorch-w-graviton/"/>
        <updated>2023-06-22T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[New generations of CPUs offer significant performance improvement in machine learning (ML) inference due to specialized built-in instructions. Combined with their flexibility, high speed of development, and low operating cost, these general-purpose processors offer an alternative ML inference solution to other existing hardware solutions.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#2]]]></title>
        <id>http://xianblog.wordpress.com/?p=53342</id>
        <link href="https://xianblog.wordpress.com/2023/06/22/approximation-methods-in-bayesian-analysis-2/"/>
        <updated>2023-06-21T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[A more theoretical Day #2 of the workshop, with Debdeep Pati comparing two representations of Gaussian processes with significantly different efficiencies, and Aad van der Vaart presenting a form of linearisation for a range of inverse problems, Kolyan Ray debiasing Lasso impacts by variational Bayes, although through a somewhat intricate process that distanced the procedure […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: AI for Social Good]]></title>
        <id>http://ai.googleblog.com/2023/06/responsible-ai-at-google-research-ai.html</id>
        <link href="http://ai.googleblog.com/2023/06/responsible-ai-at-google-research-ai.html"/>
        <updated>2023-06-21T20:57:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Jimmy Tobin and Katrin Tomanek, Software Engineers, Google Research, AI for Social Good


Google’s AI for Social Good team consists of researchers, engineers, volunteers, and others with a shared focus on positive social impact. Our mission is to demonstrate AI’s societal benefit by enabling real-world value, with projects spanning work in public health, accessibility, crisis response, climate and energy, and nature and society. We believe that the best way to drive positive change in underserved communities is by partnering with change-makers and the organizations they serve.


 


In this blog post we discuss work done by Project Euphonia, a team within AI for Social Good, that aims to improve automatic speech recognition (ASR) for people with disordered speech. For people with…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The world’s first braiding of non-Abelian anyons]]></title>
        <id>http://ai.googleblog.com/2023/06/the-worlds-first-braiding-of-non.html</id>
        <link href="http://ai.googleblog.com/2023/06/the-worlds-first-braiding-of-non.html"/>
        <updated>2023-06-21T17:29:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Trond Andersen and Yuri Lensky, Research Scientists, Google Quantum AI Team  






Imagine you’re shown two identical objects and then asked to close your eyes. When you open your eyes, you see the same two objects in the same position. How can you determine if they have been swapped back and forth? Intuition and the laws of quantum mechanics agree: If the objects are truly identical, there is no way to tell. 



While this sounds like common sense, it only applies to our familiar three-dimensional world. Researchers have predicted that for a special type of particle, called an anyon, that is restricted to move only in a two-dimensional (2D) plane, quantum mechanics allows for something quite different. Anyons are indistinguishable from one another and some, non-Abelian anyons, …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On-the-Fly Adaptation of Source Code Models using Meta-Learning]]></title>
        <id>http://arxiv.org/abs/2003.11768</id>
        <link href="http://arxiv.org/abs/2003.11768"/>
        <updated>2023-06-21T01:23:11.749Z</updated>
        <summary type="html"><![CDATA[Disha Shrivastava, Hugo Larochelle, Daniel Tarlow]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Novel Collaborative Self-Supervised Learning Method for Radiomic Data]]></title>
        <id>http://arxiv.org/abs/2302.09807</id>
        <link href="http://arxiv.org/abs/2302.09807"/>
        <updated>2023-06-21T01:23:11.744Z</updated>
        <summary type="html"><![CDATA[Zhiyuan Li, Hailong Li, Anca L. Ralescu, Jonathan R. Dillman, Nehal A.
  Parikh, Lili He]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Does a Deep Learning Model Architecture Impact Its Privacy? A
  Comprehensive Study of Privacy Attacks on CNNs and Transformers]]></title>
        <id>http://arxiv.org/abs/2210.11049</id>
        <link href="http://arxiv.org/abs/2210.11049"/>
        <updated>2023-06-21T01:23:11.454Z</updated>
        <summary type="html"><![CDATA[Guangsheng Zhang, Bo Liu, Huan Tian, Tianqing Zhu, Ming Ding, Wanlei
  Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Principles for Initialization and Architecture Selection in Graph Neural
  Networks with ReLU Activations]]></title>
        <id>http://arxiv.org/abs/2306.11668</id>
        <link href="http://arxiv.org/abs/2306.11668"/>
        <updated>2023-06-21T01:23:11.449Z</updated>
        <summary type="html"><![CDATA[Gage DeZoort, Boris Hanin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Implicit Bias of Batch Normalization in Linear Models and Two-layer
  Linear Convolutional Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.11680</id>
        <link href="http://arxiv.org/abs/2306.11680"/>
        <updated>2023-06-21T01:23:07.429Z</updated>
        <summary type="html"><![CDATA[Yuan Cao, Difan Zou, Yuanzhi Li, Quanquan Gu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[shallow learning]]></title>
        <id>http://xianblog.wordpress.com/?p=53337</id>
        <link href="https://xianblog.wordpress.com/2023/06/21/shallow-learning/"/>
        <updated>2023-06-20T22:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fangyán = topolect in DC]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59348</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59348&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=fangyan-topolect-in-dc"/>
        <updated>2023-06-20T20:58:16.000Z</updated>
        <summary type="html"><![CDATA[I'm in Georgetown for a few days to meet with colleagues and do some research.  Shortly after I left my hotel and headed down Wisconsin Avenue toward the Potomac for a morning run, I stopped dead in my tracks when I crossed over the canal and saw this: Especially with all the butterflies in the window, I […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Fursty Ferret]]></title>
        <id>http://xianblog.wordpress.com/?p=53009</id>
        <link href="https://xianblog.wordpress.com/2023/06/20/the-fursty-ferret/"/>
        <updated>2023-06-20T18:20:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Topolects and texts]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59286</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59286&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=topolects-and-texts"/>
        <updated>2023-06-20T14:06:53.000Z</updated>
        <summary type="html"><![CDATA[Illuminating new book from Hong Kong University Press edited by Richard VanNess Simmons: Studies in Colloquial Chinese and Its History:  Dialect and Text ISBN : 978-988-8754-09-0 The book also has a Chinese title: Hànyǔ kǒuyǔ de lìshǐ yánjiū: fāngyán hé wénxiàn 漢語口語的歷史研究：方言與文獻 I would prefer to render this into English as: Studies on the History […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tortured phrases, LLMs, and Goodhart's Law]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59339</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59339&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tortured-phrases-llms-and-goodharts-law"/>
        <updated>2023-06-20T13:55:24.000Z</updated>
        <summary type="html"><![CDATA[A few years ago, I began to notice that the scientific and technical papers relentless spammed at me, by academia.edu and similar outfits, were becoming increasingly surrealistic. And I soon learned that the source for such articles was systems for "article spinning" by "rogeting" — automatic random subsitution of (usually inappropriate) synonyms. Those techniques were […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RoboCat: A self-improving robotic agent]]></title>
        <id>https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent</id>
        <link href="https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent"/>
        <updated>2023-06-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Robots are quickly becoming part of our everyday lives, but they’re often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data. Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#1]]]></title>
        <id>http://xianblog.wordpress.com/?p=53331</id>
        <link href="https://xianblog.wordpress.com/2023/06/20/approximation-methods-in-bayesian-analysis-1/"/>
        <updated>2023-06-19T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[Interesting first day, if somewhat intense!, with Sylvia Richardson talking of divide & conquer strategies, which we had recently explored in our work on mixtures with Adrien and Judith. Then Jere Koskela (Warwick) on sufficient conditions for consistent inference on trees like Kingman’s coalescent. And in the afternoon Julia-Adela Palacios on tree estimation, with novel […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stabilized Neural Differential Equations for Learning Constrained
  Dynamics]]></title>
        <id>http://arxiv.org/abs/2306.09739</id>
        <link href="http://arxiv.org/abs/2306.09739"/>
        <updated>2023-06-19T07:14:46.765Z</updated>
        <summary type="html"><![CDATA[Alistair White, Niki Kilbertus, Maximilian Gelbrecht, Niklas Boers]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resolving the Human Subjects Status of Machine Learning's Crowdworkers]]></title>
        <id>http://arxiv.org/abs/2206.04039</id>
        <link href="http://arxiv.org/abs/2206.04039"/>
        <updated>2023-06-19T07:14:46.761Z</updated>
        <summary type="html"><![CDATA[Divyansh Kaushik, Zachary C. Lipton, Alex John London]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enhancing Activity Prediction Models in Drug Discovery with the Ability
  to Understand Human Language]]></title>
        <id>http://arxiv.org/abs/2303.03363</id>
        <link href="http://arxiv.org/abs/2303.03363"/>
        <updated>2023-06-19T07:14:46.756Z</updated>
        <summary type="html"><![CDATA[Philipp Seidl, Andreu Vall, Sepp Hochreiter, G\"unter Klambauer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Collapsed Inference for Bayesian Deep Learning]]></title>
        <id>http://arxiv.org/abs/2306.09686</id>
        <link href="http://arxiv.org/abs/2306.09686"/>
        <updated>2023-06-19T07:14:46.750Z</updated>
        <summary type="html"><![CDATA[Zhe Zeng, Guy Van den Broeck]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trained Transformers Learn Linear Models In-Context]]></title>
        <id>http://arxiv.org/abs/2306.09927</id>
        <link href="http://arxiv.org/abs/2306.09927"/>
        <updated>2023-06-19T07:14:46.650Z</updated>
        <summary type="html"><![CDATA[Ruiqi Zhang, Spencer Frei, Peter L. Bartlett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[no country for old men [Cormac McCarthy]]]></title>
        <id>http://xianblog.wordpress.com/?p=53250</id>
        <link href="https://xianblog.wordpress.com/2023/06/19/no-country-for-old-men-cormac-mccarthy/"/>
        <updated>2023-06-18T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at CVPR 2023]]></title>
        <id>http://ai.googleblog.com/2023/06/google-at-cvpr-2023.html</id>
        <link href="http://ai.googleblog.com/2023/06/google-at-cvpr-2023.html"/>
        <updated>2023-06-18T18:00:00.014Z</updated>
        <summary type="html"><![CDATA[Posted by Shaina Mehta, Program Manager, Google




This week marks the beginning of the premier annual Computer Vision and Pattern Recognition conference (CVPR 2023), held in-person in Vancouver, BC (with additional virtual content). As a leader in computer vision research and a Platinum Sponsor, Google Research will have a strong presence across CVPR 2023 with 90 papers being presented at the main conference and active involvement in over 40 conference workshops and tutorials.




If you are attending CVPR this year, please stop by our booth to chat with our researchers who are actively exploring the latest techniques for application to various areas of machine perception. Our researchers will also be available to talk about and demo several recent efforts, including on-device ML applica…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Time-averaged quantum annealing for weak processes]]></title>
        <id>http://arxiv.org/abs/2306.06008</id>
        <link href="http://arxiv.org/abs/2306.06008"/>
        <updated>2023-06-18T07:13:07.422Z</updated>
        <summary type="html"><![CDATA[Pierre Naz\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal shortcuts to adiabaticity of finite-time and weak processes]]></title>
        <id>http://arxiv.org/abs/2305.17802</id>
        <link href="http://arxiv.org/abs/2305.17802"/>
        <updated>2023-06-18T07:13:06.921Z</updated>
        <summary type="html"><![CDATA[Pierre Naz\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Saturn < Cronus (Κρόνος) ≠ Chronos (Χρόνος)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59190</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59190&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=saturn-cronus-%25ce%25ba%25cf%2581%25cf%258c%25ce%25bd%25ce%25bf%25cf%2582-%25e2%2589%25a0-chronos-%25cf%2587%25cf%2581%25cf%258c%25ce%25bd%25ce%25bf%25cf%2582"/>
        <updated>2023-06-18T04:50:29.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Jichang Lulu, with some minor modifications and additions by VHM] You might have seen this — the PRC embassy in Poland has given Badiucao's forthcoming exhibition in Warsaw (coorganised by Sinopsis) some very welcome, completely unexpected publicity by trying to have it shut down. Lots of international reporting: The Guardian, Sydney Morning Herald, &c., &c. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[webscussion on Bayesian causality]]></title>
        <id>http://xianblog.wordpress.com/?p=53243</id>
        <link href="https://xianblog.wordpress.com/2023/06/18/webscussion-on-bayesian-causality/"/>
        <updated>2023-06-17T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[Today, I attended (most of) and briefly took part in the discussion webinar run by Bayesian Analysis (the journal) and featuring the paper Causal Inference Under Mis-Specification: Adjustment Based on the Propensity Score by David Stephens, Widemberg Nobre, Erica Moodie, and Alexandra M. Schmidt, for which Pierre Jacob and I contributed a written discussion. I […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Throw a photo" in South Florida English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59266</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59266&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=throw-a-photo-in-south-florida-english"/>
        <updated>2023-06-17T20:45:14.000Z</updated>
        <summary type="html"><![CDATA[Article by Phillip M. Carter in The Conversation (6/12/23): "Linguists have identified a new English dialect that’s emerging in South Florida" Beginning sentences: “We got down from the car and went inside.” “I made the line to pay for groceries.” “He made a party to celebrate his son’s birthday.” These phrases might sound off to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ancient eggcorns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59277</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59277&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ancient-eggcorns"/>
        <updated>2023-06-17T13:29:57.000Z</updated>
        <summary type="html"><![CDATA[The word eggcorn was originally proposed in a LLOG post almost 20 years ago — "Egg corns: folk etymology, malapropism, mondegreen, ???", 9/23/2003.  And the word is now recognized by most current English dictionaries and other relevant sources, which gloss it variously, e.g. — the  Oxford English Dictionary, ("An alteration of a word or phrase […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Coors Light Bear]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59272</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59272&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=coors-light-bear"/>
        <updated>2023-06-17T09:28:04.000Z</updated>
        <summary type="html"><![CDATA[An NFL policy prohibits plays from endorsing alcoholic beverages. So Coors found a linguistic work-around: Last year's commercial promoted the Coors (Flash) Light: I have some inter-related contractual and cultural questions. Are these commercials really consistent, legally, with a contractual agreement not to promote alcoholic beverages? Is is crucial that there actual merch you can […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[shame!]]></title>
        <id>http://xianblog.wordpress.com/?p=53289</id>
        <link href="https://xianblog.wordpress.com/2023/06/17/53289/"/>
        <updated>2023-06-16T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rivers and lakes:  quackery]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59232</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59232&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rivers-and-lakes-quackery"/>
        <updated>2023-06-16T19:03:16.000Z</updated>
        <summary type="html"><![CDATA[Get ready to go a-wanderin'.  I'll take you down to the rivers and lakes, and we shall lose ourselves in them, get lost from the hurlyburly hustlebustle of the mundane world.  That's what jiānghú 江湖 ("rivers and lakes") is all about.  It's where you go to xiāoyáo yóu 逍遙遊 ("wander freely / carefreely / leisurely"). […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Her pension for body-hugging gowns…"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59257</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59257&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=her-pension-for-body-hugging-gowns"/>
        <updated>2023-06-16T12:34:28.000Z</updated>
        <summary type="html"><![CDATA[It's been a while since we discussed a new eggcorn, so here's one, from "Beauty and the bleach", The Vintage Woman 2020: Blonde bombshell. A phrase so used frequently in our accumulative vernacular that the significance now wanes. This phrase, once a revelation, was brought to our consciousness by Jean Harlow. The original platinum blonde. Her […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WavPool: A New Block for Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.08734</id>
        <link href="http://arxiv.org/abs/2306.08734"/>
        <updated>2023-06-16T07:13:31.376Z</updated>
        <summary type="html"><![CDATA[Samuel D. McDermott, M. Voetberg, Brian Nord]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phase diagram of Stochastic Gradient Descent in high-dimensional
  two-layer neural networks]]></title>
        <id>http://arxiv.org/abs/2202.00293</id>
        <link href="http://arxiv.org/abs/2202.00293"/>
        <updated>2023-06-16T07:13:30.776Z</updated>
        <summary type="html"><![CDATA[Rodrigo Veiga, Ludovic Stephan, Bruno Loureiro, Florent Krzakala,
  Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nonparametric regression using over-parameterized shallow ReLU neural
  networks]]></title>
        <id>http://arxiv.org/abs/2306.08321</id>
        <link href="http://arxiv.org/abs/2306.08321"/>
        <updated>2023-06-16T07:13:30.771Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unbiased Learning of Deep Generative Models with Structured Discrete
  Representations]]></title>
        <id>http://arxiv.org/abs/2306.08230</id>
        <link href="http://arxiv.org/abs/2306.08230"/>
        <updated>2023-06-16T07:13:30.766Z</updated>
        <summary type="html"><![CDATA[Harry Bendekgey, Gabriel Hope, Erik B. Sudderth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visualizing Deep Neural Networks with Topographic Activation Maps]]></title>
        <id>http://arxiv.org/abs/2204.03528</id>
        <link href="http://arxiv.org/abs/2204.03528"/>
        <updated>2023-06-16T07:13:30.619Z</updated>
        <summary type="html"><![CDATA[Valerie Krug, Raihan Kabir Ratul, Christopher Olson, Sebastian Stober]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[🎉 PyTorch Docathon H1 2023 Wrap-up 🎉]]></title>
        <id>https://pytorch.org/blog/docathon-h1-2023-wrap-up/</id>
        <link href="https://pytorch.org/blog/docathon-h1-2023-wrap-up/"/>
        <updated>2023-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Thank you to all who participated in our first ever PyTorch Docathon, the results have been nothing short of amazing! We want to extend our sincerest gratitude to all the participants who made this event a resounding success. Your passion, talent, and hard work have left an indelible mark on the PyTorch documentation.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[梯度流：探索通往最小值之路]]></title>
        <id>https://kexue.fm/archives/9660</id>
        <link href="https://kexue.fm/archives/9660"/>
        <updated>2023-06-16T02:10:00.000Z</updated>
        <summary type="html"><![CDATA[在这篇文章中，我们将探讨一个被称为“梯度流（Gradient Flow）”的概念。简单来说，梯度流是将我们在用梯度下降法中寻找最小值的过程中的各个点连接起来，形成一条随（虚拟的）时间变化的轨迹，...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noctureine 2023]]></title>
        <id>http://xianblog.wordpress.com/?p=53100</id>
        <link href="https://xianblog.wordpress.com/2023/06/16/noctureine-2023/"/>
        <updated>2023-06-15T22:23:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Syllabolic"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59235</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59235&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=syllabolic"/>
        <updated>2023-06-15T21:58:09.000Z</updated>
        <summary type="html"><![CDATA[On June 1 in Iowa, Donald Trump gave a speech in which he attacked Ron DeSantis from several angles. One of them was DeSantis' variation in pronunciation of his last name (see "Pronouncing 'DeSantis'", 6/3/2023), which Trump characterized as "changing his name", while introducing a puzzling (but promising?) new linguistic term, "syllabolic": Your browser does […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speed is all you need: On-device acceleration of large diffusion models via GPU-aware optimizations]]></title>
        <id>http://ai.googleblog.com/2023/06/speed-is-all-you-need-on-device.html</id>
        <link href="http://ai.googleblog.com/2023/06/speed-is-all-you-need-on-device.html"/>
        <updated>2023-06-15T20:53:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Juhyun Lee and Raman Sarokin, Software Engineers, Core Systems & Experiences




The proliferation of large diffusion models for image generation has led to a significant increase in model size and inference workloads. On-device ML inference in mobile environments requires meticulous performance optimization and consideration of trade-offs due to resource constraints. Running inference of large diffusion models (LDMs) on-device, driven by the need for cost efficiency and user privacy, presents even greater challenges due to the substantial memory requirements and computational demands of these models.
 

We address this challenge in our work titled “Speed Is All You Need: On-Device Acceleration of Large Diffusion Models via GPU-Aware Optimizations” (to be presented at the CVPR 20…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Cantophone and the state]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59228</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59228&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-cantophone-and-the-state"/>
        <updated>2023-06-15T12:19:22.000Z</updated>
        <summary type="html"><![CDATA[Cantonese — its nature, its status, its past, present, and future, its place in the realm of Sinitic languages and in the world — has been one of the chief foci of Language Log.  Consequently, it is my great pleasure to announce the publication of the three-hundred-and-thirty-fourth issue of Sino-Platonic Papers: “The Concept of the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classifier Calibration: A survey on how to assess and improve predicted
  class probabilities]]></title>
        <id>http://arxiv.org/abs/2112.10327</id>
        <link href="http://arxiv.org/abs/2112.10327"/>
        <updated>2023-06-15T07:14:30.613Z</updated>
        <summary type="html"><![CDATA[Telmo Silva Filho, Hao Song, Miquel Perello-Nieto, Raul
  Santos-Rodriguez, Meelis Kull, Peter Flach]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[soon off to CIRM]]></title>
        <id>http://xianblog.wordpress.com/?p=53229</id>
        <link href="https://xianblog.wordpress.com/2023/06/15/soon-off-to-cirm/"/>
        <updated>2023-06-14T22:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reconstructing indoor spaces with NeRF]]></title>
        <id>http://ai.googleblog.com/2023/06/reconstructing-indoor-spaces-with-nerf.html</id>
        <link href="http://ai.googleblog.com/2023/06/reconstructing-indoor-spaces-with-nerf.html"/>
        <updated>2023-06-14T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[Marcos Seefelder, Software Engineer, and Daniel Duckworth, Research Software Engineer, Google Research




When choosing a venue, we often find ourselves with questions like the following: Does this restaurant have the right vibe for a date? Is there good outdoor seating? Are there enough screens to watch the game? While photos and videos may partially answer questions like these, they are no substitute for feeling like you’re there, even when visiting in person isn't an option.



Immersive experiences that are interactive, photorealistic, and multi-dimensional stand to bridge this gap and recreate the feel and vibe of a space, empowering users to naturally and intuitively find the information they need. To help with this, Google Maps launched Immersive View, which uses advances in machin…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Tortured syllables"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59186</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59186&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tortured-syllables"/>
        <updated>2023-06-14T15:16:36.000Z</updated>
        <summary type="html"><![CDATA["Language change (about to be?) in progress" (6/12/2023) linked to media commentary on divergent features of Northeast Philadelphia speech, e.g. "Side effect of the highway collapse: A perfect example of Northeast Philly hoagiemouth", Billy Penn 6/11/2-23. Some of the characterization was extremely evaluative: Philadelphians have perfected torturing vowels like medieval Europe perfected torturing people. Every […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Indigenous languages of Taiwan]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59179</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59179&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=indigenous-languages-of-taiwan"/>
        <updated>2023-06-14T11:35:23.000Z</updated>
        <summary type="html"><![CDATA[How many are there? Taiwan’s unrecognized indigenous tribes are reviving dead languages to achieve recognition There are currently 16 officially recognized indigenous peoples in Taiwan. The Pingpu — which comprise 10 groups on the island’s lowlands — are lobbying to make that number 17, and they’re doing it by reviving lost languages and culture. By […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identification of Nonlinear Latent Hierarchical Models]]></title>
        <id>http://arxiv.org/abs/2306.07916</id>
        <link href="http://arxiv.org/abs/2306.07916"/>
        <updated>2023-06-14T07:13:58.126Z</updated>
        <summary type="html"><![CDATA[Lingjing Kong, Biwei Huang, Feng Xie, Eric Xing, Yuejie Chi, Kun Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solving the Dirichlet problem for the Monge-Amp\`ere equation using
  neural networks]]></title>
        <id>http://arxiv.org/abs/2110.03310</id>
        <link href="http://arxiv.org/abs/2110.03310"/>
        <updated>2023-06-14T07:13:58.121Z</updated>
        <summary type="html"><![CDATA[Kaj Nystr\"om, Matias Vestberg]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fixed points of arbitrarily deep 1-dimensional neural networks]]></title>
        <id>http://arxiv.org/abs/2303.12814</id>
        <link href="http://arxiv.org/abs/2303.12814"/>
        <updated>2023-06-14T07:13:57.895Z</updated>
        <summary type="html"><![CDATA[Andrew Cook, Andy Hammerlindl, Warwick Tucker]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robustly Learning a Single Neuron via Sharpness]]></title>
        <id>http://arxiv.org/abs/2306.07892</id>
        <link href="http://arxiv.org/abs/2306.07892"/>
        <updated>2023-06-14T07:13:57.890Z</updated>
        <summary type="html"><![CDATA[Puqian Wang, Nikos Zarifis, Ilias Diakonikolas, Jelena Diakonikolas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Trio Neural Model for Dynamic Entity Relatedness Ranking]]></title>
        <id>http://arxiv.org/abs/1808.08316</id>
        <link href="http://arxiv.org/abs/1808.08316"/>
        <updated>2023-06-14T07:13:57.681Z</updated>
        <summary type="html"><![CDATA[Tu Nguyen, Tuan Tran, Wolfgang Nejdl]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[astrostat webinar [IAU-IAA]]]></title>
        <id>http://xianblog.wordpress.com/?p=53218</id>
        <link href="https://xianblog.wordpress.com/2023/06/14/astrostat-webinar-iau-iaa/"/>
        <updated>2023-06-13T22:23:28.000Z</updated>
        <summary type="html"><![CDATA[Next Tuesday, June 13, at 16:00 UTC, I am giving a talk on inferring the number of components in a mixture at the international online IAU-IAA Astrostats and Astroinfo seminar. As pointed out by my Cornell friend Tom Loredo, it is unfortunately clashing with the ISI quadrenial Statistical Challenges in Modern Astronomy meeting help at […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enabling delightful user experiences via predictive models of human attention]]></title>
        <id>http://ai.googleblog.com/2023/06/enabling-delightful-user-experiences.html</id>
        <link href="http://ai.googleblog.com/2023/06/enabling-delightful-user-experiences.html"/>
        <updated>2023-06-13T17:18:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Junfeng He, Senior Research Scientist, and Kai Kohlhoff, Staff Research Scientist, Google Research




People have the remarkable ability to take in a tremendous amount of information (estimated to be ~1010 bits/s entering the retina) and selectively attend to a few task-relevant and interesting regions for further processing (e.g., memory, comprehension, action). Modeling human attention (the result of which is often called a saliency model) has therefore been of interest across the fields of neuroscience, psychology, human-computer interaction (HCI) and computer vision. The ability to predict which regions are likely to attract attention has numerous important applications in areas like graphics, photography, image compression and processing, and the measurement of visual quali…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Victorious Secret]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59183</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59183&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=victorious-secret"/>
        <updated>2023-06-13T10:25:10.000Z</updated>
        <summary type="html"><![CDATA[The next event in the Salon Sanctuary concert series is "Victorious Secret: Love Gamed and Gender Untamed in the Sparkling Courts of the Baroque": Before the bars of gender binaries caged the mainstream operatic imagination, a golden age of fluidity guided the vocal soundscape. Virility declared itself with the castrato’s clarion high notes, while femininity […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beyond the Imitation Game: Quantifying and extrapolating the
  capabilities of language models]]></title>
        <id>http://arxiv.org/abs/2206.04615</id>
        <link href="http://arxiv.org/abs/2206.04615"/>
        <updated>2023-06-13T08:19:00.775Z</updated>
        <summary type="html"><![CDATA[Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb,
  Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adri\`a
  Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea
  Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv,
  Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda
  Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen,
  Andrea Madotto, Andrea Santilli, Andreas Stuhlm\"uller, Andrew Dai, Andrew
  La, Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong,
  Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash
  Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher
  Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla
  Karaka\c{s}, B. Ryan Roberts, Bao Sheng Loe, Barret Zoph, Bart{\l}omiej
  Bojanowski, Batuhan \"Ozyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin
  Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan
  Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta,
  C\'esar Ferri Ram\'irez, Chandan Singh, Charles Rathkopf, Chenlin Meng,
  Chitta Baral, Chiyu Wu, Chris Callison-Burch, Chris Waites, Christian Voigt,
  Christopher D. Manning, Christopher Potts, Cindy Ramirez, Clara E. Rivera,
  Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien
  Sileo, Dan Garrette, Dan Hendrycks, Dan Kilman, Dan Roth, Daniel Freeman,
  Daniel Khashabi, Daniel Levy, Daniel Mosegu\'i Gonz\'alez, Danielle Perszyk,
  Danny Hernandez, Danqi Chen, Daphne Ippolito, Dar Gilboa, David Dohan, David
  Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis
  Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes, Diganta Misra,
  Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader,
  Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth
  Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodola,]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Energy-Dissipative Evolutionary Deep Operator Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.06281</id>
        <link href="http://arxiv.org/abs/2306.06281"/>
        <updated>2023-06-13T08:19:00.296Z</updated>
        <summary type="html"><![CDATA[Jiahao Zhang, Shiheng Zhang, Jie Shen, Guang Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Learning Priors for Safe Bayesian Optimization]]></title>
        <id>http://arxiv.org/abs/2210.00762</id>
        <link href="http://arxiv.org/abs/2210.00762"/>
        <updated>2023-06-13T08:19:00.280Z</updated>
        <summary type="html"><![CDATA[Jonas Rothfuss, Christopher Koenig, Alisa Rupenyan, Andreas Krause]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intensity Profile Projection: A Framework for Continuous-Time
  Representation Learning for Dynamic Networks]]></title>
        <id>http://arxiv.org/abs/2306.06155</id>
        <link href="http://arxiv.org/abs/2306.06155"/>
        <updated>2023-06-13T08:19:00.275Z</updated>
        <summary type="html"><![CDATA[Alexander Modell, Ian Gallagher, Emma Ceccherini, Nick Whiteley and
  Patrick Rubin-Delanchy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Variational Models with Unrolling and Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2209.12651</id>
        <link href="http://arxiv.org/abs/2209.12651"/>
        <updated>2023-06-13T08:19:00.264Z</updated>
        <summary type="html"><![CDATA[Christoph Brauer, Niklas Breustedt, Timo de Wolff, Dirk A. Lorenz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introduction to Queueing Theory and Stochastic Teletraffic Models]]></title>
        <id>http://arxiv.org/abs/1307.2968</id>
        <link href="http://arxiv.org/abs/1307.2968"/>
        <updated>2023-06-13T07:14:02.706Z</updated>
        <summary type="html"><![CDATA[Moshe Zukerman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Effect of driving on coarsening dynamics in phase-separating systems]]></title>
        <id>http://arxiv.org/abs/1905.13396</id>
        <link href="http://arxiv.org/abs/1905.13396"/>
        <updated>2023-06-13T07:14:02.700Z</updated>
        <summary type="html"><![CDATA[D. Tseluiko, M. Alesemi, T.-S. Lin, U. Thiele]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Converse growth estimates for ODEs with slowly growing solutions]]></title>
        <id>http://arxiv.org/abs/1811.08736</id>
        <link href="http://arxiv.org/abs/1811.08736"/>
        <updated>2023-06-13T07:14:02.683Z</updated>
        <summary type="html"><![CDATA[Janne Gr\"ohn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alexandrov geometry: foundations]]></title>
        <id>http://arxiv.org/abs/1903.08539</id>
        <link href="http://arxiv.org/abs/1903.08539"/>
        <updated>2023-06-13T07:14:02.676Z</updated>
        <summary type="html"><![CDATA[Stephanie Alexander, Vitali Kapovitch, Anton Petrunin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Good News for Polynomial Root-finding]]></title>
        <id>http://arxiv.org/abs/1805.12042</id>
        <link href="http://arxiv.org/abs/1805.12042"/>
        <updated>2023-06-13T07:14:02.670Z</updated>
        <summary type="html"><![CDATA[Victor Y. Pan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is it a rat's head or a duck's neck?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59176</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59176&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=is-it-a-rats-head-or-a-ducks-neck"/>
        <updated>2023-06-13T04:20:49.000Z</updated>
        <summary type="html"><![CDATA[Main dish served as part of a college cafeteria lunch in Nanchang, China: On the left side it says:  zhè búshì máo ma? 这不是毛吗 "Isn't this hair?" On the right side it reads: āyí shuō shì yāròu 阿姨說是鴨肉 "Auntie [i.e., the cafeteria serving lady] says that it's duck meat." The photographs and the captions are from Andrew […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red Sea [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53157</id>
        <link href="https://xianblog.wordpress.com/2023/06/13/red-sea-jatp/"/>
        <updated>2023-06-12T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Old Sinitic "wheat" and Early Middle Sinitic "camel"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59111</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59111&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=old-sinitic-wheat-and-early-middle-sinitic-camel"/>
        <updated>2023-06-12T20:56:56.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Chris Button] OC uvulars tended to condition rounding (e.g OC q- becoming EMC kw-). In the case of ʁ-, we sometimes get m- (for a modern-day example, note how惟, which also had a ʁ- onset in Old Chinese, gives an m- reflex in Fuzhou Min). The classic example is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language change (about to be?) in progress]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59145</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59145&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-change-about-to-be-in-progress"/>
        <updated>2023-06-12T11:48:10.000Z</updated>
        <summary type="html"><![CDATA[Current big news around here is the collapse of an elevated section of Interstate 95 due to a tanker truck fire. As Wikipedia explains, I-95 "is the main north–south Interstate Highway on the East Coast of the United States, running from U.S. Route 1 (US 1) in Miami, Florida, north to the Houlton–Woodstock Border Crossing […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning]]></title>
        <id>http://arxiv.org/abs/2211.06530</id>
        <link href="http://arxiv.org/abs/2211.06530"/>
        <updated>2023-06-12T07:14:12.350Z</updated>
        <summary type="html"><![CDATA[Christopher A. Choquette-Choo, H. Brendan McMahan, Keith Rush, and
  Abhradeep Thakurta]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Huber-energy measure quantization]]></title>
        <id>http://arxiv.org/abs/2212.08162</id>
        <link href="http://arxiv.org/abs/2212.08162"/>
        <updated>2023-06-12T07:14:11.384Z</updated>
        <summary type="html"><![CDATA[Gabriel Turinici]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Path Neural Networks: Expressive and Accurate Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.05955</id>
        <link href="http://arxiv.org/abs/2306.05955"/>
        <updated>2023-06-12T07:14:11.314Z</updated>
        <summary type="html"><![CDATA[Gaspard Michel, Giannis Nikolentzos, Johannes Lutzeyer, Michalis
  Vazirgiannis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Credal Self-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2205.15239</id>
        <link href="http://arxiv.org/abs/2205.15239"/>
        <updated>2023-06-12T07:14:11.308Z</updated>
        <summary type="html"><![CDATA[Julian Lienen, Caglar Demir, Eyke H\"ullermeier]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Change-Point Detection in Time Series via Deep Learning]]></title>
        <id>http://arxiv.org/abs/2211.03860</id>
        <link href="http://arxiv.org/abs/2211.03860"/>
        <updated>2023-06-12T07:14:11.201Z</updated>
        <summary type="html"><![CDATA[Jie Li, Paul Fearnhead, Piotr Fryzlewicz, Tengyao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[gamin’ the rankin’]]></title>
        <id>http://xianblog.wordpress.com/?p=53148</id>
        <link href="https://xianblog.wordpress.com/2023/06/12/gamin-the-rankin/"/>
        <updated>2023-06-11T22:23:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ravens on the garden path]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59146</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59146&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ravens-on-the-garden-path"/>
        <updated>2023-06-11T20:38:33.000Z</updated>
        <summary type="html"><![CDATA[I just ran across a particularly impressive garden path sentence in Bernd Heinrich's book RAVENS IN WINTER (p. 268); it took me several tries to get this sentence to parse grammatically: "Even the wolverine is said to do nothing to drive ravens off that land beside it and steal its food." (Of course parsing is […]]]></summary>
        <author>
            <name>Sally Thomason</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thai to English translation gets injected with Tamil]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59101</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59101&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=thai-to-english-translation-gets-injected-with-tamil"/>
        <updated>2023-06-11T19:39:16.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Charles Belov] I pasted the following Thai, which I got from a YouTube channel, into Google translate. The results were mostly in English, but Google Translate injected some apparent Tamil as well and then just gives up and leaves some of the Thai untranslated. "ตลอดระยะเวลาการทำงานในวงการบันเทิงมันทำให้เราได้เรียนรู้ว่าจริงๆ เเล้วความสุขอยู่รอบตัวเราไปหมด เเล้วความสุขมันง่ายมาก จริงๆ บางทีความสุขมันก็ไม่ต้องมีเงินเยอะมากมาย […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quirky speech-to-text, weird diarization]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59108</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59108&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=quirky-asr-weird-diarization"/>
        <updated>2023-06-11T14:28:01.000Z</updated>
        <summary type="html"><![CDATA[From Daniel Deutsch: We had a long drive yesterday, so we listened to a “robot” reading the entire indictment. It certainly isn’t flawless, but I was surprised by how good it is, especially when it gets “excited” while enacting dialogue. Indeed, the text-to-speech quality is quite good — though unfortunately they don't tell us which […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apostrophes in Hanyu Pinyin]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59105</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59105&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=apostrophes-in-hanyu-pinyin"/>
        <updated>2023-06-11T12:39:45.000Z</updated>
        <summary type="html"><![CDATA[The most famous instance of the use of an apostrophe in Hanyu Pinyin romanization is in the place name "Xi'an", the capital of Shaanxi (the doubled "a" is another story) Province. Xī'ān 西安 — two characters signifying "Western Peace" If you don't use an apostrophe to separate the syllables, you end up with the monosyllable […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT has a sense of humor (sort of)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59096</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59096&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-has-a-sense-of-humor-sort-of"/>
        <updated>2023-06-11T01:50:18.000Z</updated>
        <summary type="html"><![CDATA[Benj Edwards has a mirthful article in Ars Technica (6/9/23) Researchers discover that ChatGPT prefers repeating 25 jokes over and over When tested, "Over 90% of 1,008 generated jokes were the same 25 jokes." [includes an AI generated image of "a laughing robot"] On Wednesday, two German researchers, Sophie Jentzsch and Kristian Kersting, released a […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[technical steps]]></title>
        <id>http://xianblog.wordpress.com/?p=53198</id>
        <link href="https://xianblog.wordpress.com/2023/06/11/technical-steps/"/>
        <updated>2023-06-10T22:23:32.000Z</updated>
        <summary type="html"><![CDATA[After procrastinating as much as feasible, I switched at last to (K)Ubuntu 22.04, Jammy Jellyfish, after security updates stopped for the 20.04 version. While this proceeded mostly without hiccups, the upgrade stalled when upgrading Firefox, which I had foolishly left open. When I turned it off and completed the upgrade, this erased all of my […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Steak the First"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59077</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59077&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=steak-the-first"/>
        <updated>2023-06-10T21:32:29.000Z</updated>
        <summary type="html"><![CDATA[Enlightening article by Peter Backhaus in The Japan Times (6/9/23): "Za grammar notes: How to properly handle the 'the' in Japanese" Japanese seems to be able to assimilate any English word, including the ubiquitous definite article "the", which is unlike anything in Japanese itself. If there’s something like a Murphy’s Law for syntax, the name […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["The beautiful mind paper boxes"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59074</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59074&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-beautiful-mind-paper-boxes"/>
        <updated>2023-06-10T12:51:43.000Z</updated>
        <summary type="html"><![CDATA[The most recent Trump indictment reproduces this exchange of text messages (p. 11) : Trump Employee 2: We can definitely make it work if we move his papers into the lake room? Trump Employee 1: There is still a little room in the shower where his other stuff is. Is it only his papers he […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InternLM]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59071</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59071&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=internlm"/>
        <updated>2023-06-10T11:46:43.000Z</updated>
        <summary type="html"><![CDATA[As I am about to deliver a keynote address to an international conference on Chinese language pedagogy, I receive news of this new LLM that knocks my socks off: InternLM is a multilingual large language model jointly developed by Shanghai AI Lab and SenseTime (with equal contribution), in collaboration with the Chinese University of Hong […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT does Emily Dickinson writing a recipe for Pad Thai (and haiku too)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59030</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59030&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-does-emily-dickinson-writing-a-recipe-for-pad-thai-and-haiku-too"/>
        <updated>2023-06-10T03:02:36.000Z</updated>
        <summary type="html"><![CDATA[From Scott D. Seligman via Facebook:   ChatGPT is really creeping me out. I asked it for a recipe for Pad Thai in the form of an Emily Dickinson poem. I'm no poetry maven, but the damned thing seems to have the ability to turn a phrase, at least some of the time. Below is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[statistical modeling with R [book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53183</id>
        <link href="https://xianblog.wordpress.com/2023/06/10/statistical-modeling-with-r-book-review/"/>
        <updated>2023-06-09T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[Statistical Modeling with R (A dual frequentist and Bayesian approach for life scientists) is a recent book written by Pablo Inchausti, from Uruguay. In a highly personal and congenial style (witness the preface), with references to (fiction) books that enticed me to buy them. The book was sent to me by the JASA book editor […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Imagen Editor and EditBench: Advancing and evaluating text-guided image inpainting]]></title>
        <id>http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html</id>
        <link href="http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html"/>
        <updated>2023-06-09T19:09:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Su Wang and Ceslee Montgormery, Research Engineers, Google Research





In the last few years, text-to-image generation research has seen an explosion of breakthroughs (notably, Imagen, Parti, DALL-E 2, etc.) that have naturally permeated into related topics. In particular, text-guided image editing (TGIE) is a practical task that involves editing generated and photographed visuals rather than completely redoing them. Quick, automated, and controllable editing is a convenient solution when recreating visuals would be time-consuming or infeasible (e.g., tweaking objects in vacation photos or perfecting fine-grained details on a cute pup generated from scratch). Further, TGIE represents a substantial opportunity to improve training of foundational models themselves. Multimodal mod…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-owning peeve of the week: Compersion]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59056</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59056&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=self-owning-peeve-of-the-week-compersion"/>
        <updated>2023-06-09T13:27:09.000Z</updated>
        <summary type="html"><![CDATA[Email from Florent Moncomble [links added]: A few months ago, the distinguished member of the Académie française Alain Finkielkraut was featured in a video where he deplored the loss of “a word which used to exist in the [French] language and disappeared from it”, ie. “compersion”. Apparently, little does he know that “compersion” was actually coined […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural
  Language Understanding]]></title>
        <id>http://arxiv.org/abs/2306.04933</id>
        <link href="http://arxiv.org/abs/2306.04933"/>
        <updated>2023-06-09T08:18:07.758Z</updated>
        <summary type="html"><![CDATA[Junda Wu, Tong Yu, Rui Wang, Zhao Song, Ruiyi Zhang, Handong Zhao,
  Chaochao Lu, Shuai Li, Ricardo Henao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Large Language Model Annotations for Valid Downstream Statistical
  Inference in Social Science: Design-Based Semi-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2306.04746</id>
        <link href="http://arxiv.org/abs/2306.04746"/>
        <updated>2023-06-09T08:18:07.753Z</updated>
        <summary type="html"><![CDATA[Naoki Egami, Musashi Jacobs-Harukawa, Brandon M. Stewart, Hanying Wei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multitask Learning and Bandits via Robust Statistics]]></title>
        <id>http://arxiv.org/abs/2112.14233</id>
        <link href="http://arxiv.org/abs/2112.14233"/>
        <updated>2023-06-09T08:18:07.741Z</updated>
        <summary type="html"><![CDATA[Kan Xu, Hamsa Bastani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Polynomial Time and Private Learning of Unbounded Gaussian Mixture
  Models]]></title>
        <id>http://arxiv.org/abs/2303.04288</id>
        <link href="http://arxiv.org/abs/2303.04288"/>
        <updated>2023-06-09T08:18:07.736Z</updated>
        <summary type="html"><![CDATA[Jamil Arbas, Hassan Ashtiani, Christopher Liaw]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Meets Sparse Regularization: A Signal Processing
  Perspective]]></title>
        <id>http://arxiv.org/abs/2301.09554</id>
        <link href="http://arxiv.org/abs/2301.09554"/>
        <updated>2023-06-09T08:18:06.909Z</updated>
        <summary type="html"><![CDATA[Rahul Parhi, Robert D. Nowak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The asymptotics of r(4,t)]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"/>
        <updated>2023-06-09T06:17:30.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved…]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The asymptotics of r(4,t)]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"/>
        <updated>2023-06-09T06:17:30.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved…]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[de-MCM’d]]></title>
        <id>http://xianblog.wordpress.com/?p=53208</id>
        <link href="https://xianblog.wordpress.com/2023/06/09/de-mcmd/"/>
        <updated>2023-06-08T22:23:02.000Z</updated>
        <summary type="html"><![CDATA[This morning I received a message from the MCM 23 conference organisers that my registration [submitted two months ago] was declined for lack of room! I wonder why the organisers did not opt for broadcasting in a second amphitheater, as was done for ISBA in Edinburgh. Unfortunately, we have attained the maximal capacity of the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Determining Ramsey numbers using finite geometry]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"/>
        <updated>2023-06-08T19:31:29.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Anurag's Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a…]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Determining Ramsey numbers using finite geometry]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"/>
        <updated>2023-06-08T19:31:29.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Anurag's Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a…]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transliterations aplenty]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59014</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59014&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=transliterations-aplenty"/>
        <updated>2023-06-08T16:50:05.000Z</updated>
        <summary type="html"><![CDATA[From Simon Cartoon: Here's something I just saw at a local bakery in Berkeley, CA. Simon explains: We have English, Spanish, and then French in the last position, no issues there. 3rd position is Mandarin Chinese via pinyin: Who is this for? What is the population of people uncomfortable reading in English, but comfortable reading […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We may finally crack Maths. But should we?]]></title>
        <id>6481b5876965110001df8c10</id>
        <link href="https://www.inference.vc/we-may-finally-crack-maths-but-should-we/"/>
        <updated>2023-06-08T15:58:13.000Z</updated>
        <summary type="html"><![CDATA[Automating mathematical theorem proving has been a long standing goal of artificial intelligence and indeed computer science. It's one of the areas I became very interested in recently. This is because I feel we may have the ingredients needed to make very, very significant progress:

a structured search]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is the logical form of that?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59026</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59026&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=what-is-the-logical-form-of-that"/>
        <updated>2023-06-08T13:36:25.000Z</updated>
        <summary type="html"><![CDATA[This post wanders down a series of rabbit holes, from a couple of dead economists, to a dead philosopher, to a dead Supreme Court justice. It all started with Eric Rahim's obituary in the Guardian, which links to the British Academy's obituary for Piero Sraffa, which includes this passage: He also formed a close friendship […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greco-Sinitic ψάμμος / ʃˠa  mɑk̚ ("desert")]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59024</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59024&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=greco-sinitic-%25cf%2588%25ce%25ac%25ce%25bc%25ce%25bc%25ce%25bf%25cf%2582-%25ca%2583%25cb%25a0a-mak%25cc%259a-desert"/>
        <updated>2023-06-08T12:39:35.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Chau Wu] The psammo- component of the winning word in this year's Scripps National Spelling Bee, psammophile, is of interest to me because it is a good example of European-Sinitic lexical correspondence. The Ancient Greek word psámmos (ψάμμος) means ‘sand’.  When used together with a definite article (ἡ ψάμμος), […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Invariance in Policy Optimisation and Partial Identifiability in Reward
  Learning]]></title>
        <id>http://arxiv.org/abs/2203.07475</id>
        <link href="http://arxiv.org/abs/2203.07475"/>
        <updated>2023-06-08T07:13:38.535Z</updated>
        <summary type="html"><![CDATA[Joar Skalse, Matthew Farrugia-Roberts, Stuart Russell, Alessandro
  Abate, Adam Gleave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformers as Statisticians: Provable In-Context Learning with
  In-Context Algorithm Selection]]></title>
        <id>http://arxiv.org/abs/2306.04637</id>
        <link href="http://arxiv.org/abs/2306.04637"/>
        <updated>2023-06-08T07:13:38.518Z</updated>
        <summary type="html"><![CDATA[Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multimodal Learning Without Labeled Multimodal Data: Guarantees and
  Applications]]></title>
        <id>http://arxiv.org/abs/2306.04539</id>
        <link href="http://arxiv.org/abs/2306.04539"/>
        <updated>2023-06-08T07:13:38.512Z</updated>
        <summary type="html"><![CDATA[Paul Pu Liang, Chun Kai Ling, Yun Cheng, Alex Obolenskiy, Yudong Liu,
  Rohan Pandey, Alex Wilf, Louis-Philippe Morency, Ruslan Salakhutdinov]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics,
  Directional Convergence, and Equilibria]]></title>
        <id>http://arxiv.org/abs/2212.02457</id>
        <link href="http://arxiv.org/abs/2212.02457"/>
        <updated>2023-06-08T07:13:38.507Z</updated>
        <summary type="html"><![CDATA[Tengyuan Liang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PILLAR: How to make semi-private learning more effective]]></title>
        <id>http://arxiv.org/abs/2306.03962</id>
        <link href="http://arxiv.org/abs/2306.03962"/>
        <updated>2023-06-08T07:13:38.500Z</updated>
        <summary type="html"><![CDATA[Francesco Pinto, Yaxi Hu, Fanny Yang, Amartya Sanyal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2023世界人工智能大会“AI生成与垂直大语言模型”论坛重磅来袭！]]></title>
        <id>https://www.52nlp.cn/?p=13474</id>
        <link href="https://www.52nlp.cn/2023%e4%b8%96%e7%95%8c%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%a4%a7%e4%bc%9aai%e7%94%9f%e6%88%90%e4%b8%8e%e5%9e%82%e7%9b%b4%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e8%ae%ba"/>
        <updated>2023-06-08T02:23:31.000Z</updated>
        <summary type="html"><![CDATA[当前AI生成与大语言模型的指数级发展，为相关产业链带来新的发展引擎，也为AI落地应用带来新的想象空间。2023 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Naive Bayes is all you need ?]]></title>
        <id>https://kexue.fm/archives/9648</id>
        <link href="https://kexue.fm/archives/9648"/>
        <updated>2023-06-08T01:25:00.000Z</updated>
        <summary type="html"><![CDATA[很抱歉，起了这么个具有标题党特征的题目。在写完《NBCE：使用朴素贝叶斯扩展LLM的Context处理长度》之后，笔者就觉得朴素贝叶斯（Naive Bayes）跟Attention机制有很多相同...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[uniform spacings]]></title>
        <id>http://xianblog.wordpress.com/?p=53161</id>
        <link href="https://xianblog.wordpress.com/2023/06/08/uniform-spacings/"/>
        <updated>2023-06-07T22:23:28.000Z</updated>
        <summary type="html"><![CDATA[A riddle on uniform spacings!, namely when considering eight iid Uniform (0,1) variates as visiting times and three further iid Uniform (0,1) variates as server availability times, with unit service time, the question being the probability a server is available for a ninth visiting time, T⁹. Which can be decomposed into four cases: at least […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating speech synthesis in many languages with SQuId]]></title>
        <id>http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html</id>
        <link href="http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html"/>
        <updated>2023-06-07T18:07:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Thibault Sellam, Research Scientist, Google





Previously, we presented the 1,000 languages initiative and the Universal Speech Model with the goal of making speech and language technologies available to billions of users around the world. Part of this commitment involves developing high-quality speech synthesis technologies, which build upon projects such as VDTTS and AudioLM, for users that speak many different languages.






listening tests, during which dozens of annotators listen to the utterances one after the other to determine how natural they sound. While humans are still unbeaten at detecting whether a piece of text sounds natural, this process can be impractical — especially in the early stages of research projects, when engineers need rapid feedback to test and re…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aligning Language Models with Preferences through f-divergence
  Minimization]]></title>
        <id>http://arxiv.org/abs/2302.08215</id>
        <link href="http://arxiv.org/abs/2302.08215"/>
        <updated>2023-06-07T07:13:39.489Z</updated>
        <summary type="html"><![CDATA[Dongyoung Go, Tomasz Korbak, Germ\'an Kruszewski, Jos Rozen, Nahyeon
  Ryu, Marc Dymetman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Denise: Deep Robust Principal Component Analysis for Positive
  Semidefinite Matrices]]></title>
        <id>http://arxiv.org/abs/2004.13612</id>
        <link href="http://arxiv.org/abs/2004.13612"/>
        <updated>2023-06-07T07:13:39.484Z</updated>
        <summary type="html"><![CDATA[Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen,
  Josef Teichmann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Orthogonal Statistical Learning]]></title>
        <id>http://arxiv.org/abs/1901.09036</id>
        <link href="http://arxiv.org/abs/1901.09036"/>
        <updated>2023-06-07T07:13:39.478Z</updated>
        <summary type="html"><![CDATA[Dylan J. Foster, Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep neural networks architectures from the perspective of manifold
  learning]]></title>
        <id>http://arxiv.org/abs/2306.03406</id>
        <link href="http://arxiv.org/abs/2306.03406"/>
        <updated>2023-06-07T07:13:39.454Z</updated>
        <summary type="html"><![CDATA[German Magai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Join the PyTorch Foundation: Membership Now Open]]></title>
        <id>https://pytorch.org/blog/join-pytorch/</id>
        <link href="https://pytorch.org/blog/join-pytorch/"/>
        <updated>2023-06-07T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[In September 2022, we welcomed PyTorch to the Linux Foundation from Meta, which formed the PyTorch Foundation with founding members AMD, Amazon Web Services (AWS), Google, Meta, Microsoft, and NVIDIA.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unknown language #15]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59005</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59005&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=unknown-language-15"/>
        <updated>2023-06-07T02:46:22.000Z</updated>
        <summary type="html"><![CDATA[Yuan (? dynasty (1271-1368) jade seal in the Bristol Museum: Know what language this is, or even what it says? Yes? Please get back to me. No? Please retweet it until somebody does. (But be aware, it's stumped some quite clever people who've already been asked, so it isn't obvious) Also, advance apologies if it […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding CPUs can help speed up Numba and NumPy code]]></title>
        <id>https://pythonspeed.com/articles/speeding-up-numba/</id>
        <link href="https://pythonspeed.com/articles/speeding-up-numba/"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[When you need to speed up your NumPy processing—or just reduce your memory usage—the Numba just-in-time compiler is a great tool.
It lets you write Python code that gets compiled at runtime to machine code, allowing you to get the kind of speed improvements you’d get from languages like C, Fortran, or Rust.
Or at least, that’s the theory.
In practice, your initial Numba code may be no faster than the NumPy equivalent.
But you can do better, once you have a better understanding of how CPUs work.
And this knowledge will help you more broadly with any compiled language.
In this article we’ll:
Consider a simple image-processing problem.
Try, and initially fail, to speed it up with Numba.
We’ll review just a little bit how modern CPUs are so fast, and the limits of compilers.
Based on our new understanding, we’ll then show how we can tweak our code to run 25× faster than our original version.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimising computer systems with more generalised AI tools]]></title>
        <id>https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools</id>
        <link href="https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Based on reinforcement learning, our AI models AlphaZero and MuZero have achieved superhuman performance winning games. Now, they’re expanding their capabilities to help optimise resources in data centres and advance video compression – and most recently, our specialised version of AlphaZero, called AlphaDev, discovered new algorithms that are already accelerating the software applications at the foundations of our digital society.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AlphaDev discovers faster sorting algorithms]]></title>
        <id>https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms</id>
        <link href="https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In our paper published today in Nature, we introduce AlphaDev, an artificial intelligence (AI) system that uses reinforcement learning to discover enhanced computer science algorithms – surpassing those honed by scientists and engineers over decades.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[stack overflow on strike]]></title>
        <id>http://xianblog.wordpress.com/?p=53202</id>
        <link href="https://xianblog.wordpress.com/2023/06/07/stack-overflow-on-strike/"/>
        <updated>2023-06-06T22:23:40.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinitic exclamations in English speech]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58949</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58949&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinitic-exclamations-in-english-speech"/>
        <updated>2023-06-06T17:45:45.000Z</updated>
        <summary type="html"><![CDATA[Listen to Malaysian comedian Nigel Ng (aka "Uncle Roger"), who has had his Weibo and bilibili social media accounts banned due to "violation of relevant regulations": The ban comes one day after Ng uploaded this clip to various social media platforms. pic.twitter.com/8Wwf2aTrfZ — Aaron Busch (@tripperhead) May 19, 2023 Under the subject line "Uncle Roger […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual captions: Using large language models to augment video conferences with dynamic visuals]]></title>
        <id>http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html</id>
        <link href="http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html"/>
        <updated>2023-06-06T16:58:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ruofei Du, Research Scientist, and Alex Olwal, Senior Staff Research Scientist, Google Augmented Reality




Recent advances in video conferencing have significantly improved remote video communication through features like live captioning and noise cancellation. However, there are various situations where dynamic visual augmentation would be useful to better convey complex and nuanced information. For example, when discussing what to order at a Japanese restaurant, your friends could share visuals that would help you feel more confident about ordering the “Sukiyaki”. Or when talking about your recent family trip to San Francisco, you may want to show a photo from your personal album.




In “Visual Captions: Augmenting Verbal Communication With On-the-fly Visuals”, presented at …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LLMs as coders?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58977</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58977&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=llms-as-coders"/>
        <updated>2023-06-06T12:19:14.000Z</updated>
        <summary type="html"><![CDATA[I've recently seen many articles like this one, "You probably don't need to learn to code anymore" (Medium 6/5/2023), arguing that Large Language Models will make human programming (and human programmers) unnecessary. These arguments puzzle me, because my experience with LLMs suggests that they can't be relied on even for very simple programming tasks. After […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Bayesian Active Learning for Accelerating Stochastic Simulation]]></title>
        <id>http://arxiv.org/abs/2106.02770</id>
        <link href="http://arxiv.org/abs/2106.02770"/>
        <updated>2023-06-06T07:14:01.826Z</updated>
        <summary type="html"><![CDATA[Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, Yi-An
  Ma, Rose Yu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alignment with human representations supports robust few-shot learning]]></title>
        <id>http://arxiv.org/abs/2301.11990</id>
        <link href="http://arxiv.org/abs/2301.11990"/>
        <updated>2023-06-06T07:14:01.819Z</updated>
        <summary type="html"><![CDATA[Ilia Sucholutsky, Thomas L. Griffiths]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Emergence of Clean-Priority Learning in Early Stopped Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.02533</id>
        <link href="http://arxiv.org/abs/2306.02533"/>
        <updated>2023-06-06T07:14:01.813Z</updated>
        <summary type="html"><![CDATA[Chaoyue Liu, Amirhesam Abedsoltan, Mikhail Belkin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LibAUC: A Deep Learning Library for X-Risk Optimization]]></title>
        <id>http://arxiv.org/abs/2306.03065</id>
        <link href="http://arxiv.org/abs/2306.03065"/>
        <updated>2023-06-06T07:14:01.438Z</updated>
        <summary type="html"><![CDATA[Zhuoning Yuan, Dixian Zhu, Zi-Hao Qiu, Gang Li, Xuanhui Wang, Tianbao
  Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Linear Causal Representations from Interventions under General
  Nonlinear Mixing]]></title>
        <id>http://arxiv.org/abs/2306.02235</id>
        <link href="http://arxiv.org/abs/2306.02235"/>
        <updated>2023-06-06T07:14:01.143Z</updated>
        <summary type="html"><![CDATA[Simon Buchholz, Goutham Rajendran, Elan Rosenfeld, Bryon Aragam,
  Bernhard Sch\"olkopf, Pradeep Ravikumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinitic semiliteracy]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58917</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58917&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinitic-semiliteracy"/>
        <updated>2023-06-06T04:43:50.000Z</updated>
        <summary type="html"><![CDATA[From a story on CNN on "begpackers" in Asia: The photo is captioned, "Professor Stephen Pratt posed as a begpacker to do fieldwork in Hong Kong." The sign says: qǐng bāngzhù wǒ zài quán shìjiè lǚxíng 請幫助我在全世界旅行 "Please help me travel around the world" Despite the fractured grammar (the zài 在* is especially egregious), all the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of biang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58888</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58888&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-biang"/>
        <updated>2023-06-06T04:34:16.000Z</updated>
        <summary type="html"><![CDATA[Shop sign in Budapest: Don't be cowed by the quixotic orthography.  The noodles are delicious, and you can get them right here in Philadelphia, and many other cities around the world. Selected readings "Biangbiang: authentic Xi'an grub in the heart of Philadelphia's University City" (6/9/22) "A Chinese character that is harder to write than 'biang'" […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[remembering May 35th]]></title>
        <id>http://xianblog.wordpress.com/?p=53194</id>
        <link href="https://xianblog.wordpress.com/2023/06/06/remembering-may-35th/"/>
        <updated>2023-06-05T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The (local) unit of intelligence is FLOPs]]></title>
        <id>http://windowsontheory.org/?p=8630</id>
        <link href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/"/>
        <updated>2023-06-05T18:22:58.000Z</updated>
        <summary type="html"><![CDATA[[Crossposting again on Lesswrong and Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it’s hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure … Continue reading The (local) unit of intelligence is FLOPs]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The (local) unit of intelligence is FLOPs]]></title>
        <id>http://windowsontheory.org/?p=8630</id>
        <link href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/"/>
        <updated>2023-06-05T18:22:58.000Z</updated>
        <summary type="html"><![CDATA[[Crossposting again on Lesswrong and Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it’s hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure … Continue reading The (local) unit of intelligence is FLOPs]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bilingual road signs]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58960</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58960&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bilingual-road-signs"/>
        <updated>2023-06-05T12:15:41.000Z</updated>
        <summary type="html"><![CDATA[…in New Zealand. Phil Pennington, "Analysis: National opposed bilingual road signs, so what does the evidence say?", RNZ 62/2023: Analysis – Bilingual road signs send a signal – that the country values te reo Māori. But going bilingual was confusing and National would not support it, National's Simeon Brown told voters in blue-ribbon Tauranga recently. […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding the Dynamics of Gaussian-Stein Variational
  Gradient Descent]]></title>
        <id>http://arxiv.org/abs/2305.14076</id>
        <link href="http://arxiv.org/abs/2305.14076"/>
        <updated>2023-06-05T07:13:47.914Z</updated>
        <summary type="html"><![CDATA[Tianle Liu, Promit Ghosal, Krishnakumar Balasubramanian, Natesh S.
  Pillai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linked Deep Gaussian Process Emulation for Model Networks]]></title>
        <id>http://arxiv.org/abs/2306.01212</id>
        <link href="http://arxiv.org/abs/2306.01212"/>
        <updated>2023-06-05T07:13:47.903Z</updated>
        <summary type="html"><![CDATA[Deyu Ming, Daniel Williamson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding Generalization of Macro-AUC in Multi-label
  Learning]]></title>
        <id>http://arxiv.org/abs/2305.05248</id>
        <link href="http://arxiv.org/abs/2305.05248"/>
        <updated>2023-06-05T07:13:47.890Z</updated>
        <summary type="html"><![CDATA[Guoqiang Wu, Chongxuan Li, Yilong Yin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Developing A Visual-Interactive Interface for Electronic Health Record
  Labeling: An Explainable Machine Learning Approach]]></title>
        <id>http://arxiv.org/abs/2209.12778</id>
        <link href="http://arxiv.org/abs/2209.12778"/>
        <updated>2023-06-05T07:13:47.871Z</updated>
        <summary type="html"><![CDATA[Donlapark Ponnoprat, Parichart Pattarapanitchai, Phimphaka Taninpong,
  Suthep Suantai, Natthanaphop Isaradech, Thiraphat Tanphiriyakun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hyperparameter Learning under Data Poisoning: Analysis of the Influence
  of Regularization via Multiobjective Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2306.01613</id>
        <link href="http://arxiv.org/abs/2306.01613"/>
        <updated>2023-06-05T07:13:47.865Z</updated>
        <summary type="html"><![CDATA[Javier Carnerero-Cano, Luis Mu\~noz-Gonz\'alez, Phillippa Spencer,
  Emil C. Lupu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[fusing simulation with data science [18-19 July 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=53177</id>
        <link href="https://xianblog.wordpress.com/2023/06/05/fusing-simulation-with-data-science-18-19-july-2023/"/>
        <updated>2023-06-04T22:23:59.000Z</updated>
        <summary type="html"><![CDATA[In collaboration with the Met Office, my friend and Warwick colleague Rito Dutta is co-organising a two-day workshop in Warwick in July on the use of statistics and machine learning tools in weather prediction. Attendance is free, but registration needed for tea breaks.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greater China Co-Prosperity Sushi and Ramen Kitchen]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58924</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58924&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=greater-china-co-prosperity-sushi-and-ramen-kitchen"/>
        <updated>2023-06-04T17:30:33.000Z</updated>
        <summary type="html"><![CDATA[Shouldn’t that be Zhonghua Pan-Asian Kitchen Ramen Wok Premium Sushi? pic.twitter.com/tTUaWidjL3 — James Millward 米華健 (@JimMillward) June 4, 2023 The small characters at the top of the sign say: Hànzú Yàzhōu chúfáng 汉族亚洲厨房 "Han ethnicity Asian kitchen" The wording in large Hànyǔ Pīnyīn ("Sinitic spelling") is HANZU, the roman letter transcription of the first two […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revelation:  Scythians and Shang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58846</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58846&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=revelation-scythians-and-shang"/>
        <updated>2023-06-04T15:48:03.000Z</updated>
        <summary type="html"><![CDATA[I was stunned when I read the following article in the South China Morning Post, both because it was published in Hong Kong, which is now completely under the censorial control of the People's Republic of China (PRC) / Chinese Communist Party (CCP), and because it raises some disturbing political issues and troubling linguistic problems. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of inventive pinyin: rua]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58832</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58832&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-inventive-pinyin-rua"/>
        <updated>2023-06-04T15:26:32.000Z</updated>
        <summary type="html"><![CDATA[This exercise video shows a woman repeating the syllable "rua" to describe a move that she makes: Problem is that there's no Sinoglyph (hànzì 漢字 / 汉字) for writing that in Modern Standard Mandarin (MSM), although some might claim that it can be written with this character, ruó 挼 ("rub; knead; massage"). According to this table, "rua" is not a […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The rise (and fall?) of shiesties]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58927</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58927&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-rise-and-fall-of-shiesties"/>
        <updated>2023-06-04T10:52:10.000Z</updated>
        <summary type="html"><![CDATA[Last month I learned a new word, shiesty — which rhymes with feisty, as if it were written "sheisty" — because shiesties have been banned on the local transit system ("SEPTA"): Your browser does not support the audio element. Keith, I'm sure if you walked around Philadelphia, live in Philadelphia, work in Philadelphia, you've seen […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Role Of Social Media On Selected Businesses In Nigeria In The Era Of
  Covid-19 Pandemic]]></title>
        <id>http://arxiv.org/abs/2305.19299</id>
        <link href="http://arxiv.org/abs/2305.19299"/>
        <updated>2023-06-04T07:13:27.273Z</updated>
        <summary type="html"><![CDATA[Cajetan Ihemebiri, Elochukwu Ukwandu, Lizzy Ofusori, Comfort
  Olebara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near-Atomic Scale Perspective on the Oxidation of Ti$_3$C$_2$T$_x$
  MXenes: Insights from Atom Probe Tomography]]></title>
        <id>http://arxiv.org/abs/2305.19822</id>
        <link href="http://arxiv.org/abs/2305.19822"/>
        <updated>2023-06-04T07:13:27.240Z</updated>
        <summary type="html"><![CDATA[Mathias Kr\"amer, Bar Favelukis, Ayman A. El-Zoka, Maxim Sokol, Brian
  A. Rosen, Noam Eliaz, Se-Ho Kim, Baptiste Gault]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual Exploratory Data Analysis of the Covid-19 Pandemic in Nigeria:
  Two Years after the Outbreak]]></title>
        <id>http://arxiv.org/abs/2305.19297</id>
        <link href="http://arxiv.org/abs/2305.19297"/>
        <updated>2023-06-04T07:13:27.228Z</updated>
        <summary type="html"><![CDATA[Ugochukwu Orji, Modesta Ezema, Elochukwu Ukwandu, Chikaodili
  Ugwuishiwu, Ezugwu Obianuju, Malachi Egbugha]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[To what extent can control policies influence the epidemic spreading? --
  A data-driven analysis based on the first wave of COVID-19]]></title>
        <id>http://arxiv.org/abs/2305.19544</id>
        <link href="http://arxiv.org/abs/2305.19544"/>
        <updated>2023-06-04T07:13:27.223Z</updated>
        <summary type="html"><![CDATA[Dongyan Zhang, Wanqi Wen, Wuyue Yang, Liangrong Peng, Changjingn
  Zhuge, Liu Hong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Beacon [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53153</id>
        <link href="https://xianblog.wordpress.com/2023/06/04/the-beacon-jatp/"/>
        <updated>2023-06-03T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dog bites man:  Indian wins spelling bee]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58921</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58921&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dog-bites-man-indian-wins-spelling-bee"/>
        <updated>2023-06-03T20:25:55.000Z</updated>
        <summary type="html"><![CDATA[New old news: "Dev Shah wins 2023 Scripps National Spelling Bee by correctly spelling 'psammophile'"Chris BumbacaUSA TODAY (6/1/23) Another year, same story: The 2023 Scripps National Spelling Bee ended the old-fashioned way. Two competitors left on the stage. No spell-off required. Dev Shah, an eighth-grader from Largo, Florida, spelled "psammophile" correctly to win the 95th […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pronouncing "DeSantis"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58876</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58876&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pronouncing-desantis"/>
        <updated>2023-06-03T14:21:21.000Z</updated>
        <summary type="html"><![CDATA[The question of how to pronounce Ron DeSantis' last name — and the observation that the candidate, his wife, and his campaign have made different choices at different times — is among the more trivial bits of political flotsam recently washing up on the shores of social and political media. In fact the issue has […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinological formatting]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58874</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58874&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinological-formatting"/>
        <updated>2023-06-03T12:02:31.000Z</updated>
        <summary type="html"><![CDATA[I recently received this book: Sūn Sīmiǎo, Sabine Wilms.  Healing Virtue-Power: Medical Ethics and the Doctor's Dao.  Whidbey Island WA:  Happy Goat Productions, 2022. ISBN:  978-1-7321571-9-4 website As soon as I started to leaf through the volume, I was struck by its unusual format and usages:  every Chinese character is accompanied by Hanyu Pinyin phonetic […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tsunami and megathrust earthquake disaster prevention warnings:
  Real-time monitoring of the genesis processes with Physical Wavelets]]></title>
        <id>http://arxiv.org/abs/2305.13249</id>
        <link href="http://arxiv.org/abs/2305.13249"/>
        <updated>2023-06-03T07:12:38.216Z</updated>
        <summary type="html"><![CDATA[Fumihide Takeda]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diagonalization of Polynomial-Time Deterministic Turing Machines Via
  Nondeterministic Turing Machine]]></title>
        <id>http://arxiv.org/abs/2110.06211</id>
        <link href="http://arxiv.org/abs/2110.06211"/>
        <updated>2023-06-03T07:12:38.210Z</updated>
        <summary type="html"><![CDATA[Tianrong Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[van Dantzig seminar]]></title>
        <id>http://xianblog.wordpress.com/?p=53169</id>
        <link href="https://xianblog.wordpress.com/2023/06/03/van-dantzig-seminar/"/>
        <updated>2023-06-02T22:23:48.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Just < Not the same as it was]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58869</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58869&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=just-not-the-same-as-it-was"/>
        <updated>2023-06-02T22:12:54.000Z</updated>
        <summary type="html"><![CDATA[I listened to this Harry Styles song dozens of times on the radio, and every time I heard him sing "You know it's just the same as it was" over and over: It was only after watching the video and reading the subtitles that I realized he was saying "You know it's not the same […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Austronesian languages of Taiwan]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58855</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58855&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=austronesian-languages-of-taiwan"/>
        <updated>2023-06-02T19:27:48.000Z</updated>
        <summary type="html"><![CDATA[Handbook of Formosan Languages (Online): The Indigenous Languages of Taiwan Editors: Paul Jen-kuei Li, Academia SinicaElizabeth Zeitoun, Academia SinicaRik De Busser, National Taiwan Cheng-Chi University Leiden:  Brill, 2023 Outright Purchase: € 2249 / US dollars 2495Subscription: € 350 / US dollars 390 A print version is forthcoming (September 2023 ; 3 vols, ~ 2200 pp.) […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AVFormer: Injecting vision into frozen speech models for zero-shot AV-ASR]]></title>
        <id>http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html</id>
        <link href="http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html"/>
        <updated>2023-06-02T17:02:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Arsha Nagrani and Paul Hongsuck Seo, Research Scientists, Google Research






Automatic speech recognition (ASR) is a well-established technology that is widely adopted for various applications such as conference calls, streamed video transcription and voice commands. While the challenges for this technology are centered around noisy audio inputs, the visual stream in multimodal videos (e.g., TV, online edited videos) can provide strong cues for improving the robustness of ASR systems — this is called audiovisual ASR (AV-ASR).
 

Although lip motion can provide strong signals for speech recognition and is the most common area of focus for AV-ASR, the mouth is often not directly visible in videos in the wild (e.g., due to egocentric viewpoints, face coverings, and low resolution…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Historical speech styles]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58857</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58857&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=historical-speech-styles"/>
        <updated>2023-06-02T11:48:13.000Z</updated>
        <summary type="html"><![CDATA[A recent Dinosaur Comics strip features T-Rex imitating (a certain kind of) speech style from the 1940s: Mouseover title: "to t-rex's mind, and mine as well, all of the past takes place around the 1930s. well sure! and why not?" The next strip: Mouseover title: "you want a gender-neutral way to address a room, well here […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
</feed>