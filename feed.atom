<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2024-09-29T17:14:54.098Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[R[are]SS meeting]]></title>
        <id>http://xianblog.wordpress.com/?p=57558</id>
        <link href="https://xianblog.wordpress.com/2024/09/29/raress-meeting/"/>
        <updated>2024-09-28T22:24:35.000Z</updated>
        <summary type="html"><![CDATA[Yesterday, I happened to be at the right time in the right place, as I was in Warwick for a RSS local section meeting on rare event simulation. (If missing the aurora borealis and the moon eclipse on previous nights!) And hence attended a seminar by Francesca Crucinio in six days!, as she talked about […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gobsmacked!]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66239</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66239&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=gobsmacked"/>
        <updated>2024-09-28T13:06:52.000Z</updated>
        <summary type="html"><![CDATA[Ben Yagoda's new book, Gobsmacked!: The British Invasion of American English, is "A spot-on guide to how and why Americans have become so bloody keen on Britishisms—for good or ill". The publisher's blurb: The British love to complain that words and phrases imported from America—from French fries to Awesome, man!—are destroying the English language. But […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gyro, part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66216</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66216&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=gyro-part-2"/>
        <updated>2024-09-28T11:29:38.000Z</updated>
        <summary type="html"><![CDATA[There's a chain of about half-a-dozen fast food restaurants called Gyro Shack in Boise, Idaho, where I find myself now.  They're cool little shops, just as Boise is a cool (big-)little city spread across a broad, flat plain (nearly three thousand feet in elevation) that lies at the foothills of the Rocky Mountains. Several things […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is English a "creole language"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66229</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66229&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=is-english-a-creole-language"/>
        <updated>2024-09-28T10:50:25.000Z</updated>
        <summary type="html"><![CDATA[The first two panels of today's SMBC: The rest of the strip: The AfterComic: The mouseover title: "Hoping the Welsh isn't lol." The premise seems to be that King Arthur has arisen again, to deal with socio-economic crises in today's Britain. I'll leave interpretation of the Arthur legend to others, and focus on the description […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Swiss winter school on Theoretical CS]]></title>
        <id>http://windowsontheory.org/?p=8796</id>
        <link href="https://windowsontheory.org/2024/09/27/swiss-winter-school-on-theoretical-cs/"/>
        <updated>2024-09-28T01:10:16.000Z</updated>
        <summary type="html"><![CDATA[The Swiss Winter School on Theoretical Computer Science (Jan 26 — 31 2025, https://theory.epfl.ch/WinterSchool2025/) is the third installment in a series of annual winter schools jointly organized by EPFL and ETH Zurich.The goal of the school is to educate outstanding international PhD students about exciting recent developments in theoretical computer science.The winter school will be held in … Continue reading Swiss winter school on Theoretical CS]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Swiss winter school on Theoretical CS]]></title>
        <id>http://windowsontheory.org/?p=8796</id>
        <link href="https://windowsontheory.org/2024/09/27/swiss-winter-school-on-theoretical-cs/"/>
        <updated>2024-09-28T01:10:16.000Z</updated>
        <summary type="html"><![CDATA[The Swiss Winter School on Theoretical Computer Science (Jan 26 — 31 2025, https://theory.epfl.ch/WinterSchool2025/) is the third installment in a series of annual winter schools jointly organized by EPFL and ETH Zurich.The goal of the school is to educate outstanding international PhD students about exciting recent developments in theoretical computer science.The winter school will be held in … Continue reading Swiss winter school on Theoretical CS]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[semi-marathon d’Argentan]]></title>
        <id>http://xianblog.wordpress.com/?p=54214</id>
        <link href="https://xianblog.wordpress.com/2024/09/28/semi-marathon-dargentan/"/>
        <updated>2024-09-27T22:24:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Freudian slip of the week]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66219</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66219&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=freudian-slip-of-the-week"/>
        <updated>2024-09-27T17:10:09.000Z</updated>
        <summary type="html"><![CDATA[That'll be tough to explain… [image or embed] — George Takei (@georgetakei.bsky.social) September 25, 2024 at 6:00 PM The material below is taken from my lecture notes for my undergraduate Introduction to Linguistics course at Penn: In figuring out how the brain works, one standard line of inquiry is to look at how it fails. […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Looking above and below]]></title>
        <id>https://www.argmin.net/p/looking-above-and-below</id>
        <link href="https://www.argmin.net/p/looking-above-and-below"/>
        <updated>2024-09-27T14:03:41.000Z</updated>
        <summary type="html"><![CDATA[I've finally found a satisfying derivation of Lagrangian duality.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Looking above and below]]></title>
        <id>https://www.argmin.net/p/looking-above-and-below</id>
        <link href="https://www.argmin.net/p/looking-above-and-below"/>
        <updated>2024-09-27T14:03:41.000Z</updated>
        <summary type="html"><![CDATA[I've finally found a satisfying derivation of Lagrangian duality.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Our supersubstantial rice]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66199</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66199&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=our-supersubstantial-rice"/>
        <updated>2024-09-27T13:56:09.000Z</updated>
        <summary type="html"><![CDATA["Some idioms and terms pertaining to Japan's favorite grain", by Yuko Tamura, The Japan Times (9/25/24) Rice is an essential part of the Japanese diet, so naturally it's also a part of the language. In fact, the word for "meal," ご飯 (gohan), also means "cooked rice." Before it's cooked, however, you'll see it referred to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PIPLA [mostly MCMC’nar]]]></title>
        <id>http://xianblog.wordpress.com/?p=57519</id>
        <link href="https://xianblog.wordpress.com/2024/09/27/pipla-mostly-mcmcnar/"/>
        <updated>2024-09-26T22:24:52.000Z</updated>
        <summary type="html"><![CDATA[The first “mostly MCMC ” seminar (Season 2) had our new Ocean postdoc Tim Johnston, freshly graduated from the University of Edinburgh, involved in both talks, with proximal approximations for discontinuity! The first talk was given by Francesca Crucinio (formerly Warwick and formerly CREST, to point out potential COI!!), about the Proximal Interacting Particle Langevin […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How AlphaChip transformed computer chip design]]></title>
        <id>https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/</id>
        <link href="https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/"/>
        <updated>2024-09-26T14:08:34.000Z</updated>
        <summary type="html"><![CDATA[Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Duality]]></title>
        <id>https://www.argmin.net/p/duality</id>
        <link href="https://www.argmin.net/p/duality"/>
        <updated>2024-09-26T14:08:25.000Z</updated>
        <summary type="html"><![CDATA[From Volume 3: The Subliminal Verses]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Duality]]></title>
        <id>https://www.argmin.net/p/duality</id>
        <link href="https://www.argmin.net/p/duality"/>
        <updated>2024-09-26T14:08:25.000Z</updated>
        <summary type="html"><![CDATA[From Volume 3: The Subliminal Verses]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["The cosmic jam from whence it came"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66206</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66206&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-cosmic-jam-from-whence-it-came"/>
        <updated>2024-09-26T10:06:48.000Z</updated>
        <summary type="html"><![CDATA[Elle Cordova offers an update from ChatGTP on the number of Rs in "strawberry": As of this morning, ChatGPT 4o gives me the same old boring wrong answer of "2": But @nemonaught2772 (in a youTube comment) guides ChatGPT down  an impressively creative rabbit hole: I saw the video and had to try it for myself!!! […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dimsum:  dot your heart]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66172</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66172&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dimsum-dot-your-heart"/>
        <updated>2024-09-26T05:54:14.000Z</updated>
        <summary type="html"><![CDATA[Nick Tursi spotted this shop in Korea: Haewon Cho tells me that three characters are pronounced as jeomjeomsim in Korean, and that jeomsim means lunch in Korean. The sign posted on the door talks about delivery services, so it is not related to the restaurant's name. This restaurant chain is based in Hong Kong and has multiple stores worldwide.  […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[利用“熄火保护 + 通断器”实现燃气灶智能关火]]></title>
        <id>https://kexue.fm/archives/10394</id>
        <link href="https://kexue.fm/archives/10394"/>
        <updated>2024-09-26T02:39:00.000Z</updated>
        <summary type="html"><![CDATA[燃气灶智能化主要有两个方向：一是检测开关火状态，实现跟抽油烟机等其他设备的联动；二是实现智能关火，这包括定时关火以及接入米家（或者其他智能家居）实现语音关火、远程关火等。目前带有这两点功能的燃气...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Words for king:  Greek, Tocharian, Sinitic]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66195</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66195&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=words-for-king-greek-tocharian-sinitic"/>
        <updated>2024-09-26T00:31:22.000Z</updated>
        <summary type="html"><![CDATA[Sino-Platonic Papers is pleased to announce the publication of its three-hundred-and-fifty-seventh issue:  “Resurrecting an Etymology: Greek (w)ánax ‘king’ and Tocharian A nātäk ‘lord,’ and Possible Wider Connections,” by Douglas Q. Adams. (pdf) ABSTRACT Examined here is the possible cognancy of Homeric Greek (w)ánax ‘king’ and Tocharian A nātäk ‘lord’ and their respective feminine derivatives (w)ánassa […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[nuclear disarmament now!]]></title>
        <id>http://xianblog.wordpress.com/?p=56277</id>
        <link href="https://xianblog.wordpress.com/2024/09/26/nuclear-disarmament-now/"/>
        <updated>2024-09-25T22:24:51.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pre-pre-meetings]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66190</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66190&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pre-pre-meetings"/>
        <updated>2024-09-25T14:25:38.000Z</updated>
        <summary type="html"><![CDATA[The Indeed Editorial Team explains to us ("What Is a Pre-Meeting? (Plus Benefits and How To Host One", 8/18/2024) that A successful meeting engages attendees, achieves organizational objectives and allows professionals to make informed decisions in an allotted time frame. Before the actual event occurs, employees may gather for a pre-meeting to help them prepare. […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CUDA-Free Inference for LLMs]]></title>
        <id>https://pytorch.org/blog/pytorch-native-architecture-optimization/</id>
        <link href="https://pytorch.org/blog/pytorch-native-architecture-optimization/"/>
        <updated>2024-09-25T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[PyTorch Native Architecture Optimization: torchao By Team PyTorch We’re happy to officially launch torchao, a PyTorch native library that makes models faster and smaller by leveraging low bit dtypes, quantization and sparsity. torchao is an accessible toolkit of techniques written (mostly) in easy to read PyTorch code spanning both inference and training. This blog will help you pick which techniques matter for your workloads. We benchmarked our techniques on popular GenAI models like LLama 3 and Diffusion models and saw minimal drops in accuracy. Unless otherwise noted the baselines are bf16 run on A100 80GB GPU. Our topline metrics for llama 3 are For inference 97% speedup for Llama 3 8B using autoquant with int4 weight only quantization and hqq 73% peak VRAM reduction for Llama 3.1 8B at 128K context length with a quantized KV cache For training 50% speedup for Llama 3 70B pretraining using float8 training on H100 30% peak VRAM reduction for Llama 3 8B using 4 bit quantized optimizers. Our topline metrics for diffusion model inference 53% speedup using float8 dynamic quantization inference with float8 row-wise scaling on flux1.dev onH100 50% reduction in model VRAM for CogVideoX using int8 dynamic quantization Below we’ll walk through some of the techniques available in torchao you can apply to your models for inference and training. Inference Our inference quantization algorithms work over arbitrary PyTorch models that contain nn.Linear layers. Weight only and dynamic activation quantization for various dtypes and sparse layouts can be chosen using our top level quantize_ api from torchao.quantization import ( quantize_, int4_weight_only, ) quantize_(model, int4_weight_only()) Sometimes quantizing a layer can make it slower because of overhead so if you’d rather we just pick how to quantize each layer in a model for you then you can instead run model = torchao.autoquant(torch.compile(model, mode=’max-autotune’)) quantize_ API has a few different options depending on whether your model is compute bound or memory bound. from torchao.quantization import ( # Memory bound models int4_weight_only, int8_weight_only, \# Compute bound models int8\_dynamic\_activation\_int8\_semi\_sparse\_weight, int8\_dynamic\_activation\_int8\_weight, \# Device capability 8.9+ float8\_weight\_only, float8\_dynamic\_activation\_float8\_weight, ) «««&lt; HEAD:_posts/2024-09-25-pytorch-native-architecture-optimization.md We also have extensive benchmarks on diffusion models in collaboration with the HuggingFace diffusers team in diffusers-torchao where we demonstrated 53.88% speedup on Flux.1-Dev and 27.33% speedup on CogVideoX-5b ======= We also have extensive benchmarks on diffusion models in collaboration with the HuggingFace diffusers team in diffusers-torchao where we demonstrated 53.88% speedup on Flux.1-Dev and 27.33% speedup on CogVideoX-5b 97898699f7101b847da377106274783ced03bb3d:_posts/2024-09-25-pytorch-native-architecture-optimizaion.md Our APIs are composable so we’ve for example composed sparsity and quantization to bring 5% speedup for ViT-H inference But also can do things like quantize weights to int4 and the kv cache to int8 to support Llama 3.1 8B at the full 128K context length running in under 18.9GB of VRAM. QAT Post training quantization, especially at less than 4 bit can suffer from serious accuracy degradations. Using Quantization Aware Training (QAT) we’ve managed to recover up to 96% of the accuracy degradation on hellaswag. We’ve integrated this as an end to end recipe in torchtune with a minimal tutorial Training Low precision compute and communications torchao provides easy to use e2e workflows for reducing the precision of training compute and distributed communications, starting with float8 for `torch.nn.Linear` layers.Here is a one-liner to convert the compute gemms of your training run to float8: from torchao.float8 import convert_to_float8_training convert_to_float8_training(model) For an e2e example of how to speed up LLaMa 3 70B pretraining by up to 1.5x with float8, see our README, and torchtitan’s blog and float8 recipe. Performance and accuracy of float8 pretraining of LLaMa 3 70B, vs bfloat16 (source: https://dev-discuss.pytorch.org/t/enabling-float8-all-gather-in-fsdp2/2359) We are expanding our training workflows to more dtypes and layouts NF4 QLoRA in torchtune Prototype int8 training support Accelerated sparse 2:4 training Low bit Optimizers Inspired by Bits and Bytes we’ve also added prototype support for 8 and 4 bit optimizers as a drop in replacement for AdamW. from torchao.prototype.low_bit_optim import AdamW8bit, AdamW4bit optim = AdamW8bit(model.parameters()) Integrations We’ve been actively working on making sure torchao works well in some of the most important projects in open source. Huggingface transformers as an inference backend In diffusers-torchao as a reference implementation for accelerating diffusion models In HQQ for fast 4 bit inference In torchtune for PyTorch native QLoRA and QAT recipes In torchchat for post training quantization In SGLang for for int4 and int8 post training quantization # Conclusion If you’re interested in making your models faster and smaller for training or inference, we hope you’ll find torchao useful and easy to integrate. pip install torchao There are a lot of things we’re excited about next ranging from going lower than 4 bit, performant kernels for high-throughput inference, expanding to more layers, scaling types or granularities, MX hardware support and supporting more hardware backends. If any of the above sounds exciting you can follow our progress at: https://github.com/pytorch/ao If you’re interested in working on torchao, we’ve created a contributors guide, and if you have any questions we hang out on the #torchao channel on discord.gg/cudamode Acknowledgements We are fortunate to stand on the shoulders of giants and collaborate with some of the best people in open source. Thank you! Bits and Bytes for pioneering work in low bit optimizers and QLoRA Answer.ai for their engineering work to get FSDP and QLoRA composing Mobius Labs for the lovely back and forths on quantization algorithms and low bit kernels HuggingFace transformers for their help in battle testing and integrating our work HuggingFace diffusers for our collaboration on extensive benchmarks and best practices torch.compile so we could write our algorithms in pure PyTorch CUDA MODE for most of our early contributors]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CUDA-Free Inference for LLMs]]></title>
        <id>https://pytorch.org/blog/pytorch-native-architecture-optimizaion/</id>
        <link href="https://pytorch.org/blog/pytorch-native-architecture-optimizaion/"/>
        <updated>2024-09-25T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[PyTorch Native Architecture Optimization: torchao By Team PyTorch We’re happy to officially launch torchao, a PyTorch native library that makes models faster and smaller by leveraging low bit dtypes, quantization and sparsity. torchao is an accessible toolkit of techniques written (mostly) in easy to read PyTorch code spanning both inference and training. This blog will help you pick which techniques matter for your workloads. We benchmarked our techniques on popular GenAI models like LLama 3 and Diffusion models and saw minimal drops in accuracy. Unless otherwise noted the baselines are bf16 run on A100 80GB GPU. Our topline metrics for llama 3 are For inference 97% speedup for Llama 3 8B using autoquant with int4 weight only quantization and hqq 73% peak VRAM reduction for Llama 3.1 8B at 128K context length with a quantized KV cache For training 50% speedup for Llama 3 70B pretraining using float8 training on H100 30% peak VRAM reduction for Llama 3 8B using 4 bit quantized optimizers. Our topline metrics for diffusion model inference 53% speedup using float8 dynamic quantization inference with float8 row-wise scaling on flux1.dev onH100 50% reduction in model VRAM for CogVideoX using int8 dynamic quantization Below we’ll walk through some of the techniques available in torchao you can apply to your models for inference and training. Inference Our inference quantization algorithms work over arbitrary PyTorch models that contain nn.Linear layers. Weight only and dynamic activation quantization for various dtypes and sparse layouts can be chosen using our top level quantize_ api from torchao.quantization import ( quantize_, int4_weight_only, ) quantize_(model, int4_weight_only()) Sometimes quantizing a layer can make it slower because of overhead so if you’d rather we just pick how to quantize each layer in a model for you then you can instead run model = torchao.autoquant(torch.compile(model, mode=’max-autotune’)) quantize_ API has a few different options depending on whether your model is compute bound or memory bound. from torchao.quantization import ( # Memory bound models int4_weight_only, int8_weight_only, \# Compute bound models int8\_dynamic\_activation\_int8\_semi\_sparse\_weight, int8\_dynamic\_activation\_int8\_weight, \# Device capability 8.9+ float8\_weight\_only, float8\_dynamic\_activation\_float8\_weight, ) We also have extensive benchmarks on diffusion models in collaboration with the HuggingFace diffusers team in diffusers-torchao where we demonstrated 53.88% speedup on Flux.1-Dev and 27.33% speedup on CogVideoX-5b Our APIs are composable so we’ve for example composed sparsity and quantization to bring 5% speedup for ViT-H inference But also can do things like quantize weights to int4 and the kv cache to int8 to support Llama 3.1 8B at the full 128K context length running in under 18.9GB of VRAM. QAT Post training quantization, especially at less than 4 bit can suffer from serious accuracy degradations. Using Quantization Aware Training (QAT) we’ve managed to recover up to 96% of the accuracy degradation on hellaswag. We’ve integrated this as an end to end recipe in torchtune with a minimal tutorial Training Low precision compute and communications torchao provides easy to use e2e workflows for reducing the precision of training compute and distributed communications, starting with float8 for `torch.nn.Linear` layers.Here is a one-liner to convert the compute gemms of your training run to float8: from torchao.float8 import convert_to_float8_training convert_to_float8_training(model) For an e2e example of how to speed up LLaMa 3 70B pretraining by up to 1.5x with float8, see our README, and torchtitan’s blog and float8 recipe. Performance and accuracy of float8 pretraining of LLaMa 3 70B, vs bfloat16 (source: https://dev-discuss.pytorch.org/t/enabling-float8-all-gather-in-fsdp2/2359) We are expanding our training workflows to more dtypes and layouts NF4 QLoRA in torchtune Prototype int8 training support Accelerated sparse 2:4 training Low bit Optimizers Inspired by Bits and Bytes we’ve also added prototype support for 8 and 4 bit optimizers as a drop in replacement for AdamW. from torchao.prototype.low_bit_optim import AdamW8bit, AdamW4bit optim = AdamW8bit(model.parameters()) Integrations We’ve been actively working on making sure torchao works well in some of the most important projects in open source. Huggingface transformers as an inference backend In diffusers-torchao as a reference implementation for accelerating diffusion models In HQQ for fast 4 bit inference In torchtune for PyTorch native QLoRA and QAT recipes In torchchat for post training quantization In SGLang for for int4 and int8 post training quantization # Conclusion If you’re interested in making your models faster and smaller for training or inference, we hope you’ll find torchao useful and easy to integrate. pip install torchao There are a lot of things we’re excited about next ranging from going lower than 4 bit, performant kernels for high-throughput inference, expanding to more layers, scaling types or granularities, MX hardware support and supporting more hardware backends. If any of the above sounds exciting you can follow our progress at: https://github.com/pytorch/ao If you’re interested in working on torchao, we’ve created a contributors guide, and if you have any questions we hang out on the #torchao channel on discord.gg/cudamode Acknowledgements We are fortunate to stand on the shoulders of giants and collaborate with some of the best people in open source. Thank you! Bits and Bytes for pioneering work in low bit optimizers and QLoRA Answer.ai for their engineering work to get FSDP and QLoRA composing Mobius Labs for the lovely back and forths on quantization algorithms and low bit kernels HuggingFace transformers for their help in battle testing and integrating our work HuggingFace diffusers for our collaboration on extensive benchmarks and best practices torch.compile so we could write our algorithms in pure PyTorch CUDA MODE for most of our early contributors]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[murder of a Dauphine student]]></title>
        <id>http://xianblog.wordpress.com/?p=57594</id>
        <link href="https://xianblog.wordpress.com/2024/09/25/murder-of-a-dauphine-student/"/>
        <updated>2024-09-24T22:24:21.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more]]></title>
        <id>https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/</id>
        <link href="https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/"/>
        <updated>2024-09-24T16:03:03.000Z</updated>
        <summary type="html"><![CDATA[We’re releasing two updated production-ready Gemini models]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Membership Checks and Short Proofs]]></title>
        <id>https://www.argmin.net/p/membership-checks-and-short-proofs</id>
        <link href="https://www.argmin.net/p/membership-checks-and-short-proofs"/>
        <updated>2024-09-24T14:04:46.000Z</updated>
        <summary type="html"><![CDATA[Slouching our way to duality theory]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Membership Checks and Short Proofs]]></title>
        <id>https://www.argmin.net/p/membership-checks-and-short-proofs</id>
        <link href="https://www.argmin.net/p/membership-checks-and-short-proofs"/>
        <updated>2024-09-24T14:04:46.000Z</updated>
        <summary type="html"><![CDATA[Slouching our way to duality theory]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pun of the week]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66176</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66176&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pun-of-the-week-2"/>
        <updated>2024-09-24T11:01:16.000Z</updated>
        <summary type="html"><![CDATA[From George Takei, on Bluesky: This left me in stitches. [image or embed] — George Takei (@georgetakei.bsky.social) September 21, 2024 at 10:00 AM Replies includes "I'm torn", "This is the kind of knit-wit I enjoy reading", "It's a race to the bobbin", "oh brother…", "I expect this thread to be patchy", "Rip it up!", "Needling […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[rewriting history]]></title>
        <id>http://xianblog.wordpress.com/?p=57406</id>
        <link href="https://xianblog.wordpress.com/2024/09/24/rewriting-history/"/>
        <updated>2024-09-23T22:24:23.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Viterbo’s conjecture was refuted by Pazit Haim-Kislev and Yaron Ostrover]]></title>
        <id>http://gilkalai.wordpress.com/?p=26892</id>
        <link href="https://gilkalai.wordpress.com/2024/09/23/viterbos-conjecture-was-refuted-by-pazit-haim-kislev-and-yaron-ostrover/"/>
        <updated>2024-09-23T17:57:38.000Z</updated>
        <summary type="html"><![CDATA[Viterbo conjecture – refuted Claude Viterbo’s 2000 volume-capacity conjecture asserts that the Euclidean (even dimensional) ball maximizes  (every) symplectic capacity  among convex bodies of the same volume. In the recent paper A Counterexample to Viterbo’s Conjecture, Pazit Haim-Kislev and Yaron … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Viterbo’s conjecture was refuted by Pazit Haim-Kislev and Yaron Ostrover]]></title>
        <id>http://gilkalai.wordpress.com/?p=26892</id>
        <link href="https://gilkalai.wordpress.com/2024/09/23/viterbos-conjecture-was-refuted-by-pazit-haim-kislev-and-yaron-ostrover/"/>
        <updated>2024-09-23T17:57:38.000Z</updated>
        <summary type="html"><![CDATA[Viterbo conjecture – refuted Claude Viterbo’s 2000 volume-capacity conjecture asserts that the Euclidean (even dimensional) ball maximizes  (every) symplectic capacity  among convex bodies of the same volume. In the recent paper A Counterexample to Viterbo’s Conjecture, Pazit Haim-Kislev and Yaron … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Garbage time of history", part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66157</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66157&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=garbage-time-of-history-part-2"/>
        <updated>2024-09-23T14:22:46.000Z</updated>
        <summary type="html"><![CDATA[This is a phrase that has been sweeping through China during recent months.  In Chinese it is "lìshǐ de lājī shíjiān 历史的垃圾时间".  The expression "lājī shíjiān 垃圾时间" started out in sports to characterize a situation where one side has such a commanding lead that it would be impossible for the other team to catch up.  […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Political deepfakes]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66161</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66161&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=political-deepfakes"/>
        <updated>2024-09-23T10:30:06.000Z</updated>
        <summary type="html"><![CDATA[Daysia Tolentino, "Trump shares fake photo of Harris with Diddy in now-deleted Truth Social post", NBC News 9/20/2024: Amid the recent news of Sean “Diddy” Combs’ arrest, former President Donald Trump reposted a doctored image falsely showing Vice President Kamala Harris with Combs with text questioning if she was involved in his alleged “freak offs.” […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[another, older, truncated Normal algorithm [X’ed]]]></title>
        <id>http://xianblog.wordpress.com/?p=57525</id>
        <link href="https://xianblog.wordpress.com/2024/09/23/another-older-truncated-normal-algorithm/"/>
        <updated>2024-09-22T22:24:57.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["A fancy way to say 'fancy'"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66154</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66154&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-fancy-way-to-say-fancy"/>
        <updated>2024-09-22T18:48:15.000Z</updated>
        <summary type="html"><![CDATA[I was in a Salt Lake City shop called Caputo's that bills itself as a Market and Deli, Purveyors of Regional Italian and Southern European Foods.  It reminds me somewhat of the great Di Bruno Bros. in Philly, but more on the "paisan"* side (sort of like the South Asian word "desi" as used in […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teeth as part of the vocal tract]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66124</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66124&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=teeth-as-part-of-the-vocal-tract"/>
        <updated>2024-09-22T12:40:13.000Z</updated>
        <summary type="html"><![CDATA[The oral cavity is one section of the vocal tract.  Along with the tongue, lips, and hard and soft palates, the teeth help to form different types of speech sounds.  If any one of these components is missing or deformed, it will have a pronounced (!) effect on speech production. Two days ago, I met […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[International Talk Like a Pirate Day, again…]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66143</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66143&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=international-talk-like-a-pirate-day-again"/>
        <updated>2024-09-22T11:32:40.000Z</updated>
        <summary type="html"><![CDATA[We missed it this year, but the New York Times didn't , and posted a link to Laurel MacKenzie's "Pirate Lingo 101": Past Talk Like a Pirate Day posts: "R!", 11/03/2003 "Type like a pirate day", 9/9/2004 "R!?", 9/19/2005 "Type like a pirate", 9/18/2006 "Pirate R as I-R-eland", 9/20/2006 "Powarrr law", 9/20/2006 "Post like a […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trump all-caps theories]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66128</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66128&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=trump-all-caps-theories"/>
        <updated>2024-09-22T10:41:49.000Z</updated>
        <summary type="html"><![CDATA[From Lane Greene on Bluesky (link): I've been trying for a while to figure out a theory of Trump's capitalisation. It's mostly nouns like Country, but not always positive ones. I never did nail down the pattern. But I've got a new theory – bear with me here. ALL CAPS IS FOR UNGRATEFUL WOMEN. [image […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Genealogy rocks]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66097</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66097&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=genealogy-rocks"/>
        <updated>2024-09-22T02:16:38.000Z</updated>
        <summary type="html"><![CDATA[Not only is it hard to spell, few people know what it means. As I mentioned in earlier posts, on my trip to SLC three or four days ago, I fulfilled three of my childhood dreams:  1. float in the Great Salt Lake; 2. hear the Mormon Tabernacle Choir in person; 3. visit the Family […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2024 ERC Starting Grants announced]]></title>
        <id>http://xianblog.wordpress.com/?p=57431</id>
        <link href="https://xianblog.wordpress.com/2024/09/22/2024-erc-starting-grants-announced/"/>
        <updated>2024-09-21T22:24:34.000Z</updated>
        <summary type="html"><![CDATA[Today the European Research Council (ERC) has made public which Starting Grants proposals were selected this year, for a total amount of €780m. Congrats to all recipients!These include 14 grants for the PE1 panel in which I sat earlier this year for the fourth and final time. (The PE1 panel stands within the Physical Sciences […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is a poll?]]></title>
        <id>https://www.argmin.net/p/what-is-a-poll</id>
        <link href="https://www.argmin.net/p/what-is-a-poll"/>
        <updated>2024-09-21T20:25:17.000Z</updated>
        <summary type="html"><![CDATA[In lieu of a Twitter thread, a short post about our obsession with polls.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is a poll?]]></title>
        <id>https://www.argmin.net/p/what-is-a-poll</id>
        <link href="https://www.argmin.net/p/what-is-a-poll"/>
        <updated>2024-09-21T20:25:17.000Z</updated>
        <summary type="html"><![CDATA[In lieu of a Twitter thread, a short post about our obsession with polls.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vanceism of the week: "Haitia"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66110</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66110&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=vanceism-of-the-week-haitia"/>
        <updated>2024-09-21T15:39:16.000Z</updated>
        <summary type="html"><![CDATA[Back in the early 2000s, George W. Bush got a lot of flac for calling Greeks "Grecians" and making similar mistakes in the mapping from place names to ethnonyms. J.D. Vance recently went the other way, mapping the ethnonym Haitians to a possible place name pronounced /ˈhej.ʃə/, as if it were spelled "Haitia": Your browser […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Can Google AI count?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66103</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66103&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=can-google-ai-count"/>
        <updated>2024-09-21T14:08:57.000Z</updated>
        <summary type="html"><![CDATA[Apparently not. Given this recent tweet, in which Google AI Overview explains that "October 21 is not a Libra, as the Libra zodiac sign is from September 23 to October 22", I thought I'd try for myself. The result had a different format but the same problem: We've previously described AI problems with counting R's […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the chaos, conquest, war, abundance, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=57341</id>
        <link href="https://xianblog.wordpress.com/2024/09/21/a-journal-of-the-chaos-conquest-war-abundance-and-death-year/"/>
        <updated>2024-09-20T22:24:43.000Z</updated>
        <summary type="html"><![CDATA[Read The Daevabad Trilogy by S. A. Chakraborty within a few weeks, after I started the first book in a NE Seattle Barnes & Noble on a bookstore long stop between two Airbnb‘s. A suitable choice to read out the sleepless bouts induced by the jetlag. Some original ideas around a Middle East djinn kingdom, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Saint-Joseph]]></title>
        <id>http://xianblog.wordpress.com/?p=57413</id>
        <link href="https://xianblog.wordpress.com/2024/09/20/57413/"/>
        <updated>2024-09-20T18:20:33.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cone Programming]]></title>
        <id>https://www.argmin.net/p/cone-programming</id>
        <link href="https://www.argmin.net/p/cone-programming"/>
        <updated>2024-09-20T14:21:04.000Z</updated>
        <summary type="html"><![CDATA[Sometimes a technical term makes for a catchy title.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cone Programming]]></title>
        <id>https://www.argmin.net/p/cone-programming</id>
        <link href="https://www.argmin.net/p/cone-programming"/>
        <updated>2024-09-20T14:21:04.000Z</updated>
        <summary type="html"><![CDATA[Sometimes a technical term makes for a catchy title.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mormon Tabernacle Choir vowel variations]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66072</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66072&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mormon-tabernacle-choir-vowel-variations"/>
        <updated>2024-09-20T14:09:54.000Z</updated>
        <summary type="html"><![CDATA[I departed a total of about 260 miles from my Route 30 / Lincoln Highway running route to come down to Salt Lake City for a few perduring reasons. 1. From the time I was a little boy, I have always wanted to float in the Great Salt Lake. 2. From the time I was […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is there evidence of senility in Trump's speech?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66080</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66080&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=is-there-evidence-of-senility-in-trumps-speech"/>
        <updated>2024-09-20T12:12:39.000Z</updated>
        <summary type="html"><![CDATA[Sarah Posner on Bluesky, linking to a kamalahq tweet and a kamalahq Instagram post: In the thread below: a completely rambling, unhinged, incomprehensible quote from Trump at his Flint town hall with Sarah Huckabee Sanders that the Harris campaign distributed, then news headlines about same event. Where is all the coverage that Trump is old […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Xing²⁰ Corsica]]></title>
        <id>http://xianblog.wordpress.com/?p=57571</id>
        <link href="https://xianblog.wordpress.com/2024/09/20/xing%c2%b2%e2%81%b0-corsica/"/>
        <updated>2024-09-20T10:24:45.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linguistic Bias in ChatGPT: Language Models Reinforce Dialect Discrimination]]></title>
        <id>http://bair.berkeley.edu/blog/2024/09/20/linguistic-bias/</id>
        <link href="http://bair.berkeley.edu/blog/2024/09/20/linguistic-bias/"/>
        <updated>2024-09-20T09:00:00.000Z</updated>
        <summary type="html"><![CDATA[Sample language model responses to different varieties of English and native speaker reactions.


ChatGPT does amazingly well at communicating with people in English. But whose English?
Only 15% of ChatGPT users are from the US, where Standard American English is the default. But the model is also commonly used in countries and communities where people speak other varieties of English. Over 1 billion people around the world speak varieties such as Indian English, Nigerian English, Irish English, and African-American English.
Speakers of these non-“standard” varieties often face discrimination in the real world. They’ve been told that the way they speak is unprofessional or incorrect, discredited as witnesses, and denied housing–despite extensive research indicating that all language variet…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Timothy Chow’s Amazing Fifteen Boxes Puzzle (TYI 56)]]></title>
        <id>http://gilkalai.wordpress.com/?p=26763</id>
        <link href="https://gilkalai.wordpress.com/2024/09/20/timothy-chows-amazing-fifteen-boxes-puzzle-tyi-56/"/>
        <updated>2024-09-20T07:35:40.000Z</updated>
        <summary type="html"><![CDATA[TYI56 asked the following question of Timothy Chow: You have fifteen boxes labelled with the English letters from A to O. Two identical prizes are placed in two (distinct) boxes chosen at random. Andrew’s  search order is  ABCDEFGHIJKLMNO. Barbara’s search … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Timothy Chow’s Amazing Fifteen Boxes Puzzle (TYI 56)]]></title>
        <id>http://gilkalai.wordpress.com/?p=26763</id>
        <link href="https://gilkalai.wordpress.com/2024/09/20/timothy-chows-amazing-fifteen-boxes-puzzle-tyi-56/"/>
        <updated>2024-09-20T07:35:40.000Z</updated>
        <summary type="html"><![CDATA[TYI56 asked the following question of Timothy Chow: You have fifteen boxes labelled with the English letters from A to O. Two identical prizes are placed in two (distinct) boxes chosen at random. Andrew’s  search order is  ABCDEFGHIJKLMNO. Barbara’s search … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cultural literacy at The Guardian]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66066</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66066&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=cultural-literacy-at-the-guardian"/>
        <updated>2024-09-19T15:56:17.000Z</updated>
        <summary type="html"><![CDATA[There has been an enormous turbulence over the simultaneous explosion of Hezbollah pagers (some call them walkie-talkies) at 3:30 PM on September 17, 2024, involving as it does actors in regions as far flung as the Middle East, Europe, and East Asia.  No one could be closer to the center of the turmoil than the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modeling Dystopia]]></title>
        <id>https://www.argmin.net/p/modeling-dystopia</id>
        <link href="https://www.argmin.net/p/modeling-dystopia"/>
        <updated>2024-09-19T14:55:21.000Z</updated>
        <summary type="html"><![CDATA[How do you deal with the paradox of choice in optimization modeling?]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modeling Dystopia]]></title>
        <id>https://www.argmin.net/p/modeling-dystopia</id>
        <link href="https://www.argmin.net/p/modeling-dystopia"/>
        <updated>2024-09-19T14:55:21.000Z</updated>
        <summary type="html"><![CDATA[How do you deal with the paradox of choice in optimization modeling?]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Softmax后传：寻找Top-K的光滑近似]]></title>
        <id>https://kexue.fm/archives/10373</id>
        <link href="https://kexue.fm/archives/10373"/>
        <updated>2024-09-19T07:09:00.000Z</updated>
        <summary type="html"><![CDATA[Softmax，顾名思义是“soft的max”，是$\max$算子（准确来说是$\text{argmax}$）的光滑近似，它通过指数归一化将任意向量$\boldsymbol{x}\in\math...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Font making for oracle bone inscription studies]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66052</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66052&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=font-making-for-oracle-bone-inscription-studies"/>
        <updated>2024-09-19T01:18:18.000Z</updated>
        <summary type="html"><![CDATA["Jingyuan Digital Platform: Font Making and Database Development for Shang Oracle Bones (Part 1)", Peichao Qin, The Digital Orientalist (9/17/24) If you're wondering what "Jingyuan" means, it's a fancy, allusive way to say "Mirrored contexts [for thorough investigations]" ([gézhì] jìngyuán [格致]鏡原) (source), just a means for the creator of the platform to give it a […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nature snapshots]]></title>
        <id>http://xianblog.wordpress.com/?p=57497</id>
        <link href="https://xianblog.wordpress.com/2024/09/19/nature-snapshots-6/"/>
        <updated>2024-09-18T22:24:53.000Z</updated>
        <summary type="html"><![CDATA[Some quick breakfast reads from the 22 August issue of Nature, beyond the nice pun in the cover title (which reads like Lonely Planet at first glance!) capturing a rare blooming of plants in the drylands of the Judaean Desert in 2015, discussing the higher diversity of plants in dry environments, a tribune about the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ask LLOG: Semicolons used as commas?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66059</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66059&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ask-llog-semicolons-used-as-commas"/>
        <updated>2024-09-18T14:52:52.000Z</updated>
        <summary type="html"><![CDATA[From Josh E.: I am a big fan of your posts on the Language Log and was wondering whether you often see semicolons used the way we might normally use commas to set off a dependent clause. Here is an example I just saw: A Massachusetts family is demanding a full investigation after a state […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Empowering YouTube creators with generative AI]]></title>
        <id>https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/</id>
        <link href="https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/"/>
        <updated>2024-09-18T14:30:06.000Z</updated>
        <summary type="html"><![CDATA[New video generation technology in YouTube Shorts will help millions of people realize their creative vision]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Cost of Modeling]]></title>
        <id>https://www.argmin.net/p/the-cost-of-modeling</id>
        <link href="https://www.argmin.net/p/the-cost-of-modeling"/>
        <updated>2024-09-18T14:06:25.000Z</updated>
        <summary type="html"><![CDATA[On the abstraction boundary between mathematical optimization problems and what they model.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Cost of Modeling]]></title>
        <id>https://www.argmin.net/p/the-cost-of-modeling</id>
        <link href="https://www.argmin.net/p/the-cost-of-modeling"/>
        <updated>2024-09-18T14:06:25.000Z</updated>
        <summary type="html"><![CDATA[On the abstraction boundary between mathematical optimization problems and what they model.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI-based DeepL is different]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66049</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66049&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-based-deepl-is-different"/>
        <updated>2024-09-18T11:48:27.000Z</updated>
        <summary type="html"><![CDATA[So says DeepL CEO Jarek Kutylowski. "DeepL translation targets Taiwan as next key Asian market:  CEO says AI-based model is aiming to refine nuances, politeness", Steven Borowiec, Nikkei staff writer (September 16, 2024) DeepL Write is one thing, DeepL Translator is another.  We've examined both on Language Log and are aware that the former is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Challenges and Efforts in PyTorch Multi-Device Integration: Compatibility, Portability, and Integration Efficiencies]]></title>
        <id>https://pytorch.org/blog/pt-multidevice-integration/</id>
        <link href="https://pytorch.org/blog/pt-multidevice-integration/"/>
        <updated>2024-09-18T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Introduction]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[less bats, higher mortality]]></title>
        <id>http://xianblog.wordpress.com/?p=57490</id>
        <link href="https://xianblog.wordpress.com/2024/09/18/less-bats-higher-mortality/"/>
        <updated>2024-09-17T22:24:46.000Z</updated>
        <summary type="html"><![CDATA[“…farmers compensated for bat decline by increasing their insecticide use by 31.1%. The compensatory increase in insecticide use by farmers adversely affected health—human infant mortality increased by 7.9% in the counties that experienced bat die-offs.” Eyal G. Frank A Science article by Eyal Frank got a lot of press last week for linking US bat […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Declarative Mathematical Programming]]></title>
        <id>https://www.argmin.net/p/declarative-mathematical-programming</id>
        <link href="https://www.argmin.net/p/declarative-mathematical-programming"/>
        <updated>2024-09-17T14:34:07.000Z</updated>
        <summary type="html"><![CDATA[When the output is more important than the model]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Declarative Mathematical Programming]]></title>
        <id>https://www.argmin.net/p/declarative-mathematical-programming</id>
        <link href="https://www.argmin.net/p/declarative-mathematical-programming"/>
        <updated>2024-09-17T14:34:07.000Z</updated>
        <summary type="html"><![CDATA[When the output is more important than the model]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to say "AI" in Mandarin]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66028</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66028&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-say-ai-in-mandarin"/>
        <updated>2024-09-17T13:00:46.000Z</updated>
        <summary type="html"><![CDATA[An eminent Chinese historian just sent these two sentences to me: Yǒurén shuō AI zhǐ néng jìsuàn, ér rénlèi néng suànjì. Yīncǐ AI yīdìng bùshì rénlèi duìshǒ 有人說AI只能計算，而人類能算計。因此AI一定不是人類對手。 "Some people say that AI can only calculate, while humans can compute.  Therefore, AI must not be a match for humans". Google Translate, Baidu Fanyi, and Bing […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What did Rich Lowry say?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66030</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66030&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=what-did-rich-lowry-say"/>
        <updated>2024-09-17T10:33:49.000Z</updated>
        <summary type="html"><![CDATA[Yesterday, Alejandra Caraballo tweeted: The editor in chief of the National Review just said the N word in regards to Haitians and Megyn Kelly ignores it. Andy McCarthy responded: Ridiculous. @richlowry (not tagged here, natch) obviously got crossed up between 'immigrants' (short i) and migrants (long i) — started mispronouncing "migrants" with short i; instantly corrected himself […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[one year with no school]]></title>
        <id>http://xianblog.wordpress.com/?p=57504</id>
        <link href="https://xianblog.wordpress.com/2024/09/17/one-year-with-no-school/"/>
        <updated>2024-09-16T22:24:54.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The City of Angels in Latin]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65933</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65933&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-city-of-angels-in-latin"/>
        <updated>2024-09-16T16:07:09.000Z</updated>
        <summary type="html"><![CDATA["The Best New Book Written Entirely in Latin You’ll Try to Read This Year:  Why Donatien Grau, an adviser at the Louvre, decided to write 'De Civitate Angelorum,' a book about Los Angeles, the Roman way."  By Fergus McIntosh, New Yorker (September 16, 2024) Since even elite schools like Penn and Princeton no longer have […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Let's build and optimize a Rust extension for Python]]></title>
        <id>https://pythonspeed.com/articles/intro-rust-python-extensions/</id>
        <link href="https://pythonspeed.com/articles/intro-rust-python-extensions/"/>
        <updated>2024-09-16T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[If your Python code isn’t fast enough, you have many options for compiled languages to write a faster extension.
In this article we’ll focus on Rust, which benefits from:
Modern tooling, including a package repository called crates.io, and built-in build tool (cargo).
Excellent Python integration and tooling.
The Rust package (they’re known as “crates”) for Python support is PyO3.
For packaging you can use setuptools-rust, for integration with existing setuptools projects, or for standalone extensions you can use Maturin.
Memory- and thread-safe, so it’s much less prone to crashes or memory corruption compared to C and C++.
In particular, we’ll:
Implement a small algorithm in Python.
Re-implement it as a Rust extension.
Optimize the Rust version so it runs faster.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[“Weak point; holler louder!”]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66017</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66017&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=weak-point-holler-louder"/>
        <updated>2024-09-15T23:20:41.000Z</updated>
        <summary type="html"><![CDATA[My debate analysis for The Economist included these charts: : …with the commentary The final charts show the average pitches of the two candidates and their variability within each speaking turn (which can be a rough proxy for emotional arousal). Both candidates start at a lower average pitch and with lower variability, before showing a […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[arX’ig!]]></title>
        <id>http://xianblog.wordpress.com/?p=57514</id>
        <link href="https://xianblog.wordpress.com/2024/09/16/arxig/"/>
        <updated>2024-09-15T22:24:25.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trump as brass: score]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=66001</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=66001&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=trump-as-brass-score"/>
        <updated>2024-09-15T15:23:46.000Z</updated>
        <summary type="html"><![CDATA[Following up on "Trump as brass", I was curious about the relationship between the spoken pitch track and the score that Jase used to generate the trombone sounds. Here's his Xeet again, showing his score and playing his trombone synthesis overlaid on Trump's audio: Donald Trump's 'Eating The Dogs' transcribed for trombone. pic.twitter.com/UpK4hNjNuR — The […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trump as brass]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65992</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65992&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=trump-as-brass"/>
        <updated>2024-09-15T12:12:26.000Z</updated>
        <summary type="html"><![CDATA[Trombone, specifically: Donald Trump's 'Eating The Dogs' transcribed for trombone. pic.twitter.com/UpK4hNjNuR — The Jase (@jasemonkey) September 11, 2024 See also: For those people asking for a fretless bass version… pic.twitter.com/xBCpSZoNZz — The Jase (@jasemonkey) September 11, 2024 Some relevant past posts: "Poem in the key of what", 10/9/2006 "More on pitch and time intervals in […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[低秩近似之路（一）：伪逆]]></title>
        <id>https://kexue.fm/archives/10366</id>
        <link href="https://kexue.fm/archives/10366"/>
        <updated>2024-09-15T08:53:00.000Z</updated>
        <summary type="html"><![CDATA[可能很多读者跟笔者一样，对矩阵的低秩近似有种熟悉而又陌生的感觉。熟悉是因为，低秩近似的概念和意义都不难理解，加之目前诸如LoRA等基于低秩近似的微调技术遍地开花，让低秩近似的概念在耳濡目染间就已...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pictures from Our 2024 Annual Meeting of the Israel Mathematical Union and Student Day]]></title>
        <id>http://gilkalai.wordpress.com/?p=26795</id>
        <link href="https://gilkalai.wordpress.com/2024/09/15/pictures-from-our-2024-annual-meeting-of-the-israel-mathematical-union-and-student-day/"/>
        <updated>2024-09-15T06:08:57.000Z</updated>
        <summary type="html"><![CDATA[To me and to many mathematicians in Israel, the Annual meeting of the Israeli Mathematical Union is a dear event and we try to take part. (Here we briefly described the 2017 meeting in Acre, and here the 2014 meeting … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pictures from Our 2024 Annual Meeting of the Israel Mathematical Union and Student Day]]></title>
        <id>http://gilkalai.wordpress.com/?p=26795</id>
        <link href="https://gilkalai.wordpress.com/2024/09/15/pictures-from-our-2024-annual-meeting-of-the-israel-mathematical-union-and-student-day/"/>
        <updated>2024-09-15T06:08:57.000Z</updated>
        <summary type="html"><![CDATA[To me and to many mathematicians in Israel, the Annual meeting of the Israeli Mathematical Union is a dear event and we try to take part. (Here we briefly described the 2017 meeting in Acre, and here the 2014 meeting … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nature snapshots]]></title>
        <id>http://xianblog.wordpress.com/?p=57453</id>
        <link href="https://xianblog.wordpress.com/2024/09/15/nature-snapshots-5/"/>
        <updated>2024-09-14T22:24:40.000Z</updated>
        <summary type="html"><![CDATA[Some quick breakfast reads from the 15 August issue of Nature , the incredible discovery that the massive slabs of Stonehenge were transported from Scotland, 800km North. Reuniting with the Round Table legend that Merlin brought them from Ireland. (Through a Kolmogorov-Smirnov test (!) not rejecting the null that the age distributions of the altar […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s 59 [blue wave#13]]]></title>
        <id>http://xianblog.wordpress.com/?p=57482</id>
        <link href="https://xianblog.wordpress.com/2024/09/14/oceans-59-blue-wave13/"/>
        <updated>2024-09-14T12:14:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["We Await Silent Tristero's Empire"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65977</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65977&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=we-await-silent-tristeros-empire"/>
        <updated>2024-09-14T10:01:04.000Z</updated>
        <summary type="html"><![CDATA[Abbie VanSickle and Philip Kaleta, "Conservative German Princess Says She Hosted Justice Alito at Her Castle", NYT 9/9/2024: An eccentric German princess who evolved from a 1980s punk style icon to a conservative Catholic known for hobnobbing with far-right figures said on Monday that she hosted Justice Samuel A. Alito Jr. and his wife at […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[French Horn Church]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65913</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65913&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=french-horn-church"/>
        <updated>2024-09-14T02:10:36.000Z</updated>
        <summary type="html"><![CDATA[Mark Swofford stumbled upon this church in Taipei: The Chinese part of the sign reads: fàguó hào língliáng táng 法國號靈糧堂 "French Horn Hall of Spiritual Food" This may be a branch of Táiběi língliáng táng 台北靈糧堂, which calls itself "Bread of Life Christian Church in Taipei" and has a history that goes back to 1948-1958 in Shanghai.  […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[celebrating Ivar Ekeland⁸⁰ (24-25 Sept)]]></title>
        <id>http://xianblog.wordpress.com/?p=57334</id>
        <link href="https://xianblog.wordpress.com/2024/09/14/celebrating-ivar-ekeland-24-25-sept/"/>
        <updated>2024-09-13T22:24:33.000Z</updated>
        <summary type="html"><![CDATA[Next week, our lab (CEREMADE) is celebrating the 80th birthday of our friend and colleague Ivar Ekeland with two days of talks and chats. (Registration is free.) Ivar is a leading figure in nonlinear functional analysis, calculus of variations, and mathematical economics. But also a moral beacon for many of us! He was the chairman […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is there a finite number of pronunciations for anything?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65960</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65960&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=is-there-a-finite-number-of-pronunciations-for-anything"/>
        <updated>2024-09-13T16:05:53.000Z</updated>
        <summary type="html"><![CDATA[Below is a guest post by Corey Miller. Azi Paybarah of the Washington Post quoted Trump as follows: “There’s about 19 different ways of pronouncing it, right,” Trump said falsely, during a speech in Michigan on Thursday. “But Kamala is, at least it’s a name you sort of remember.” The most interesting part of this […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Bone Apple Tea"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65972</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65972&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bone-apple-tea"/>
        <updated>2024-09-13T15:47:06.000Z</updated>
        <summary type="html"><![CDATA[The "ABOUT COMMUNITY" description from r/BoneAppleTea: There's also r/BoneAppleTypo, and the #boneappletea Discord channel. [h/t M.O.S.T.]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Doesn't Mean Easy]]></title>
        <id>https://www.argmin.net/p/linear-doesnt-mean-easy</id>
        <link href="https://www.argmin.net/p/linear-doesnt-mean-easy"/>
        <updated>2024-09-13T14:36:06.000Z</updated>
        <summary type="html"><![CDATA[Applied linear algebra is much harder than advertised.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Doesn't Mean Easy]]></title>
        <id>https://www.argmin.net/p/linear-doesnt-mean-easy</id>
        <link href="https://www.argmin.net/p/linear-doesnt-mean-easy"/>
        <updated>2024-09-13T14:36:06.000Z</updated>
        <summary type="html"><![CDATA[Applied linear algebra is much harder than advertised.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s goals [blue wave#12]]]></title>
        <id>http://xianblog.wordpress.com/?p=57474</id>
        <link href="https://xianblog.wordpress.com/2024/09/13/oceans-missing-003-seconds-blue-wave12/"/>
        <updated>2024-09-13T10:24:23.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[mostly MCMC’s back]]></title>
        <id>http://xianblog.wordpress.com/?p=57510</id>
        <link href="https://xianblog.wordpress.com/2024/09/13/mostly-mcmcs-back/"/>
        <updated>2024-09-12T22:24:11.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Programming Fail]]></title>
        <id>https://www.jeremykun.com/shortform/2024-09-12-1502/</id>
        <link href="https://www.jeremykun.com/shortform/2024-09-12-1502/"/>
        <updated>2024-09-12T22:02:05.000Z</updated>
        <summary type="html"><![CDATA[This is a story about a failure to apply dynamic programming to a woodworking project.
I’ve been building a shed in my backyard, and for one section I decided to build the floor by laying 2x4 planks side by side. I didn’t feel the need to join them with tongue-and-groove, but I did notice that using 2x4s alone wouldn’t fit the width they were supposed to fill.
I also had some 2x6 boards left over from a different part of the shed, and I realized that gave a neat dynamic programming problem: Can you fill a given width by laying planks of standard dimensional lumber?]]></summary>
        <author>
            <name>Math ∩ Programming</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stretching the Definitions]]></title>
        <id>https://www.argmin.net/p/stretching-the-definitions</id>
        <link href="https://www.argmin.net/p/stretching-the-definitions"/>
        <updated>2024-09-12T14:19:32.000Z</updated>
        <summary type="html"><![CDATA[Some problems aren't convex but are close enough.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stretching the Definitions]]></title>
        <id>https://www.argmin.net/p/stretching-the-definitions</id>
        <link href="https://www.argmin.net/p/stretching-the-definitions"/>
        <updated>2024-09-12T14:19:32.000Z</updated>
        <summary type="html"><![CDATA[Some problems aren't convex but are close enough.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Our latest advances in robot dexterity]]></title>
        <id>https://deepmind.google/discover/blog/advances-in-robot-dexterity/</id>
        <link href="https://deepmind.google/discover/blog/advances-in-robot-dexterity/"/>
        <updated>2024-09-12T14:00:05.000Z</updated>
        <summary type="html"><![CDATA[Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s missing .003 seconds [blue wave#11]]]></title>
        <id>http://xianblog.wordpress.com/?p=57467</id>
        <link href="https://xianblog.wordpress.com/2024/09/12/oceans-missing-003-seconds-blue-wave11/"/>
        <updated>2024-09-12T10:24:26.000Z</updated>
        <summary type="html"><![CDATA[3/100]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arm Joins the PyTorch Foundation as a Premier Member]]></title>
        <id>https://pytorch.org/blog/arm-joins-pytorch/</id>
        <link href="https://pytorch.org/blog/arm-joins-pytorch/"/>
        <updated>2024-09-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[The PyTorch Foundation, a neutral home for the deep learning community to collaborate on the open source PyTorch framework and ecosystem, is announcing today that Arm has joined as a premier member.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When should you upgrade to Python 3.13?]]></title>
        <id>https://pythonspeed.com/articles/upgrade-python-3.13/</id>
        <link href="https://pythonspeed.com/articles/upgrade-python-3.13/"/>
        <updated>2024-09-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Python 3.13 will be out October 1, 2024—but should you switch to it immediately?
And if you shouldn’t upgrade just yet, when should you?
Immediately after the release, you probably didn’t want to upgrade just yet.
But from December 2024 and onwards, upgrading is definitely worth trying, though it may not succeed.
To understand why, we need to consider Python packaging, the software development process, and take a look at the history of past releases.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[It's time to stop using Python 3.8]]></title>
        <id>https://pythonspeed.com/articles/stop-using-python-3.8/</id>
        <link href="https://pythonspeed.com/articles/stop-using-python-3.8/"/>
        <updated>2024-09-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Upgrading to new software versions is work, and work that doesn’t benefit your software’s users.
Users care about features and bug fixes, not how up-to-date you are.
So it’s perhaps not surprising how many people still use Python 3.8.
As of September 2024, about 14% of packages downloaded from PyPI were for Python 3.8.
This includes automated downloads as part of CI runs, so it doesn’t mean 3.8 is used in 14% of applications, but that’s still 250 million packages installed in a single day!
Still, there is only so much time you can delay upgrading, and for Python 3.8, the time to upgrade is as soon as possible.
Python 3.8 is reaching its end of life at the end of October 2024.
No more bug fixes.
No more security fixes.
“He’s dead, Jim.”
Still not convinced? Let’s see why you want to upgrade.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantifying the debate]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65935</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65935&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=quantifying-the-debate"/>
        <updated>2024-09-11T23:41:51.000Z</updated>
        <summary type="html"><![CDATA[Following up on "Type-token plots in The Economist" (9/6/2024), I lost some sleep last night doing some analyses of the presidential debate, which I shared with writers at The Economist to be published as "An alternative look at the Trump-Harris debate, in five charts",  9/11/2024. They lead with another type-token graph: One of their other […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[free Paul Watson]]></title>
        <id>http://xianblog.wordpress.com/?p=57448</id>
        <link href="https://xianblog.wordpress.com/2024/09/12/free-paul-watson/"/>
        <updated>2024-09-11T22:24:29.000Z</updated>
        <summary type="html"><![CDATA[f]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An introduction to the curiously recurring template pattern]]></title>
        <id>https://parsiad.ca/blog/2024/an_introduction_to_the_curiously_recurring_template_pattern/</id>
        <link href="https://parsiad.ca/blog/2024/an_introduction_to_the_curiously_recurring_template_pattern/"/>
        <updated>2024-09-11T17:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yet again the Voynich manuscript]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65930</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65930&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=yet-again-the-voynich-manuscript"/>
        <updated>2024-09-11T16:32:18.000Z</updated>
        <summary type="html"><![CDATA[Perhaps as early as 1640, decipherers have tried practically everything to decode the maddeningly frustrating Voynich manuscript.  So far it has resisted all efforts to identify the language in which it was presumably written.  About the only way to make further progress in cracking the code is to apply some new technology.  As described in […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Guardian on [and on and on] Grothendieck]]></title>
        <id>http://xianblog.wordpress.com/?p=57389</id>
        <link href="https://xianblog.wordpress.com/2024/09/11/the-guardian-on-and-on-and-on-grothendieck/"/>
        <updated>2024-09-10T22:24:00.000Z</updated>
        <summary type="html"><![CDATA[A very looong piece in The Guardian of 31 August relates the life and achievements of Grothendieck in a highly romanticized way, hinting at hidden secrets contained in the tens of thousands of pages he wrote during his 26 years of retirement in Lasserre, Pyrénées… (Even when acknowledging that Grothendieck’s life and personality are providing […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Functional modeling]]></title>
        <id>https://www.argmin.net/p/functional-modeling</id>
        <link href="https://www.argmin.net/p/functional-modeling"/>
        <updated>2024-09-10T14:30:27.000Z</updated>
        <summary type="html"><![CDATA[The inevitability of convexity in local search]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Functional modeling]]></title>
        <id>https://www.argmin.net/p/functional-modeling</id>
        <link href="https://www.argmin.net/p/functional-modeling"/>
        <updated>2024-09-10T14:30:27.000Z</updated>
        <summary type="html"><![CDATA[The inevitability of convexity in local search]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s three [blue wave#10]]]></title>
        <id>http://xianblog.wordpress.com/?p=57462</id>
        <link href="https://xianblog.wordpress.com/2024/09/10/oceans-three-blue-wave10/"/>
        <updated>2024-09-10T10:24:37.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mountain King [82, 19d, 4000m, 75000m, 1200km, &c]]]></title>
        <id>http://xianblog.wordpress.com/?p=57369</id>
        <link href="https://xianblog.wordpress.com/2024/09/10/57369/"/>
        <updated>2024-09-09T22:24:42.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Word salad"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65902</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65902&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=word-salad"/>
        <updated>2024-09-09T13:52:40.000Z</updated>
        <summary type="html"><![CDATA[According to Wikipedia, a word salad is a "confused or unintelligible mixture of seemingly random words and phrases", most often used to describe a symptom of a neurological or mental disorder. The name schizophasia is used in particular to describe the confused language that may be evident in schizophrenia. The words may or may not […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Welcome in!"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65880</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65880&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=welcome-in"/>
        <updated>2024-09-09T13:23:04.000Z</updated>
        <summary type="html"><![CDATA[I'm in the little (population about two hundred) town of Wamsutter in southwest Wyoming.  It's just west of the Continental Divide and bills itself as "The Gateway to the Red Desert".  It is the largest settlement, and the only incorporated town in the Great Divide Basin. The name Wamsutter is intriguing, but it doesn't sound […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[feminicide of a marathoner [Rebecca Cheptegei, 1991-2024]]]></title>
        <id>http://xianblog.wordpress.com/?p=57422</id>
        <link href="https://xianblog.wordpress.com/2024/09/09/feminicide-of-a-marathoner-rebecca-cheptegei-1991-2024/"/>
        <updated>2024-09-09T10:24:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["The Truth About English Grammar"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65896</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65896&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-truth-about-english-grammar"/>
        <updated>2024-09-08T22:36:21.000Z</updated>
        <summary type="html"><![CDATA[It's past time for me to feature Geoff Pullum's new book, The Truth About English Grammar. The publisher's blurb: Do you worry that your understanding of English grammar isn’t what it should be? It may not be your fault. For hundreds of years, vague and confused ideas about how to state the rules have been […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mountain Queen]]></title>
        <id>http://xianblog.wordpress.com/?p=56921</id>
        <link href="https://xianblog.wordpress.com/2024/09/09/mountain-queen/"/>
        <updated>2024-09-08T22:24:50.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["…X, let's say Y…"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65883</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65883&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=x-lets-say-y"/>
        <updated>2024-09-08T11:12:15.000Z</updated>
        <summary type="html"><![CDATA[Justin Weinberg, "Analytic Philosophy's Best Unintentional (?) Self-Parodying", Daily Nous 9/6/2024: “Someone, let’s say a baby, is born; his parents call him by a certain name.” That line–recently circulated on social media by Eric Winsberg (South Florida / Cambridge) as “the funniest sentence in the history of philosophy”—is from Saul Kripke‘s Naming and Necessity. I’m […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s day of plenty [blue wave#9]]]></title>
        <id>http://xianblog.wordpress.com/?p=57418</id>
        <link href="https://xianblog.wordpress.com/2024/09/08/oceans-day-of-plenty-blue-wave9/"/>
        <updated>2024-09-08T10:24:35.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch Shanghai Meetup Notes]]></title>
        <id>https://pytorch.org/blog/pytorch-shanghai-notes/</id>
        <link href="https://pytorch.org/blog/pytorch-shanghai-notes/"/>
        <updated>2024-09-08T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Summary]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Berber, emic vs. etic]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65864</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65864&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=berber-emic-vs-etic"/>
        <updated>2024-09-08T02:56:49.000Z</updated>
        <summary type="html"><![CDATA[My mental image of Berbers is one of brave, noble people of the Maghreb (western and central North Africa, comprising Algeria, Libya, Mauritania, Morocco, and Tunisia) who were there before the advent of the Arabs, whose migration into the region took place largely in the 7th and later centuries.  As happened in Southeast Asia (including […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Am Burg Gleiberg [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=57287</id>
        <link href="https://xianblog.wordpress.com/2024/09/08/am-burg-gleiberg-jatp/"/>
        <updated>2024-09-07T22:24:01.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s double [blue wave#8]]]></title>
        <id>http://xianblog.wordpress.com/?p=57399</id>
        <link href="https://xianblog.wordpress.com/2024/09/07/oceans-double-blue-wave9/"/>
        <updated>2024-09-07T10:24:09.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the Pacific and Northwest tƿēnight]]></title>
        <id>http://xianblog.wordpress.com/?p=56923</id>
        <link href="https://xianblog.wordpress.com/2024/09/07/a-journal-of-the-pacific-and-northwest-t%c6%bfenight/"/>
        <updated>2024-09-06T22:24:16.000Z</updated>
        <summary type="html"><![CDATA[Read both the first (1605) and the second (1615) books of Don Quixote along with the (William) Marx commentary (Un été avec Don Quichotte) over the PNW vacations, a delight in discovering how modern it is! Even modern enough to write a follow-up (II) and to initiate the meme that sequels are not as good […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Packing Matrix-Vector Multiplication in Fully Homomorphic Encryption]]></title>
        <id>https://www.jeremykun.com/2024/09/06/packing-matrix-vector-multiplication-in-fhe/</id>
        <link href="https://www.jeremykun.com/2024/09/06/packing-matrix-vector-multiplication-in-fhe/"/>
        <updated>2024-09-06T21:18:09.000Z</updated>
        <summary type="html"><![CDATA[In my recent overview of homomorphic encryption, I underemphasized the importance of data layout when working with arithmetic (SIMD-style) homomorphic encryption schemes. In the FHE world, the name given to data layout strategies is called “packing,” because it revolves around putting multiple plaintext data into RLWE ciphertexts in carefully-chosen ways that mesh well with the operations you’d like to perform. By “mesh well” I mean it reduces the number of extra multiplications and rotations required merely to align data elements properly, rather than doing the actual computation you care about.]]></summary>
        <author>
            <name>Math ∩ Programming</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Type-token plots in The Economist]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65873</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65873&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=type-token-plots-in-the-economist"/>
        <updated>2024-09-06T18:30:14.000Z</updated>
        <summary type="html"><![CDATA[From "The Harris-Trump debate will be a clash of speaking styles", The Economist 9/6/2024: The Economist's article covers some other easily-quantifiable aspects of political rhetoric, but this afternoon I'll focus on the type-token plots, since this an an especially consistent aspect of Donald Trump in comparison to other politicians: "Political vocabulary display", 9/10/2015 "Vocabulary display […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[China flavor]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65850</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65850&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=china-flavor"/>
        <updated>2024-09-06T15:45:37.000Z</updated>
        <summary type="html"><![CDATA[I’m still trying to figure out, in XJP rhetoric, when 中华 is used and when it’s 中国. How long has Zhongguo been used directly as an adjective this way, as opposed to 中国似的or 中国性？Is a 中国味different from a 中华味？Which smells better? pic.twitter.com/9CARnICZSu — James Millward 米華健 (@JimMillward) September 4, 2024 For non-specialists to understand this […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Degrees of Separation]]></title>
        <id>https://www.argmin.net/p/degrees-of-separation</id>
        <link href="https://www.argmin.net/p/degrees-of-separation"/>
        <updated>2024-09-06T13:59:50.000Z</updated>
        <summary type="html"><![CDATA[Separating hyperplanes and geometric proofs]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Degrees of Separation]]></title>
        <id>https://www.argmin.net/p/degrees-of-separation</id>
        <link href="https://www.argmin.net/p/degrees-of-separation"/>
        <updated>2024-09-06T13:59:50.000Z</updated>
        <summary type="html"><![CDATA[Separating hyperplanes and geometric proofs]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Where weave is from]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65847</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65847&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=where-weave-is-from"/>
        <updated>2024-09-06T11:19:41.000Z</updated>
        <summary type="html"><![CDATA[In a comment on "Trump's rhetorical 'weave'", J.R. Brewer wrote: This thread has had the side effect of causing me to learn (at least taking wiktionary at face value and not digging deeper into other reference sources) that the "weave" of "bob and weave" etc. is a homophone etymologically unrelated to the "weave" meaning "create […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s boccia [blue wave#7]]]></title>
        <id>http://xianblog.wordpress.com/?p=57384</id>
        <link href="https://xianblog.wordpress.com/2024/09/06/oceans-bad-blue-wave7/"/>
        <updated>2024-09-06T10:24:33.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[“闭门造车”之多模态思路浅谈（三）：位置编码]]></title>
        <id>https://kexue.fm/archives/10352</id>
        <link href="https://kexue.fm/archives/10352"/>
        <updated>2024-09-06T09:57:00.000Z</updated>
        <summary type="html"><![CDATA[在前面的文章中，我们曾表达过这样的观点：多模态LLM相比纯文本LLM的主要差异在于，前者甚至还没有形成一个公认为标准的方法论。这里的方法论，不仅包括之前讨论的生成和训练策略，还包括一些基础架构的...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two Events]]></title>
        <id>http://gilkalai.wordpress.com/?p=26768</id>
        <link href="https://gilkalai.wordpress.com/2024/09/06/two-events/"/>
        <updated>2024-09-06T07:36:33.000Z</updated>
        <summary type="html"><![CDATA[Israeli Mathematical Union annual meeting and student talks day, Sunday and Monday, September 8 – 9, 2024. The Annual meeting of the Israeli Mathematical Union will be held on Sunday, September 8th 2024 at the Weizmann Institute. The main speakers … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two Events]]></title>
        <id>http://gilkalai.wordpress.com/?p=26768</id>
        <link href="https://gilkalai.wordpress.com/2024/09/06/two-events/"/>
        <updated>2024-09-06T07:36:33.000Z</updated>
        <summary type="html"><![CDATA[Israeli Mathematical Union annual meeting and student talks day, Sunday and Monday, September 8 – 9, 2024. The Annual meeting of the Israeli Mathematical Union will be held on Sunday, September 8th 2024 at the Weizmann Institute. The main speakers … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[German linguist Möllendorff and the earliest recordings of Chinese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65845</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65845&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=german-linguist-mollendorff-and-the-earliest-recordings-of-chinese"/>
        <updated>2024-09-06T01:54:05.000Z</updated>
        <summary type="html"><![CDATA["UCSB Library Acquires Rare Chinese Language Audio Cylinder Recordings", UCSB Library Newsletter (September, 2024) The UC Santa Barbara Library is excited to announce the recent acquisition of the Paul Georg von Möllendorff Chinese Cylinders, a collection of wax cylinders widely considered to be the first audio recordings from China. The cylinders, recorded in the late […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[my neighbour who invented the gradient descent from the top of his hill]]></title>
        <id>http://xianblog.wordpress.com/?p=57254</id>
        <link href="https://xianblog.wordpress.com/2024/09/06/my-neighbour-who-invented-the-gradient-descent-from-the-top-of-his-hill/"/>
        <updated>2024-09-05T22:24:27.000Z</updated>
        <summary type="html"><![CDATA[“It will suffice therefore, either to resolved this last equation, or at least to attribute to θ a sufficiently small value, in order to obtain a new value of u inferior to u. If the new value of u is not a minimum, one will be able to deduce, by operating always in the same […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EditPlus 的配置方法]]></title>
        <id>https://www.skywind.me/blog/?p=2828</id>
        <link href="https://skywind.me/blog/archives/2828"/>
        <updated>2024-09-05T15:05:00.000Z</updated>
        <summary type="html"><![CDATA[作为一名编辑器爱好者，EditPlus 是我最喜欢的编辑器之一，超过 NotePad++，它启动速度比它快，打开文件比它快，功能比它强，颜值也比它高，但大小只有 2MB： 用了这么多年，我感觉我欠 EditPlus 一篇文章，介绍一下我平时是如何是用 EditPlus 搭建开发环境的，以及如何让它变得更好用： （点击 more/continue 展开） 先配置下 GCC 的工具，选择主菜单 Tools-> Configure User Tools： 然后点右边按钮 “Add Tool” 并选择 “Program”，然后在下面填空： Menu text: Execute Program Command: C:\Windows\system32\cmd.exe Argument: /C "$(FileNameNoExt)" Initial directory: $(FileDir) 这些形如 $(FileDir) 之类的宏不用死记，点输入框右边的下箭头按钮，就能弹出菜单，让你选择后自动插入： 配置好以后，点下方 … Continue reading →
The post EditPlus 的配置方法 appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EditPlus 的配置方法]]></title>
        <id>https://www.skywind.me/blog/?p=2828</id>
        <link href="https://www.skywind.me/blog/archives/2828"/>
        <updated>2024-09-05T15:05:00.000Z</updated>
        <summary type="html"><![CDATA[作为一名编辑器爱好者，EditPlus 是我最喜欢的编辑器之一，超过 NotePad++，它启动速度比它快，打开文件比它快，功能比它强，颜值也比它高，但大小只有 2MB： 不过要让它变得好用，能够方便开发，还需要做一些必要的设置，先配置下 GCC 的工具： （点击 more/continue 展开） 选择主菜单 Tools-> Configure User Tools： 然后点右边按钮 “Add Tool” 并选择 “Program”，然后在下面填空： Menu text: Execute Program Command: C:\Windows\system32\cmd.exe Argument: /C "$(FileNameNoExt)" Initial directory: $(FileDir) 这些形如 $(FileDir) 之类的宏不用死记，点输入框右边的下箭头按钮，就能弹出菜单，让你选择后自动插入： 配置好以后，点下方 “Apply” 按钮确定，这样我们多出一个工具来，按 Ctrl+1 运行当前 … Continue reading →
The post EditPlus 的配置方法 appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AlphaProteo generates novel proteins for biology and health research]]></title>
        <id>https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/</id>
        <link href="https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/"/>
        <updated>2024-09-05T15:00:00.000Z</updated>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Think global, act local]]></title>
        <id>https://www.argmin.net/p/think-global-act-local</id>
        <link href="https://www.argmin.net/p/think-global-act-local"/>
        <updated>2024-09-05T13:59:59.000Z</updated>
        <summary type="html"><![CDATA[If only direct action were convex.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Think global, act local]]></title>
        <id>https://www.argmin.net/p/think-global-act-local</id>
        <link href="https://www.argmin.net/p/think-global-act-local"/>
        <updated>2024-09-05T13:59:59.000Z</updated>
        <summary type="html"><![CDATA[If only direct action were convex.]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s bad [blue wave#6]]]></title>
        <id>http://xianblog.wordpress.com/?p=57381</id>
        <link href="https://xianblog.wordpress.com/2024/09/05/oceans-bad-blue-wave6/"/>
        <updated>2024-09-05T10:24:50.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Body wash]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65841</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65841&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=body-wash"/>
        <updated>2024-09-05T01:26:37.000Z</updated>
        <summary type="html"><![CDATA[The bottle of body wash affixed to the wall of the shower in the Cheyenne hotel where I'm staying is labeled in French as "Savon Liquide pour le Corps". English "body wash" is two words consisting of eight letters.  "Savon Liquide pour le Corps" is five words consisting of twenty-three letters. We've discussed the phenomenon […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nature snapshots]]></title>
        <id>http://xianblog.wordpress.com/?p=57269</id>
        <link href="https://xianblog.wordpress.com/2024/09/05/nature-snapshots-4/"/>
        <updated>2024-09-04T22:24:04.000Z</updated>
        <summary type="html"><![CDATA[Some quick breakfast reads from the 11 July issue of Nature (the one with the frog cover!), A tribune on the Canadian example of advocating for graduate and postdoc pay raises, with a success last April. It would prove difficult to achieve in a French academic landscape when postdocs here earn about as much as […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s tri bis [blue wave#5]]]></title>
        <id>http://xianblog.wordpress.com/?p=57359</id>
        <link href="https://xianblog.wordpress.com/2024/09/04/oceans-tri-bis-blue-wave5/"/>
        <updated>2024-09-04T10:24:39.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CUDA-Free Inference for LLMs]]></title>
        <id>https://pytorch.org/blog/cuda-free-inference-for-llms/</id>
        <link href="https://pytorch.org/blog/cuda-free-inference-for-llms/"/>
        <updated>2024-09-04T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[In this blog, we discuss the methods we used to achieve FP16 inference with popular LLM models such as Meta’s Llama3-8B and IBM’s Granite-8B Code, where 100% of the computation is performed using OpenAI’s Triton Language. For single token generation times using our Triton kernel based models, we were able to approach 0.76-0.78x performance relative to the CUDA kernel dominant workflows for both Llama and Granite on Nvidia H100 GPUs, and 0.62-0.82x on Nvidia A100 GPUs. Why explore using 100% Triton? Triton provides a path for enabling LLMs to run on different types of GPUs - NVIDIA, AMD, and in the future Intel and other GPU based accelerators. It also provides a higher layer of abstraction in Python for programming GPUs and has allowed us to write performant kernels faster than authoring them using vendor specific APIs. In the rest of this blog, we will share how we achieve CUDA-free compute, micro-benchmark individual kernels for comparison, and discuss how we can further improve future Triton kernels to close the gaps. Figure 1. Inference throughput benchmarks with Triton and CUDA variants of Llama3-8B and Granite-8B, on NVIDIA H100 and A100 Settings: batch size = 2, input sequence length = 512, output sequence length = 256 2.0 Composition of a Transformer Block We start with a breakdown of the computations that happen in Transformer-based models. The figure below shows the “kernels” of a typical Transformer block. Figure 2. Transformer Block by core kernels The core operations for a Llama3 architecture are summarized in this list: RMSNorm Matrix multiplication: Fused QKV RoPE Attention Matrix multiplication: Output Projection RMSNorm Matrix multiplication: Fused Gate + Up Projection Activation function: SiLU Element Wise Multiplication Matrix multiplication: Down Projection Each of these operations is computed on the GPU through the execution of one (or multiple) kernels. While the specifics of each of these kernels can vary across different transformer models, the core operations remain the same. For example, IBM’s Granite 8B Code model uses bias in the MLP layer, different from Llama3. Such changes do require modifications to the kernels. A typical model is a stack of these transformer blocks wired together with embedding layers. 3.0 Model Inference Typical model architecture code is shared with a python model.py file that is launched by PyTorch. In the default PyTorch eager execution mode, these kernels are all executed with CUDA. To achieve 100% Triton for end-to-end Llama3-8B and Granite-8B inference we need to write and integrate handwritten Triton kernels as well as leverage torch.compile (to generate Triton ops). First, we replace smaller ops with compiler generated Triton kernels, and second, we replace more expensive and complex computations (e.g. matrix multiplication and flash attention) with handwritten Triton kernels. Torch.compile generates Triton kernels automatically for RMSNorm, RoPE, SiLU and Element Wise Multiplication. Using tools like Nsight Systems we can observe these generated kernels; they appear as tiny dark green kernels in-between the matrix multiplications and attention. Figure 3. Trace of Llama3-8B with torch.compile, showing CUDA kernels being used for matrix multiplications and flash attention For the above trace, we note that the two major ops that make up 80% of the E2E latency in a Llama3-8B style model are matrix multiplication and attention kernels and both remain CUDA kernels. Thus to close the remaining gap, we replace both matmul and attention kernels with handwritten Triton kernels. 4.0 Triton SplitK GEMM Kernel For the matrix multiplications in the linear layers, we wrote a custom FP16 Triton GEMM (General Matrix-Matrix Multiply) kernel that leverages a SplitK work decomposition. We have previously discussed this parallelization in other blogs as a way to accelerate the decoding portion of LLM inference. 5.0 GEMM Kernel Tuning To achieve optimal performance we used the exhaustive search approach to tune our SplitK GEMM kernel. Granite-8B and Llama3-8B have linear layers with the following shapes: Linear Layer Shape (in_features, out_features) Fused QKV Projection (4096, 6144) Output Projection (4096, 4096) Fused Gate + Up Projection (4096, 28672) Down Projection (14336, 4096) Figure 4. Granite-8B and Llama3-8B Linear Layer Weight Matrix Shapes Each of these linear layers have different weight matrix shapes. Thus, for optimal performance the Triton kernel must be tuned for each of these shape profiles. After tuning for each linear layer we were able to achieve 1.20x E2E speedup on Llama3-8B and Granite-8B over the untuned Triton kernel. 6.0 Flash Attention Kernel We evaluated a suite of existing Triton flash attention kernels with different configurations, namely: AMD Flash OpenAI Flash Dao AI Lab Flash XFormers Flash PyTorch FlexAttention We evaluated the text generation quality of each of these kernels, first, in eager mode and then (if we were able to torch.compile the kernel with standard methods) compile mode. For kernels 2-5, we noted the following: Kernel Text Generation Quality Torch.compile Support for Arbitrary Sequence Length AMD Flash Coherent Yes Yes OpenAI Flash Incoherent Did not evaluate. WIP to debug precision in eager mode first No Dao AI Lab Flash Incoherent Did not evaluate. WIP to debug precision in eager mode first Yes Xformers FlashDecoding Hit a compilation error before we were able to evaluate text quality WIP No (This kernel is optimized for decoding) PyTorch FlexAttention Coherent WIP WIP Figure 5. Table of combinations we tried with different Flash Attention Kernels The above table summarizes what we observed out-of-the box. With some effort we expect that kernels 2-5 can be modified to meet the above criteria. However, this also shows that having a kernel that works for benchmarking is often only the start of having it usable as an end to end production kernel. We chose to use the AMD flash attention kernel in our subsequent tests as it can be compiled via torch.compile and produces legible output in both eager and compiled mode. To satisfy torch.compile compatibility with the AMD flash attention kernel, we had to define it as a torch custom operator. This process is explained in detail here. The tutorial link discusses how to wrap a simple image crop operation. However, we note that wrapping a more complex flash attention kernel follows a similar process. The two step approach is as follows: Wrap the function into a PyTorch Custom Operator Add a FakeTensor Kernel to the operator, which given the shapes of the input tensors of flash (q, k and v) provides a way to compute the output shape of the flash kernel After defining the Triton flash kernel as a custom op, we were able to successfully compile it for our E2E runs. Figure 6. Trace of Llama3-8B with torch.compile, after swapping in Triton matmul and Triton flash attention kernels From Figure 5, we note that now, after integrating both the SplitK matrix multiplication kernel, the torch op wrapped flash attention kernel, and then running torch.compile, we are able to achieve a forward pass that uses 100% Triton computation kernels. 7.0 End-to-End Benchmarks We performed end-to-end measurements on NVIDIA H100s and A100s (single GPU) with Granite-8B and Llama3-8B models. We performed our benchmarks with two different configurations. The Triton kernel configuration uses: Triton SplitK GEMM AMD Triton Flash Attention The CUDA Kernel configuration uses: cuBLAS GEMM cuDNN Flash Attention - Scaled Dot-Product Attention (SDPA) We found the following throughput and inter-token latencies for both eager and torch compiled modes, with typical inference settings: GPU Model Kernel Config Median Latency (Eager) [ms/tok] Median Latency (Compiled) [ms/tok] H100 Granite-8B Triton 27.42 11.59     CUDA 18.84 9.50   Llama3-8B Triton 20.36 10.61     CUDA 16.59 8.59 A100 Granite-8B Triton 53.44 16.88     CUDA 37.13 14.25   Llama3-8B Triton 44.44 17.94     CUDA 32.45 12.96 Figure 7. Granite-8B and Llama3-8B Single Token Generation Latency on H100 and A100, (batch size = 2, input sequence length = 512, output sequence length = 256) To summarize, the Triton models can get up to 78% of the performance of the CUDA models on the H100 and up to 82% on the A100. The performance gap can be explained by the kernel latencies we observe for matmul and flash attention, which are discussed in the next section. 8.0 Microbenchmarks Kernel Triton [us] CUDA [us] QKV Projection Matmul 25 21 Flash Attention 13 8 Output Projection Matmul 21 17 Gate + Up Projection Matmul 84 83 Down Projection Matmul 58 42 Figure 8. Triton and CUDA Kernel Latency Comparison (Llama3-8B on NVIDIA H100) Input was an arbitrary prompt (bs=1, prompt = 44 seq length), decoding latency time From the above, we note the following: Triton matmul kernels are 1.2-1.4x slower than CUDA AMDs Triton Flash Attention kernel is 1.6x slower than CUDA SDPA These results highlight the need to further improve the performance of kernels that are core primitives like GEMM and Flash Attention. We leave this as future research, as recent works (e.g. FlashAttention-3, FlexAttention) provide ways to leverage the underlying hardware better as well as Triton pathways that we hope to be able to build on to produce greater speedups. To illustrate this, we compared FlexAttention with SDPA and AMD’s Triton Flash kernel. We are working to verify E2E performance with FlexAttention. For now, initial microbenchmarks with Flex show promise for longer context lengths and decoding problem shapes, where the query vector is small: Figure 9. FlexAttention Kernel Benchmarks on NVIDIA H100 SXM5 80GB (batch=1, num_heads=32, seq_len=seq_len, head_dim=128) 9.0 Future Work For future work we plan to explore ways to further optimize our matmuls that leverage the hardware better, such as this blog we published on utilizing TMA for H100, as well as different work decompositions (persistent kernel techniques like StreamK etc.) to get greater speedups for our Triton-based approach. For flash attention, we plan to explore FlexAttention and FlashAttention-3 as the techniques used in these kernels can be leveraged to help further close the gap between Triton and CUDA. We also note that our prior work has shown promising results for FP8 Triton GEMM kernel performance versus cuBLAS FP8 GEMM, thus in a future post we will explore E2E FP8 LLM inference.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Australian government assessment of AI vs. human performance]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65807</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65807&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=australian-government-assessment-of-ai-vs-human-performance"/>
        <updated>2024-09-04T01:13:32.000Z</updated>
        <summary type="html"><![CDATA["AI worse than humans in every way at summarising information, government trial finds:A test of AI for Australia's corporate regulator found that the technology might actually make more work for people, not less."  Cam Wilson, Crikey (Sep 03, 2024) Artificial intelligence is worse than humans in every way at summarising documents and might actually create […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Faculty Position in [computational] Statistics at EPFL [reposted]]]></title>
        <id>http://xianblog.wordpress.com/?p=57363</id>
        <link href="https://xianblog.wordpress.com/2024/09/04/faculty-position-in-computational-statistics-at-epfl-reposted/"/>
        <updated>2024-09-03T22:24:43.000Z</updated>
        <summary type="html"><![CDATA[The School of Basic Sciences at EPFL is conducting an open-rank search for a Professor in Statistics. Appointment can be at the Tenure Track, Associate or Full Professor levels, depending on the qualifications of the successful applicant. We seek outstanding candidates with research interests in any domain of core statistical inference, including methodology, theory or […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Programmable convexity]]></title>
        <id>https://www.argmin.net/p/programmable-convexity</id>
        <link href="https://www.argmin.net/p/programmable-convexity"/>
        <updated>2024-09-03T14:00:57.000Z</updated>
        <summary type="html"><![CDATA[How to generate all convex sets with three simple tricks]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Programmable convexity]]></title>
        <id>https://www.argmin.net/p/programmable-convexity</id>
        <link href="https://www.argmin.net/p/programmable-convexity"/>
        <updated>2024-09-03T14:00:57.000Z</updated>
        <summary type="html"><![CDATA[How to generate all convex sets with three simple tricks]]></summary>
        <author>
            <name>Ben Recht</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test Your Intuition 56: Fifteen Boxes Puzzle]]></title>
        <id>http://gilkalai.wordpress.com/?p=26748</id>
        <link href="https://gilkalai.wordpress.com/2024/09/03/test-your-intuition-56-fifteen-boxes-puzzle/"/>
        <updated>2024-09-03T13:21:16.000Z</updated>
        <summary type="html"><![CDATA[Andrew and Barbara are playing a game. Fifteen boxes are arranged in a 3-by-5 grid, labeled with the letters A through O, as shown below. A B C D E F G H I J K L M N O … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test Your Intuition 56: Fifteen Boxes Puzzle]]></title>
        <id>http://gilkalai.wordpress.com/?p=26748</id>
        <link href="https://gilkalai.wordpress.com/2024/09/03/test-your-intuition-56-fifteen-boxes-puzzle/"/>
        <updated>2024-09-03T13:21:16.000Z</updated>
        <summary type="html"><![CDATA[Andrew and Barbara are playing a game. Fifteen boxes are arranged in a 3-by-5 grid, labeled with the letters A through O, as shown below. A B C D E F G H I J K L M N O … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trump's rhetorical "weave"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65814</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65814&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=trump-weaves"/>
        <updated>2024-09-03T11:32:39.000Z</updated>
        <summary type="html"><![CDATA[Shawn McCreesh, "Meandering? Off-Script? Trump Insists His ‘Weave’ Is Oratorical Genius." NYT 9/1/2024: For weeks, former President Donald J. Trump’s advisers have urged him to be more disciplined and to stop straying off-message. But on Friday, while speaking at a rally in Johnstown, Pa., Mr. Trump insisted that his oratory is not a campaign distraction […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s tri [blue wave#4]]]></title>
        <id>http://xianblog.wordpress.com/?p=57347</id>
        <link href="https://xianblog.wordpress.com/2024/09/03/oceans-tri-blue-wave4/"/>
        <updated>2024-09-03T10:24:51.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Portland murals [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=57207</id>
        <link href="https://xianblog.wordpress.com/2024/09/03/portland-murals-jatp/"/>
        <updated>2024-09-02T22:24:35.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shift Networks]]></title>
        <id>https://www.jeremykun.com/2024/09/02/shift-networks/</id>
        <link href="https://www.jeremykun.com/2024/09/02/shift-networks/"/>
        <updated>2024-09-02T21:01:03.000Z</updated>
        <summary type="html"><![CDATA[🌿 Budding: a relatively clean article which still needs additional tending.
In my recent overview of homomorphic encryption, I underemphasized the importance of data layout when working with arithmetic (SIMD-style) homomorphic encryption schemes. In the FHE world, the name given to data layout strategies is called “packing,” because it revolves around putting multiple plaintext data into RLWE ciphertexts in carefully-chosen ways that mesh well with the operations you’d like to perform.]]></summary>
        <author>
            <name>Math ∩ Programming</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Crab raccoon, part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65769</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65769&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=crab-raccoon-part-2"/>
        <updated>2024-09-02T17:09:19.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Meme Master Mark (MMM), who says he's honored that I call him that:  "3M is also from Minnesota" (see the first sentence).] Having spent many of my formative years in Minnesota, "crab raccoon" makes perfect sense. This was a pretty disturbing tattoo: And this one is sure to give […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[R squared and multiple regression]]></title>
        <id>https://parsiad.ca/blog/2024/r_squared_and_multiple_regression/</id>
        <link href="https://parsiad.ca/blog/2024/r_squared_and_multiple_regression/"/>
        <updated>2024-09-02T17:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[R squared and multiple regression]]></title>
        <id>https://parsiad.ca/blog/2024/r_squared_and_ordinary_least_squares/</id>
        <link href="https://parsiad.ca/blog/2024/r_squared_and_ordinary_least_squares/"/>
        <updated>2024-09-02T17:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CD4：Windows XP 开发宝典]]></title>
        <id>https://www.skywind.me/blog/?p=2808</id>
        <link href="https://skywind.me/blog/archives/2808"/>
        <updated>2024-09-02T15:05:00.000Z</updated>
        <summary type="html"><![CDATA[今天互联网上的内容，由于各种原因，正在以越来越快的速度消失，而习惯什么都从网上找的新一代网民们，却并没有备份和记录的习惯及意识。不远的将来，会有一天，当你特别想找某个工具却搜尽互联网你都找不到时，才会发现对珍贵资源做好收藏的必要性。 Windows XP 依然是一个完美的怀旧平台，它可以向后兼容到 Windows 95 的程序，是一个运行经典软件，玩经典游戏的完美方案。 图形界大佬 John Carmack 在推特上呼吁大家，现在应该有意识的保存你的开发环境，这样多年以后你想重新构建你的软件时才不会慌脚乱手，因为通常每过几年你常常会发现，自己之前的老代码已经没有合适的环境编译了： 本光盘包含了构建 Windows XP 程序所需要的必要工具，包括编译器，文本编辑器，集成开发环境和各种工具，他们全都能运行于 XP 下，并且能构建兼容 Windows XP 的项目。 制作原则：精选工具，断网可用，末日恢复，自包含无依赖，开发工具博物馆，帮你完全在 Windows XP 下工作，让你拥有 XP 下的沉浸式开发体验，容量却不超过一张 CD。 版权声明：本光碟采用 winworldpc.com 类似的版权声明，尽量收录开源或者不再销售的软件产品，目的是保护这些快绝版的资源。 光盘目录如下： 具体内容和下载地址见下文说明。 （点击 more 继续） 编译器（Compiler） 编译器的 Compiler 目录内包含以下几个工具： 目录内包含三套 … Continue reading →
The post CD4：Windows XP 开发宝典 appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CD4：Windows XP 开发宝典]]></title>
        <id>https://www.skywind.me/blog/?p=2808</id>
        <link href="https://www.skywind.me/blog/archives/2808"/>
        <updated>2024-09-02T15:05:00.000Z</updated>
        <summary type="html"><![CDATA[今天互联网上的内容，由于各种原因，正在以越来越快的速度消失，而习惯什么都从网上找的新一代网民们，却并没有备份和记录的习惯及意识。不远的将来，会有一天，当你特别想找某个工具却搜尽互联网你都找不到时，才会发现对珍贵资源做好收藏的必要性。 Windows XP 依然是一个完美的怀旧平台，它可以向后兼容到 Windows 95 的程序，是一个运行经典软件，玩经典游戏的完美方案。 图形界大佬 John Carmack 在推特上呼吁大家，现在应该有意识的保存你的开发环境，这样多年以后你想重新构建你的软件时才不会慌脚乱手，因为通常每过几年你常常会发现，自己之前的老代码已经没有合适的环境编译了： 本光盘包含了构建 Windows XP 程序所需要的必要工具，包括编译器，文本编辑器，集成开发环境和各种工具，他们全都能运行于 XP 下，并且能构建兼容 Windows XP 的项目。 制作原则：精选工具，断网可用，末日恢复，自包含无依赖，开发工具博物馆，帮你完全在 Windows XP 下工作，让你拥有 XP 下的沉浸式开发体验，容量却不超过一张 CD。 版权声明：本光碟采用 winworldpc.com 类似的版权声明，尽量收录开源或者不再销售的软件产品，目的是保护这些快绝版的资源。 光盘目录如下： （点击 more 继续） 编译器（Compiler） 编译器的 Compiler 目录内包含以下几个工具： 目录内包含三套 MinGW … Continue reading →
The post CD4：Windows XP 开发宝典 appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s hundred [blue wave#3]]]></title>
        <id>http://xianblog.wordpress.com/?p=57344</id>
        <link href="https://xianblog.wordpress.com/2024/09/02/oceans-hundred-blue-wave3/"/>
        <updated>2024-09-02T10:24:28.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Crab raccoon]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65703</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65703&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=crab-raccoon"/>
        <updated>2024-09-02T03:17:30.000Z</updated>
        <summary type="html"><![CDATA[From the menu of a Chinese restaurant in Eden Prairie, MN: Because they are printed in black against a dark background, it is difficult to read the Chinese characters for the name of the dish, which are right below the English name: sūzhà xièjiǎo 蘇炸蟹腳 "crispy fried crab legs" It's actually worse than you thought. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diffusion is spectral autoregression]]></title>
        <id>https://sander.ai/2024/09/02/spectral-autoregression.html</id>
        <link href="https://sander.ai/2024/09/02/spectral-autoregression.html"/>
        <updated>2024-09-01T23:00:00.000Z</updated>
        <summary type="html"><![CDATA[A deep dive into spectral analysis of diffusion models of images, revealing how they implicitly perform a form of autoregression in the frequency domain.]]></summary>
        <author>
            <name>Sander Dieleman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nature tidbits]]></title>
        <id>http://xianblog.wordpress.com/?p=57223</id>
        <link href="https://xianblog.wordpress.com/2024/09/02/nature-tidbits-4/"/>
        <updated>2024-09-01T22:24:48.000Z</updated>
        <summary type="html"><![CDATA[Going quickly through the four issues of Nature I found in my mailbox when returning from the Pacific Northwest, beyond the great picture of these frogs warming up, and fighting fungal infection, in the 11 July edition, a few (Sunday morn breakfast) quick reads from the 4 July 2024 edition: a “technology and tools” long […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transcription conventions]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65780</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65780&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=transcription-conventions"/>
        <updated>2024-09-01T16:26:30.000Z</updated>
        <summary type="html"><![CDATA[From Lane Greene on bluesky: This is an unusual transcript (of Harris/Walz by CNN), filled with "gonna", "wearin'", "I'll tell ya", "pulling outta the race". These things are ubiquitous in speech, but most transcribers would change these to "going to", "wearing", "I'll tell you", "out of". edition.cnn.com/2024/08/29/p… [image or embed] — Lane Greene (@lanegreene.bsky.social) Aug […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Japan's favorite aphorism about eggplants]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65744</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65744&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=japans-favorite-aphorism-about-eggplants"/>
        <updated>2024-09-01T14:16:00.000Z</updated>
        <summary type="html"><![CDATA["Japan’s autumn eggplant: Too delicious for your daughter-in-law"By Elizabeth Andoh, The Japan Times (Sep 1, 2024) Cooked properly, nothing beats an eggplant for succulence, softness, and savoriness.  It's so good that you almost want to keep it for yourself. In Japan, eggplants reach their peak of flavor during a period of time known as zansho […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Putin: "pollutant"? "pooch and"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65757</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65757&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=putin-pollutant-pooch-and"/>
        <updated>2024-09-01T13:31:32.000Z</updated>
        <summary type="html"><![CDATA[The transcriptions on YouTube are generally pretty good these days, but sometimes the results are weird. A notable recent example is the transcription of Donald Trump's 8/31/2024 Fox interview with Mark Levin, where the system renders "Putin" first as "pollutant" and then as "pooch and". The relevant audio clip, with my transcription: Your browser does […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Writing with AI]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65747</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65747&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=writing-with-ai"/>
        <updated>2024-09-01T11:28:36.000Z</updated>
        <summary type="html"><![CDATA[It's been clear for a while that "large language models" can be prompted to fulfill writing assignments, and that LLM detection doesn't work, and that "watermarking" won't come to the rescue. There's lots of on-going published discussion, and even more discussion in real life. As documented by the MLA-CCCC Joint Task Force on Writing and […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UTMB 2024]]></title>
        <id>http://xianblog.wordpress.com/?p=57328</id>
        <link href="https://xianblog.wordpress.com/2024/09/01/utmb-2024/"/>
        <updated>2024-09-01T10:24:15.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Decoder-only的LLM为什么需要位置编码？]]></title>
        <id>https://kexue.fm/archives/10347</id>
        <link href="https://kexue.fm/archives/10347"/>
        <updated>2024-09-01T07:09:00.000Z</updated>
        <summary type="html"><![CDATA[众所周知，目前主流的LLM，都是基于Causal Attention的Decoder-only模型（对此我们在《为什么现在的LLM都是Decoder-only的架构？》也有过相关讨论），而对于C...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Paralympiques au Grand Palais]]></title>
        <id>http://xianblog.wordpress.com/?p=57306</id>
        <link href="https://xianblog.wordpress.com/2024/09/01/paralympiques-au-grand-palais/"/>
        <updated>2024-08-31T22:24:27.000Z</updated>
        <summary type="html"><![CDATA[While we did not try to attend any of the Paris 2024 Olympics events, primarily for being in the Pacific Northwest during the Olympics (in not in Olympic National Park!), being back in Paris and tickets being widely available and looking forward attending an event in the Grand Palais, we found tickets for the taekwondo […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Old Turkic origins of the Tang Dynasty]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65730</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65730&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-old-turkic-origins-of-the-tang-dynasty"/>
        <updated>2024-08-31T22:21:04.000Z</updated>
        <summary type="html"><![CDATA[Sino-Platonic Papers is pleased to announce the publication of its three-hundred-and-fifty-sixth issue:  “The Tang as a Tuoba Dynasty” (pdf) by Sanping Chen. ABSTRACT By examining the record of a local anti-Tibetan rebellion in document scroll S.1438 from the Dunhuang “library cave,” this discussion demonstrates that the nomadic Tuoba origin of the Tang royal house was […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Teacher voice"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65736</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65736&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=teacher-voice"/>
        <updated>2024-08-31T19:41:26.000Z</updated>
        <summary type="html"><![CDATA[Now I read that J D Vance said he was "really disturbed" by teachers who don't have biological children. Well for a long time Tim and I were teachers who struggled with infertility. And we were only able to start a family because of fertility treatments. So this is really personal. we do not take […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Eric Doty duels with Grammarly]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65732</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65732&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=eric-doty-duels-with-grammarly"/>
        <updated>2024-08-31T13:34:39.000Z</updated>
        <summary type="html"><![CDATA[Eric Doty dueling with Grammarly on LinkedIn: me: in real time grammarly: in real-time me: k, in real-time grammarly: in real time me: i'm going to smash you in real time grammarly: i'm going to smash you in real-time I don't have a Grammarly account, so I can't check, but I wonder if maybe the […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Within one year or more" ???]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65723</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65723&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=within-one-year-or-more"/>
        <updated>2024-08-31T12:43:28.000Z</updated>
        <summary type="html"><![CDATA[From Frederick Newmeyer: I recently had to cancel a flight with Delta Airlines and was directed to their webpage that discusses what to do to get a refund. I found the following bizarre instruction: Please retain the ticket/document number(s) below as they have become an eCredit and the remaining value can be used to rebook […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Doing a literature]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65710</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65710&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=doing-a-literature"/>
        <updated>2024-08-31T11:08:38.000Z</updated>
        <summary type="html"><![CDATA[Today's Dinosaur Comics: Mouseover title: “this has TREMENDOUS implications for my two original characters, Anna Phora and E. P. Strophe” One of the comments on Ryan North's bluesky post for this strip is: The dudes who start every reply with "Well, actually…" are doing a literature?? Who knew?!? — MisterJayEm (@misterjayem.bsky.social) Aug 30, 2024 at […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ocean’s gwen ha du [blue wave#2]]]></title>
        <id>http://xianblog.wordpress.com/?p=57318</id>
        <link href="https://xianblog.wordpress.com/2024/08/31/oceans-gwen-ha-du-blue-wave2/"/>
        <updated>2024-08-31T10:24:16.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The beauty of open access]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=65699</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=65699&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-beauty-of-open-access"/>
        <updated>2024-08-31T09:30:55.000Z</updated>
        <summary type="html"><![CDATA[Just published is a volume edited by David Holm, Vernacular Chinese-Character Manuscripts from East and Southeast Asia (De Gruyter), in their Studies in Manuscript Cultures series. Now available open access at the De Gruyter website. The book has chapters on Hokkien, Cantonese, Vietnamese, Yao, Zhuang, and other Tai-speakers who use Chinese-based vernacular scripts. Previously announced on […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Can neural networks do arithmetic? A survey on the elementary numerical
  skills of state-of-the-art deep learning models]]></title>
        <id>http://arxiv.org/abs/2303.07735</id>
        <link href="http://arxiv.org/abs/2303.07735"/>
        <updated>2024-02-08T04:17:54.327Z</updated>
        <summary type="html"><![CDATA[Alberto Testolin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical Guarantees for Link Prediction using Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2402.02692</id>
        <link href="http://arxiv.org/abs/2402.02692"/>
        <updated>2024-02-08T04:17:54.104Z</updated>
        <summary type="html"><![CDATA[Alan Chung, Amin Saberi, Morgane Austern]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning from Time Series under Temporal Label Noise]]></title>
        <id>http://arxiv.org/abs/2402.04398</id>
        <link href="http://arxiv.org/abs/2402.04398"/>
        <updated>2024-02-08T04:17:53.662Z</updated>
        <summary type="html"><![CDATA[Sujay Nagaraj, Walter Gerych, Sana Tonekaboni, Anna Goldenberg, Berk
  Ustun, Thomas Hartvigsen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scaling laws for learning with real and surrogate data]]></title>
        <id>http://arxiv.org/abs/2402.04376</id>
        <link href="http://arxiv.org/abs/2402.04376"/>
        <updated>2024-02-08T04:17:53.629Z</updated>
        <summary type="html"><![CDATA[Ayush Jain, Andrea Montanari, Eren Sasoglu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simple online learning with consistent oracle]]></title>
        <id>http://arxiv.org/abs/2308.08055</id>
        <link href="http://arxiv.org/abs/2308.08055"/>
        <updated>2024-02-08T04:17:53.560Z</updated>
        <summary type="html"><![CDATA[Alexander Kozachinskiy, Tomasz Steifer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classical Verification of Quantum Learning]]></title>
        <id>http://arxiv.org/abs/2306.04843</id>
        <link href="http://arxiv.org/abs/2306.04843"/>
        <updated>2024-02-07T15:14:09.456Z</updated>
        <summary type="html"><![CDATA[Matthias C. Caro, Marcel Hinsche, Marios Ioannou, Alexander Nietner,
  Ryan Sweke]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Empirical Study of Self-supervised Learning with Wasserstein Distance]]></title>
        <id>http://arxiv.org/abs/2310.10143</id>
        <link href="http://arxiv.org/abs/2310.10143"/>
        <updated>2024-02-07T15:14:08.881Z</updated>
        <summary type="html"><![CDATA[Makoto Yamada, Yuki Takezawa, Guillaume Houry, Kira Michaela
  Dusterwald, Deborah Sulem, Han Zhao, Yao-Hung Hubert Tsai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Representations of Annealing Paths: Bregman Information
  under Monotonic Embedding]]></title>
        <id>http://arxiv.org/abs/2209.07481</id>
        <link href="http://arxiv.org/abs/2209.07481"/>
        <updated>2024-02-07T15:14:08.806Z</updated>
        <summary type="html"><![CDATA[Rob Brekelmans, Frank Nielsen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provably Efficient UCB-type Algorithms For Learning Predictive State
  Representations]]></title>
        <id>http://arxiv.org/abs/2307.00405</id>
        <link href="http://arxiv.org/abs/2307.00405"/>
        <updated>2024-02-07T15:14:08.617Z</updated>
        <summary type="html"><![CDATA[Ruiquan Huang, Yingbin Liang, Jing Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Margin Mechanism and Pseudo Query Set on Cross-Domain Few-Shot
  Learning]]></title>
        <id>http://arxiv.org/abs/2005.09218</id>
        <link href="http://arxiv.org/abs/2005.09218"/>
        <updated>2024-02-07T15:14:08.613Z</updated>
        <summary type="html"><![CDATA[Jia-Fong Yeh, Hsin-Ying Lee, Bing-Chen Tsai, Yi-Rong Chen and
  Ping-Chia Huang, Winston H. Hsu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complete intersections in binomial and lattice ideals]]></title>
        <id>http://arxiv.org/abs/1205.0772</id>
        <link href="http://arxiv.org/abs/1205.0772"/>
        <updated>2024-02-07T04:17:40.507Z</updated>
        <summary type="html"><![CDATA[Hiram H. Lopez, Rafael H. Villarreal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Projective nested cartesian codes]]></title>
        <id>http://arxiv.org/abs/1411.6819</id>
        <link href="http://arxiv.org/abs/1411.6819"/>
        <updated>2024-02-07T04:17:40.503Z</updated>
        <summary type="html"><![CDATA[Cicero Carvalho, V. G. Lopez Neumann, Hiram H. Lopez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Affine cartesian codes]]></title>
        <id>http://arxiv.org/abs/1202.0085</id>
        <link href="http://arxiv.org/abs/1202.0085"/>
        <updated>2024-02-07T03:16:09.633Z</updated>
        <summary type="html"><![CDATA[Hiram H. Lopez, Carlos Renteria, Rafael H. Villarreal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Parameterized affine codes]]></title>
        <id>http://arxiv.org/abs/1109.2353</id>
        <link href="http://arxiv.org/abs/1109.2353"/>
        <updated>2024-02-07T03:16:09.580Z</updated>
        <summary type="html"><![CDATA[Hiram H. Lopez, Eliseo Sarmiento, Maria Vaz Pinto, Rafael H.
  Villarreal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computing the degree of a lattice ideal of dimension one]]></title>
        <id>http://arxiv.org/abs/1206.1892</id>
        <link href="http://arxiv.org/abs/1206.1892"/>
        <updated>2024-02-07T03:16:09.403Z</updated>
        <summary type="html"><![CDATA[Hiram H. Lopez, Rafael H. Villarreal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complete intersection vanishing ideals on degenerate tori over finite
  fields]]></title>
        <id>http://arxiv.org/abs/1207.0244</id>
        <link href="http://arxiv.org/abs/1207.0244"/>
        <updated>2024-02-07T03:16:09.392Z</updated>
        <summary type="html"><![CDATA[Hiram H. Lopez, Rafael H. Villarreal, Leticia Zarate]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rank distribution of Delsarte codes]]></title>
        <id>http://arxiv.org/abs/1510.01008</id>
        <link href="http://arxiv.org/abs/1510.01008"/>
        <updated>2024-02-07T03:16:09.388Z</updated>
        <summary type="html"><![CDATA[Javier de la Cruz, Elisa Gorla, Hiram H. Lopez, Alberto Ravagnani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the combinatorics of commutators of Lie algebras]]></title>
        <id>http://arxiv.org/abs/1609.09407</id>
        <link href="http://arxiv.org/abs/1609.09407"/>
        <updated>2024-02-06T04:16:46.631Z</updated>
        <summary type="html"><![CDATA[Eduardo Hitomi, Felipe Yasumura]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometric properties of some totally ordered compact sets]]></title>
        <id>http://arxiv.org/abs/1207.0330</id>
        <link href="http://arxiv.org/abs/1207.0330"/>
        <updated>2024-02-06T03:15:47.413Z</updated>
        <summary type="html"><![CDATA[Mohammad Daher, Khalil Saadi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In constructive and informal mathematics, in contradistinction to any
  empirical science, the predicate of the current knowledge in the subject is
  necessary]]></title>
        <id>http://arxiv.org/abs/1309.2605</id>
        <link href="http://arxiv.org/abs/1309.2605"/>
        <updated>2024-02-06T03:15:47.410Z</updated>
        <summary type="html"><![CDATA[Apoloniusz Tyszka]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Holographic Phase Transitions in (2+1)-dimensional black hole spacetimes
  in NMG]]></title>
        <id>http://arxiv.org/abs/1307.1460</id>
        <link href="http://arxiv.org/abs/1307.1460"/>
        <updated>2024-02-06T03:15:47.406Z</updated>
        <summary type="html"><![CDATA[E. Abdalla, Jeferson de Oliveira, A. B. Pavan, C. E. Pellicer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Impulse control maximising average cost per unit time: a non-uniformly
  ergodic case]]></title>
        <id>http://arxiv.org/abs/1606.08731</id>
        <link href="http://arxiv.org/abs/1606.08731"/>
        <updated>2024-02-06T03:15:47.307Z</updated>
        <summary type="html"><![CDATA[Jan Palczewski, Lukasz Stettner]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nilpotent orbit theorem in $p$-adic Hodge theory]]></title>
        <id>http://arxiv.org/abs/1612.03367</id>
        <link href="http://arxiv.org/abs/1612.03367"/>
        <updated>2024-02-06T03:15:46.799Z</updated>
        <summary type="html"><![CDATA[Mohammad Reza Rahmati, Gerardo Flores]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From geometry to invertibility preservers]]></title>
        <id>http://arxiv.org/abs/1304.0232</id>
        <link href="http://arxiv.org/abs/1304.0232"/>
        <updated>2024-02-05T03:16:27.389Z</updated>
        <summary type="html"><![CDATA[Hans Havlicek, Peter \v{S}emrl]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cayley's surface revisited]]></title>
        <id>http://arxiv.org/abs/1304.0225</id>
        <link href="http://arxiv.org/abs/1304.0225"/>
        <updated>2024-02-05T03:16:27.376Z</updated>
        <summary type="html"><![CDATA[Hans Havlicek]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On distant-isomorphisms of projective lines]]></title>
        <id>http://arxiv.org/abs/1304.0226</id>
        <link href="http://arxiv.org/abs/1304.0226"/>
        <updated>2024-02-05T03:16:27.063Z</updated>
        <summary type="html"><![CDATA[Andrea Blunck, Hans Havlicek]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lifting of divisible designs]]></title>
        <id>http://arxiv.org/abs/1304.1337</id>
        <link href="http://arxiv.org/abs/1304.1337"/>
        <updated>2024-02-05T03:16:26.995Z</updated>
        <summary type="html"><![CDATA[Andrea Blunck, Hans Havlicek, Corrado Zanella]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Divisible designs from twisted dual numbers]]></title>
        <id>http://arxiv.org/abs/1304.1338</id>
        <link href="http://arxiv.org/abs/1304.1338"/>
        <updated>2024-02-05T03:16:26.965Z</updated>
        <summary type="html"><![CDATA[Andrea Blunck, Hans Havlicek, Corrado Zanella]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Comparing Machine Learning Algorithms by Union-Free Generic Depth]]></title>
        <id>http://arxiv.org/abs/2312.12839</id>
        <link href="http://arxiv.org/abs/2312.12839"/>
        <updated>2024-02-02T05:15:03.576Z</updated>
        <summary type="html"><![CDATA[Hannah Blocher, Georg Schollmeyer, Malte Nalenz, Christoph Jansen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI]]></title>
        <id>http://arxiv.org/abs/2402.00809</id>
        <link href="http://arxiv.org/abs/2402.00809"/>
        <updated>2024-02-02T05:15:02.951Z</updated>
        <summary type="html"><![CDATA[Theodore Papamarkou, Maria Skoularidou, Konstantina Palla, Laurence
  Aitchison, Julyan Arbel, David Dunson, Maurizio Filippone, Vincent Fortuin,
  Philipp Hennig, Aliaksandr Hubin, Alexander Immer, Theofanis Karaletsos,
  Mohammad Emtiyaz Khan, Agustinus Kristiadi, Yingzhen Li, Jose Miguel
  Hernandez Lobato, Stephan Mandt, Christopher Nemeth, Michael A. Osborne, Tim
  G. J. Rudner, David R\"ugamer, Yee Whye Teh, Max Welling, Andrew Gordon
  Wilson, Ruqi Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Benefits of Transformer: In-Context Learning in Linear Regression Tasks
  with Unstructured Data]]></title>
        <id>http://arxiv.org/abs/2402.00743</id>
        <link href="http://arxiv.org/abs/2402.00743"/>
        <updated>2024-02-02T05:15:02.714Z</updated>
        <summary type="html"><![CDATA[Yue Xing, Xiaofeng Lin, Namjoon Suh, Qifan Song, Guang Cheng]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Exploration for LLMs]]></title>
        <id>http://arxiv.org/abs/2402.00396</id>
        <link href="http://arxiv.org/abs/2402.00396"/>
        <updated>2024-02-02T05:15:02.704Z</updated>
        <summary type="html"><![CDATA[Vikranth Dwaracherla, Seyed Mohammad Asghari, Botao Hao, Benjamin Van
  Roy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Purely Algebraic Approach to The Generalized Jacobian Conjecture]]></title>
        <id>http://arxiv.org/abs/1203.1691</id>
        <link href="http://arxiv.org/abs/1203.1691"/>
        <updated>2024-02-01T03:16:01.870Z</updated>
        <summary type="html"><![CDATA[Susumu Oda]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mapping Exoplanets]]></title>
        <id>http://arxiv.org/abs/1704.07832</id>
        <link href="http://arxiv.org/abs/1704.07832"/>
        <updated>2024-02-01T03:16:01.537Z</updated>
        <summary type="html"><![CDATA[Nicolas B. Cowan, Yuka Fujii]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Atoms of None of the Elements Ionize While Atoms of Inert Behavior Split
  by Photonic Current]]></title>
        <id>http://arxiv.org/abs/1611.05392</id>
        <link href="http://arxiv.org/abs/1611.05392"/>
        <updated>2024-02-01T03:16:00.531Z</updated>
        <summary type="html"><![CDATA[Mubarak Ali]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Lieb-Thirring inequality revisited]]></title>
        <id>http://arxiv.org/abs/1808.09017</id>
        <link href="http://arxiv.org/abs/1808.09017"/>
        <updated>2024-01-31T10:15:33.140Z</updated>
        <summary type="html"><![CDATA[Rupert L. Frank, Dirk Hundertmark, Michal Jex, Phan Th\`anh Nam]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Algebraic approximations of compact K\"ahler threefolds]]></title>
        <id>http://arxiv.org/abs/1710.01083</id>
        <link href="http://arxiv.org/abs/1710.01083"/>
        <updated>2024-01-31T10:15:32.979Z</updated>
        <summary type="html"><![CDATA[Hsueh-Yung Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the dual positive cones and the algebraicity of a compact K\"ahler
  manifold]]></title>
        <id>http://arxiv.org/abs/2001.10654</id>
        <link href="http://arxiv.org/abs/2001.10654"/>
        <updated>2024-01-31T10:15:32.974Z</updated>
        <summary type="html"><![CDATA[Hsueh-Yung Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Branching process descriptions of information cascades on Twitter]]></title>
        <id>http://arxiv.org/abs/2007.08916</id>
        <link href="http://arxiv.org/abs/2007.08916"/>
        <updated>2024-01-31T10:15:32.960Z</updated>
        <summary type="html"><![CDATA[James P. Gleeson, Tomokatsu Onaga, Peter Fennell, James Cotter,
  Raymond Burke, David J. P. O'Sullivan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tautological classes and symmetry in Khovanov-Rozansky homology]]></title>
        <id>http://arxiv.org/abs/2103.01212</id>
        <link href="http://arxiv.org/abs/2103.01212"/>
        <updated>2024-01-31T10:15:32.955Z</updated>
        <summary type="html"><![CDATA[Eugene Gorsky, Matthew Hogancamp, Anton Mellit]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural networks for geospatial data]]></title>
        <id>http://arxiv.org/abs/2304.09157</id>
        <link href="http://arxiv.org/abs/2304.09157"/>
        <updated>2024-01-31T07:14:01.684Z</updated>
        <summary type="html"><![CDATA[Wentao Zhan, Abhirup Datta]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-modal Molecule Structure-text Model for Text-based Retrieval and
  Editing]]></title>
        <id>http://arxiv.org/abs/2212.10789</id>
        <link href="http://arxiv.org/abs/2212.10789"/>
        <updated>2024-01-31T07:14:01.662Z</updated>
        <summary type="html"><![CDATA[Shengchao Liu, Weili Nie, Chengpeng Wang, Jiarui Lu, Zhuoran Qiao,
  Ling Liu, Jian Tang, Chaowei Xiao, Anima Anandkumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Effect of Weight Quantization on Learning Models by Typical Case
  Analysis]]></title>
        <id>http://arxiv.org/abs/2401.17269</id>
        <link href="http://arxiv.org/abs/2401.17269"/>
        <updated>2024-01-31T07:14:01.629Z</updated>
        <summary type="html"><![CDATA[Shuhei Kashiwamura, Ayaka Sakata, Masaaki Imaizumi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multiple Yield Curve Modeling and Forecasting using Deep Learning]]></title>
        <id>http://arxiv.org/abs/2401.16985</id>
        <link href="http://arxiv.org/abs/2401.16985"/>
        <updated>2024-01-31T07:14:01.626Z</updated>
        <summary type="html"><![CDATA[Ronald Richman, Salvatore Scognamiglio]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified Transfer Learning Models in High-Dimensional Linear Regression]]></title>
        <id>http://arxiv.org/abs/2307.00238</id>
        <link href="http://arxiv.org/abs/2307.00238"/>
        <updated>2024-01-31T07:14:01.579Z</updated>
        <summary type="html"><![CDATA[Shuo Shuo Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The sample complexity of multi-distribution learning]]></title>
        <id>http://arxiv.org/abs/2312.04027</id>
        <link href="http://arxiv.org/abs/2312.04027"/>
        <updated>2024-01-30T07:14:51.968Z</updated>
        <summary type="html"><![CDATA[Binghui Peng]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computer Vision Self-supervised Learning Methods on Time Series]]></title>
        <id>http://arxiv.org/abs/2109.00783</id>
        <link href="http://arxiv.org/abs/2109.00783"/>
        <updated>2024-01-30T07:14:51.811Z</updated>
        <summary type="html"><![CDATA[Daesoo Lee, Erlend Aune]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Multi-Grained Symmetric Differential Equation Model for Learning
  Protein-Ligand Binding Dynamics]]></title>
        <id>http://arxiv.org/abs/2401.15122</id>
        <link href="http://arxiv.org/abs/2401.15122"/>
        <updated>2024-01-30T07:14:51.805Z</updated>
        <summary type="html"><![CDATA[Shengchao Liu, Weitao Du, Yanjing Li, Zhuoxinran Li, Vignesh
  Bhethanabotla, Nakul Rampal, Omar Yaghi, Christian Borgs, Anima Anandkumar,
  Hongyu Guo, Jennifer Chayes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adversarial Attacks on Graph Neural Networks via Meta Learning]]></title>
        <id>http://arxiv.org/abs/1902.08412</id>
        <link href="http://arxiv.org/abs/1902.08412"/>
        <updated>2024-01-30T07:14:51.741Z</updated>
        <summary type="html"><![CDATA[Daniel Z\"ugner, Stephan G\"unnemann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length
  Extrapolation]]></title>
        <id>http://arxiv.org/abs/2401.16421</id>
        <link href="http://arxiv.org/abs/2401.16421"/>
        <updated>2024-01-30T07:14:51.737Z</updated>
        <summary type="html"><![CDATA[Zhenyu He, Guhao Feng, Shengjie Luo, Kai Yang, Di He, Jingjing Xu, Zhi
  Zhang, Hongxia Yang, Liwei Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rank Jumps and Growth of Shafarevich--Tate Groups for Elliptic Curves in
  $\mathbb{Z}/p\mathbb{Z}$-Extensions]]></title>
        <id>http://arxiv.org/abs/2107.09166</id>
        <link href="http://arxiv.org/abs/2107.09166"/>
        <updated>2024-01-29T08:18:11.026Z</updated>
        <summary type="html"><![CDATA[Lea Beneish, Debanjana Kundu, Anwesh Ray]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Categorical Koszul duality]]></title>
        <id>http://arxiv.org/abs/2006.01705</id>
        <link href="http://arxiv.org/abs/2006.01705"/>
        <updated>2024-01-29T08:18:10.638Z</updated>
        <summary type="html"><![CDATA[Julian Holstein, Andrey Lazarev]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast-HotStuff: A Fast and Resilient HotStuff Protocol]]></title>
        <id>http://arxiv.org/abs/2010.11454</id>
        <link href="http://arxiv.org/abs/2010.11454"/>
        <updated>2024-01-29T08:18:10.634Z</updated>
        <summary type="html"><![CDATA[Mohammad M. Jalalzai, Jianyu Niu, Chen Feng, Fangyu Gai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some Rigidity Theorem for Anosov Geodesic Flows]]></title>
        <id>http://arxiv.org/abs/1709.09524</id>
        <link href="http://arxiv.org/abs/1709.09524"/>
        <updated>2024-01-29T08:18:10.622Z</updated>
        <summary type="html"><![CDATA[\'Italo Dowell, Sergio Roma\~na]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Affine Anosov representations and proper actions]]></title>
        <id>http://arxiv.org/abs/1711.09712</id>
        <link href="http://arxiv.org/abs/1711.09712"/>
        <updated>2024-01-29T08:18:10.618Z</updated>
        <summary type="html"><![CDATA[Sourav Ghosh, Nicolaus Treib]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Signature Methods in Machine Learning]]></title>
        <id>http://arxiv.org/abs/2206.14674</id>
        <link href="http://arxiv.org/abs/2206.14674"/>
        <updated>2024-01-29T07:13:36.380Z</updated>
        <summary type="html"><![CDATA[Terry Lyons, Andrew D. McLeod]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language
  Models]]></title>
        <id>http://arxiv.org/abs/2310.02998</id>
        <link href="http://arxiv.org/abs/2310.02998"/>
        <updated>2024-01-29T07:13:36.376Z</updated>
        <summary type="html"><![CDATA[Yi-Lin Sung, Jaehong Yoon, Mohit Bansal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A multiobjective continuation method to compute the regularization path
  of deep neural networks]]></title>
        <id>http://arxiv.org/abs/2308.12044</id>
        <link href="http://arxiv.org/abs/2308.12044"/>
        <updated>2024-01-29T07:13:36.372Z</updated>
        <summary type="html"><![CDATA[Augustina C. Amakor, Konstantin Sonntag, Sebastian Peitz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Disparities in Post Hoc Machine Learning Explanation]]></title>
        <id>http://arxiv.org/abs/2401.14539</id>
        <link href="http://arxiv.org/abs/2401.14539"/>
        <updated>2024-01-29T07:13:36.368Z</updated>
        <summary type="html"><![CDATA[Vishwali Mhasawade, Salman Rahman, Zoe Haskell-Craig, Rumi Chunara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High-dimensional Functional Graphical Model Structure Learning via
  Neighborhood Selection Approach]]></title>
        <id>http://arxiv.org/abs/2105.02487</id>
        <link href="http://arxiv.org/abs/2105.02487"/>
        <updated>2024-01-29T07:13:36.360Z</updated>
        <summary type="html"><![CDATA[Boxin Zhao, Percy S. Zhai, Y. Samuel Wang, Mladen Kolar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building a Nest by an Automaton]]></title>
        <id>http://arxiv.org/abs/1904.10850</id>
        <link href="http://arxiv.org/abs/1904.10850"/>
        <updated>2024-01-26T08:17:51.498Z</updated>
        <summary type="html"><![CDATA[Jurek Czyzowicz, Dariusz Dereniowski, Andrzej Pelc]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-fattening of mean curvature flow at singularities of mean convex
  type]]></title>
        <id>http://arxiv.org/abs/1704.00431</id>
        <link href="http://arxiv.org/abs/1704.00431"/>
        <updated>2024-01-26T08:17:51.482Z</updated>
        <summary type="html"><![CDATA[Or Hershkovits, Brian White]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RETRACTED: Yang-Mills theory for bundle gerbes]]></title>
        <id>http://arxiv.org/abs/hep-th/0509037</id>
        <link href="http://arxiv.org/abs/hep-th/0509037"/>
        <updated>2024-01-26T08:17:51.177Z</updated>
        <summary type="html"><![CDATA[Varghese Mathai, David Roberts]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Two-Page "Derivation" of Schroedinger's Equation]]></title>
        <id>http://arxiv.org/abs/1907.09917</id>
        <link href="http://arxiv.org/abs/1907.09917"/>
        <updated>2024-01-26T08:17:50.952Z</updated>
        <summary type="html"><![CDATA[C. Baumgarten]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quadratic fields, Artin-Schreier extensions, and Bell numbers]]></title>
        <id>http://arxiv.org/abs/1912.04647</id>
        <link href="http://arxiv.org/abs/1912.04647"/>
        <updated>2024-01-26T08:17:50.919Z</updated>
        <summary type="html"><![CDATA[Yoshinosuke Hirakawa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CompactifAI: Extreme Compression of Large Language Models using
  Quantum-Inspired Tensor Networks]]></title>
        <id>http://arxiv.org/abs/2401.14109</id>
        <link href="http://arxiv.org/abs/2401.14109"/>
        <updated>2024-01-26T04:18:48.455Z</updated>
        <summary type="html"><![CDATA[Andrei Tomut, Saeed S. Jahromi, Sukhbinder Singh, Faysal Ishtiaq,
  Cesar Mu\~noz, Prabdeep Singh Bajaj, Ali Elborady, Gianni del Bimbo, Mehrazin
  Alizadeh, David Montero, Pablo Martin-Ramiro, Muhammad Ibrahim, Oussama
  Tahiri Alaoui, John Malcolm, Samuel Mugel, Roman Orus]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transfer Learning for Contextual Multi-armed Bandits]]></title>
        <id>http://arxiv.org/abs/2211.12612</id>
        <link href="http://arxiv.org/abs/2211.12612"/>
        <updated>2024-01-26T04:18:48.334Z</updated>
        <summary type="html"><![CDATA[Changxiao Cai, T. Tony Cai, Hongzhe Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[At the junction between deep learning and statistics of extremes:
  formalizing the landslide hazard definition]]></title>
        <id>http://arxiv.org/abs/2401.14210</id>
        <link href="http://arxiv.org/abs/2401.14210"/>
        <updated>2024-01-26T04:18:48.330Z</updated>
        <summary type="html"><![CDATA[Ashok Dahal, Rapha\"el Huser, Luigi Lombardo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Systematic Approach to Robustness Modelling for Deep Convolutional
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2401.13751</id>
        <link href="http://arxiv.org/abs/2401.13751"/>
        <updated>2024-01-26T04:18:48.313Z</updated>
        <summary type="html"><![CDATA[Charles Meyers, Mohammad Reza Saleh Sedghpour, Tommy L\"ofstedt, Erik
  Elmroth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A V2X-based Privacy Preserving Federated Measuring and Learning System]]></title>
        <id>http://arxiv.org/abs/2401.13848</id>
        <link href="http://arxiv.org/abs/2401.13848"/>
        <updated>2024-01-26T04:18:48.310Z</updated>
        <summary type="html"><![CDATA[Levente Alekszejenk\'o, Tadeusz Dobrowiecki]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Probabilistic Demand Forecasting with Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2401.13096</id>
        <link href="http://arxiv.org/abs/2401.13096"/>
        <updated>2024-01-25T04:19:46.798Z</updated>
        <summary type="html"><![CDATA[Nikita Kozodoi, Elizaveta Zinovyeva, Simon Valentin, Jo\~ao Pereira,
  Rodrigo Agundez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Latent Force Models: ODE-based Process Convolutions for Bayesian
  Deep Learning]]></title>
        <id>http://arxiv.org/abs/2311.14828</id>
        <link href="http://arxiv.org/abs/2311.14828"/>
        <updated>2024-01-25T04:19:46.668Z</updated>
        <summary type="html"><![CDATA[Thomas Baldwin-McDonald, Mauricio A. \'Alvarez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially Private Distributed Estimation and Learning]]></title>
        <id>http://arxiv.org/abs/2306.15865</id>
        <link href="http://arxiv.org/abs/2306.15865"/>
        <updated>2024-01-25T04:19:46.664Z</updated>
        <summary type="html"><![CDATA[Marios Papachristou, M. Amin Rahimian]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Can overfitted deep neural networks in adversarial training generalize?
  -- An approximation viewpoint]]></title>
        <id>http://arxiv.org/abs/2401.13624</id>
        <link href="http://arxiv.org/abs/2401.13624"/>
        <updated>2024-01-25T04:19:46.538Z</updated>
        <summary type="html"><![CDATA[Zhongjie Shi, Fanghui Liu, Yuan Cao, Johan A.K. Suykens]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Full Bayesian Significance Testing for Neural Networks]]></title>
        <id>http://arxiv.org/abs/2401.13335</id>
        <link href="http://arxiv.org/abs/2401.13335"/>
        <updated>2024-01-25T04:19:46.528Z</updated>
        <summary type="html"><![CDATA[Zehua Liu, Zimeng Li, Jingyuan Wang, Yue He]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep multitask neural networks for solving some stochastic optimal
  control problems]]></title>
        <id>http://arxiv.org/abs/2401.12923</id>
        <link href="http://arxiv.org/abs/2401.12923"/>
        <updated>2024-01-24T05:15:11.783Z</updated>
        <summary type="html"><![CDATA[Christian Yeo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian identification of nonseparable Hamiltonians with multiplicative
  noise using deep learning and reduced-order modeling]]></title>
        <id>http://arxiv.org/abs/2401.12476</id>
        <link href="http://arxiv.org/abs/2401.12476"/>
        <updated>2024-01-24T05:15:10.802Z</updated>
        <summary type="html"><![CDATA[Nicholas Galioto, Harsh Sharma, Boris Kramer, Alex Arkady Gorodetsky]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Stability Principle for Learning under Non-Stationarity]]></title>
        <id>http://arxiv.org/abs/2310.18304</id>
        <link href="http://arxiv.org/abs/2310.18304"/>
        <updated>2024-01-24T05:15:10.793Z</updated>
        <summary type="html"><![CDATA[Chengpiao Huang, Kaizheng Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Neural Network Benchmarks for Selective Classification]]></title>
        <id>http://arxiv.org/abs/2401.12708</id>
        <link href="http://arxiv.org/abs/2401.12708"/>
        <updated>2024-01-24T05:15:10.783Z</updated>
        <summary type="html"><![CDATA[Andrea Pugnana, Lorenzo Perini, Jesse Davis, Salvatore
  Ruggieri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contrastive Learning and Cycle Consistency-based Transductive Transfer
  Learning for Target Annotation]]></title>
        <id>http://arxiv.org/abs/2401.12340</id>
        <link href="http://arxiv.org/abs/2401.12340"/>
        <updated>2024-01-24T05:15:10.779Z</updated>
        <summary type="html"><![CDATA[Shoaib Meraj Sami, Md Mahedi Hasan, Nasser M. Nasrabadi, Raghuveer Rao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantum-classical phase transition with spontaneous superposition
  breaking and single photon detection]]></title>
        <id>http://arxiv.org/abs/1007.2538</id>
        <link href="http://arxiv.org/abs/1007.2538"/>
        <updated>2024-01-23T05:14:55.367Z</updated>
        <summary type="html"><![CDATA[Vladan Pankovic]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Orbital period derivative of a binary system using an exact orbital
  energy equation]]></title>
        <id>http://arxiv.org/abs/0707.4544</id>
        <link href="http://arxiv.org/abs/0707.4544"/>
        <updated>2024-01-23T05:14:54.260Z</updated>
        <summary type="html"><![CDATA[Vikram H. Zaveri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Periodic relativity: the theory of gravity in flat space time]]></title>
        <id>http://arxiv.org/abs/0707.4539</id>
        <link href="http://arxiv.org/abs/0707.4539"/>
        <updated>2024-01-23T05:14:54.225Z</updated>
        <summary type="html"><![CDATA[Vikram H. Zaveri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian nonparametric modeling for mean residual life regression]]></title>
        <id>http://arxiv.org/abs/1412.0367</id>
        <link href="http://arxiv.org/abs/1412.0367"/>
        <updated>2024-01-23T05:14:54.219Z</updated>
        <summary type="html"><![CDATA[Valerie Poynor, Athanasios Kottas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Collapsing 4-manifolds under a lower curvature bound]]></title>
        <id>http://arxiv.org/abs/1205.0323</id>
        <link href="http://arxiv.org/abs/1205.0323"/>
        <updated>2024-01-23T05:14:54.206Z</updated>
        <summary type="html"><![CDATA[Takao Yamaguchi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Braid group actions from categorical symmetric Howe duality on deformed
  Webster algebras]]></title>
        <id>http://arxiv.org/abs/1802.05358</id>
        <link href="http://arxiv.org/abs/1802.05358"/>
        <updated>2024-01-22T04:19:33.875Z</updated>
        <summary type="html"><![CDATA[Mikhail Khovanov, Aaron D. Lauda, Joshua Sussan, Yasuyoshi Yonezawa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Characterizing Exoplanet Habitability]]></title>
        <id>http://arxiv.org/abs/1701.05205</id>
        <link href="http://arxiv.org/abs/1701.05205"/>
        <updated>2024-01-22T04:19:33.332Z</updated>
        <summary type="html"><![CDATA[Tyler D. Robinson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Labeling Neural Representations with Inverse Recognition]]></title>
        <id>http://arxiv.org/abs/2311.13594</id>
        <link href="http://arxiv.org/abs/2311.13594"/>
        <updated>2024-01-19T07:14:24.212Z</updated>
        <summary type="html"><![CDATA[Kirill Bykov, Laura Kopf, Shinichi Nakajima, Marius Kloft, Marina
  M.-C. H\"ohne]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Upper and lower bounds for the Lipschitz constant of random neural
  networks]]></title>
        <id>http://arxiv.org/abs/2311.01356</id>
        <link href="http://arxiv.org/abs/2311.01356"/>
        <updated>2024-01-19T07:14:24.178Z</updated>
        <summary type="html"><![CDATA[Paul Geuchen, Thomas Heindl, Dominik St\"oger, Felix Voigtlaender]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training Neural Networks is NP-Hard in Fixed Dimension]]></title>
        <id>http://arxiv.org/abs/2303.17045</id>
        <link href="http://arxiv.org/abs/2303.17045"/>
        <updated>2024-01-19T07:14:24.163Z</updated>
        <summary type="html"><![CDATA[Vincent Froese, Christoph Hertrich]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Augmentation-based Self-Supervised Representation Learning
  via RKHS Approximation and Regression]]></title>
        <id>http://arxiv.org/abs/2306.00788</id>
        <link href="http://arxiv.org/abs/2306.00788"/>
        <updated>2024-01-19T07:14:24.148Z</updated>
        <summary type="html"><![CDATA[Runtian Zhai, Bingbin Liu, Andrej Risteski, Zico Kolter, Pradeep
  Ravikumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Querying Easily Flip-flopped Samples for Deep Active Learning]]></title>
        <id>http://arxiv.org/abs/2401.09787</id>
        <link href="http://arxiv.org/abs/2401.09787"/>
        <updated>2024-01-19T07:14:24.107Z</updated>
        <summary type="html"><![CDATA[Seong Jin Cho, Gwangsu Kim, Junghyun Lee, Jinwoo Shin, Chang D.
  Yoo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Expected Utility Networks]]></title>
        <id>http://arxiv.org/abs/1301.6714</id>
        <link href="http://arxiv.org/abs/1301.6714"/>
        <updated>2024-01-18T06:20:34.795Z</updated>
        <summary type="html"><![CDATA[Pierfrancesco La Mura, Yoav Shoham]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Game Networks]]></title>
        <id>http://arxiv.org/abs/1301.3870</id>
        <link href="http://arxiv.org/abs/1301.3870"/>
        <updated>2024-01-18T05:15:04.471Z</updated>
        <summary type="html"><![CDATA[Pierfrancesco La Mura]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Projective Expected Utility]]></title>
        <id>http://arxiv.org/abs/0802.3300</id>
        <link href="http://arxiv.org/abs/0802.3300"/>
        <updated>2024-01-18T05:15:04.466Z</updated>
        <summary type="html"><![CDATA[Pierfrancesco La Mura]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Team Decision Problems with Classical and Quantum Signals]]></title>
        <id>http://arxiv.org/abs/1107.0237</id>
        <link href="http://arxiv.org/abs/1107.0237"/>
        <updated>2024-01-18T05:15:04.455Z</updated>
        <summary type="html"><![CDATA[Adam Brandenburger, Pierfrancesco La Mura]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Local regularity of the Bergman projection on a class of pseudoconvex
  domains of finite type]]></title>
        <id>http://arxiv.org/abs/1406.6532</id>
        <link href="http://arxiv.org/abs/1406.6532"/>
        <updated>2024-01-18T05:15:04.451Z</updated>
        <summary type="html"><![CDATA[Tran Vu Khanh, Andrew Raich]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Algebraic solutions of tropical optimization problems]]></title>
        <id>http://arxiv.org/abs/1406.1777</id>
        <link href="http://arxiv.org/abs/1406.1777"/>
        <updated>2024-01-18T05:15:04.446Z</updated>
        <summary type="html"><![CDATA[N. Krivulin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tangent functor on microformal morphisms, and non-linear pullbacks for
  forms and cohomology]]></title>
        <id>http://arxiv.org/abs/1710.04335</id>
        <link href="http://arxiv.org/abs/1710.04335"/>
        <updated>2024-01-17T06:20:25.299Z</updated>
        <summary type="html"><![CDATA[Theodore Th. Voronov]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal transient behavior in large dynamical systems on networks]]></title>
        <id>http://arxiv.org/abs/1906.10634</id>
        <link href="http://arxiv.org/abs/1906.10634"/>
        <updated>2024-01-17T06:20:24.477Z</updated>
        <summary type="html"><![CDATA[Wojciech Tarnowski, Izaak Neri, Pierpaolo Vivo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometric analysis of 1+1 dimensional quasilinear wave equations]]></title>
        <id>http://arxiv.org/abs/1912.04692</id>
        <link href="http://arxiv.org/abs/1912.04692"/>
        <updated>2024-01-17T06:20:24.467Z</updated>
        <summary type="html"><![CDATA[Leonardo Enrique Abbrescia, Willie Wai Yeung Wong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Global Optimization of Gaussian processes]]></title>
        <id>http://arxiv.org/abs/2005.10902</id>
        <link href="http://arxiv.org/abs/2005.10902"/>
        <updated>2024-01-17T06:20:24.301Z</updated>
        <summary type="html"><![CDATA[Artur M. Schweidtmann, Dominik Bongartz, Daniel Grothe, Tim
  Kerkenhoff, Xiaopeng Lin, Jaromil Najman, Alexander Mitsos]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Ramanujan-Petersson ans Selberg conjectures for Maass forms]]></title>
        <id>http://arxiv.org/abs/2001.10956</id>
        <link href="http://arxiv.org/abs/2001.10956"/>
        <updated>2024-01-17T06:20:24.275Z</updated>
        <summary type="html"><![CDATA[Andr'e Unterberger]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unifying supervised learning and VAEs -- coverage, systematics and
  goodness-of-fit in normalizing-flow based neural network models for
  astro-particle reconstructions]]></title>
        <id>http://arxiv.org/abs/2008.05825</id>
        <link href="http://arxiv.org/abs/2008.05825"/>
        <updated>2024-01-17T04:19:15.881Z</updated>
        <summary type="html"><![CDATA[Thorsten Gl\"usenkamp]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convergence of stochastic gradient descent under a local Lojasiewicz
  condition for deep neural networks]]></title>
        <id>http://arxiv.org/abs/2304.09221</id>
        <link href="http://arxiv.org/abs/2304.09221"/>
        <updated>2024-01-17T04:19:15.786Z</updated>
        <summary type="html"><![CDATA[Jing An, Jianfeng Lu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via
  Mixed-Effect Models and Hierarchical Clustering]]></title>
        <id>http://arxiv.org/abs/2308.06399</id>
        <link href="http://arxiv.org/abs/2308.06399"/>
        <updated>2024-01-17T04:19:15.639Z</updated>
        <summary type="html"><![CDATA[Lorenzo Valleggi, Marco Scutari, Federico Mattia Stefanini]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Imperfect Surrogates for Downstream Inference: Design-based
  Supervised Learning for Social Science Applications of Large Language Models]]></title>
        <id>http://arxiv.org/abs/2306.04746</id>
        <link href="http://arxiv.org/abs/2306.04746"/>
        <updated>2024-01-17T04:19:15.613Z</updated>
        <summary type="html"><![CDATA[Naoki Egami, Musashi Hinck, Brandon M. Stewart, Hanying Wei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modeling Latent Selection with Structural Causal Models]]></title>
        <id>http://arxiv.org/abs/2401.06925</id>
        <link href="http://arxiv.org/abs/2401.06925"/>
        <updated>2024-01-17T04:19:15.198Z</updated>
        <summary type="html"><![CDATA[Leihao Chen, Onno Zoeter, Joris M. Mooij]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explaining Neural Networks without Access to Training Data]]></title>
        <id>http://arxiv.org/abs/2206.04891</id>
        <link href="http://arxiv.org/abs/2206.04891"/>
        <updated>2024-01-15T06:21:31.054Z</updated>
        <summary type="html"><![CDATA[Sascha Marton, Stefan L\"udtke, Christian Bartelt, Andrej Tschalzev,
  Heiner Stuckenschmidt]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Controlling Moments with Kernel Stein Discrepancies]]></title>
        <id>http://arxiv.org/abs/2211.05408</id>
        <link href="http://arxiv.org/abs/2211.05408"/>
        <updated>2024-01-15T06:21:25.314Z</updated>
        <summary type="html"><![CDATA[Heishiro Kanagawa, Alessandro Barp, Arthur Gretton, Lester
  Mackey]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A finite sample analysis of the benign overfitting phenomenon for ridge
  function estimation]]></title>
        <id>http://arxiv.org/abs/2007.12882</id>
        <link href="http://arxiv.org/abs/2007.12882"/>
        <updated>2024-01-15T06:21:25.279Z</updated>
        <summary type="html"><![CDATA[Emmanuel Caron, Stephane Chretien]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Query Complexity of Training Data Reconstruction in Private
  Learning]]></title>
        <id>http://arxiv.org/abs/2303.16372</id>
        <link href="http://arxiv.org/abs/2303.16372"/>
        <updated>2024-01-15T06:21:25.162Z</updated>
        <summary type="html"><![CDATA[Prateeti Mukherjee, Satya Lokam]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural
  Architecture Search]]></title>
        <id>http://arxiv.org/abs/2210.06015</id>
        <link href="http://arxiv.org/abs/2210.06015"/>
        <updated>2024-01-15T06:21:25.152Z</updated>
        <summary type="html"><![CDATA[Pedram Bakhtiarifard, Christian Igel, Raghavendra Selvan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Explainable Stacked Ensemble Model for Static Route-Free Estimation
  of Time of Arrival]]></title>
        <id>http://arxiv.org/abs/2203.09438</id>
        <link href="http://arxiv.org/abs/2203.09438"/>
        <updated>2024-01-12T05:15:16.664Z</updated>
        <summary type="html"><![CDATA[S\"oren Schleibaum, J\"org P. M\"uller, Monika Sester]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ARMA Cell: A Modular and Effective Approach for Neural Autoregressive
  Modeling]]></title>
        <id>http://arxiv.org/abs/2208.14919</id>
        <link href="http://arxiv.org/abs/2208.14919"/>
        <updated>2024-01-12T05:15:16.660Z</updated>
        <summary type="html"><![CDATA[Philipp Schiele, Christoph Berninger, David R\"ugamer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Spaces of Meanings: Compositional Structures in Vision-Language
  Models]]></title>
        <id>http://arxiv.org/abs/2302.14383</id>
        <link href="http://arxiv.org/abs/2302.14383"/>
        <updated>2024-01-12T05:15:16.494Z</updated>
        <summary type="html"><![CDATA[Matthew Trager, Pramuditha Perera, Luca Zancato, Alessandro Achille,
  Parminder Bhatia, Stefano Soatto]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPEX, A Framework For Interpreting Artificial Neural Networks]]></title>
        <id>http://arxiv.org/abs/2112.09820</id>
        <link href="http://arxiv.org/abs/2112.09820"/>
        <updated>2024-01-12T05:15:16.491Z</updated>
        <summary type="html"><![CDATA[Amir Akbarnejad, Gilbert Bigras, Nilanjan Ray]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural
  Networks with Total-Variation Penalty]]></title>
        <id>http://arxiv.org/abs/2208.08626</id>
        <link href="http://arxiv.org/abs/2208.08626"/>
        <updated>2024-01-12T05:15:16.463Z</updated>
        <summary type="html"><![CDATA[Zhikang Dong, Pawel Polak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Theoretical View of Linear Backpropagation and Its Convergence]]></title>
        <id>http://arxiv.org/abs/2112.11018</id>
        <link href="http://arxiv.org/abs/2112.11018"/>
        <updated>2024-01-11T04:19:04.080Z</updated>
        <summary type="html"><![CDATA[Ziang Li, Yiwen Guo, Haodi Liu, Changshui Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GANDALF: Gated Adaptive Network for Deep Automated Learning of Features]]></title>
        <id>http://arxiv.org/abs/2207.08548</id>
        <link href="http://arxiv.org/abs/2207.08548"/>
        <updated>2024-01-11T04:19:04.064Z</updated>
        <summary type="html"><![CDATA[Manu Joseph, Harsh Raj]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hierarchical Correlation Clustering and Tree Preserving Embedding]]></title>
        <id>http://arxiv.org/abs/2002.07756</id>
        <link href="http://arxiv.org/abs/2002.07756"/>
        <updated>2024-01-11T04:19:04.060Z</updated>
        <summary type="html"><![CDATA[Morteza Haghir Chehreghani, Mostafa Haghir Chehreghani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive joint distribution learning]]></title>
        <id>http://arxiv.org/abs/2110.04829</id>
        <link href="http://arxiv.org/abs/2110.04829"/>
        <updated>2024-01-11T04:19:04.012Z</updated>
        <summary type="html"><![CDATA[Damir Filipovic, Michael Multerer, Paul Schneider]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalized Optimistic Methods for Convex-Concave Saddle Point Problems]]></title>
        <id>http://arxiv.org/abs/2202.09674</id>
        <link href="http://arxiv.org/abs/2202.09674"/>
        <updated>2024-01-11T04:19:04.000Z</updated>
        <summary type="html"><![CDATA[Ruichen Jiang, Aryan Mokhtari]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New bounds on the strength of some restrictions of Hindman's Theorem]]></title>
        <id>http://arxiv.org/abs/1701.06095</id>
        <link href="http://arxiv.org/abs/1701.06095"/>
        <updated>2024-01-10T08:19:40.975Z</updated>
        <summary type="html"><![CDATA[Lorenzo Carlucci, Leszek Aleksander Ko{\l}odziejczyk, Francesco
  Lepore, Konrad Zdanowski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The zonoid algebra, generalized mixed volumes, and random determinants]]></title>
        <id>http://arxiv.org/abs/2109.14996</id>
        <link href="http://arxiv.org/abs/2109.14996"/>
        <updated>2024-01-10T08:19:40.889Z</updated>
        <summary type="html"><![CDATA[Paul Breiding, Peter B\"urgisser, Antonio Lerario, L\'eo Mathis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Virasoro Constraints for Toric Bundles]]></title>
        <id>http://arxiv.org/abs/1508.06282</id>
        <link href="http://arxiv.org/abs/1508.06282"/>
        <updated>2024-01-10T08:19:40.383Z</updated>
        <summary type="html"><![CDATA[Tom Coates, Alexander Givental, Hsian-Hua Tseng]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lifelong Ensemble Learning based on Multiple Representations for
  Few-Shot Object Recognition]]></title>
        <id>http://arxiv.org/abs/2205.01982</id>
        <link href="http://arxiv.org/abs/2205.01982"/>
        <updated>2024-01-10T08:19:40.029Z</updated>
        <summary type="html"><![CDATA[Hamidreza Kasaei, Songsong Xiong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Evolution of A.I. and Machine Learning: Towards a Meta-level
  Measuring and Understanding Impact, Influence, and Leadership at Premier A.I.
  Conferences]]></title>
        <id>http://arxiv.org/abs/2205.13131</id>
        <link href="http://arxiv.org/abs/2205.13131"/>
        <updated>2024-01-10T08:19:40.020Z</updated>
        <summary type="html"><![CDATA[Rafael B. Audibert, Henrique Lemos, Pedro Avelar, Anderson R. Tavares,
  Lu\'is C. Lamb]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chain of LoRA: Efficient Fine-tuning of Language Models via Residual
  Learning]]></title>
        <id>http://arxiv.org/abs/2401.04151</id>
        <link href="http://arxiv.org/abs/2401.04151"/>
        <updated>2024-01-10T06:20:28.336Z</updated>
        <summary type="html"><![CDATA[Wenhan Xia, Chengwei Qin, Elad Hazan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal rates of approximation by shallow ReLU$^k$ neural networks and
  applications to nonparametric regression]]></title>
        <id>http://arxiv.org/abs/2304.01561</id>
        <link href="http://arxiv.org/abs/2304.01561"/>
        <updated>2024-01-10T06:20:28.287Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes
  based on a Hybrid Spectral Method and the Harmonic Oscillator]]></title>
        <id>http://arxiv.org/abs/2302.09580</id>
        <link href="http://arxiv.org/abs/2302.09580"/>
        <updated>2024-01-10T06:20:28.275Z</updated>
        <summary type="html"><![CDATA[Dionissios T.Hristopulos]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[General-Purpose In-Context Learning by Meta-Learning Transformers]]></title>
        <id>http://arxiv.org/abs/2212.04458</id>
        <link href="http://arxiv.org/abs/2212.04458"/>
        <updated>2024-01-10T06:20:28.252Z</updated>
        <summary type="html"><![CDATA[Louis Kirsch, James Harrison, Jascha Sohl-Dickstein, Luke Metz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal Consistency of Wide and Deep ReLU Neural Networks and Minimax
  Optimal Convergence Rates for Kolmogorov-Donoho Optimal Function Classes]]></title>
        <id>http://arxiv.org/abs/2401.04286</id>
        <link href="http://arxiv.org/abs/2401.04286"/>
        <updated>2024-01-10T06:20:28.249Z</updated>
        <summary type="html"><![CDATA[Hyunouk Ko, Xiaoming Huo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
</feed>