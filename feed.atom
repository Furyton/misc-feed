<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-05-28T10:14:28.533Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Chickee cakes]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58803</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58803&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chickee-cakes"/>
        <updated>2023-05-28T03:27:05.000Z</updated>
        <summary type="html"><![CDATA[Taken at a restaurant in¬†Hangzhou: The big Chinese characters say: Cant. gai1zai2 beng2¬† MSM¬† jƒ´z«éi b«êng È∏°‰ªîÈ•º "phoenix cookie" This is a type of chewy biscuit made with lard, originating in¬†Guangzhou¬†/ Canton.¬† (source)¬† Its original name was¬†Cant. siu2fung6¬†beng2¬†¬†MSM¬†xi«éof√®ng b«êng¬†Â∞èÈ≥≥È§Ö¬†("little phoenix cake"). Here are some¬†recipes for "phoenix cookies".¬† I noticed plenty of fat and sesame, peanuts, [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Natural nested sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53091</id>
        <link href="https://xianblog.wordpress.com/2023/05/28/natural-nested-sampling/"/>
        <updated>2023-05-27T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[‚ÄúThe nested sampling algorithm solves otherwise challenging, high-dimensional integrals by evolving a collection of live points through parameter space. The algorithm was immediately adopted in cosmology because it partially overcomes three of the major difficulties in Markov chain Monte Carlo, the algorithm traditionally used for Bayesian computation. Nested sampling simultaneously returns results for model comparison [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[on control variates]]></title>
        <id>http://xianblog.wordpress.com/?p=52378</id>
        <link href="https://xianblog.wordpress.com/2023/05/27/on-control-variates/"/>
        <updated>2023-05-26T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[A few months ago, I had to write a thesis evaluation of R√©mi Leluc‚Äôs PhD, which contained several novel Monte Carlo proposals on control variates and importance techniques. For instance, Leluc et al. (Statistics and Computing, 2021) revisits the concept of control variables by adding a perspective of control variable selection using LASSO. This prior [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Foundation models for reasoning on charts]]></title>
        <id>http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html</id>
        <link href="http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html"/>
        <updated>2023-05-26T19:08:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Julian Eisenschlos, Research Software Engineer, Google Research





Visual language is the form of communication that relies on pictorial symbols outside of text to convey information. It is ubiquitous in our digital life in the form of iconography, infographics, tables, plots, and charts, extending to the real world in street signs, comic books, food labels, etc. For that reason, having computers better understand this type of media can help with scientific communication and discovery, accessibility, and data transparency.
 

While computer vision models have made tremendous progress using learning-based solutions since the advent of ImageNet, the focus has been on natural images, where all sorts of tasks, such as classification, visual question answering (VQA), captioning, det‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Barkour: Benchmarking animal-level agility with quadruped robots]]></title>
        <id>http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html</id>
        <link href="http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html"/>
        <updated>2023-05-26T16:58:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ken Caluwaerts and Atil Iscen, Research Scientists, Google





Creating robots that exhibit robust and dynamic locomotion capabilities, similar to animals or humans, has been a long-standing goal in the robotics community. In addition to completing tasks quickly and efficiently, agility allows legged robots to move through complex environments that are otherwise difficult to traverse. Researchers at Google have been pursuing agility for multiple years and across various form factors. Yet, while researchers have enabled robots to hike or jump over some obstacles, there is still no generally accepted benchmark that comprehensively measures robot agility or mobility. In contrast, benchmarks are driving forces behind the development of machine learning, such as ImageNet for computer‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Insults, oaths, and curses in the Middle Ages]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58791</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58791&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=insults-oaths-and-curses-in-the-middle-ages"/>
        <updated>2023-05-26T12:37:34.000Z</updated>
        <summary type="html"><![CDATA[From Medievalists.net: "By God‚Äôs Bones: Medieval Swear Words" What were bad words in the Middle Ages? Cursing or swearing in medieval England was really different from today‚Äôs world. May, 2023 The post begins: Some historians have looked into the topic, such as Melissa Mohr, the author of¬†Holy Sh*t: A Brief History of Swearing. In her [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A theory of representation learning gives a deep generalisation of
  kernel methods]]></title>
        <id>http://arxiv.org/abs/2108.13097</id>
        <link href="http://arxiv.org/abs/2108.13097"/>
        <updated>2023-05-26T02:32:49.402Z</updated>
        <summary type="html"><![CDATA[Adam X. Yang, Maxime Robeyns, Edward Milsom, Ben Anson, Nandi Schoots,
  Laurence Aitchison]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment]]></title>
        <id>http://arxiv.org/abs/2304.06767</id>
        <link href="http://arxiv.org/abs/2304.06767"/>
        <updated>2023-05-26T02:32:49.394Z</updated>
        <summary type="html"><![CDATA[Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng
  Zhang, Kashun Shum, Tong Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Theoretical Guarantees of Learning Ensembling Strategies with
  Applications to Time Series Forecasting]]></title>
        <id>http://arxiv.org/abs/2305.15786</id>
        <link href="http://arxiv.org/abs/2305.15786"/>
        <updated>2023-05-26T02:32:49.374Z</updated>
        <summary type="html"><![CDATA[Hilaf Hasson, Danielle C. Maddix, Yuyang Wang, Gaurav Gupta, Youngsuk
  Park]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memory-Based Meta-Learning on Non-Stationary Distributions]]></title>
        <id>http://arxiv.org/abs/2302.03067</id>
        <link href="http://arxiv.org/abs/2302.03067"/>
        <updated>2023-05-26T02:32:49.365Z</updated>
        <summary type="html"><![CDATA[Tim Genewein, Gr\'egoire Del\'etang, Anian Ruoss, Li Kevin Wenliang,
  Elliot Catt, Vincent Dutordoir, Jordi Grau-Moya, Laurent Orseau, Marcus
  Hutter, Joel Veness]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Neural Network Layers Promote Learning Single- and Multiple-Index
  Models]]></title>
        <id>http://arxiv.org/abs/2305.15598</id>
        <link href="http://arxiv.org/abs/2305.15598"/>
        <updated>2023-05-26T02:32:49.357Z</updated>
        <summary type="html"><![CDATA[Suzanna Parkinson, Greg Ongie, Rebecca Willett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially private clustering for large-scale datasets]]></title>
        <id>http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html</id>
        <link href="http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html"/>
        <updated>2023-05-25T23:09:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Vincent Cohen-Addad and  Alessandro Epasto, Research Scientists, Google Research, Graph Mining team




Clustering is a central problem in unsupervised machine learning (ML) with many applications across domains in both industry and academic research more broadly. At its core, clustering consists of the following problem: given a set of data elements, the goal is to partition the data elements into groups such that similar objects are in the same group, while dissimilar objects are in different groups. This problem has been studied in math, computer science, operations research and statistics for more than 60 years in its myriad variants. Two common forms of clustering are metric clustering, in which the elements are points in a metric space, like in the k-means problem, and grap‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EMS 2023, Warsaw]]></title>
        <id>http://xianblog.wordpress.com/?p=53085</id>
        <link href="https://xianblog.wordpress.com/2023/05/26/ems-2023-warsaw/"/>
        <updated>2023-05-25T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google Research at I/O 2023]]></title>
        <id>http://ai.googleblog.com/2023/05/google-research-at-io-2023.html</id>
        <link href="http://ai.googleblog.com/2023/05/google-research-at-io-2023.html"/>
        <updated>2023-05-25T17:03:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by James Manyika, SVP Google Research and Technology & Society, and Jeff Dean, Chief Scientist, Google DeepMind and Google Research




Wednesday, May 10th was an exciting day for the Google Research community as we watched the results of months and years of our foundational and applied work get announced on the Google I/O stage. With the quick pace of announcements on stage, it can be difficult to convey the substantial effort and unique innovations that underlie the technologies we presented. So today, we‚Äôre excited to reveal more about the research efforts behind some of the many exciting announcements at this year's I/O. 


 

PaLM 2 
PaLM 2, is built on advances in compute-optimal scaling, scaled instruction-fine tuning and improved dataset mixture. By fine-tuning and instructi‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Failure to Launch"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58795</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58795&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=failure-to-launch"/>
        <updated>2023-05-25T12:19:56.000Z</updated>
        <summary type="html"><![CDATA[Along with half a million other people, I logged onto Twitter at the designated hour to hear Elon Musk help Ron DeSantis announce his run for U.S. President. After about half an hour of¬† noises, silences, and puzzling graphics, I gave up ‚Äî too early to catch the restart on a different account. This event [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Master the essence of solid"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58775</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58775&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=master-the-essence-of-solid"/>
        <updated>2023-05-25T08:48:28.000Z</updated>
        <summary type="html"><![CDATA[From the website for Royal China Group, a famous Chinese restaurant group in London: The problem begins at the beginning:¬† jingcui¬†Á≤æÁ≤π does not mean "master"; it means "essence". The entire text reads as follows: Zh≈çnggu√≥ y«ênsh√≠ w√©nhu√† b√≥d√†jƒ´ngshƒìn,Hu√°ngch√°o n«îl√¨ b√πxi√® y√°nsh«íu zh√®ngz≈çng chu√°nt«íng Yu√®c√†i de fƒìngg√©,b√¨ng z√†i w√®iju√© de l«êngy√π zh≈çng x√∫nqi√∫ t√∫p√≤,zh«éngw√≤ g√πzh≈çng jƒ´ngcu√¨ [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test your intuition 52: Can you predict the ratios of ones?]]></title>
        <id>http://gilkalai.wordpress.com/?p=24359</id>
        <link href="https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/"/>
        <updated>2023-05-25T08:33:58.000Z</updated>
        <summary type="html"><![CDATA[Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice‚Äôs task is to choose, at a certain time of her choice, some number (smaller than the number of unseen ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test your intuition 52: Can you predict the ratios of ones?]]></title>
        <id>http://gilkalai.wordpress.com/?p=24359</id>
        <link href="https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/"/>
        <updated>2023-05-25T08:33:58.000Z</updated>
        <summary type="html"><![CDATA[Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice‚Äôs task is to choose, at a certain time of her choice, some number (smaller than the number of unseen ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning for Survival Analysis: A Review]]></title>
        <id>http://arxiv.org/abs/2305.14961</id>
        <link href="http://arxiv.org/abs/2305.14961"/>
        <updated>2023-05-25T07:13:51.339Z</updated>
        <summary type="html"><![CDATA[Simon Wiegrebe, Philipp Kopper, Raphael Sonabend, Andreas Bender]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Masked Bayesian Neural Networks : Theoretical Guarantee and its
  Posterior Inference]]></title>
        <id>http://arxiv.org/abs/2305.14765</id>
        <link href="http://arxiv.org/abs/2305.14765"/>
        <updated>2023-05-25T07:13:51.311Z</updated>
        <summary type="html"><![CDATA[Insung Kong, Dongyoon Yang, Jongjin Lee, Ilsang Ohn, Gyuseung Baek,
  Yongdai Kim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Rate Free Bayesian Inference in Constrained Domains]]></title>
        <id>http://arxiv.org/abs/2305.14943</id>
        <link href="http://arxiv.org/abs/2305.14943"/>
        <updated>2023-05-25T07:13:51.252Z</updated>
        <summary type="html"><![CDATA[Louis Sharrock, Lester Mackey, Christopher Nemeth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Rigorous Link between Deep Ensembles and (Variational) Bayesian
  Methods]]></title>
        <id>http://arxiv.org/abs/2305.15027</id>
        <link href="http://arxiv.org/abs/2305.15027"/>
        <updated>2023-05-25T07:13:50.477Z</updated>
        <summary type="html"><![CDATA[Veit David Wild, Sahra Ghalebikesabi, Dino Sejdinovic, Jeremias
  Knoblauch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test like you Train in Implicit Deep Learning]]></title>
        <id>http://arxiv.org/abs/2305.15042</id>
        <link href="http://arxiv.org/abs/2305.15042"/>
        <updated>2023-05-25T07:13:50.461Z</updated>
        <summary type="html"><![CDATA[Zaccharie Ramzi, Pierre Ablin, Gabriel Peyr\'e, Thomas Moreau]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An early warning system for novel AI risks]]></title>
        <id>https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks</id>
        <link href="https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks"/>
        <updated>2023-05-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[AI researchers already use a range of evaluation benchmarks to identify unwanted behaviours in AI systems, such as AI systems making misleading statements, biased decisions, or repeating copyrighted content. Now, as the AI community builds and deploys increasingly powerful AI, we must expand the evaluation portfolio to include the possibility of extreme risks from general-purpose AI models that have strong skills in manipulation, deception, cyber-offense, or other dangerous capabilities.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stochastic Numerics and Statistical Learning]]></title>
        <id>http://xianblog.wordpress.com/?p=53075</id>
        <link href="https://xianblog.wordpress.com/2023/05/25/stochastic-numerics-and-statistical-learning/"/>
        <updated>2023-05-24T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[This week, I am taking part in the Stochastic Numerics and Statistical Learning workshop, in KAUST, which should prove an interesting experience!]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Decipherment of Linear A]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58786</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58786&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=decipherment-of-linear-a"/>
        <updated>2023-05-24T11:14:27.000Z</updated>
        <summary type="html"><![CDATA[Methodologically, the following communication from Elizabeth J. W. Barber is too important to be left buried in a comment to this post:¬† "ChatGPT does cuneiform studies" (5/21/23) As I showed in my 1974 book, Archaeological Decipherment, there is a mathematical algorithm showing how much text one needs to PROVABLY accomplish a decipherment for what sort [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mind the spikes: Benign overfitting of kernels and neural networks in
  fixed dimension]]></title>
        <id>http://arxiv.org/abs/2305.14077</id>
        <link href="http://arxiv.org/abs/2305.14077"/>
        <updated>2023-05-24T07:13:44.399Z</updated>
        <summary type="html"><![CDATA[Moritz Haas, David Holzm\"uller, Ulrike von Luxburg, Ingo Steinwart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The CoT Collection: Improving Zero-shot and Few-shot Learning of
  Language Models via Chain-of-Thought Fine-Tuning]]></title>
        <id>http://arxiv.org/abs/2305.14045</id>
        <link href="http://arxiv.org/abs/2305.14045"/>
        <updated>2023-05-24T07:13:44.392Z</updated>
        <summary type="html"><![CDATA[Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye,
  Jamin Shin, Minjoon Seo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding]]></title>
        <id>http://arxiv.org/abs/2305.14196</id>
        <link href="http://arxiv.org/abs/2305.14196"/>
        <updated>2023-05-24T07:13:44.382Z</updated>
        <summary type="html"><![CDATA[Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, Omer
  Levy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning with Kernels through RKHM and the Perron-Frobenius
  Operator]]></title>
        <id>http://arxiv.org/abs/2305.13588</id>
        <link href="http://arxiv.org/abs/2305.13588"/>
        <updated>2023-05-24T07:13:44.376Z</updated>
        <summary type="html"><![CDATA[Yuka Hashimoto, Masahiro Ikeda, Hachem Kadri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transferring Learning Trajectories of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.14122</id>
        <link href="http://arxiv.org/abs/2305.14122"/>
        <updated>2023-05-24T07:13:44.370Z</updated>
        <summary type="html"><![CDATA[Daiki Chijiwa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Choosing a good file format for Pandas]]></title>
        <id>https://pythonspeed.com/articles/best-file-format-for-pandas/</id>
        <link href="https://pythonspeed.com/articles/best-file-format-for-pandas/"/>
        <updated>2023-05-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Before you can process your data with Pandas, you need to load it (from disk or remote storage).
There are plenty of data formats supported by Pandas, from CSV, to JSON, to Parquet, and many others as well.
Which should you use?
You don‚Äôt want loading the data to be slow, or use lots of memory: that‚Äôs pure overhead.
Ideally you‚Äôd want a file format that‚Äôs fast, efficient, small, and broadly supported.
You also want to make sure the loaded data has all the right types: numeric types, datetimes, and so on.
Some data formats do a better job at this than others.
While there is no one true answer that works for everyone, this article will try to help you narrow down the field and make an informed decision.
Read more...]]></summary>
        <author>
            <name>Python‚áíSpeed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[art brut]]></title>
        <id>http://xianblog.wordpress.com/?p=53022</id>
        <link href="https://xianblog.wordpress.com/2023/05/24/art-brut-90/"/>
        <updated>2023-05-23T22:23:05.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resolving code review comments with ML]]></title>
        <id>http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html</id>
        <link href="http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html"/>
        <updated>2023-05-23T17:51:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Alexander Fr√∂mmgen, Staff Software Engineer, and Lera Kharatyan, Senior Software Engineer, Core Systems & Experiences


  

Code-change reviews are a critical part of the software development process at scale, taking a significant amount of the code authors‚Äô and the code reviewers‚Äô time. As part of this process, the reviewer inspects the proposed code and asks the author for code changes through comments written in natural language. At Google, we see millions of reviewer comments per year, and authors require an average of ~60 minutes active shepherding time between sending changes for review and finally submitting the change. In our measurements, the required active work time that the code author must do to address reviewer comments grows almost linearly with the number of comme‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPT-4 + Stable-Diffusion = ?: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models]]></title>
        <id>http://bair.berkeley.edu/blog/2023/05/23/lmd/</id>
        <link href="http://bair.berkeley.edu/blog/2023/05/23/lmd/"/>
        <updated>2023-05-23T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[TL;DR: Text Prompt -> LLM -> Intermediate Representation (such as an image layout) -> Stable Diffusion -> Image.
Recent advancements in text-to-image generation with diffusion models have yielded remarkable results synthesizing highly realistic and diverse images. However, despite their impressive capabilities, diffusion models, such as Stable Diffusion, often struggle to accurately follow the prompts when spatial or common sense reasoning is required.
The following figure lists four scenarios in which Stable Diffusion falls short in generating images that accurately correspond to the given prompts, namely negation, numeracy, and attribute assignment, spatial relationships. In contrast, our method, LLM-grounded Diffusion (LMD), delivers much better prompt understanding in text-to-image gen‚Ä¶]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yann LeCun - Towards Machines that can Learn, Reason, and Plan.]]></title>
        <id>https://mlfoundations.org/talk/lecun/</id>
        <link href="https://mlfoundations.org/talk/lecun/"/>
        <updated>2023-05-23T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[How could machines learn as efficiently as humans and animals? How could machines learn how the world works and acquire common sense? How could machines learn to reason and plan? Current AI architectures, such as Auto-Regressive Large Language Models fall short.  I will propose a modular cognitive architecture that may constitute a path towards answering these questions.  The centerpiece of the architecture is a predictive world model that allows the system to predict the consequences of its actions and to plan a sequence of actions that optimize a set of objectives. The world model employs a Hierarchical Joint Embedding Predictive Architecture (H-JEPA) trained with self-supervised learning. The JEPA learns abstract representations of the percepts that are simultaneously maximally informative and maximally predictable. The corresponding working paper is available here - [A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chinese characters and the messiness of Chinese culture]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58781</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58781&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chinese-characters-and-the-messiness-of-chinese-culture"/>
        <updated>2023-05-23T10:57:23.000Z</updated>
        <summary type="html"><![CDATA[Is it really so? Uncannily and independently, Apollo Wu* sent me the following note before I made this post: H√†nz√¨ b√πr√∫ pƒ´nyƒ´n de guƒÅnji√†n l«êngy√π sh√¨ p√°ix√π, ji«énsu«í h√© r√©ng≈çng zh√¨n√©ng. F√πz√°, f√°nsu«í, n√°n xu√© n√°n y√≤ng sh√¨ w«ímen m√πqi√°n mi√†nl√≠n de k√πnn√°n. H√†nz√¨ de lu√†n, biƒÅozh√¨zhe Zh≈çnggu√≥ w√©nhu√† de lu√†n! Ê±âÂ≠ó ÊØî‰∏ç‰∏ä Â≠óÊØçÊñáÂ≠ó ÁöÑ [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memorization and Optimization in Deep Neural Networks with Minimum
  Over-parameterization]]></title>
        <id>http://arxiv.org/abs/2205.10217</id>
        <link href="http://arxiv.org/abs/2205.10217"/>
        <updated>2023-05-23T07:13:42.300Z</updated>
        <summary type="html"><![CDATA[Simone Bombari, Mohammad Hossein Amani, Marco Mondelli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Discriminative to Kernel Generative Networks for Calibrated
  Inference]]></title>
        <id>http://arxiv.org/abs/2201.13001</id>
        <link href="http://arxiv.org/abs/2201.13001"/>
        <updated>2023-05-23T07:13:42.293Z</updated>
        <summary type="html"><![CDATA[Jayanta Dey, Haoyin Xu, Ashwin De Silva, Will LeVine, Tyler M. Tomita,
  Ali Geisa, Tiffany Chu, Jacob Desman, Joshua T. Vogelstein]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Counterfactual Explanations for Neural Networks With
  Probabilistic Guarantees]]></title>
        <id>http://arxiv.org/abs/2305.11997</id>
        <link href="http://arxiv.org/abs/2305.11997"/>
        <updated>2023-05-23T07:13:42.269Z</updated>
        <summary type="html"><![CDATA[Faisal Hamman, Erfaun Noorani, Saumitra Mishra, Daniele Magazzeni,
  Sanghamitra Dutta]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Not All Semantics are Created Equal: Contrastive Self-supervised
  Learning with Automatic Temperature Individualization]]></title>
        <id>http://arxiv.org/abs/2305.11965</id>
        <link href="http://arxiv.org/abs/2305.11965"/>
        <updated>2023-05-23T07:13:42.257Z</updated>
        <summary type="html"><![CDATA[Zi-Hao Qiu, Quanqi Hu, Zhuoning Yuan, Denny Zhou, Lijun Zhang, Tianbao
  Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive and Robust Multi-Task Learning]]></title>
        <id>http://arxiv.org/abs/2202.05250</id>
        <link href="http://arxiv.org/abs/2202.05250"/>
        <updated>2023-05-23T07:13:42.204Z</updated>
        <summary type="html"><![CDATA[Yaqi Duan, Kaizheng Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NBCEÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÊãìÂ±ïLLMÁöÑContextÂ§ÑÁêÜÈïøÂ∫¶]]></title>
        <id>https://kexue.fm/archives/9617</id>
        <link href="https://kexue.fm/archives/9617"/>
        <updated>2023-05-23T02:45:00.000Z</updated>
        <summary type="html"><![CDATA[Âú®LLMÊó∂‰ª£ËøòÁé©Êú¥Á¥†Ë¥ùÂè∂ÊñØÔºàNaive BayesÔºâÔºüËøôÂèØËÉΩÊòØËÆ∏Â§öËØªËÄÖÂú®ÁúãÂà∞Ê†áÈ¢òÂêéÁöÑÈ¶ñ‰∏™ÊÉ≥Ê≥ï„ÄÇÁ°ÆÂÆûÂ¶ÇÊ≠§ÔºåÂΩìÂè§ËÄÅÁöÑÊú¥Á¥†Ë¥ùÂè∂ÊñØ‰∏éÂâçÊ≤øÁöÑLLMÁõ∏ÈÅáÊó∂Ôºå‰∫ßÁîü‰∫Ü‰ª§‰∫∫ÊÉäËÆ∂ÁöÑÊïàÊûú‚Äî‚ÄîÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•ÊèêÂçáÁé∞ÊúâLLM...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bernoulli factory on a budget]]></title>
        <id>http://xianblog.wordpress.com/?p=53038</id>
        <link href="https://xianblog.wordpress.com/2023/05/23/bernoulli-factory-on-a-budget/"/>
        <updated>2023-05-22T22:23:22.000Z</updated>
        <summary type="html"><![CDATA[A form of Bernoulli factory with limited energy from The Riddler: being given the choice of 0<p<1, what is the minimal number n of throws such that the outcomes of n iid B(p) draws can be partitioned into six groups of equal probability? Running a brute force R code [in the train to Cambridge] and [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning sinitic and sinoglyphic "zero"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58778</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58778&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=learning-sinitic-and-sinoglyphic-zero"/>
        <updated>2023-05-22T12:00:04.000Z</updated>
        <summary type="html"><![CDATA[Plus Indic, plus Arabic, Korean, Vietnamese, Hokkien (Taiwanese), Hakka, and Fuzhou (Eastern Min). For an exciting read / ride, be sure to follow the whole thread, travelling through time and space. Èõ∂ originally didn't mean 'zero,' but 'small rain, drizzle.' Makes it easy to learn: Rain Èõ® above, pronunciation ‰ª§ below (ok, tone is different). [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-Shot Continual Learning for Conditional Generative Adversarial
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.11400</id>
        <link href="http://arxiv.org/abs/2305.11400"/>
        <updated>2023-05-22T08:19:27.936Z</updated>
        <summary type="html"><![CDATA[Cat P. Le, Juncheng Dong, Ahmed Aloui, Vahid Tarokh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-learning for heterogeneous treatment effect estimation with
  closed-form solvers]]></title>
        <id>http://arxiv.org/abs/2305.11353</id>
        <link href="http://arxiv.org/abs/2305.11353"/>
        <updated>2023-05-22T08:19:27.389Z</updated>
        <summary type="html"><![CDATA[Tomoharu Iwata, Yoichi Chikahara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Real-Time Variational Method for Learning Neural Trajectory and its
  Dynamics]]></title>
        <id>http://arxiv.org/abs/2305.11278</id>
        <link href="http://arxiv.org/abs/2305.11278"/>
        <updated>2023-05-22T08:19:27.383Z</updated>
        <summary type="html"><![CDATA[Matthew Dowling, Yuan Zhao, Il Memming Park]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incorporating Unlabelled Data into Bayesian Neural Networks]]></title>
        <id>http://arxiv.org/abs/2304.01762</id>
        <link href="http://arxiv.org/abs/2304.01762"/>
        <updated>2023-05-22T08:19:27.328Z</updated>
        <summary type="html"><![CDATA[Mrinank Sharma, Tom Rainforth, Yee Whye Teh, Vincent Fortuin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Out of the box acceleration and memory savings of ü§ó decoder models with PyTorch 2.0]]></title>
        <id>https://pytorch.org/blog/out-of-the-box-acceleration/</id>
        <link href="https://pytorch.org/blog/out-of-the-box-acceleration/"/>
        <updated>2023-05-22T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[As part of PyTorch 2.0 release, an accelerated implementation of the attention mechanism as part of the ‚ÄúBetter Transformer‚Äù project (and known in PyTorch as Accelerated Transformers) has been added natively into PyTorch as torch.nn.functional.scaled_dot_product_attention. This implementation leverages fused kernels from FlashAttention and Memory-efficient attention, and supports both training and inference.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Italy no-no‚Äôs]]></title>
        <id>http://xianblog.wordpress.com/?p=52979</id>
        <link href="https://xianblog.wordpress.com/2023/05/22/italy-no-nos/"/>
        <updated>2023-05-21T22:23:12.000Z</updated>
        <summary type="html"><![CDATA[The Lonely Planet blog has a list of prohibitions on tourists‚Äô activities when visiting some Italian cities. Like Venice, Rome or Milan (below). Most of which is sort of obvious, like not walking around shirtless or barefoot away from beaches, feed the pigeons (although our kids did when visiting Venice for the first time!), hold [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hack of the year: 1980]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58767</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58767&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hack-of-the-year-1980"/>
        <updated>2023-05-21T15:00:41.000Z</updated>
        <summary type="html"><![CDATA[I recently stumbled on this 5/10/2023 Medium article by David Brock, "A Backup of Historical Proportions" ‚Äî which reminded me of the Xerox Palo Alto Research Center ("PARC") and the Xerox Alto. Those were the people and the machine that invented interactive GUIs on bit-mapped displays, the computer mouse, and so on ‚Äî though it [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT does cuneiform studies]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58745</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58745&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-does-cuneiform-studies"/>
        <updated>2023-05-21T10:32:21.000Z</updated>
        <summary type="html"><![CDATA[We have seen ChatGPT tell stories (and variants of the stories it tells), fancify Coleridge's famous poem on Xanadu, pose a serious challenge to the Great Firewall of China, mimic VHM, write Haiku, and perform all manner of amazing feats.¬† In a forthcoming post, we will witness its efforts to translate Chinese poetry.¬† Today, we [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[foxhuntshire]]></title>
        <id>http://xianblog.wordpress.com/?p=53034</id>
        <link href="https://xianblog.wordpress.com/2023/05/21/foxhuntshire/"/>
        <updated>2023-05-20T22:23:42.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ch√¢teau Balac [Haut-M√©doc]]]></title>
        <id>http://xianblog.wordpress.com/?p=52447</id>
        <link href="https://xianblog.wordpress.com/2023/05/20/chateau-balac-haut-medoc/"/>
        <updated>2023-05-20T18:20:23.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI comic strip creation?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58752</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58752&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-comic-strip-creation"/>
        <updated>2023-05-20T15:02:30.000Z</updated>
        <summary type="html"><![CDATA[Today's Tank McNamara: Of course the joke in this strip is the seven fingers on Tank's right hand, and the eight fingers on his left hand. A quick web search for {ai comic generator} turns out lots of options. As far as I can tell, these are all systems for creating images, not image sequences [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Romanisation 'gives clarity'"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58734</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58734&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=romanisation-gives-clarity"/>
        <updated>2023-05-20T04:48:59.000Z</updated>
        <summary type="html"><![CDATA[As we have pointed out countless times on Language Log, if one wishes to learn a Sinitic language, one can concentrate on the characters (writing system), one can rely exclusively on romanization or other phoneticization, or one can devise various means for combining the two approaches.¬† Here is a clever, fun method for learning Cantonese [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPT as an ‚ÄúIntelligence Forklift.‚Äù]]></title>
        <id>http://windowsontheory.org/?p=8615</id>
        <link href="https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/"/>
        <updated>2023-05-19T21:16:17.000Z</updated>
        <summary type="html"><![CDATA[[See my¬†post with Edelman on AI takeover and¬†Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.] ¬†One challenge for considering the implications of ‚Äúartificial intelligence,‚Äù especially of the ‚Äúgeneral‚Äù variety, is that we don‚Äôt have a consensus definition of intelligence. The¬†Oxford Companion ‚Ä¶ Continue reading GPT as an ‚ÄúIntelligence Forklift.‚Äù]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPT as an ‚ÄúIntelligence Forklift.‚Äù]]></title>
        <id>http://windowsontheory.org/?p=8615</id>
        <link href="https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/"/>
        <updated>2023-05-19T21:16:17.000Z</updated>
        <summary type="html"><![CDATA[[See my¬†post with Edelman on AI takeover and¬†Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.] ¬†One challenge for considering the implications of ‚Äúartificial intelligence,‚Äù especially of the ‚Äúgeneral‚Äù variety, is that we don‚Äôt have a consensus definition of intelligence. The¬†Oxford Companion ‚Ä¶ Continue reading GPT as an ‚ÄúIntelligence Forklift.‚Äù]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[‰∫íËÅîÁΩëÊäÄÊúØÊØîÊ∏∏ÊàèÂêéÁ´ØÊäÄÊúØÈ¢ÜÂÖàÂçÅÂπ¥ÂêóÔºü]]></title>
        <id>https://www.skywind.me/blog/?p=2719</id>
        <link href="https://www.skywind.me/blog/archives/2719"/>
        <updated>2023-05-19T17:14:00.000Z</updated>
        <summary type="html"><![CDATA[ÊúÄËøëÊó∂Èó¥Á∫ø‰∏äÁúãÂà∞‰∏çÂ∞ë‰∫∫Âú®ËÆ∫ÊàòÔºåÂÅö‰∫íËÅîÁΩëÁöÑ‰∫∫ËßâÂæóÊ∏∏ÊàèÊúçÂä°Á´ØÂèëÂ±ïÂæàÊÖ¢ÔºåËÄå‰∫íËÅîÁΩëÊäÄÊúØÊó•Êñ∞ÊúàÂºÇÔºåËßâÂæó‰ºº‰πé‰∫íËÅîÁΩëÊäÄÊúØÈ¢ÜÂÖà‰∫ÜÊ∏∏ÊàèÂêéÁ´ØÊäÄÊúØÂçÅÂπ¥ÔºåËøô‰∏™ÁªìËÆ∫ÊòæÁÑ∂ÊòØÊ≠¶Êñ≠ÁöÑÔºå‰∫íËÅîÁΩëÂ∞±ÊòØÂèëÂ±ïÂà∞‰ªäÂ§©ÔºåÂ∞±ÊòØ‰ªªÊÑè‰∏ÄÂè∞‰∫íËÅîÁΩëÁöÑÊúçÂä°Âô®ÊãøÂá∫Êù•ÔºåÂÖ∂Â§çÊùÇÂ∫¶‰πüËøúËøúÊØî‰∏ç‰∏äÊ∏∏ÊàèÊúçÂä°Âô®ÔºåÂç≥‰æøÂêÑÁßç C/C++ ÂºÄÂèëÁöÑ‰∫íËÅîÁΩëÂü∫Âª∫È°πÁõÆ„ÄÇ ÂêåÊó∂Ê≤°ÊúâÊÑèËØÜÂà∞Ê∏∏ÊàèÁé©ÂÆ∂‰πãÈó¥‰∫§‰∫íÊÄßÁöÑÂ§çÊùÇÊÄß‰∏éÂÆûÊó∂ÊÄßÊòØÂ§ßÈÉ®ÂàÜ‰∫íËÅîÁΩëÈ°πÁõÆÊó†Ê≥ïÊØîËæÉÁöÑ„ÄÇËØùÂàÜ‰∏§Â§¥ËØ¥ÔºåÁúãÂà∞‰∏Ä‰∫õÂÅöÊ∏∏ÊàèÂêéÁ´ØÁöÑÂêåÂ≠¶ËßâÂæó‰∫íËÅîÁΩëÊõ¥ÁÆÄÂçïÔºåÁîµÂïÜ‰πãÁ±ªÁöÑÊõ¥ÊòØ CRUD ÁöÑÂ¢ûÂà†ÊîπÊü•ÔºåÊØîËµ∑Ê∏∏ÊàèÊúçÂä°Âô®ËêΩÂêéÂçÅÂπ¥‰∏çÊ≠¢„ÄÇ ÊàëËßâÂæóÊ∏∏ÊàèÊúçÂä°Á´ØÁöÑÂêåÂ≠¶ÂÆûÂ±ûÊ≤°ÂøÖË¶ÅÂíåËøô‰∏™‰∫íËÅîÁΩëÁöÑ‰∫∫‰∏ÄËà¨ËßÅËØÜÔºå‰∏çÁÆ°‰∏çÈ°æÁöÑ‰πüË∑üÁùÄËØ¥‰ªÄ‰πàÊ∏∏ÊàèÊúçÂä°Á´ØÊØî‰∫íËÅîÁΩëÂÖàËøõÂçÅÂπ¥‰ªÄ‰πàÁöÑÔºåËøôÊòØÂè¶‰∏Ä‰∏™ÊûÅÁ´Ø‰∫ÜÔºå‰∏Ä‰∫õÊÉÖÂÜµ‰πüÈúÄË¶ÅÊ≠£ËßÜÔºö 1ÔºâÊ∏∏ÊàèÊúçÂä°Á´ØË∂≥Â§üÂ§çÊùÇÔºå‰ΩÜÊòØÂèëÂ±ïÂ§™ÊÖ¢ÔºåÁ•ñ‰º†‰ª£Á†Å‰øÆ‰øÆË°•Ë°•Ë∑ë‰∏™ÂçÅÂ§öÂπ¥ÁöÑ‰∏çË¶ÅÂ§™Â§ö„ÄÇËÉΩÁî®Âõ∫ÁÑ∂ÊòØÂ•Ω‰∫ãÔºå‰ΩÜÊ≤°ÊúâÊñ∞ËßÇÂøµÁöÑÂºïÂÖ•ÔºåÂØºËá¥ÂèØÁî®ÊÄßÂíåÂºÄÂèëÊïàÁéá‰∏ÄÁõ¥Ê≤°ÊúâÂ§™Â§öÊèêÂçá„ÄÇ 2ÔºâÂêÑËá™Èó≠Èó®ÈÄ†ËΩ¶ÔºåÊ≤°ÊúâÂΩ¢ÊàêË°å‰∏öÊ†áÂáÜ‰∏éÂêàÂäõÔºåËøô‰∏™È°πÁõÆÁöÑ‰ª£Á†ÅÔºåÂæàÈöæÂú®Âè¶‰∏Ä‰∏™È°πÁõÆÂÖ±‰∫´ÔºåÁõ∏‰∫í‰πãÈó¥Áº∫Â∞ëÊîØÊåÅÂíåÂçèÂêå„ÄÇ 3Ôºâ‰∫íËÅîÁΩëÂêéÁ´ØÈöè‰æøÊãéÂá∫‰∏Ä‰∏™ÊúçÂä°Êù•ÔºàÂåÖÊã¨ÂêÑÁßç C/C++ Âü∫Âª∫ÔºâÂ§ßÊ¶ÇÁéáÈÉΩÊ≤°ÊúâÊ∏∏ÊàèÊúçÂä°Á´ØÂ§çÊùÇÔºå‰ΩÜÊúÄËøëÂçÅÂπ¥Êó•Êñ∞ÊúàÂºÇÔºåÂΩ¢Êàê‰∫ÜÂæàÂº∫ÁöÑ‰∫íÁõ∏ÁªÑÂêà‰∫íÁõ∏Â¢ûÂº∫ÁöÑÊÄÅÂäø„ÄÇ Êàë‰∏äÈù¢ÊåáÁöÑÊòØ‰∫íËÅîÁΩëÂü∫Âª∫È°πÁõÆÔºå‰∏çÊòØ‰∫íËÅîÁΩë CRUDÔºåÂÆûËØùÂÆûËØ¥ÔºåÊ∏∏ÊàèÊúçÂä°Âô®ÁöÑÁ°ÆÂæàÂ§çÊùÇÂæàÈöæÔºåÂèØËÉΩ ARPG ÈáåÁ†ç‰∏ÄÂàÄËøôÁßçÂ∞è‰∫ãÊÉÖÔºåÊÉ≥Á†çÁöÑÊúâÊâãÊÑüÔºåÂÅö‰∫íËÅîÁΩëÁöÑ‰πü‰∏ç‰∏ÄÂÆöËÉΩÁêÜËß£ËÉåÂêéÁöÑÂ§çÊùÇÂ∫¶ÊúâÂ§öÂ∞ë„ÄÇ‰ΩÜ‰∫íËÅîÁΩëËøëÂçÅÂπ¥ÁöÑÂèëÂ±ïÔºåËÆ©ÂÖ∂Êï¥‰ΩìÂèØÁî®ÊÄßÔºåÊïàËÉΩÔºåÂºÄÂèëÊïàÁéáÔºåÈÉΩ‰∏ä‰∫ÜÂæàÂ§ö‰∏™Âè∞Èò∂Ôºå‰∏çÂ∫î‰∏ÄÂë≥ÂøΩËßÜ„ÄÇ Â¶ÇÊûúÁªßÁª≠ËßâÂæóÊ∏∏ÊàèÊúçÂä°Á´ØÈ¢ÜÂÖà‰∫íËÅîÁΩëÂçÅÂπ¥ÂèØ‰ª•Áõ¥Êé•Âè≥ËΩ¨‰∫ÜÔºåÂºÄÊîæÂøÉÊÄÅÁöÑËØùÊàë‰πüÂèØ‰ª•Â§öËÅä‰∏Ä‰∫õÔºàÁÇπÂáª‰∏ãÊñπ more ÈòÖËØªÊõ¥Â§öÔºâÔºö ‰∏æ‰∏™‰æãÂ≠êÔºåÈü≥ËßÜÈ¢ëÈ¢ÜÂüüÁöÑÂü∫Âª∫ÔºåÂπ∂‰∏çÊØîÊ∏∏ÊàèÊúçÂä°Á´ØÁÆÄÂçïÔºö 1Ôºâ‰∏ÄË∑ØÈ´òÊ∏ÖËßÜÈ¢ë 720-1080p ÁöÑÔºåÂ∑Æ‰∏çÂ§öÊØèÁßíÈíü 2MB/s ÁöÑÊï∞ÊçÆÈáèÔºåÂêåÊó∂Âú®Á∫ø 100w ÁöÑÔºåÊï¥‰∏™ÁΩëÁªúÊØèÁßíÈíüËá≥Â∞ëÊúâ 2T/s ÁöÑÊï∞ÊçÆÈáèÂú®Ë∑ëÁùÄÔºå‰∏ç‰ΩÜ‰∏çÂàÜÊúçÔºåËÄå‰∏îÁé©ÂÆ∂ÈÅçÂ∏É‰∏ñÁïåÊØè‰∏™ËßíËêΩÔºåËøòË¶Å‰∏çÂç°‰∏çÊéâ‰∏çÂª∂ËøüÔºåËøô‰∏™Êï∞ÊçÆÈáèÊØîËµ∑Ê∏∏ÊàèÁöÑÊ∂àÊÅØË¶ÅÂ§ßÂ•ΩÂá†‰∏™Êï∞ÈáèÁ∫ßÂêßÔºüÂú®ÊääËøô 2T/s Êï∞ÊçÆÂÆâÊéíÊòéÁôΩÂ¶•ÂΩìÁöÑÂêåÊó∂ÔºåËøòÂæó‰øùËØÅÂª∂Ëøü‰∏çËÉΩË∂ÖËøá 500msÔºåË∂ÖËøáÂ∞±Ê≤°Ê≥ïÁé©‰∫Ü„ÄÇ 2Ôºâ‰∏Ä‰∏™ÊàøÈó¥ÁöÑ‰∫∫Êï∞Â∞ëÁöÑÊòØ 2-4 ‰∫∫ÔºåÂ§öÁöÑ‰∏äÂçÉ‰∫∫ÔºåÈÅçÂ∏É 4-5 ‰∏™ÂõΩÂÆ∂Ôºå‰Ω†‰∏ÄÂ±èÂπïÊâìÂºÄÔºåÂèØ‰ª•ÂêåÊó∂ÁúãÂà∞ 50 ‰∏™‰∫∫ÁöÑËßÜÈ¢ëÔºåËôΩÁÑ∂ÊòØÂ∞èÁ™óÂè£Ôºå‰ΩÜÊòØ‰Ω†Êãâ‰Ωè‰ªªÊÑèÂ∞èÁ™óÂè£ÔºåÂø´ÈÄüÊãâÂ§ßÂà∞ÂÖ®Â±èÔºåÁúã‰∏çÂà∞ÊòéÊòæÁöÑÊ∏ÖÊô∞Â∫¶Ê¢ØÂ∫¶ÂàáÊç¢Â∏¶Êù•ÁöÑÊäñÂä®ÔºåÂ¶Ç‰ΩïÂÆûÁé∞Âë¢Ôºü 3ÔºâÂÖ®ÁêÉ‰∏äÁôæ‰∏™Êú∫ÊàøÂçèÂêåÂ∑•‰ΩúÔºåÁªÑÊàê‰∏ÄÂº†ÂæàÂ§ßÁöÑÁΩëÁªúÔºå‰∏Ä‰ºöËøô‰∏™Êú∫ÊàøÂá∫ÈóÆÈ¢òÔºå‰∏Ä‰ºöÈÇ£ÈáåÁ∫øË∑ØÈòªÂ°û‰∫ÜÔºåËÉΩÂÅöÂà∞Âä®ÊÄÅËá™Â¶ÇÁöÑÂàáÊç¢ÔºåËÆ©Áî®Êà∑Âá†‰πéÊÑüËßâ‰∏çÂà∞Ôºå‰πü‰∏çÂÆπÊòìÂêßÔºü 4ÔºâÊõ¥Êñ∞Êó†ÈúÄÂÅúÊú∫ÔºåÂÅúÊúçÔºåÂç≥‰æø‰∏Ä‰∏™ 1000 ‰∫∫ÁöÑÊàøÈó¥ÂêéÈù¢ÁöÑÊúçÂä°Âô®Êõ¥Êñ∞ÔºåÂèØËÉΩ‰Ω†ÈÉΩÊÑüËßâ‰∏çÂá∫Êù•ÔºåËßÜÈ¢ëÁöÑÊàøÈó¥‰πüÁÆóÊòØÊúâÁä∂ÊÄÅÁöÑÔºåËøôÁßçÂπ≥ÊªëÁöÑÂàáÊç¢Ôºå‰∏çÁÆóÁÆÄÂçïÂêßÔºü 5ÔºâÂº±ÁΩëÊÉÖÂÜµ‰∏ãÔºåÂºÄÁùÄËΩ¶Êé•ÁùÄËßÜÈ¢ëÔºå‰∏çÂÅúÂàáÊç¢Âü∫Á´ôÔºå60% ÁöÑ‰∏¢ÂåÖÊÉÖÂÜµ‰∏ãÔºåËôΩÁÑ∂‰ºöÂç°‰∏Ä‰∫õÔºå‰ΩÜÂ¶ÇÊûúË¶Å‰øùËØÅÂü∫Á°ÄÂèØÁî®Ôºå‰πüËøòÊòØÊúâÁÇπÊäÄÊúØÂê´ÈáèÁöÑÂêß„ÄÇ ÔºñÔºâÊúçÂä°Á´ØË∑ëËßÜÈ¢ëÁºñÁ†ÅÂô®ÔºåÂç≥‰æøÊúâÁé∞ÊàêÂºÄÊ∫êÁöÑ‰πüÈúÄË¶ÅËá™Â∑±Ëä±Â§ßÂäõÊ∞î‰∫åÊ¨°ÂºÄÂèëÔºåÁºñÁ†ÅÂô®ÊñπÈù¢ÁöÑÁßØÁ¥ØÔºå‰Ω†‰∏çÊêû‰∏™Âõõ‰∫îÂπ¥Ôºå‰Ω†ÂÖ•‰∏ç‰∫ÜÊâãÂêßÔºüËøôÊñπÈù¢ÁöÑÁü•ËØÜÊó•Êñ∞ÊúàÂºÇÔºåÊØèÂπ¥ÈÉΩÊúâÊñ∞Ê†áÂáÜÔºåÊõ¥Êñ∞ÊØîÊ∏∏ÊàèÂø´Â§ö‰∫Ü„ÄÇ ÔºóÔºâÂêéÁ´ØÂõæË±°Â¢ûÂº∫ÔºåÂÖÅËÆ∏Â∏¶ÂÆΩ‰∏çË∂≥Áî®Êà∑ÂèëÈÄÅÊØîËæÉÂ∑ÆÁöÑËßÜÈ¢ëÔºåÂ¢ûÂº∫ÊàêÊØîËæÉÊ∏ÖÊô∞ÁöÑËßÜÈ¢ëÔºåËøô‰∏™ AI Â¢ûÂº∫ÊäÄÊúØÔºåÊØî DLSS 1/2 Â§çÊùÇÂ•ΩÂá†‰∏™Âè∞Èò∂„ÄÇ 8ÔºâÂç≥‰æø‰∏çÊòØÂÆûÊó∂ÈÄö‰ø°ÔºåÁÇπÊí≠ÔºåÁúãÁùÄÁÆÄÂçïÔºå‰πüÊúâÂæàÂ§öÊåëÊàòÁöÑÂú∞ÊñπÔºåÊØîÂ¶Ç‰Ω†ÂÆ¢Êà∑Á´ØÁúãÁü≠ËßÜÈ¢ëÔºå‰∏çÂÅúÁöÑÊâãÊåáÂæÄ‰∏äÊªëÔºåËøûÁª≠ÂàíÂçÅ‰∏™Ôºå‰∏çÂç°ÔºåÁßíÂá∫Ôºå‰∏ùÊªëÂàáÊç¢ÔºåÂÖâËøô‰∏ÄÁÇπÊï∞ÊçÆÈáèÊúâÂ§öÂ§ßÔºüÂÆ¢Êà∑Á´ØËØ•ÊÄé‰πàÁÆ°ÁêÜËµÑÊ∫êÔºüÊúçÂä°Á´Ø‰ªéÊé•ÂÖ•ÊúçÂä°ÔºåË∞ÉÂ∫¶ÊúçÂä°ÔºåÂà∞ CDN Âíå‰º†ËæìÂçèËÆÆÔºåË¶ÅÂÅöÂ§öÂ∞ëÈ°π‰ºòÂåñÂë¢Ôºü [‚Ä¶]
The post ‰∫íËÅîÁΩëÊäÄÊúØÊØîÊ∏∏ÊàèÂêéÁ´ØÊäÄÊúØÈ¢ÜÂÖàÂçÅÂπ¥ÂêóÔºü appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Making ML models differentially private: Best practices and open challenges]]></title>
        <id>http://ai.googleblog.com/2023/05/making-ml-models-differentially-private.html</id>
        <link href="http://ai.googleblog.com/2023/05/making-ml-models-differentially-private.html"/>
        <updated>2023-05-19T16:59:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Natalia Ponomareva and Alex Kurakin, Staff Software Engineers, Google Research






Large machine learning (ML) models are ubiquitous in modern applications: from spam filters to recommender systems and virtual assistants. These models achieve remarkable performance partially due to the abundance of available training data. However, these data can sometimes contain private information, including personal identifiable information, copyright material, etc. Therefore, protecting the privacy of the training data is critical to practical, applied ML.  



Differential Privacy (DP) is one of the most widely accepted technologies that allows reasoning about data anonymization in a formal way. In the context of an ML model, DP can guarantee that each individual user's contribution will ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Timothy Lillicrap - Model-based reinforcement learning and the future of language models]]></title>
        <id>https://mlfoundations.org/talk/lilicrap/</id>
        <link href="https://mlfoundations.org/talk/lilicrap/"/>
        <updated>2023-05-19T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Large language models are capable of an incredible array of tasks. Language models are pre-trained on large amounts of text data from the internet. Then they are fine-tuned on instruction following and further improved by optimizing human preferences. The resulting models are imperfect but are nevertheless able to hold conversations, solve problems, and use tools. How quickly will these models continue to improve? There are a variety of opinions. The answer to this question is also important because language models are poised to make significant changes to the way we live and work. Some researchers think we‚Äôve hit a plateau in performance and that progress will stall without a breakthrough. Others predict the arrival of general intelligence within a couple of years.Putting aside the question of AGI, I will argue that rapid progress in model capabilities will continue without the need for a breakthrough. I will draw connections between language model research and the past decade of work in deep reinforcement learning, especially the Go & Starcraft projects.
These projects followed a similar methodology - models were pre-trained using data collected from game databases. Then they were improved iteratively with reinforcement learning. Viewed from the vantage point of model-based reinforcement learning, optimization of language models is in its infancy. Put simply, there are clear experiments which are likely to create much better models. Why haven‚Äôt these experiments been run already? Since performant language models are large and reward is derived from human preferences, experiments require extensive coordination of people and compute. Given economic incentives, we can expect researchers to overcome these hurdles. There is therefore good reason to believe that language model capabilities will continue to improve rapidly. This motivates increased investment in AI safety research, policy, and governance.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Epistemic Neural Networks]]></title>
        <id>http://arxiv.org/abs/2107.08924</id>
        <link href="http://arxiv.org/abs/2107.08924"/>
        <updated>2023-05-19T07:13:19.926Z</updated>
        <summary type="html"><![CDATA[Ian Osband, Zheng Wen, Seyed Mohammad Asghari, Vikranth Dwaracherla,
  Morteza Ibrahimi, Xiuyuan Lu, Benjamin Van Roy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample
  Complexity for Learning Single Index Models]]></title>
        <id>http://arxiv.org/abs/2305.10633</id>
        <link href="http://arxiv.org/abs/2305.10633"/>
        <updated>2023-05-19T07:13:19.919Z</updated>
        <summary type="html"><![CDATA[Alex Damian, Eshaan Nichani, Rong Ge, Jason D. Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified machine learning: Open-set learning with augmented category by
  exploiting unlabelled data (Open-LACU)]]></title>
        <id>http://arxiv.org/abs/2002.01368</id>
        <link href="http://arxiv.org/abs/2002.01368"/>
        <updated>2023-05-19T07:13:19.894Z</updated>
        <summary type="html"><![CDATA[Emile R. Engelbrecht, Johan A. du Preez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Measure of the Complexity of Neural Representations based on Partial
  Information Decomposition]]></title>
        <id>http://arxiv.org/abs/2209.10438</id>
        <link href="http://arxiv.org/abs/2209.10438"/>
        <updated>2023-05-19T07:13:19.888Z</updated>
        <summary type="html"><![CDATA[David A. Ehrlich, Andreas C. Schneider, Viola Priesemann, Michael
  Wibral, Abdullah Makkeh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[French coast]]></title>
        <id>http://xianblog.wordpress.com/?p=53019</id>
        <link href="https://xianblog.wordpress.com/2023/05/19/french-coast/"/>
        <updated>2023-05-18T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse video tubes for joint video and image vision transformers]]></title>
        <id>http://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html</id>
        <link href="http://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html"/>
        <updated>2023-05-18T21:08:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by AJ Piergiovanni and Anelia Angelova, Research Scientists, Google








Video understanding is a challenging problem that requires reasoning about both spatial information (e.g., for objects in a scene, including their locations and relations) and temporal information for activities or events shown in a video. There are many video understanding applications and tasks, such as understanding the semantic content of web videos and robot perception. However, current works, such as ViViT and TimeSFormer, densely process the video and require significant compute, especially as model size plus video length and resolution increase. 



In ‚ÄúRethinking Video ViTs: Sparse Video Tubes for Joint Image and Video Learning‚Äù, to be presented at CVPR 2023, we introduce a simple technique that tur‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: PAIR]]></title>
        <id>http://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html</id>
        <link href="http://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html"/>
        <updated>2023-05-18T17:12:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Lucas Dixon and Michael Terry, co-leads, PAIR, Google Research




PAIR (People + AI Research) first launched in 2017 with the belief that ‚ÄúAI can go much further ‚Äî and be more useful to all of us ‚Äî if we build systems with people in mind at the start of the process.‚Äù We continue to focus on making AI more understandable, interpretable, fun, and usable by more people around the world. It‚Äôs a mission that is particularly timely given the emergence of generative AI and chatbots.



Today, PAIR is part of the Responsible AI and Human-Centered Technology team within Google Research, and our work spans this larger research space: We advance foundational research on human-AI interaction (HAI) and machine learning (ML); we publish educational materials, including the PAIR Guidebook and ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Âü∫‰∫éÈáèÂ≠êÂåñÂÅáËÆæÊé®ÂØºÊ®°ÂûãÁöÑÂ∞∫Â∫¶ÂÆöÂæãÔºàScaling LawÔºâ]]></title>
        <id>https://kexue.fm/archives/9607</id>
        <link href="https://kexue.fm/archives/9607"/>
        <updated>2023-05-18T12:55:00.000Z</updated>
        <summary type="html"><![CDATA[Â∞∫Â∫¶ÂÆöÂæãÔºàScaling LawÔºâÔºåÊåáÁöÑÊòØÊ®°ÂûãËÉΩÂäõ‰∏éÊ®°ÂûãÂ∞∫Â∫¶‰πãÈó¥ÁöÑÊ∏êËøëÂÖ≥Á≥ª„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊ®°ÂûãËÉΩÂäõÊàë‰ª¨ÂèØ‰ª•ÁÆÄÂçïÁêÜËß£‰∏∫Ê®°ÂûãÁöÑÊçüÂ§±ÂáΩÊï∞ÔºåÊ®°ÂûãÂ∞∫Â∫¶ÂèØ‰ª•ÊåáÊ®°ÂûãÂèÇÊï∞Èáè„ÄÅËÆ≠ÁªÉÊï∞ÊçÆÈáè„ÄÅËÆ≠ÁªÉÊ≠•Êï∞Á≠âÔºåÊâÄË∞ìÂ∞∫Â∫¶ÂÆöÂæãÔºåÂ∞±...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stratified Learning: A General-Purpose Statistical Method for Improved
  Learning under Covariate Shift]]></title>
        <id>http://arxiv.org/abs/2106.11211</id>
        <link href="http://arxiv.org/abs/2106.11211"/>
        <updated>2023-05-18T07:13:31.695Z</updated>
        <summary type="html"><![CDATA[Maximilian Autenrieth, David A. van Dyk, Roberto Trotta, David C.
  Stenning]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep quantum neural networks form Gaussian processes]]></title>
        <id>http://arxiv.org/abs/2305.09957</id>
        <link href="http://arxiv.org/abs/2305.09957"/>
        <updated>2023-05-18T07:13:31.666Z</updated>
        <summary type="html"><![CDATA[Diego Garc\'ia-Mart\'in, Martin Larocca, M. Cerezo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Active Learning in Symbolic Regression Performance with Physical
  Constraints]]></title>
        <id>http://arxiv.org/abs/2305.10379</id>
        <link href="http://arxiv.org/abs/2305.10379"/>
        <updated>2023-05-18T07:13:30.762Z</updated>
        <summary type="html"><![CDATA[Jorge Medina, Andrew D. White]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning curves for deep structured Gaussian feature models]]></title>
        <id>http://arxiv.org/abs/2303.00564</id>
        <link href="http://arxiv.org/abs/2303.00564"/>
        <updated>2023-05-18T07:13:30.755Z</updated>
        <summary type="html"><![CDATA[Jacob A. Zavatone-Veth, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[grasshoppers for pythons]]></title>
        <id>http://xianblog.wordpress.com/?p=53069</id>
        <link href="https://xianblog.wordpress.com/2023/05/18/grasshoppers-for-pythons/"/>
        <updated>2023-05-17T22:23:17.000Z</updated>
        <summary type="html"><![CDATA[Following my earlier post on the terrible performances of ChatGPT for a grasshopping riddle, Bob Carpenter sent me his interaction with GPT4, using the same entry. Here is the python code outcome he obtained. The code is running¬† and the answer is correct. BC: Thanks. Can you write a python program to simulate the final [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ph·ªü]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58720</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58720&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pho"/>
        <updated>2023-05-17T13:34:32.000Z</updated>
        <summary type="html"><![CDATA[Since about the 90s, pho has been popping up all over the place.¬† It has been especially conspicuous after the turn of the millennium, and I think it adapted well to the pandemic as a quick and ready kind of street food.¬† I've often wondered whether it had anything to do with French "fire" or [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up Learning Quantum States through Group Equivariant
  Convolutional Quantum Ans\"atze]]></title>
        <id>http://arxiv.org/abs/2112.07611</id>
        <link href="http://arxiv.org/abs/2112.07611"/>
        <updated>2023-05-17T07:13:38.489Z</updated>
        <summary type="html"><![CDATA[Han Zheng, Zimu Li, Junyu Liu, Sergii Strelchuk, Risi Kondor]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph neural networks-based Scheduler for Production planning problems
  using Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2009.03836</id>
        <link href="http://arxiv.org/abs/2009.03836"/>
        <updated>2023-05-17T07:13:38.479Z</updated>
        <summary type="html"><![CDATA[Mohammed Sharafath Abdul Hameed, Andreas Schwung]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Expressivity of Shallow and Deep Neural Networks for Polynomial
  Approximation]]></title>
        <id>http://arxiv.org/abs/2303.03544</id>
        <link href="http://arxiv.org/abs/2303.03544"/>
        <updated>2023-05-17T07:13:38.456Z</updated>
        <summary type="html"><![CDATA[Itai Shapira]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning from Aggregated Data: Curated Bags versus Random Bags]]></title>
        <id>http://arxiv.org/abs/2305.09557</id>
        <link href="http://arxiv.org/abs/2305.09557"/>
        <updated>2023-05-17T07:13:37.498Z</updated>
        <summary type="html"><![CDATA[Lin Chen, Thomas Fu, Amin Karbasi, Vahab Mirrokni]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning-Rate-Free Learning by D-Adaptation]]></title>
        <id>http://arxiv.org/abs/2301.07733</id>
        <link href="http://arxiv.org/abs/2301.07733"/>
        <updated>2023-05-17T07:13:37.479Z</updated>
        <summary type="html"><![CDATA[Aaron Defazio, Konstantin Mishchenko]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Festschift for Sylvia]]></title>
        <id>http://xianblog.wordpress.com/?p=53043</id>
        <link href="https://xianblog.wordpress.com/2023/05/17/53043/"/>
        <updated>2023-05-16T22:23:17.000Z</updated>
        <summary type="html"><![CDATA[At Sylvia Richardson‚Äôs career celebration last Friday, I gave a talk on How many components in a mixture? which was most relevant given Sylvia‚Äôs contributions to mixture inference over the years, including her highly influential 1997 Read Paper with Peter Green. The other talks highlighted the many facets of Sylvia to the field and the [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using reinforcement learning for dynamic planning in open-ended conversations]]></title>
        <id>http://ai.googleblog.com/2023/05/using-reinforcement-learning-for.html</id>
        <link href="http://ai.googleblog.com/2023/05/using-reinforcement-learning-for.html"/>
        <updated>2023-05-16T19:22:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Deborah Cohen, Staff Research Scientist, and Craig Boutilier, Principal Scientist, Google Research




As virtual assistants become ubiquitous, users increasingly interact with them to learn about new topics or obtain recommendations and expect them to deliver capabilities beyond narrow dialogues of one or two turns. Dynamic planning, namely the capability to look ahead and replan based on the flow of the conversation, is an essential ingredient for the making of engaging conversations with the deeper, open-ended interactions that users expect.
 

While large language models (LLMs) are now beating state-of-the-art approaches in many natural language processing benchmarks, they are typically trained to output the next best response, rather than planning ahead, which is required fo‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Quid pro crow"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58724</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58724&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=quid-pro-crow"/>
        <updated>2023-05-16T13:42:43.000Z</updated>
        <summary type="html"><![CDATA[In Maria Bartiromo's recent interview with James Comer (R-KY), there's an interesting speech error ‚Äî "quid pro crow" for "quid pro quo": This being Language Log rather than Making Fun Of Politicians Log, I'm going to start by assuming that this was a slip of the tongue rather than an inadequate command of legal Latin [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CCP scamming with a Taiwanese-like accent]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58702</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58702&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ccp-scamming-with-a-taiwanese-like-accent"/>
        <updated>2023-05-16T11:40:37.000Z</updated>
        <summary type="html"><![CDATA[Topolects matter: Taiwanese buys anti-CCP book, gets scam call from Chinese propagandist: Caller posing as Eslite Bookstore‚Äôs ‚Äòmarketing department‚Äô tells consumer book content inappropriate By Stephanie Chiang, Taiwan News, Staff Reporter (5/14/23) Before delving into the substance of this report, I should mention that Eslite is a huge, and hugely influential, bookstore in Taiwan. AntC, [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Guided Deep Kernel Learning]]></title>
        <id>http://arxiv.org/abs/2302.09574</id>
        <link href="http://arxiv.org/abs/2302.09574"/>
        <updated>2023-05-16T07:14:20.124Z</updated>
        <summary type="html"><![CDATA[Idan Achituve, Gal Chechik, Ethan Fetaya]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating Self-Supervised Learning via Risk Decomposition]]></title>
        <id>http://arxiv.org/abs/2302.03068</id>
        <link href="http://arxiv.org/abs/2302.03068"/>
        <updated>2023-05-16T07:14:20.117Z</updated>
        <summary type="html"><![CDATA[Yann Dubois, Tatsunori Hashimoto, Percy Liang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentiable Neural Networks with RePU Activation: with Applications
  to Score Estimation and Isotonic Regression]]></title>
        <id>http://arxiv.org/abs/2305.00608</id>
        <link href="http://arxiv.org/abs/2305.00608"/>
        <updated>2023-05-16T07:14:20.110Z</updated>
        <summary type="html"><![CDATA[Guohao Shen, Yuling Jiao, Yuanyuan Lin, Jian Huang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Topological Interpretability for Deep-Learning]]></title>
        <id>http://arxiv.org/abs/2305.08642</id>
        <link href="http://arxiv.org/abs/2305.08642"/>
        <updated>2023-05-16T07:14:20.072Z</updated>
        <summary type="html"><![CDATA[Adam Spannaus, Heidi A.Hanson, Lynne Penberthy, Georgia Tourassi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch Conference 2023: Join us in San Francisco October 16-17]]></title>
        <id>https://pytorch.org/blog/pytorch-conference-2023/</id>
        <link href="https://pytorch.org/blog/pytorch-conference-2023/"/>
        <updated>2023-05-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[<div type="html"/>]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[more [grass]hope]]></title>
        <id>http://xianblog.wordpress.com/?p=53063</id>
        <link href="https://xianblog.wordpress.com/2023/05/16/more-grasshope/"/>
        <updated>2023-05-15T22:23:34.000Z</updated>
        <summary type="html"><![CDATA[Following my earlier post on the terrible performances of ChatGPT for a grasshopping riddle, Bob Carpenter sent me his interaction with GPT4, using the same entry. Here is the outcome he obtained. The answer is correct, but the reasoning is wrong. GPT4: This is a classic problem of infinite series and expected values in probability [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Larger language models do in-context learning differently]]></title>
        <id>http://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html</id>
        <link href="http://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html"/>
        <updated>2023-05-15T20:59:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Jerry Wei, Student Researcher, and Denny Zhou, Principal Scientist, Google Research




There have recently been tremendous advances in language models, partly because they can perform tasks with strong performance via in-context learning (ICL), a process whereby models are prompted with a few examples of input-label pairs before performing the task on an unseen evaluation example. In general, models‚Äô success at in-context learning is enabled by:
 


Their use of semantic prior knowledge from pre-training to predict labels while following the format of in-context examples (e.g., seeing examples of movie reviews with ‚Äúpositive sentiment‚Äù and ‚Äúnegative sentiment‚Äù as labels and performing sentiment analysis using prior knowledge).


Learning the input-label mappings in context from ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Consensus and subjectivity of skin tone annotation for ML fairness]]></title>
        <id>http://ai.googleblog.com/2023/05/consensus-and-subjectivity-of-skin-tone_15.html</id>
        <link href="http://ai.googleblog.com/2023/05/consensus-and-subjectivity-of-skin-tone_15.html"/>
        <updated>2023-05-15T17:16:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Candice Schumann, Software Engineer, and Gbolahan O. Olanubi, User Experience Researcher, Google Research




Skin tone is an observable characteristic that is subjective, perceived differently by individuals (e.g., depending on their location or culture) and thus is complicated to annotate. That said, the ability to reliably and accurately annotate skin tone is highly important in computer vision. This became apparent in 2018, when the Gender Shades study highlighted that computer vision systems struggled to detect people with darker skin tones, and performed particularly poorly for women with darker skin tones. The study highlights the importance for computer researchers and practitioners to evaluate their technologies across the full range of skin tones and at intersections of‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI Anchorman "@EdisonGPT"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58706</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58706&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-anchorman-edisongpt"/>
        <updated>2023-05-15T11:52:37.000Z</updated>
        <summary type="html"><![CDATA[The future of news? üö® BREAKING!!! Just when we thought we'd defeated the #CensorshipIndustrialComplex and @TuckerCarlson rose again on @Twitter, @elonmusk appoints #LindaYaccarino as new #TwitterCEO. Can an Executive Chair from the #WEF lead the revolution?#BreakingNews #EdisonThrustwell #WTF pic.twitter.com/uHt7NjCiO6 ‚Äî Edison Thrustwell (@EdisonGPT) May 12, 2023 That's the first "Edison Thrustwell" tweet that I saw. [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sperm whale talk]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58687</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58687&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sperm-whale-talk"/>
        <updated>2023-05-15T09:04:22.000Z</updated>
        <summary type="html"><![CDATA[Animal communication is not a favorite topic here at Language Log, but according to the following account, one project concerning it seems serious and is being conducted by credible scientists.¬† Although their claims for its ultimate significance may be inflated, I believe the research they are undertaking is worth considering, especially after hearing the clicks [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable Coupling of Deep Learning with Logical Reasoning]]></title>
        <id>http://arxiv.org/abs/2305.07617</id>
        <link href="http://arxiv.org/abs/2305.07617"/>
        <updated>2023-05-15T07:15:23.838Z</updated>
        <summary type="html"><![CDATA[Marianne Defresne, Sophie Barbe, Thomas Schiex]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aleatoric uncertainty for Errors-in-Variables models in deep regression]]></title>
        <id>http://arxiv.org/abs/2105.09095</id>
        <link href="http://arxiv.org/abs/2105.09095"/>
        <updated>2023-05-15T07:15:21.022Z</updated>
        <summary type="html"><![CDATA[J\"org Martin, Clemens Elster]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[COVID-19 diagnosis by routine blood tests using machine learning]]></title>
        <id>http://arxiv.org/abs/2006.03476</id>
        <link href="http://arxiv.org/abs/2006.03476"/>
        <updated>2023-05-15T07:15:20.992Z</updated>
        <summary type="html"><![CDATA[Matja\v{z} Kukar, Gregor Gun\v{c}ar, Toma\v{z} Vovko, Simon Podnar,
  Peter \v{C}ernel\v{c}, Miran Brvar, Mateja Zalaznik, Mateja Notar, Sa\v{s}o
  Mo\v{s}kon, Marko Notar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chez Guy**(*)]]></title>
        <id>http://xianblog.wordpress.com/?p=52858</id>
        <link href="https://xianblog.wordpress.com/2023/05/15/chez-guy/"/>
        <updated>2023-05-14T22:23:37.000Z</updated>
        <summary type="html"><![CDATA[While I rarely enter company sweepstakes and lotteries (and correlatively never win!), I answered a contest from my credit card company around the 2022 Beijing Winter Olympics, and won the prize of having a Chinese dinner cooked at home by a chef, news that I first treated as a spam for being so improbable. The [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Mama ≈†ƒå!"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58691</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58691&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mama-sc"/>
        <updated>2023-05-14T13:37:33.000Z</updated>
        <summary type="html"><![CDATA[Among the entries in the¬† 2023 Eurovision Song Contest,¬† there's one of particular linguistic and political interest ‚Äî from Croatia, Let 3's Mama ≈†ƒå!: [The video of the song's final Eurovision performance is blocked (at least for now) in the U.S. ‚Ä¶] The Croatian lyrics and an English translation are available on genius.com, and the [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mathematical parking]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58671</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58671&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mathematical-parking"/>
        <updated>2023-05-14T03:36:45.000Z</updated>
        <summary type="html"><![CDATA[Sign on the campus of¬†Zh≈çnggu√≥ kƒìxu√© j√¨sh√π d√†xu√© ‰∏≠ÂõΩÁßëÂ≠¶ÊäÄÊúØÂ§ßÂ≠¶ (University of Science and Technology of China) telling people how to park: t√≠ng h«éo chƒìli√†ng de¬†h√°ngli√®sh√¨ ÂÅúÂ•ΩËΩ¶ËæÜÁöÑË°åÂàóÂºè* ("park your vehicles well according to rows and columns")*matrix determinant zu√≤ h«éo xi≈´y«éng de¬†w√©ijƒ´fƒìn¬†ÂÅöÂ•Ω‰øÆÂÖªÁöÑÂæÆÁßØÂàÜ* ("cultivate yourself well to gradually accumulate points [i.e., merit]")*calculus Parking according to one's profession. Selected [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[grass hopping on the wrong fgpt]]></title>
        <id>http://xianblog.wordpress.com/?p=52986</id>
        <link href="https://xianblog.wordpress.com/2023/05/14/grass-hopping-on-the-wrong-fgpt/"/>
        <updated>2023-05-13T22:23:23.000Z</updated>
        <summary type="html"><![CDATA[Checking the R coding abilities of ChatGPT, I entered the latest Riddler puzzle that asks for the expected value of the stationary distribution of a slowing-down random walk over the real line when the N-th jump from x is to x¬±2-N. Which is ¬Ω since the limiting distribution is uniform over (-1,1). The first proposed [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Iowa town names]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58680</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58680&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=iowa-town-names"/>
        <updated>2023-05-13T14:04:03.000Z</updated>
        <summary type="html"><![CDATA[I'm in Ames, home of Iowa State University.¬† The next town down the road is Nevada.¬† What?¬† Yes, but it's /n…ôÀàve…™d…ô/ n…ô-VAY-d…ô, not /n…™Ààv√¶d…ô/ nih-VAD-…ô; Spanish:¬†[neÀàŒ≤a√∞a], and the locals I've met know the difference.¬† The same thing holds for Madrid, which is on the other side of Ames; it is /Ààm√¶dr…™d/, not /m…ôÀàdr…™d/ m…ô-DRID, Spanish:¬†[maÀà√∞…æi√∞]. [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zen again]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58677</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58677&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=zen-again"/>
        <updated>2023-05-13T11:31:10.000Z</updated>
        <summary type="html"><![CDATA[From Nancy Friedman: I'm writing about "zen" in brand names and corporate lingo, having been amused by an email from Medium (where I'm a contributing writer) touting the platform's updates as "Project Zen"‚Äìa name chosen "because that's our goal: a zen-like reading experience." ¬† I'm not sure I know what a "zen-like reading experience" is [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[operation precisely impossible]]></title>
        <id>http://xianblog.wordpress.com/?p=52971</id>
        <link href="https://xianblog.wordpress.com/2023/05/13/operation-precisely-impossible/"/>
        <updated>2023-05-12T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Since the solution to the previous riddle from The Riddler on the maximum of¬† different terms in the composed operation a‚àÖb‚àÖc‚àÖd‚àÖe‚àÖf depending on the bracketing ordering and the meaning of each ‚àÖ among one of the six elementary operations got posted today as 974,860, I got back to my R code to understand why it [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[F-VLM: Open-vocabulary object detection upon frozen vision and language models]]></title>
        <id>http://ai.googleblog.com/2023/05/f-vlm-open-vocabulary-object-detection.html</id>
        <link href="http://ai.googleblog.com/2023/05/f-vlm-open-vocabulary-object-detection.html"/>
        <updated>2023-05-12T20:56:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Weicheng Kuo and Anelia Angelova, Research Scientists, Google Research






Detection is a fundamental vision task that aims to localize and recognize objects in an image. However, the data collection process of manually annotating bounding boxes or instance masks is tedious and costly, which limits the modern detection vocabulary size to roughly 1,000 object classes. This is orders of magnitude smaller than the vocabulary people use to describe the visual world and leaves out many categories. Recent vision and language models (VLMs), such as CLIP, have demonstrated improved open-vocabulary visual recognition capabilities through learning from Internet-scale image-text pairs. These VLMs are applied to zero-shot classification using frozen model weights without the need for fine-‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enabling conversational interaction on mobile with LLMs]]></title>
        <id>http://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html</id>
        <link href="http://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html"/>
        <updated>2023-05-12T17:03:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Bryan Wang, Student Researcher, and Yang Li, Research Scientist, Google Research





Intelligent assistants on mobile devices have significantly advanced language-based interactions for performing simple daily tasks, such as setting a timer or turning on a flashlight. Despite the progress, these assistants still face limitations in supporting conversational interactions in mobile user interfaces (UIs), where many user tasks are performed. For example, they cannot answer a user's question about specific information displayed on a screen. An agent would need to have a computational understanding of graphical user interfaces (GUIs) to achieve such capabilities. 



Prior research has investigated several important technical building blocks to enable conversational interaction with ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yejin Choi - Common Sense: the Dark Matter of Language and Intelligence]]></title>
        <id>https://mlfoundations.org/talk/choi/</id>
        <link href="https://mlfoundations.org/talk/choi/"/>
        <updated>2023-05-12T14:15:00.000Z</updated>
        <summary type="html"><![CDATA[Scale appears to be the winning recipe in today's leaderboards. And yet, extreme-scale neural models are (un)surprisingly brittle and make errors that are often nonsensical and even counterintuitive. In this talk, I will argue for the importance of knowledge, especially commonsense knowledge, as well as inference-time reasoning algorithms, and demonstrate how smaller models developed in academia can still have an edge over larger industry-scale models, if powered with knowledge and/or reasoning algorithms.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[-tucky]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58650</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58650&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tucky"/>
        <updated>2023-05-12T10:15:06.000Z</updated>
        <summary type="html"><![CDATA[Last weekend, I was in Omaha for the annual Berkshire-Hathaway Shareholders Meeting.¬† Not that I am a shareholder of Berkshire-Hathaway, but simply because I was curious to see two nonagenarian financial wizards hold forth in front of 20,000 enthusiastic fans for a whole day.¬† I wasn't disappointed, though I must confess that I didn't understand [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TransformerÂçáÁ∫ß‰πãË∑ØÔºö9„ÄÅ‰∏ÄÁßçÂÖ®Â±ÄÈïøÂ∫¶Â§ñÊé®ÁöÑÊñ∞ÊÄùË∑Ø]]></title>
        <id>https://kexue.fm/archives/9603</id>
        <link href="https://kexue.fm/archives/9603"/>
        <updated>2023-05-12T09:11:00.000Z</updated>
        <summary type="html"><![CDATA[ËØ¥Âà∞TransformerÊó†Ê≥ïÂ§ÑÁêÜË∂ÖÈïøÂ∫èÂàóÁöÑÂéüÂõ†ÔºåÂ§ßÂÆ∂ÁöÑÁ¨¨‰∏ÄÂèçÂ∫îÈÄöÂ∏∏ÈÉΩÊòØSelf AttentionÁöÑ‰∫åÊ¨°Â§çÊùÇÂ∫¶„ÄÇ‰ΩÜ‰∫ãÂÆû‰∏äÔºåÂç≥‰æøÂøΩÁï•ÁÆóÂäõÈôêÂà∂ÔºåÂ∏∏ËßÑÁöÑTransformer‰πüÊó†Ê≥ïÂ§ÑÁêÜË∂ÖÈïøÂ∫èÂàóÔºåÂõ†‰∏∫...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Risk-limiting Financial Audits via Weighted Sampling without Replacement]]></title>
        <id>http://arxiv.org/abs/2305.06884</id>
        <link href="http://arxiv.org/abs/2305.06884"/>
        <updated>2023-05-12T07:13:34.006Z</updated>
        <summary type="html"><![CDATA[Shubhanshu Shekhar, Ziyu Xu, Zachary C. Lipton, Pierre J. Liang,
  Aaditya Ramdas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convergence Rates for Learning Linear Operators from Noisy Data]]></title>
        <id>http://arxiv.org/abs/2108.12515</id>
        <link href="http://arxiv.org/abs/2108.12515"/>
        <updated>2023-05-12T07:13:33.665Z</updated>
        <summary type="html"><![CDATA[Maarten V. de Hoop, Nikola B. Kovachki, Nicholas H. Nelsen, Andrew M.
  Stuart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Fine-Gray: Monotonic neural networks for competing risks]]></title>
        <id>http://arxiv.org/abs/2305.06703</id>
        <link href="http://arxiv.org/abs/2305.06703"/>
        <updated>2023-05-12T07:13:33.622Z</updated>
        <summary type="html"><![CDATA[Vincent Jeanselme, Chang Ho Yoon, Brian Tom, Jessica Barrett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization bounds for neural ordinary differential equations and
  deep residual networks]]></title>
        <id>http://arxiv.org/abs/2305.06648</id>
        <link href="http://arxiv.org/abs/2305.06648"/>
        <updated>2023-05-12T07:13:33.615Z</updated>
        <summary type="html"><![CDATA[Pierre Marion]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.06986</id>
        <link href="http://arxiv.org/abs/2305.06986"/>
        <updated>2023-05-12T07:13:33.598Z</updated>
        <summary type="html"><![CDATA[Eshaan Nichani, Alex Damian, Jason D. Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language Identification: Building an End-to-End AI Solution using PyTorch]]></title>
        <id>https://pytorch.org/blog/language-identification/</id>
        <link href="https://pytorch.org/blog/language-identification/"/>
        <updated>2023-05-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Language Identification is the process of identifying the primary language from multiple audio input samples. In natural language processing (NLP), language identification is an important problem and a challenging issue. There are many language-related tasks such as entering text on your phone, finding news articles you enjoy, or discovering answers to questions that you may have. All these tasks are powered by NLP models. To decide which model to invoke at a particular point in time, we must perform language identification.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CIRM, Luminy, 1995]]></title>
        <id>http://xianblog.wordpress.com/?p=53001</id>
        <link href="https://xianblog.wordpress.com/2023/05/12/cirm-luminy-1995/"/>
        <updated>2023-05-11T22:23:15.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mechanism of feature learning in deep fully connected networks and
  kernel machines that recursively learn features]]></title>
        <id>http://arxiv.org/abs/2212.13881</id>
        <link href="http://arxiv.org/abs/2212.13881"/>
        <updated>2023-05-11T07:13:57.402Z</updated>
        <summary type="html"><![CDATA[Adityanarayanan Radhakrishnan, Daniel Beaglehole, Parthe Pandit,
  Mikhail Belkin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Penalized deep neural networks estimator with general loss functions
  under weak dependence]]></title>
        <id>http://arxiv.org/abs/2305.06230</id>
        <link href="http://arxiv.org/abs/2305.06230"/>
        <updated>2023-05-11T07:13:57.396Z</updated>
        <summary type="html"><![CDATA[William Kengne, Modou Wade]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From Modern CNNs to Vision Transformers: Assessing the Performance,
  Robustness, and Classification Strategies of Deep Learning Models in
  Histopathology]]></title>
        <id>http://arxiv.org/abs/2204.05044</id>
        <link href="http://arxiv.org/abs/2204.05044"/>
        <updated>2023-05-11T07:13:56.982Z</updated>
        <summary type="html"><![CDATA[Maximilian Springenberg, Annika Frommholz, Markus Wenzel, Eva Weicken,
  Jackie Ma, Nils Strodthoff]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Best Arm Identification in Bandits with Limited Precision Sampling]]></title>
        <id>http://arxiv.org/abs/2305.06082</id>
        <link href="http://arxiv.org/abs/2305.06082"/>
        <updated>2023-05-11T07:13:56.946Z</updated>
        <summary type="html"><![CDATA[Kota Srinivas Reddy, P. N. Karthik, Nikhil Karamchandani and
  Jayakrishnan Nair]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Amnon Shashua‚Äôs lecture at Reichman University: A Deep Dive into LLMs and their Future Impact.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24235</id>
        <link href="https://gilkalai.wordpress.com/2023/05/11/amnon-shashuas-lecture-at-reichman-university-a-deep-dive-into-llms-and-their-future-impact/"/>
        <updated>2023-05-11T05:31:20.000Z</updated>
        <summary type="html"><![CDATA[LLM is the acronym for ‚Äúlarge language model‚Äù like GPT-3, ChatGPT, GPT-4 etc. Amnon Shashua gave an enlightening clear lecture about the repeated recent breakthroughs for LLM‚Äôs and where we stand. Here is the You-Tube link for the lecture (in ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Amnon Shashua‚Äôs lecture at Reichman University: A Deep Dive into LLMs and their Future Impact.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24235</id>
        <link href="https://gilkalai.wordpress.com/2023/05/11/amnon-shashuas-lecture-at-reichman-university-a-deep-dive-into-llms-and-their-future-impact/"/>
        <updated>2023-05-11T05:31:20.000Z</updated>
        <summary type="html"><![CDATA[LLM is the acronym for ‚Äúlarge language model‚Äù like GPT-3, ChatGPT, GPT-4 etc. Amnon Shashua gave an enlightening clear lecture about the repeated recent breakthroughs for LLM‚Äôs and where we stand. Here is the You-Tube link for the lecture (in ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Signs of the phonetics of Moroccan French]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58647</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58647&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=signs-of-the-phonetics-of-moroccan-french"/>
        <updated>2023-05-11T02:36:36.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Scott Mauldin] I recently visited Marrakesh and was fascinated by the signs that I submit in the attached photographs. Ostensibly these were originally a kind of business sign that artisans and professionals could hang on their businesses or homes to advertise their profession, but they have evolved into something [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Clean Up After Your Dog]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58636</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58636&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=clean-up-after-your-dog"/>
        <updated>2023-05-11T02:26:48.000Z</updated>
        <summary type="html"><![CDATA[Sign in Hong Kong: f√†ng g«íu h√≤u q«êng l√¨j√≠ qƒ´ngl«ê ÊîæÁãóÂæåË´ãÁ´ãÂç≥Ê∏ÖÁêÜ "Please clean up immediately after letting your dog out" This is a case where the English and the Chinese both make sense, and the one is a rough approximation of the other, but the English is not an exact translation of the Chinese. Selected [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Retraction Watch: Swamp Man Thing]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58652</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58652&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=retraction-watch-swamp-man-thing"/>
        <updated>2023-05-10T23:33:21.000Z</updated>
        <summary type="html"><![CDATA[A recent Dinosaur Comic features a passionate investigation into alleged philosophical plagiarism: The mouseover title: "For my next thought experiment, suppose a man, a super man, gets turned into energy and is widely considered to be the same man, but then one day splits into two energy guys: one red and one blue. WHICH IS [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[back to a correction of the harmonic mean estimator]]></title>
        <id>http://xianblog.wordpress.com/?p=52956</id>
        <link href="https://xianblog.wordpress.com/2023/05/11/back-to-a-correction-of-the-harmonic-mean-estimator/"/>
        <updated>2023-05-10T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[In a 2009 JCGS paper, Peter Lenk proposed a bias correction of the harmonic mean estimator, which is somewhat surprising given that the estimator usually has no variance and hence that its consistency is purely formal, since no speed of convergence can be taken for granted. In particular, the conjugate Normal model serving as a [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building better pangenomes to improve the equity of genomics]]></title>
        <id>http://ai.googleblog.com/2023/05/building-better-pangenomes-to-improve.html</id>
        <link href="http://ai.googleblog.com/2023/05/building-better-pangenomes-to-improve.html"/>
        <updated>2023-05-10T15:03:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Andrew Carroll, Product Lead, and Kishwar Shafin, Research Scientist, Genomics






For decades, researchers worked together to assemble a complete copy of the molecular instructions for a human ‚Äî a map of the human genome. The first draft was finished in 2000, but with several missing pieces.  Even when a complete reference genome was achieved in 2022, their work was not finished. A single reference genome can‚Äôt incorporate known genetic variations, such as the variants for the gene determining whether a person has a blood type A, B, AB or O. Furthermore, the reference genome didn‚Äôt represent the vast diversity of human ancestries, making it less useful for detecting disease or finding cures for people from some backgrounds than others. For the past three years, we have been pa‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable Bayesian optimization with high-dimensional outputs using
  randomized prior networks]]></title>
        <id>http://arxiv.org/abs/2302.07260</id>
        <link href="http://arxiv.org/abs/2302.07260"/>
        <updated>2023-05-10T07:13:51.801Z</updated>
        <summary type="html"><![CDATA[Mohamed Aziz Bhouri, Michael Joly, Robert Yu, Soumalya Sarkar
 , Paris Perdikaris]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Prospective Approach for Human-to-Human Interaction Recognition from
  Wi-Fi Channel Data using Attention Bidirectional Gated Recurrent Neural
  Network with GUI Application Implementation]]></title>
        <id>http://arxiv.org/abs/2202.08146</id>
        <link href="http://arxiv.org/abs/2202.08146"/>
        <updated>2023-05-10T07:13:51.796Z</updated>
        <summary type="html"><![CDATA[Md. Mohi Uddin Khan, Abdullah Bin Shams, Md. Mohsin Sarker Raihan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A duality framework for generalization analysis of random feature models
  and two-layer neural networks]]></title>
        <id>http://arxiv.org/abs/2305.05642</id>
        <link href="http://arxiv.org/abs/2305.05642"/>
        <updated>2023-05-10T07:13:51.688Z</updated>
        <summary type="html"><![CDATA[Hongrui Chen, Jihao Long, Lei Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Proportional Fairness in Federated Learning]]></title>
        <id>http://arxiv.org/abs/2202.01666</id>
        <link href="http://arxiv.org/abs/2202.01666"/>
        <updated>2023-05-10T07:13:51.665Z</updated>
        <summary type="html"><![CDATA[Guojun Zhang, Saber Malekmohammadi, Xi Chen, Yaoliang Yu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Development of a Risk-Free COVID-19 Screening Algorithm from Routine
  Blood Tests Using Ensemble Machine Learning]]></title>
        <id>http://arxiv.org/abs/2108.05660</id>
        <link href="http://arxiv.org/abs/2108.05660"/>
        <updated>2023-05-10T07:13:51.474Z</updated>
        <summary type="html"><![CDATA[Md. Mohsin Sarker Raihan, Md. Mohi Uddin Khan, Laboni Akter and
  Abdullah Bin Shams]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[mean simulations]]></title>
        <id>http://xianblog.wordpress.com/?p=52944</id>
        <link href="https://xianblog.wordpress.com/2023/05/10/mean-simulations/"/>
        <updated>2023-05-09T22:23:48.000Z</updated>
        <summary type="html"><![CDATA[A rather intriguing question on X validated, namely a simulation approach to sampling a bivariate distribution fully specified by one conditional p(x|y) and the symmetric conditional expectation IE[Y|X=x]. The book Conditional Specification of Statistical Models, by Arnold, Castillo and Sarabia, as referenced by and in the question, contains (¬ß7.7) illustrations of such cases. As for [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Online Federated Learning via Non-Stationary Detection and Adaptation
  amidst Concept Drift]]></title>
        <id>http://arxiv.org/abs/2211.12578</id>
        <link href="http://arxiv.org/abs/2211.12578"/>
        <updated>2023-05-09T07:13:44.771Z</updated>
        <summary type="html"><![CDATA[Bhargav Ganguly, Vaneet Aggarwal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TabPFN: A Transformer That Solves Small Tabular Classification Problems
  in a Second]]></title>
        <id>http://arxiv.org/abs/2207.01848</id>
        <link href="http://arxiv.org/abs/2207.01848"/>
        <updated>2023-05-09T07:13:44.764Z</updated>
        <summary type="html"><![CDATA[Noah Hollmann, Samuel M\"uller, Katharina Eggensperger, Frank Hutter]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Stochastic Dynamical System via Flow Map Operator]]></title>
        <id>http://arxiv.org/abs/2305.03874</id>
        <link href="http://arxiv.org/abs/2305.03874"/>
        <updated>2023-05-09T07:13:44.742Z</updated>
        <summary type="html"><![CDATA[Yuan Chen, Dongbin Xiu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning-Augmented Private Algorithms for Multiple Quantile Release]]></title>
        <id>http://arxiv.org/abs/2210.11222</id>
        <link href="http://arxiv.org/abs/2210.11222"/>
        <updated>2023-05-09T07:13:44.735Z</updated>
        <summary type="html"><![CDATA[Mikhail Khodak, Kareem Amin, Travis Dick, Sergei Vassilvitskii]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast parameter estimation of Generalized Extreme Value distribution
  using Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.04341</id>
        <link href="http://arxiv.org/abs/2305.04341"/>
        <updated>2023-05-09T07:13:44.719Z</updated>
        <summary type="html"><![CDATA[Sweta Rai, Alexis Hoffman, Soumendra Lahiri, Douglas W. Nychka,
  Stephan R. Sain, Soutir Bandyopadhyay]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generative AI and AI Product Moats]]></title>
        <id>http://jalammar.github.io/generative-ai-and-ai-product-moats/</id>
        <link href="http://jalammar.github.io/generative-ai-and-ai-product-moats/"/>
        <updated>2023-05-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Here are eight observations I‚Äôve shared recently on the Cohere blog and videos that go over them.: Article: What‚Äôs the big deal with Generative AI? Is it the future or the present? Article: AI is Eating The World]]></summary>
        <author>
            <name>Jay Alammar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Europe Day]]></title>
        <id>http://xianblog.wordpress.com/?p=52998</id>
        <link href="https://xianblog.wordpress.com/2023/05/09/europe-day/"/>
        <updated>2023-05-08T22:23:52.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Node Representations against Perturbations]]></title>
        <id>http://arxiv.org/abs/2008.11416</id>
        <link href="http://arxiv.org/abs/2008.11416"/>
        <updated>2023-05-08T07:14:23.586Z</updated>
        <summary type="html"><![CDATA[Xu Chen, Yuangang Pan, Ivor Tsang, Ya Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random Smoothing Regularization in Kernel Gradient Descent Learning]]></title>
        <id>http://arxiv.org/abs/2305.03531</id>
        <link href="http://arxiv.org/abs/2305.03531"/>
        <updated>2023-05-08T07:14:23.581Z</updated>
        <summary type="html"><![CDATA[Liang Ding, Tianyang Hu, Jiahang Jiang, Donghao Li, Wenjia Wang, Yuan
  Yao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recipes for when Physics Fails: Recovering Robust Learning of Physics
  Informed Neural Networks]]></title>
        <id>http://arxiv.org/abs/2110.13330</id>
        <link href="http://arxiv.org/abs/2110.13330"/>
        <updated>2023-05-08T07:14:23.576Z</updated>
        <summary type="html"><![CDATA[Chandrajit Bajaj, Luke McLennan, Timothy Andeen, Avik Roy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparsifying Bayesian neural networks with latent binary variables and
  normalizing flows]]></title>
        <id>http://arxiv.org/abs/2305.03395</id>
        <link href="http://arxiv.org/abs/2305.03395"/>
        <updated>2023-05-08T07:14:23.361Z</updated>
        <summary type="html"><![CDATA[Lars Skaaret-Lund, Geir Storvik, Aliaksandr Hubin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mathematics (mainly combinatorics) related matters: A lot of activity.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24215</id>
        <link href="https://gilkalai.wordpress.com/2023/05/08/mathematics-mainly-combinatorics-related-matters-a-lot-of-activity/"/>
        <updated>2023-05-08T06:50:10.000Z</updated>
        <summary type="html"><![CDATA[Plan for next weeks blogging There are various things to blog about and let me give a quick preview for the plan for the next few posts. The purpose of this post is to give an impression about the hectic ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mathematics (mainly combinatorics) related matters: A lot of activity.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24215</id>
        <link href="https://gilkalai.wordpress.com/2023/05/08/mathematics-mainly-combinatorics-related-matters-a-lot-of-activity/"/>
        <updated>2023-05-08T06:50:10.000Z</updated>
        <summary type="html"><![CDATA[Plan for next weeks blogging There are various things to blog about and let me give a quick preview for the plan for the next few posts. The purpose of this post is to give an impression about the hectic ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Crappy metaphor:  slippers that make you feel like you're stepping on shit]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58630</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58630&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=crappy-metaphor-slippers-that-make-you-feel-like-youre-stepping-on-shit"/>
        <updated>2023-05-08T02:41:46.000Z</updated>
        <summary type="html"><![CDATA[Sign on the elevator doors of a Taipei department store: Here's the writing on the sign (romanized transcriptions and parenthetical English translations have been added by me [VHM]): One Boy Atmosphere / Function Jƒ´n√©ng¬†¬†qƒ´ng l«ö xi√© x√¨li√®Ê©üËÉΩ ËºïÊóÖÈûãÁ≥ªÂàó("Function¬†¬†¬† light travel slippers series") 2F Sh√®ngd√† kƒÅim√πÁõõÂ§ßÈñãÂπï("Grand Opening") New Opening D√†iy√°nr√©n GEmma W√∫ Y√¨ngji√© ‰ª£Ë®Ä‰∫∫ GEmma Âê≥Êò†ÊΩî("Spokesperson [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[book reviews]]></title>
        <id>http://xianblog.wordpress.com/?p=52870</id>
        <link href="https://xianblog.wordpress.com/2023/05/08/52870/"/>
        <updated>2023-05-07T22:23:35.000Z</updated>
        <summary type="html"><![CDATA[‚ÄúI believe neither in luck nor in destiny, I trust only the science of probabilities. I have studied mathematical statistics, combinatorial analysis, mass functions, and random variables, and they never have held any surprise for me.‚Äù Over the past weeks, I read¬† both second and third volumes of The Mirror Visitor series, by Christelle Dabos, [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TEAR here]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58633</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58633&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tear-here"/>
        <updated>2023-05-07T10:49:38.000Z</updated>
        <summary type="html"><![CDATA[The hotel where I'm staying in Morgantown, West Virginia kindly gave me a complimentary rectangular packet of freshmint toothpaste.¬† At the top right corner of the packet, there was a dotted, diagonal line with the words "TEAR HERE" printed above it.¬† Alas, no matter how hard I tried, I could not tear it open. Then [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The automatic computation for SUSY processes]]></title>
        <id>http://arxiv.org/abs/hep-ph/9503364</id>
        <link href="http://arxiv.org/abs/hep-ph/9503364"/>
        <updated>2023-05-07T07:13:04.429Z</updated>
        <summary type="html"><![CDATA[Masato Jimbo, Tadashi Kon, Minami-Tateya collaboration]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kimono exhibition]]></title>
        <id>http://xianblog.wordpress.com/?p=52915</id>
        <link href="https://xianblog.wordpress.com/2023/05/07/kimono-exhibition/"/>
        <updated>2023-05-06T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[Taking advantage of the 01 May break and a relatively low density of people in Paris, we went to the Mus√©e du Quai Branly to see a soon to close exhibit on kimonos, with many pieces loaned from Japanese collections, through an exhibit designed by the Victoria and Albert Museum in London. The collection is [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding the Transformer architecture for neural networks]]></title>
        <id>64489047578bbf003dccd8e8</id>
        <link href="https://www.jeremyjordan.me/transformer-architecture/"/>
        <updated>2023-05-06T18:17:57.000Z</updated>
        <summary type="html"><![CDATA[The attention mechanism allows us to merge a variable-length sequence of vectors into a fixed-size context vector. What if we could use this mechanism to entirely replace recurrence for sequential modeling? This blog post covers the Transformer architecture which explores such an approach.]]></summary>
        <author>
            <name>Jeremy Jordan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Move out of Missouri"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58624</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58624&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=move-out-of-missouri"/>
        <updated>2023-05-06T10:20:45.000Z</updated>
        <summary type="html"><![CDATA[Here I am in the middle of Missouri, Macon, to be exact (not precisely the geographical center, but not very far from it either, and certainly not near the edges of the state), and I still don't know the origins of this authentic Doggyism:¬† "Move out of Missouri!" As I explained in "How to pronounce [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Napaljarri-wanu Jukurrpa]]></title>
        <id>http://xianblog.wordpress.com/?p=52904</id>
        <link href="https://xianblog.wordpress.com/2023/05/06/napaljarri-wanu-jukurrpa/"/>
        <updated>2023-05-05T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical Optimality of Deep Wide Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.02657</id>
        <link href="http://arxiv.org/abs/2305.02657"/>
        <updated>2023-05-05T07:13:30.015Z</updated>
        <summary type="html"><![CDATA[Yicheng Li, Zixiong Yu, Guhan Chen, Qian Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-linear Functional Modeling using Neural Networks]]></title>
        <id>http://arxiv.org/abs/2104.09371</id>
        <link href="http://arxiv.org/abs/2104.09371"/>
        <updated>2023-05-05T07:13:30.009Z</updated>
        <summary type="html"><![CDATA[Aniruddha Rajendra Rao, Matthew Reimherr]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sequential Training of Neural Networks with Gradient Boosting]]></title>
        <id>http://arxiv.org/abs/1909.12098</id>
        <link href="http://arxiv.org/abs/1909.12098"/>
        <updated>2023-05-05T07:13:30.002Z</updated>
        <summary type="html"><![CDATA[Seyedsaman Emami, Gonzalo Mart\'inez-Mu\~noz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Joint Graph Learning and Model Fitting in Laplacian Regularized
  Stratified Models]]></title>
        <id>http://arxiv.org/abs/2305.02573</id>
        <link href="http://arxiv.org/abs/2305.02573"/>
        <updated>2023-05-05T07:13:29.977Z</updated>
        <summary type="html"><![CDATA[Ziheng Cheng, Junzi Zhang, Akshay Agrawal, Stephen Boyd]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AutoML-GPT: Automatic Machine Learning with GPT]]></title>
        <id>http://arxiv.org/abs/2305.02499</id>
        <link href="http://arxiv.org/abs/2305.02499"/>
        <updated>2023-05-05T07:13:29.971Z</updated>
        <summary type="html"><![CDATA[Shujian Zhang, Chengyue Gong, Lemeng Wu, Xingchao Liu, Mingyuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[10/05 11am-12pm: CRiSM Seminar]]></title>
        <id>8a17841b87bcdaa00187eaa431674bef</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9"/>
        <updated>2023-05-05T06:40:41.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		11:00
		-
		12:00, Wed, 10 May '23

	
Where: MB0.07]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[24/05 11am-12pm: CRiSM Seminar]]></title>
        <id>8a17841b87bcdaa00187eaa431674bf0</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9"/>
        <updated>2023-05-05T06:40:41.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		11:00
		-
		12:00, Wed, 24 May '23

	
Where: MB0.07]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[07/06 11am-12pm: CRiSM Seminar]]></title>
        <id>8a17841b87bcdaa00187eaa431674bf1</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9"/>
        <updated>2023-05-05T06:40:41.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		11:00
		-
		12:00, Wed, 07 Jun '23

	
Where: MB0.07]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[21/06 11am-12pm: CRiSM Seminar]]></title>
        <id>8a17841b87bcdaa00187eaa431674bf2</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9"/>
        <updated>2023-05-05T06:40:41.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		11:00
		-
		12:00, Wed, 21 Jun '23

	
Where: MB0.07]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["I don't think it exactly qualifies as language"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58621</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58621&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=i-dont-think-it-exactly-qualifies-as-language"/>
        <updated>2023-05-05T04:20:11.000Z</updated>
        <summary type="html"><![CDATA[From 9 Chickweed Lane (4/28/23): (source) Question from Francois Lang, who sent this in:¬†¬† "Don't agonized screams have semantic or pragmatic content?" Selected readings "More 'screaming and spluttering' from Matthew Engel" (7/21/11) "The emerging science of gendered yelling" (9/5/06)]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Â¶Ç‰ΩïÂ∫¶ÈáèÊï∞ÊçÆÁöÑÁ®ÄÁñèÁ®ãÂ∫¶Ôºü]]></title>
        <id>https://kexue.fm/archives/9595</id>
        <link href="https://kexue.fm/archives/9595"/>
        <updated>2023-05-05T03:19:00.000Z</updated>
        <summary type="html"><![CDATA[Âú®Êú∫Âô®Â≠¶‰π†‰∏≠ÔºåÊàë‰ª¨ÁªèÂ∏∏‰ºöË∞àÂà∞Á®ÄÁñèÊÄßÔºåÊØîÂ¶ÇÊàë‰ª¨ÁªèÂ∏∏ËØ¥Ê≥®ÊÑèÂäõÁü©ÈòµÈÄöÂ∏∏ÊòØÂæàÁ®ÄÁñèÁöÑ„ÄÇÁÑ∂ËÄåÔºå‰∏çÁü•ÈÅìÂ§ßÂÆ∂ÂèëÁé∞Ê≤°ÊúâÔºåÊàë‰ª¨‰ºº‰πé‰ªéÊ≤°ÊúâÁªôÂá∫ËøáÂ∫¶ÈáèÁ®ÄÁñèÁ®ãÂ∫¶ÁöÑÊ†áÂáÜÊñπÊ≥ï„ÄÇ‰πüÂ∞±ÊòØËØ¥Ôºå‰ª•ÂæÄÊàë‰ª¨ÂÖ≥‰∫éÁ®ÄÁñèÊÄßÁöÑËÆ®ËÆ∫Ôºå‰ªÖ‰ªÖÊòØÁõ¥ËßÇÂ±Ç...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Externally managed environments": when PEP 668 breaks pip]]></title>
        <id>https://pythonspeed.com/articles/externally-managed-environment-pep-668/</id>
        <link href="https://pythonspeed.com/articles/externally-managed-environment-pep-668/"/>
        <updated>2023-05-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[You‚Äôre on a new version of Linux, you try a pip install, and it errors out, talking about ‚Äúexternally managed environments‚Äù and ‚ÄúPEP 668‚Äù.
What‚Äôs going on?
How do you solve this?
Let‚Äôs see:
What the problem looks like, and what causes it.
The places you are likely to encounter it.
A variety of solutions, depending on your use case.
Read more...]]></summary>
        <author>
            <name>Python‚áíSpeed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Balto‚Äôs genome]]></title>
        <id>http://xianblog.wordpress.com/?p=52894</id>
        <link href="https://xianblog.wordpress.com/2023/05/05/baltos-genome/"/>
        <updated>2023-05-04T22:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MaMMUT: A simple vision-encoder text-decoder architecture for multimodal tasks]]></title>
        <id>http://ai.googleblog.com/2023/05/mammut-simple-vision-encoder-text.html</id>
        <link href="http://ai.googleblog.com/2023/05/mammut-simple-vision-encoder-text.html"/>
        <updated>2023-05-04T21:59:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by AJ Piergiovanni and Anelia Angelova, Research Scientists, Google Research




Vision-language foundational models are built on the premise of a single pre-training followed by subsequent adaptation to multiple downstream tasks. Two main and disjoint training scenarios are popular: a CLIP-style contrastive learning and next-token prediction. Contrastive learning trains the model to predict if image-text pairs correctly match, effectively building visual and text representations for the corresponding image and text inputs, whereas next-token prediction predicts the most likely next text token in a sequence, thus learning to generate text, according to the required task. Contrastive learning enables image-text and text-image retrieval tasks, such as finding the image that best match‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian learning]]></title>
        <id>http://xianblog.wordpress.com/?p=52879</id>
        <link href="https://xianblog.wordpress.com/2023/05/04/bayesian-learning/"/>
        <updated>2023-05-04T16:01:52.000Z</updated>
        <summary type="html"><![CDATA[‚Äú‚Ä¶many well-known learning-algorithms, such as those used in optimization, deep learning, and machine learning in general, can now be derived directly following the above scheme using a single algorithm‚Äù The One World ABC webinar today was delivered by Emtiyaz Khan (RIKEN), about the Bayesian Learning Rule, following Khan and Rue 2021 arXival on Bayesian learning. [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A survey on online active learning]]></title>
        <id>http://arxiv.org/abs/2302.08893</id>
        <link href="http://arxiv.org/abs/2302.08893"/>
        <updated>2023-05-04T07:14:32.958Z</updated>
        <summary type="html"><![CDATA[Davide Cacciarelli, Murat Kulahci]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transferablility of coVariance Neural Networks and Application to
  Interpretable Brain Age Prediction using Anatomical Features]]></title>
        <id>http://arxiv.org/abs/2305.01807</id>
        <link href="http://arxiv.org/abs/2305.01807"/>
        <updated>2023-05-04T07:14:32.172Z</updated>
        <summary type="html"><![CDATA[Saurabh Sihag, Gonzalo Mateos, Corey T. McMillan, Alejandro Ribeiro]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cheap and Deterministic Inference for Deep State-Space Models of
  Interacting Dynamical Systems]]></title>
        <id>http://arxiv.org/abs/2305.01773</id>
        <link href="http://arxiv.org/abs/2305.01773"/>
        <updated>2023-05-04T07:14:31.666Z</updated>
        <summary type="html"><![CDATA[Andreas Look, Melih Kandemir, Barbara Rakitsch, Jan Peters]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Probabilistic Contrastive Learning Recovers the Correct Aleatoric
  Uncertainty of Ambiguous Inputs]]></title>
        <id>http://arxiv.org/abs/2302.02865</id>
        <link href="http://arxiv.org/abs/2302.02865"/>
        <updated>2023-05-04T07:14:31.419Z</updated>
        <summary type="html"><![CDATA[Michael Kirchhof, Enkelejda Kasneci, Seong Joon Oh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[fairml: A Statistician's Take on Fair Machine Learning Modelling]]></title>
        <id>http://arxiv.org/abs/2305.02009</id>
        <link href="http://arxiv.org/abs/2305.02009"/>
        <updated>2023-05-04T07:14:31.413Z</updated>
        <summary type="html"><![CDATA[Marco Scutari]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Shribe" in Mongolian historiography]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58615</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58615&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=shribe-in-mongolian-historiography"/>
        <updated>2023-05-04T03:58:50.000Z</updated>
        <summary type="html"><![CDATA[A couple of days ago, I was having a conversation with one of my former students at a tea/coffee shop (that's what I call 'em because I don't drink coffee very often, almost never). We were talking about a controversy in Mongolian historiography.¬† It was a question of whether it is ever suitable to use [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[IndoorSim-to-OutdoorReal: Learning to navigate outdoors without any outdoor experience]]></title>
        <id>http://ai.googleblog.com/2023/05/indoorsim-to-outdoorreal-learning-to.html</id>
        <link href="http://ai.googleblog.com/2023/05/indoorsim-to-outdoorreal-learning-to.html"/>
        <updated>2023-05-03T17:22:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Joanne Truong, Student Researcher, and Wenhao Yu, Research Scientist, Robotics at Google





Teaching mobile robots to navigate in complex outdoor environments is critical to real-world applications, such as delivery or search and rescue. However, this is also a challenging problem as the robot needs to perceive its surroundings, and then explore to identify feasible paths towards the goal. Another common challenge is that the robot needs to overcome uneven terrains, such as stairs, curbs, or rockbed on a trail, while avoiding obstacles and pedestrians. In our prior work, we investigated the second challenge by teaching a quadruped robot to tackle challenging uneven obstacles and various outdoor terrains. 



In ‚ÄúIndoorSim-to-OutdoorReal: Learning to Navigate Outdoors without an‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding the Generalization Ability of Deep Learning Algorithms: A
  Kernelized Renyi's Entropy Perspective]]></title>
        <id>http://arxiv.org/abs/2305.01143</id>
        <link href="http://arxiv.org/abs/2305.01143"/>
        <updated>2023-05-03T07:15:02.721Z</updated>
        <summary type="html"><![CDATA[Yuxin Dong, Tieliang Gong, Hong Chen, Chen Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-asymptotic estimates for TUSLA algorithm for non-convex learning
  with applications to neural networks with ReLU activation function]]></title>
        <id>http://arxiv.org/abs/2107.08649</id>
        <link href="http://arxiv.org/abs/2107.08649"/>
        <updated>2023-05-03T07:15:02.715Z</updated>
        <summary type="html"><![CDATA[Dong-Young Lim, Ariel Neufeld, Sotirios Sabanis, Ying Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Physics between Digital Twins with Low-Fidelity Models and
  Physics-Informed Gaussian Processes]]></title>
        <id>http://arxiv.org/abs/2206.08201</id>
        <link href="http://arxiv.org/abs/2206.08201"/>
        <updated>2023-05-03T07:15:01.356Z</updated>
        <summary type="html"><![CDATA[Michail Spitieris, Ingelin Steinsland]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noise Injection Node Regularization for Robust Learning]]></title>
        <id>http://arxiv.org/abs/2210.15764</id>
        <link href="http://arxiv.org/abs/2210.15764"/>
        <updated>2023-05-03T07:15:01.340Z</updated>
        <summary type="html"><![CDATA[Noam Levi, Itay M. Bloch, Marat Freytsis, Tomer Volansky]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noise Injection as a Probe of Deep Learning Dynamics]]></title>
        <id>http://arxiv.org/abs/2210.13599</id>
        <link href="http://arxiv.org/abs/2210.13599"/>
        <updated>2023-05-03T07:15:01.333Z</updated>
        <summary type="html"><![CDATA[Noam Levi, Itay Bloch, Marat Freytsis, Tomer Volansky]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing PyTorch Docathon 2023]]></title>
        <id>https://pytorch.org/blog/announcing-docathon/</id>
        <link href="https://pytorch.org/blog/announcing-docathon/"/>
        <updated>2023-05-03T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[<div type="html"/>]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No paddling]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58604</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58604&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=no-paddling"/>
        <updated>2023-05-03T03:45:38.000Z</updated>
        <summary type="html"><![CDATA[And no dabbling either (see "Selected readings"). Q«êng w√π xƒ´ shu«ê Ë´ãÂãøÂ¨âÊ∞¥ "Please don't play in the water" The anonymous contributor who took this photograph in Hong Kong and sent it to me remarked:¬† "I believe it is correct English though." You will also see signs that translate¬†xƒ´ shu«ê¬†Â¨âÊ∞¥ ("play in the water") as ("frolicking") [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AIxcuse me?!]]></title>
        <id>http://xianblog.wordpress.com/?p=52923</id>
        <link href="https://xianblog.wordpress.com/2023/05/03/aixcuse-me/"/>
        <updated>2023-05-02T22:23:29.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The geometric mean rate of return]]></title>
        <id>https://parsiad.ca/blog/2023/the_geometric_mean_rate_of_return/</id>
        <link href="https://parsiad.ca/blog/2023/the_geometric_mean_rate_of_return/"/>
        <updated>2023-05-02T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Consider a horizon of disjoint periods labelled $1$ through $N$. On the entire horizon, an asset with a rate of return $r_n$ on the $n$-th period has a geometric mean rate of return of \begin{equation} \overline{r} = \left( \prod_{n = 1}^N \left(1 + r_n\right) \right)^{1 / N} - 1. \end{equation} Note in particular that \begin{equation} \left(1 + \overline{r}\right)^N = \prod_{n = 1}^N \left(1 + r_n\right). \end{equation} In other words, a hypothetical asset whose rate of return is equal to $\overline{r}$ on all $N$ periods yields the same return (over the horizon) as the original asset.]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uncorrelated coordinates in PCA]]></title>
        <id>https://parsiad.ca/blog/2023/uncorrelated_coordinates_in_pca/</id>
        <link href="https://parsiad.ca/blog/2023/uncorrelated_coordinates_in_pca/"/>
        <updated>2023-05-02T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Let $X$ be an $N\times p$ real matrix. Let $D$ be a real diagonal matrix, $w$ be a vector of nonnegative weights that sum to one, and \begin{equation} Y=\left(X-\frac{1}{N}ee^{\intercal}X\right)D^{-1}. \end{equation} $Y$ is a demeaned and rescaled version of $X$.]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LAVA: Data Valuation without Pre-Specified Learning Algorithms]]></title>
        <id>http://arxiv.org/abs/2305.00054</id>
        <link href="http://arxiv.org/abs/2305.00054"/>
        <updated>2023-05-02T07:13:48.931Z</updated>
        <summary type="html"><![CDATA[Hoang Anh Just, Feiyang Kang, Jiachen T. Wang, Yi Zeng, Myeongseob Ko,
  Ming Jin, Ruoxi Jia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained
  models]]></title>
        <id>http://arxiv.org/abs/2305.00350</id>
        <link href="http://arxiv.org/abs/2305.00350"/>
        <updated>2023-05-02T07:13:48.900Z</updated>
        <summary type="html"><![CDATA[Korawat Tanwisuth, Shujian Zhang, Huangjie Zheng, Pengcheng He,
  Mingyuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Byzantines can also Learn from History: Fall of Centered Clipping in
  Federated Learning]]></title>
        <id>http://arxiv.org/abs/2208.09894</id>
        <link href="http://arxiv.org/abs/2208.09894"/>
        <updated>2023-05-02T07:13:48.895Z</updated>
        <summary type="html"><![CDATA[Kerem Ozfatura, Emre Ozfatura, Alptekin Kupcu, Deniz Gunduz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Inference for Bayesian Neural Networks under Model and
  Parameter Uncertainty]]></title>
        <id>http://arxiv.org/abs/2305.00934</id>
        <link href="http://arxiv.org/abs/2305.00934"/>
        <updated>2023-05-02T07:13:48.877Z</updated>
        <summary type="html"><![CDATA[Aliaksandr Hubin, Geir Storvik]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerated Image Segmentation using PyTorch]]></title>
        <id>https://pytorch.org/blog/accelerated-image-seg/</id>
        <link href="https://pytorch.org/blog/accelerated-image-seg/"/>
        <updated>2023-05-02T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Using Intel¬Æ Extension for PyTorch to Boost Image Processing Performance]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the plague, sword, and famine year]]></title>
        <id>http://xianblog.wordpress.com/?p=52802</id>
        <link href="https://xianblog.wordpress.com/2023/05/02/a-journal-of-the-plague-sword-and-famine-year-5/"/>
        <updated>2023-05-01T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Read Brent Weeks‚Äô The Way of Shadows, a rather traditional tale of an orphan boy learning assassin‚Äôs skills from a master, within a crime guild organisation tolerated by a feudal structure itself ruled by a below-par king, with the usual dilemma between dedication to the (gory and amoral) job and love+friendship+loyalty constraints. Both collide when [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LLMs in education: the historical view]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58613</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58613&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=llms-in-education-the-historical-view"/>
        <updated>2023-05-01T11:37:42.000Z</updated>
        <summary type="html"><![CDATA[Frazz for 4/25/2023: Let's not forget Plato's argument against the use of written language in education (From Phaedrus, in the voice of Socrates quoting Thamus): SOCRATES: At the Egyptian city of Naucratis, there was a famous old god, whose name was Theuth; the bird which is called the Ibis is sacred to him, and he [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A feature selection method based on Shapley values robust to concept
  shift in regression]]></title>
        <id>http://arxiv.org/abs/2304.14774</id>
        <link href="http://arxiv.org/abs/2304.14774"/>
        <updated>2023-05-01T07:14:17.709Z</updated>
        <summary type="html"><![CDATA[Carlos Sebasti\'an, Carlos E. Gonz\'alez-Guill\'en]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minimalistic Unsupervised Learning with the Sparse Manifold Transform]]></title>
        <id>http://arxiv.org/abs/2209.15261</id>
        <link href="http://arxiv.org/abs/2209.15261"/>
        <updated>2023-05-01T07:14:17.666Z</updated>
        <summary type="html"><![CDATA[Yubei Chen, Zeyu Yun, Yi Ma, Bruno Olshausen, Yann LeCun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why Learning of Large-Scale Neural Networks Behaves Like Convex
  Optimization]]></title>
        <id>http://arxiv.org/abs/1903.02140</id>
        <link href="http://arxiv.org/abs/1903.02140"/>
        <updated>2023-05-01T07:14:17.661Z</updated>
        <summary type="html"><![CDATA[Hui Jiang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Stable and Scalable Method for Solving Initial Value PDEs with Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2304.14994</id>
        <link href="http://arxiv.org/abs/2304.14994"/>
        <updated>2023-05-01T07:14:17.647Z</updated>
        <summary type="html"><![CDATA[Marc Finzi, Andres Potapczynski, Matthew Choptuik, Andrew Gordon
  Wilson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training Neural Networks for Sequential Change-point Detection]]></title>
        <id>http://arxiv.org/abs/2210.17312</id>
        <link href="http://arxiv.org/abs/2210.17312"/>
        <updated>2023-05-01T07:14:17.642Z</updated>
        <summary type="html"><![CDATA[Junghwan Lee, Tingnan Gong, Xiuyuan Cheng, Yao Xie]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at ICLR 2023]]></title>
        <id>http://ai.googleblog.com/2023/04/google-at-iclr-2023.html</id>
        <link href="http://ai.googleblog.com/2023/04/google-at-iclr-2023.html"/>
        <updated>2023-05-01T06:37:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Catherine Armato, Program Manager, Google




The Eleventh International Conference on Learning Representations (ICLR 2023) is being held this week as a hybrid event in Kigali, Rwanda. We are proud to be a Diamond Sponsor of ICLR 2023, a premier conference on deep learning, where Google researchers contribute at all levels. This year we are presenting over 100 papers and are actively involved in organizing and hosting a number of different events, including workshops and interactive sessions.

 

If you‚Äôre registered for ICLR 2023, we hope you‚Äôll visit the Google booth to learn more about the exciting work we‚Äôre doing across topics spanning representation and reinforcement learning, theory and optimization, social impact, safety and privacy, and applications from generative AI to‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Goodbye to Flake8 and PyLint: faster linting with Ruff]]></title>
        <id>https://pythonspeed.com/articles/pylint-flake8-ruff/</id>
        <link href="https://pythonspeed.com/articles/pylint-flake8-ruff/"/>
        <updated>2023-05-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Flake8 and PyLint are commonly used, and very useful, linting tools: they can help you find potential bugs and other problems with your code, aka ‚Äúlints‚Äù.
But they can also be slow.
And even if they‚Äôre fast on your computer, they may still be slow in your CI system (GitHub Actions, GitLab, or whatever else.)
Happily, there‚Äôs a new linter available, Ruff, which is much faster.
And it supports many of the same lints, including those from many of Flake8‚Äôs plugins.
In this article we‚Äôll get a sense of why Ruff‚Äôs extra linting speed is so useful compared to the alternatives.
Specifically, we‚Äôll cover:
A useful lint that isn‚Äôt in standard Flake8.
A speed comparison to Ruff‚Äôs implementation (preview: it‚Äôs much faster!).
Why seemingly fast linting on your computer might still be slow in CI.
The worst case for Ruff (preview: it‚Äôs ridiculously fast).
Why Ruff may not work for you.
A bonus speed-up for linting by changing tox‚Äôs configuration.
Read more...]]></summary>
        <author>
            <name>Python‚áíSpeed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ÁªüËÆ°ÊúàËØªÔºà2023 Âπ¥ 4 ÊúàÔºâ]]></title>
        <id>https://cosx.org/2023/05/monthly/</id>
        <link href="https://cosx.org/2023/05/monthly/"/>
        <updated>2023-05-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Êé®ËçêËØ≠ÔºöÊ∑±Â∫¶Â≠¶‰π†Ôºå‰ΩÜÊòØLassoÔºüÂÖ∑ÊúâÁÆóÊ≥ïÂåÖÂíåÂØπÂ∫îÁöÑÂéüÁêÜËÆ∫ÊñáÔºåÂÄºÂæó‰∏ÄËØï Êé®Ëçê‰∫∫ÔºöÂ≠î‰ª§‰ªÅ ÈìæÊé•Ôºöhttps://lassonet.ml/ Êé®ËçêËØ≠ÔºöÊòé]]></summary>
        <author>
            <name>ÁªüËÆ°‰πãÈÉΩ</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["The age of Socratic AI"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58607</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58607&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-age-of-socratic-ai"/>
        <updated>2023-04-30T23:20:50.000Z</updated>
        <summary type="html"><![CDATA[Or should we call it "Delphic AI"? Alexy Khrabrov suggested both possibilities a few days ago, in "Reasonable AI ‚Äî the Golden Age of AI Programming": The emerging techniques are all around the way you construct the prompts and also chain them. Effectively, we‚Äôre plotting dialogues. I call it the Age of Socratic AI, or [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a particularly unhelpful graph [about UN Water Conferences]]]></title>
        <id>http://xianblog.wordpress.com/?p=52648</id>
        <link href="https://xianblog.wordpress.com/2023/05/01/a-particularly-unhelpful-graph-about-un-water-conferences/"/>
        <updated>2023-04-30T22:23:54.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[5 worlds of AI]]></title>
        <id>http://windowsontheory.org/?p=8605</id>
        <link href="https://windowsontheory.org/2023/04/30/5-worlds-of-ai/"/>
        <updated>2023-04-30T21:39:21.000Z</updated>
        <summary type="html"><![CDATA[Scott Aaronson and I wrote a post about 5 possible worlds for (the progress of) Artificial Intelligence. See Scott‚Äôs blog for the post itself and discussions. The post was, of course, inspired by the classic essay on the 5 worlds of computational complexity by Russell Impagliazzo who will be turning 60 soon ‚Äì Happy birthday!]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[5 worlds of AI]]></title>
        <id>http://windowsontheory.org/?p=8605</id>
        <link href="https://windowsontheory.org/2023/04/30/5-worlds-of-ai/"/>
        <updated>2023-04-30T21:39:21.000Z</updated>
        <summary type="html"><![CDATA[Scott Aaronson and I wrote a post about 5 possible worlds for (the progress of) Artificial Intelligence. See Scott‚Äôs blog for the post itself and discussions. The post was, of course, inspired by the classic essay on the 5 worlds of computational complexity by Russell Impagliazzo who will be turning 60 soon ‚Äì Happy birthday!]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The interplay between Cantonese and Mandarin as an index of sociopolitical tensions in Hong Kong]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58594</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58594&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-interplay-between-cantonese-and-mandarin-as-an-index-of-sociopolitical-tensions-in-hong-kong"/>
        <updated>2023-04-30T11:22:18.000Z</updated>
        <summary type="html"><![CDATA[First it was the British from afar, and now it is the Chinese from the north who are imposing themselves on the people of Hong Kong.¬† In both cases, the imposition has been not merely political and economic, but has had important cultural and linguistic implications.¬† Language-wise, under which master have the Hongkongers (also known [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[operation impossible]]></title>
        <id>http://xianblog.wordpress.com/?p=52850</id>
        <link href="https://xianblog.wordpress.com/2023/04/30/operation-impossible/"/>
        <updated>2023-04-29T22:23:36.000Z</updated>
        <summary type="html"><![CDATA[A riddle from The Riddler on how many different numbers one could at most produce from six initial values and the four basic operations. In other words, how many values could the terms in a‚àÖ(b‚àÖ{c‚àÖ[d‚àÖ(e‚àÖf)]}) could take? (With each ‚àÖ being one of the four operations and a,‚Ä¶,f the initial values or a permutation of [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calling Benjamin Lee Whorf]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58597</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58597&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=calling-benjamin-lee-whorf"/>
        <updated>2023-04-29T14:56:58.000Z</updated>
        <summary type="html"><![CDATA[What do a baker, a shepherd, and a drummer have in common? You can add an orchestra conductor, Harry Potter, and a drill sergeant. Hint: this is in French. Answer: A central focus of their lives is one or more baguettes ‚Äî which in English variously translates as "stick", "wand", "rod", "baton", "staff", "chopstick", "drumstick", [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diabolo:  devil / yo-yo]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58591</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58591&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=diabolo-devil-yo-yo"/>
        <updated>2023-04-29T09:10:51.000Z</updated>
        <summary type="html"><![CDATA[The diabolo, sometimes called a Chinese yo-yo, is a two-headed top controlled by a string manipulated by two sticks, one attached to each end.¬† It is popular among jugglers. Diabolo, commonly misspelled as diablo, was formerly also known as "the devil on two sticks" (Juggling Wiki). In this post, I am concerned primarily with language [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[jeune fille √† la perle [street art]]]></title>
        <id>http://xianblog.wordpress.com/?p=52487</id>
        <link href="https://xianblog.wordpress.com/2023/04/29/jeune-fille-a-la-perle-street-art/"/>
        <updated>2023-04-28T22:23:43.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
</feed>