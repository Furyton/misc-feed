<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-12-01T16:19:30.062Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Major Linguistic Faux Pas in Chinese Football Association PPT]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61503</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61503&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=major-linguistic-faux-pas-in-chinese-football-association-ppt"/>
        <updated>2023-12-01T05:47:54.000Z</updated>
        <summary type="html"><![CDATA[The Chinese Football Association used dǎngguó 党国 ("party state" — nettlesome term to be explained fully below) in a powerpoint on its plans for '24. Awkward political illiteracy!  Here's a screenshot. Here's the line of text above the photographic image: Zhōngguó zúxié bù huì yòng cí bùyào luànyòng@zhōngguó zúxié 中国足协不会用词不要乱用@中国足协 "If the Chinese Football Association does not know how to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Comparison Between Invariant and Equivariant Classical and Quantum
  Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2311.18672</id>
        <link href="http://arxiv.org/abs/2311.18672"/>
        <updated>2023-12-01T04:18:59.278Z</updated>
        <summary type="html"><![CDATA[Roy T. Forestano, Mar\c{c}al Comajoan Cara, Gopal Ramesh Dahale,
  Zhongtian Dong, Sergei Gleyzer, Daniel Justice, Kyoungchul Kong, Tom
  Magorsch, Konstantin T. Matchev, Katia Matcheva, Eyup B. Unlu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[$\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks:
  Benchmarking against Classical Neural Networks]]></title>
        <id>http://arxiv.org/abs/2311.18744</id>
        <link href="http://arxiv.org/abs/2311.18744"/>
        <updated>2023-12-01T04:18:59.083Z</updated>
        <summary type="html"><![CDATA[Zhongtian Dong, Mar\c{c}al Comajoan Cara, Gopal Ramesh Dahale, Roy T.
  Forestano, Sergei Gleyzer, Daniel Justice, Kyoungchul Kong, Tom Magorsch,
  Konstantin T. Matchev, Katia Matcheva, Eyup B. Unlu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fair Community Detection and Structure Learning in Heterogeneous
  Graphical Models]]></title>
        <id>http://arxiv.org/abs/2112.05128</id>
        <link href="http://arxiv.org/abs/2112.05128"/>
        <updated>2023-12-01T04:18:59.025Z</updated>
        <summary type="html"><![CDATA[Davoud Ataee Tarzanagh, Laura Balzano, Alfred O. Hero]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contextualized Policy Recovery: Modeling and Interpreting Medical
  Decisions with Adaptive Imitation Learning]]></title>
        <id>http://arxiv.org/abs/2310.07918</id>
        <link href="http://arxiv.org/abs/2310.07918"/>
        <updated>2023-12-01T04:18:59.008Z</updated>
        <summary type="html"><![CDATA[Jannik Deuschel, Caleb N. Ellington, Benjamin J. Lengerich, Yingtao
  Luo, Pascal Friederich, Eric P. Xing]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep learning and differential equations for modeling changes in
  individual-level latent dynamics between observation periods]]></title>
        <id>http://arxiv.org/abs/2202.07403</id>
        <link href="http://arxiv.org/abs/2202.07403"/>
        <updated>2023-12-01T04:18:58.995Z</updated>
        <summary type="html"><![CDATA[G\"oran K\"ober, Raffael Kalisch, Lara Puhlmann, Andrea Chmitorz,
  Anita Schick, Harald Binder]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[nous, laminaire]]></title>
        <id>http://xianblog.wordpress.com/?p=54436</id>
        <link href="https://xianblog.wordpress.com/2023/12/01/nous-laminaire/"/>
        <updated>2023-11-30T23:23:12.000Z</updated>
        <summary type="html"><![CDATA[A chance occurrence of a superb exhibit during our trip to Martinique last month, namely a photograph exhibit at the Foundation Clément (funded by the Clément rum factory!) around some poems of Aimé Césaire, the most famous Martinique writer from his book Moi, laminaire, which I had not seen before, but found fabulous, by the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spelling and intuition]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61499</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61499&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=spelling-and-intuition"/>
        <updated>2023-11-30T13:02:24.000Z</updated>
        <summary type="html"><![CDATA[Long have we pondered the overwhelming dominance by individuals of Indian heritage over the spelling bees.  Do they have some sort of mysterious power or secret for memorizing hundreds of thousands of obscure words?  Now we have an answer from one of the masters himself, Dev Shah, a ninth-grader living in Largo, Florida, who won […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerating Generative AI with PyTorch II: GPT, Fast]]></title>
        <id>https://pytorch.org/blog/accelerating-generative-ai-2/</id>
        <link href="https://pytorch.org/blog/accelerating-generative-ai-2/"/>
        <updated>2023-11-30T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[This post is the second part of a multi-series blog focused on how to accelerate generative AI models with pure, native PyTorch. We are excited to share a breadth of newly released PyTorch performance features alongside practical examples to see how far we can push PyTorch native performance. In part one, we showed how to accelerate Segment Anything over 8x using only pure, native PyTorch. In this blog we’ll focus on LLM optimization.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning sources of variability from high-dimensional observational
  studies]]></title>
        <id>http://arxiv.org/abs/2307.13868</id>
        <link href="http://arxiv.org/abs/2307.13868"/>
        <updated>2023-11-30T04:18:50.274Z</updated>
        <summary type="html"><![CDATA[Eric W. Bridgeford, Jaewon Chung, Brian Gilbert, Sambit Panda, Adam
  Li, Cencheng Shen, Alexandra Badea, Brian Caffo, Joshua T. Vogelstein]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Over-Squashing in Riemannian Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2311.15945</id>
        <link href="http://arxiv.org/abs/2311.15945"/>
        <updated>2023-11-30T04:18:50.270Z</updated>
        <summary type="html"><![CDATA[Julia Balla]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks]]></title>
        <id>http://arxiv.org/abs/2310.03684</id>
        <link href="http://arxiv.org/abs/2310.03684"/>
        <updated>2023-11-30T04:18:50.246Z</updated>
        <summary type="html"><![CDATA[Alexander Robey, Eric Wong, Hamed Hassani, George J. Pappas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Primer on Deep Learning for Causal Inference]]></title>
        <id>http://arxiv.org/abs/2110.04442</id>
        <link href="http://arxiv.org/abs/2110.04442"/>
        <updated>2023-11-30T04:18:50.232Z</updated>
        <summary type="html"><![CDATA[Bernard Koch, Tim Sainburg, Pablo Geraldo, Song Jiang, Yizhou Sun,
  Jacob Gates Foster]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Maximum Entropy Model Correction in Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2311.17855</id>
        <link href="http://arxiv.org/abs/2311.17855"/>
        <updated>2023-11-30T04:18:50.221Z</updated>
        <summary type="html"><![CDATA[Amin Rakhsha, Mete Kemertas, Mohammad Ghavamzadeh, Amir-massoud
  Farahmand]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[St Kilda beach [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=54564</id>
        <link href="https://xianblog.wordpress.com/2023/11/30/st-kilda-beach-jatp/"/>
        <updated>2023-11-29T23:23:01.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Millions of new materials discovered with deep learning]]></title>
        <id>https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/</id>
        <link href="https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/"/>
        <updated>2023-11-29T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[We share the discovery of 2.2 million new crystals  –  equivalent to nearly 800 years’ worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sanskrit is far from extinct]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61486</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61486&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sanskrit-is-far-from-extinct"/>
        <updated>2023-11-29T15:38:21.000Z</updated>
        <summary type="html"><![CDATA[[This is the first of two consecutive posts on things Indian.  After reading them, if someone is prompted to send me material for a third, I'll be happy to make it a trifecta.] Our entry point to the linguistically compelling topic of today's post is this Nikkei Asia (11/29/23) article by Barkha Shah in its […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch 2.1 Contains New Performance Features for AI Developers]]></title>
        <id>https://pytorch.org/blog/new-features-for-ai/</id>
        <link href="https://pytorch.org/blog/new-features-for-ai/"/>
        <updated>2023-11-29T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to see the release of PyTorch 2.1. In this blog, we discuss the five features for which Intel made significant contributions to PyTorch 2.1:]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometry-Aware Adaptation for Pretrained Models]]></title>
        <id>http://arxiv.org/abs/2307.12226</id>
        <link href="http://arxiv.org/abs/2307.12226"/>
        <updated>2023-11-29T04:19:00.084Z</updated>
        <summary type="html"><![CDATA[Nicholas Roberts, Xintong Li, Dyah Adila, Sonia Cromp, Tzu-Heng Huang,
  Jitian Zhao, Frederic Sala]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[OccamNet: A Fast Neural Model for Symbolic Regression at Scale]]></title>
        <id>http://arxiv.org/abs/2007.10784</id>
        <link href="http://arxiv.org/abs/2007.10784"/>
        <updated>2023-11-29T04:19:00.047Z</updated>
        <summary type="html"><![CDATA[Owen Dugan, Rumen Dangovski, Allan Costa, Samuel Kim and
  Pawan Goyal, Joseph Jacobson, Marin Solja\v{c}i\'c]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Attentional Graph Neural Networks for Robust Massive Network
  Localization]]></title>
        <id>http://arxiv.org/abs/2311.16856</id>
        <link href="http://arxiv.org/abs/2311.16856"/>
        <updated>2023-11-29T04:18:59.979Z</updated>
        <summary type="html"><![CDATA[Wenzhong Yan, Juntao Wang, Feng Yin, Abdelhak M. Zoubir]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image
  Generation]]></title>
        <id>http://arxiv.org/abs/2311.16201</id>
        <link href="http://arxiv.org/abs/2311.16201"/>
        <updated>2023-11-29T04:18:59.965Z</updated>
        <summary type="html"><![CDATA[Yuhui Zhang, Brandon McKinzie, Zhe Gan, Vaishaal Shankar, Alexander
  Toshev]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Co-learning synaptic delays, weights and adaptation in spiking neural
  networks]]></title>
        <id>http://arxiv.org/abs/2311.16112</id>
        <link href="http://arxiv.org/abs/2311.16112"/>
        <updated>2023-11-29T04:18:59.947Z</updated>
        <summary type="html"><![CDATA[Lucas Deckers, Laurens Van Damme, Ing Jyh Tsang, Werner Van Leekwijck
 , Steven Latr\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[我在Performer中发现了Transformer-VQ的踪影]]></title>
        <id>https://kexue.fm/archives/9862</id>
        <link href="https://kexue.fm/archives/9862"/>
        <updated>2023-11-29T03:04:00.000Z</updated>
        <summary type="html"><![CDATA[前些天我们在《VQ一下Key，Transformer的复杂度就变成线性了》介绍了“Transformer-VQ”，这是通过将Key序列做VQ（Vector Quantize）变换来实现Atten...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2023 Workshop in honour of Professors Donald Poskitt and Gael Martin]]></title>
        <id>http://xianblog.wordpress.com/?p=54525</id>
        <link href="https://xianblog.wordpress.com/2023/11/29/2023-workshop-in-honour-of-professors-donald-poskitt-and-gael-martin/"/>
        <updated>2023-11-28T23:23:47.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Charlie Chaplin in French class]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61489</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61489&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=charlie-chaplin-in-french-class"/>
        <updated>2023-11-28T14:08:23.000Z</updated>
        <summary type="html"><![CDATA[In addition to a proto-regular-expression for English monosyllables, Benjamin Lee Whorf's 12/1940 Technology Review article has a weird diagram showing how a linguist (?) would organize French language instruction along the lines of mid-20th-century factory work: The student preparing to dive through the "English Sound-Pattern Analyzer", into the "English Sound-Pattern Disintegrator", evokes Charlie Chaplin in […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cancel your taem sher]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61470</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61470&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=cancel-your-taem-sher"/>
        <updated>2023-11-28T13:06:29.000Z</updated>
        <summary type="html"><![CDATA[Driving to work this morning, I heard an advertisement on the radio that left me mightily perplexed till the last 5-10 seconds when I finally figured out what the speaker was talking about. He had a thick southern accent and kept talking about how bad it was to have a "taem sher".  The first word […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bias-Variance Trade-off in Physics-Informed Neural Networks with
  Randomized Smoothing for High-Dimensional PDEs]]></title>
        <id>http://arxiv.org/abs/2311.15283</id>
        <link href="http://arxiv.org/abs/2311.15283"/>
        <updated>2023-11-28T04:18:48.569Z</updated>
        <summary type="html"><![CDATA[Zheyuan Hu, Zhouhao Yang, Yezhen Wang, George Em Karniadakis, Kenji
  Kawaguchi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Global $\mathcal{L}^2$ minimization with certainty via geometrically
  adapted gradient descent in Deep Learning]]></title>
        <id>http://arxiv.org/abs/2311.15487</id>
        <link href="http://arxiv.org/abs/2311.15487"/>
        <updated>2023-11-28T04:18:48.552Z</updated>
        <summary type="html"><![CDATA[Thomas Chen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Will More Expressive Graph Neural Networks do Better on Generative
  Tasks?]]></title>
        <id>http://arxiv.org/abs/2308.11978</id>
        <link href="http://arxiv.org/abs/2308.11978"/>
        <updated>2023-11-28T04:18:48.350Z</updated>
        <summary type="html"><![CDATA[Xiandong Zou, Xiangyu Zhao, Pietro Li\`o, Yiren Zhao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A review of ensemble learning and data augmentation models for class
  imbalanced problems: combination, implementation and evaluation]]></title>
        <id>http://arxiv.org/abs/2304.02858</id>
        <link href="http://arxiv.org/abs/2304.02858"/>
        <updated>2023-11-28T04:18:48.344Z</updated>
        <summary type="html"><![CDATA[Azal Ahmad Khan, Omkar Chaudhari, Rohitash Chandra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Polars in a Pandas world]]></title>
        <id>https://pythonspeed.com/articles/polars-pandas-interopability/</id>
        <link href="https://pythonspeed.com/articles/polars-pandas-interopability/"/>
        <updated>2023-11-28T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Polars is a dataframe-based library that can be faster, more memory efficient, and often simpler to use than Pandas.
It’s also much newer, and correspondingly less popular.
In November 2023:
Polars had ~2.6 million downloads from PyPI.
Pandas had ~140 million downloads!
Because of Pandas’ popularity and decade and a half of availability, there are many third-party libraries with built-in support for Pandas, and others that specifically extend Pandas.
Many plotting and visualization libraries will accept Pandas dataframes as an input, for example, and GeoPandas adds geographical data types to Pandas dataframes.
If you’re using Polars, can you use these libraries?
And if so, how?
In this article we’ll cover the various integration options you have between Polars and third-party libraries originally designed to work with Pandas:
It Just Works.
Manual conversion to Pandas dataframes, and how to do it with essentially zero cost.
Manual interoperability via files.
Other alternatives.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[consolidator grants 2023]]></title>
        <id>http://xianblog.wordpress.com/?p=54512</id>
        <link href="https://xianblog.wordpress.com/2023/11/28/consolidator-grants-2023/"/>
        <updated>2023-11-27T23:23:45.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Slap varieties]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61464</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61464&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=slap-varieties"/>
        <updated>2023-11-27T18:05:32.000Z</updated>
        <summary type="html"><![CDATA[Sunny Jhatti wrote to me: "I didn't know what 'pimp slap' meant till I saw this." After witnessing her astonishing diatribe, Conal Boyce said: I felt like I needed to take a shower. (Adding insult to injury, google failed to elucidate 'Skims' for me. Had to look elsewhere to get an inkling of what that […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The convexity package for Hamiltonian actions on conformal symplectic
  manifolds]]></title>
        <id>http://arxiv.org/abs/1905.12703</id>
        <link href="http://arxiv.org/abs/1905.12703"/>
        <updated>2023-11-27T09:16:22.189Z</updated>
        <summary type="html"><![CDATA[Youming Chen, Reyer Sjamaar, Xiangdong Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deformations of Wreath Products]]></title>
        <id>http://arxiv.org/abs/1609.00604</id>
        <link href="http://arxiv.org/abs/1609.00604"/>
        <updated>2023-11-27T09:16:22.186Z</updated>
        <summary type="html"><![CDATA[Marius Dadarlat, Ulrich Pennig, Andrew Schneider]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Morse subsets of CAT(0) spaces are strongly contracting]]></title>
        <id>http://arxiv.org/abs/1810.02119</id>
        <link href="http://arxiv.org/abs/1810.02119"/>
        <updated>2023-11-27T09:16:22.092Z</updated>
        <summary type="html"><![CDATA[Christopher H. Cashen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yang-Baxter representations of the infinite symmetric group]]></title>
        <id>http://arxiv.org/abs/1707.00196</id>
        <link href="http://arxiv.org/abs/1707.00196"/>
        <updated>2023-11-27T09:16:22.064Z</updated>
        <summary type="html"><![CDATA[Gandalf Lechner, Ulrich Pennig, Simon Wood]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arc lifting for the Nash manifold]]></title>
        <id>http://arxiv.org/abs/1103.5723</id>
        <link href="http://arxiv.org/abs/1103.5723"/>
        <updated>2023-11-27T09:16:22.052Z</updated>
        <summary type="html"><![CDATA[John Atwell Moody]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Deep Learning Method for Comparing Bayesian Hierarchical Models]]></title>
        <id>http://arxiv.org/abs/2301.11873</id>
        <link href="http://arxiv.org/abs/2301.11873"/>
        <updated>2023-11-27T04:18:56.106Z</updated>
        <summary type="html"><![CDATA[Lasse Elsem\"uller, Martin Schnuerch, Paul-Christian B\"urkner, Stefan
  T. Radev]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep learning based dictionary learning and tomographic image
  reconstruction]]></title>
        <id>http://arxiv.org/abs/2108.11730</id>
        <link href="http://arxiv.org/abs/2108.11730"/>
        <updated>2023-11-27T04:18:56.072Z</updated>
        <summary type="html"><![CDATA[Jevgenija Rudzusika, Thomas Koehler, Ozan \"Oktem]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Preference Learning Based on Sequential Bayesian Optimization with
  Pairwise Comparison]]></title>
        <id>http://arxiv.org/abs/2103.13192</id>
        <link href="http://arxiv.org/abs/2103.13192"/>
        <updated>2023-11-27T04:18:55.911Z</updated>
        <summary type="html"><![CDATA[Tanya Ignatenko, Kirill Kondrashov, Marco Cox, Bert de Vries]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rethinking Influence Functions of Neural Networks in the
  Over-parameterized Regime]]></title>
        <id>http://arxiv.org/abs/2112.08297</id>
        <link href="http://arxiv.org/abs/2112.08297"/>
        <updated>2023-11-27T04:18:55.489Z</updated>
        <summary type="html"><![CDATA[Rui Zhang, Shihua Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Hierarchical Polynomials with Three-Layer Neural Networks]]></title>
        <id>http://arxiv.org/abs/2311.13774</id>
        <link href="http://arxiv.org/abs/2311.13774"/>
        <updated>2023-11-27T04:18:55.483Z</updated>
        <summary type="html"><![CDATA[Zihao Wang, Eshaan Nichani, Jason D. Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vowel systems and musical sounds]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61434</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61434&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=vowel-systems-and-musical-sounds"/>
        <updated>2023-11-27T01:01:29.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by H. Krishnapriyan] Would you know of any ready reference that talks about vowels not getting articulated in specific places in the mouth, but rather being part of a system of vowels where the sound value of a vowel is determined by the vowel's relative position of articulation with respect […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My mentored internship at scikit-learn]]></title>
        <id>https://blog.scikit-learn.org/diversity/mentoring/</id>
        <link href="https://blog.scikit-learn.org/diversity/mentoring/"/>
        <updated>2023-11-27T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Author: Stefanie Senger , François Goupil]]></summary>
        <author>
            <name>scikit-learn Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[off to St. Kilda]]></title>
        <id>http://xianblog.wordpress.com/?p=54419</id>
        <link href="https://xianblog.wordpress.com/2023/11/27/off-to-st-kilda/"/>
        <updated>2023-11-26T23:23:33.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Whorf invents generative phonology?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61453</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61453&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=whorf-invents-generative-phonology"/>
        <updated>2023-11-26T23:15:02.000Z</updated>
        <summary type="html"><![CDATA[After stumbling on Benjamin Lee Whorf's affiliation with the Theosophical Society, I read two articles that he contributed to the MIT Technology Review in 1940: "Science and Linguistics" in the April issues, and "Linguistics as an Exact Science" in the December issue. Something in the second article surprised me. Whorf gives a formal account of […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[26ème semi-marathon de Boulogne-Billancourt]]></title>
        <id>http://xianblog.wordpress.com/?p=54247</id>
        <link href="https://xianblog.wordpress.com/2023/11/26/26eme-semi-marathon-de-boulogne-billancourt/"/>
        <updated>2023-11-25T23:26:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Theosophical racism]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61440</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61440&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=theosophical-racism"/>
        <updated>2023-11-25T17:29:42.000Z</updated>
        <summary type="html"><![CDATA[Today's SMBC: Those first four panels resonated with my recent experience skimming Helena Blavatsky's The Secret Doctrine: The Synthesis of Science, Religion, and Philosophy. Vol II — Anthropogensis (1888). I learned of Blavatsky's existence due to the restaurant located in her former residence, and my sense of her influence in Philadelphia was reinforced by years […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[international day for the elimination of violence against women]]></title>
        <id>http://xianblog.wordpress.com/?p=54518</id>
        <link href="https://xianblog.wordpress.com/2023/11/25/international-day-for-the-elimination-of-violence-against-women/"/>
        <updated>2023-11-25T11:23:20.000Z</updated>
        <summary type="html"><![CDATA[[translated from a unified call by dozens of organisations and unions] On this international day of November 25, in a context of more and more wars, our support goes to all women in the world, the first victims, along with children, of armed conflicts. We particularly show our support for the women of Ukraine, Burma, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sauerkraut fish]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61424</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61424&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sauerkraut-fish"/>
        <updated>2023-11-25T06:14:09.000Z</updated>
        <summary type="html"><![CDATA[All right, I know it sounds funny, but it's a thing in Taiwan, as at this Taichung restaurant: To clear up the first problem, the Chinese word that is translated as "sauerkraut" is suāncài 酸菜 (lit., "sour vegetable"). What is this suāncài 酸菜?  Wiktionary tells us: (Northern, Northeastern China) a variety of Chinese pickle made by fermenting salt-cured napa cabbage […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Eddie Bauer]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61421</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61421&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=eddie-bauer"/>
        <updated>2023-11-25T06:11:08.000Z</updated>
        <summary type="html"><![CDATA["Eddie Bauer changed its logo because Gen Z doesn’t read cursive" (Fast Company, Oct. 6, 2023) Sigh! Selected readings "The new logo" (2/11/09) "Language Log logo and t-shirts" (6/2/18) "How do you say 'polo', 'logo', and 'erase' with Photoshop' in Chinese?" (9/15/23)]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mr. Mark]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61418</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61418&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mr-mark"/>
        <updated>2023-11-25T02:54:03.000Z</updated>
        <summary type="html"><![CDATA[Storefront in Taichung, Taiwan: The Chinese characters say: Mǎkě xiānshēng 馬可先生 Mr. Mark Reminds me of Mr. Brown Coffee and Beard Papa's Cream Puffs. Selected readings "Of cream puffs and shoe polish" (6/23/22) — Beard Papa's, from Japan, with an old man having a white, fluffy beard for a logo "Mr. Brown Coffee" — from […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Come The Felicity The Door]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61413</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61413&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=come-the-felicity-the-door"/>
        <updated>2023-11-25T02:51:25.000Z</updated>
        <summary type="html"><![CDATA[From Charles Belov: Sending along a photo from a videodisc cover I encountered in a little free library. The Chinese title 幸福来敲门 is translated into English as "Come The Felicity The Door". xìngfú lái qiāo mén 幸福来敲门 "Happiness comes knocking at the door" The syntax of the English on the videodisc cover is completely off […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tanuka Chattopadhyay (26 Jan 1963 – 16 Oct 2023)]]></title>
        <id>http://xianblog.wordpress.com/?p=54497</id>
        <link href="https://xianblog.wordpress.com/2023/11/25/tanuka-chattopadhyay-26-jan-1963-16-oct-2023/"/>
        <updated>2023-11-24T23:23:14.000Z</updated>
        <summary type="html"><![CDATA[Most sadly, I learned today that applied mathematics Professor Tanuka Chattopadhyay, from the University of Calcutta, had passed away last month. We had been briefly collaborating after I met her and her husband Asis Chattopadhyay, also Professor of Statistics at the University of Calcutta, following a Franco-Indian workshop in Bangalore. Discussing research directions in astrostatistics […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Confusing coffee and tea:  blowing hot and cold]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61409</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61409&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=confusing-coffee-and-tea-blowing-hot-and-cold"/>
        <updated>2023-11-24T13:53:19.000Z</updated>
        <summary type="html"><![CDATA[Klaus Nuber, who four years ago sent us this amusing post, "Restaurant logo with a dingus" (5/29/19), has contributed another droll Anekdote. The following article is in today's Süddeutsche Zeitung, "Kannste knicken?"* (11/23/23) — herewith the second anecdote of three from all over the world: *VHM:  The meaning of the article title escapes me — […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Real-Time Under-Display Cameras Image Restoration and HDR on Mobile
  Devices]]></title>
        <id>http://arxiv.org/abs/2211.14040</id>
        <link href="http://arxiv.org/abs/2211.14040"/>
        <updated>2023-11-24T03:16:01.356Z</updated>
        <summary type="html"><![CDATA[Marcos V. Conde, Florin Vasluianu, Sabari Nathan, Radu
  Timofte]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the twice Caribean year]]></title>
        <id>http://xianblog.wordpress.com/?p=54371</id>
        <link href="https://xianblog.wordpress.com/2023/11/24/a-journal-of-the-twice-caribean-year/"/>
        <updated>2023-11-23T23:23:16.000Z</updated>
        <summary type="html"><![CDATA[Read the second volume of Aliette de Bodard’s series, The House of Binding Thorns, during the Martinique trip, which proved kind of a chore, disappointingly… Visited a nice bookstore in Fort-de-France, Kazabul, which was originally twinned with La Cas’A Bulles in Cayenne that I also visited when our daughter was residing there. But did not […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Americanisms in the OED]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61397</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61397&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=americanisms-in-the-oed"/>
        <updated>2023-11-23T18:49:05.000Z</updated>
        <summary type="html"><![CDATA[One of my favorite diversions is looking at old photographs of James Murray (1837-1915), chief editor of the OED, and his cohort working away in their scriptorium, "a shed in Murray’s back garden in Oxford". What a bunch of committed eccentrics!  That includes Sarah Ogilvie, who worked at the OED for awhile and wrote this […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning principle and mathematical realization of the learning
  mechanism in the brain]]></title>
        <id>http://arxiv.org/abs/2311.13341</id>
        <link href="http://arxiv.org/abs/2311.13341"/>
        <updated>2023-11-23T04:18:17.912Z</updated>
        <summary type="html"><![CDATA[Taisuke Katayose]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A General Theoretical Paradigm to Understand Learning from Human
  Preferences]]></title>
        <id>http://arxiv.org/abs/2310.12036</id>
        <link href="http://arxiv.org/abs/2310.12036"/>
        <updated>2023-11-23T04:18:17.908Z</updated>
        <summary type="html"><![CDATA[Mohammad Gheshlaghi Azar, Mark Rowland, Bilal Piot, Daniel
  Guo, Daniele Calandriello, Michal Valko, R\'emi Munos]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fixing the problems of deep neural networks will require better training
  data and learning algorithms]]></title>
        <id>http://arxiv.org/abs/2311.12819</id>
        <link href="http://arxiv.org/abs/2311.12819"/>
        <updated>2023-11-23T04:18:17.889Z</updated>
        <summary type="html"><![CDATA[Drew Linsley, Thomas Serre]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[$\sigma$-PCA: a unified neural model for linear and nonlinear principal
  component analysis]]></title>
        <id>http://arxiv.org/abs/2311.13580</id>
        <link href="http://arxiv.org/abs/2311.13580"/>
        <updated>2023-11-23T04:18:17.858Z</updated>
        <summary type="html"><![CDATA[Fahdi Kanavati, Lucy Katsnith, Masayuki Tsuneki]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improved identification accuracy in equation learning via comprehensive
  $\boldsymbol{R^2}$-elimination and Bayesian model selection]]></title>
        <id>http://arxiv.org/abs/2311.13265</id>
        <link href="http://arxiv.org/abs/2311.13265"/>
        <updated>2023-11-23T04:18:17.817Z</updated>
        <summary type="html"><![CDATA[Daniel Nickelsen, Bubacarr Bah]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Natural statistical science [#2]]]></title>
        <id>http://xianblog.wordpress.com/?p=54398</id>
        <link href="https://xianblog.wordpress.com/2023/11/23/natural-statistical-science-2/"/>
        <updated>2023-11-22T23:23:10.000Z</updated>
        <summary type="html"><![CDATA[A rare occurrence of a Bayesian statistics paper in Nature with this “State estimation of a physical system with unknown governing equations” by Course and Nair. A variational Bayes modelling of a state system observed with noise, but without a physical model on the state (SDE) evolution itself. Which means a prior is set on […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving simulations of clouds and their effects on climate]]></title>
        <id>http://blog.research.google/2023/11/improving-simulations-of-clouds-and.html</id>
        <link href="http://blog.research.google/2023/11/improving-simulations-of-clouds-and.html"/>
        <updated>2023-11-22T16:03:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Tapio Schneider, Visiting Researcher, and Yi-fan Chen, Engineering Lead, Google Research




Today’s climate models successfully capture broad global warming trends. However, because of uncertainties about processes that are small in scale yet globally important, such as clouds and ocean turbulence, these models’ predictions of upcoming climate changes are not very accurate in detail. For example, predictions of the time by which the global mean surface temperature of Earth will have warmed 2℃, relative to preindustrial times, vary by 40–50 years (a full human generation) among today’s models. As a result, we do not have the accurate and geographically granular predictions we need to plan resilient infrastructure, adapt supply chains to climate disruption, and assess the risks of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Indigo and cabbage]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61389</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61389&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=indigo-and-cabbage"/>
        <updated>2023-11-22T15:31:41.000Z</updated>
        <summary type="html"><![CDATA[In the first comment to this post on a Northeastern topolectal word for kohlrabi, "piě-le 丿了" (cf. MSM piělán 苤蓝), Jenny Chu astutely asked whether the second syllable is related to the Chinese word for the color blue, lán 藍 (also "indigo", for which see below). That sent me scurrying, since — although I was vaguely […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rebuttal depth and the mainvisionist dogstream]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61398</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61398&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rebuttal-depth-and-the-mainvisionist-dogstream"/>
        <updated>2023-11-22T15:26:30.000Z</updated>
        <summary type="html"><![CDATA[As is so often true, xkcd points to an important topic so far ignored by linguists: Mouseover title: "The mainstream dogma sparked a wave of dogmatic revisionism, and this revisionist mainstream dogmatism has now given way to a more rematic mainvisionist dogstream." As is generally true for discourse analysis, rebuttal depth is a concept that […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bridging Algorithmic Information Theory and Machine Learning: A New
  Approach to Kernel Learning]]></title>
        <id>http://arxiv.org/abs/2311.12624</id>
        <link href="http://arxiv.org/abs/2311.12624"/>
        <updated>2023-11-22T04:18:42.778Z</updated>
        <summary type="html"><![CDATA[Boumediene Hamzi, Marcus Hutter, Houman Owhadi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Topological properties of basins of attraction and expressiveness of
  width bounded neural networks]]></title>
        <id>http://arxiv.org/abs/2011.04923</id>
        <link href="http://arxiv.org/abs/2011.04923"/>
        <updated>2023-11-22T04:18:42.411Z</updated>
        <summary type="html"><![CDATA[Hans-Peter Beise, Steve Dias Da Cruz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Causal Representations from General Environments:
  Identifiability and Intrinsic Ambiguity]]></title>
        <id>http://arxiv.org/abs/2311.12267</id>
        <link href="http://arxiv.org/abs/2311.12267"/>
        <updated>2023-11-22T04:18:42.392Z</updated>
        <summary type="html"><![CDATA[Jikai Jin, Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch Geometric Signed Directed: A Software Package on Graph Neural
  Networks for Signed and Directed Graphs]]></title>
        <id>http://arxiv.org/abs/2202.10793</id>
        <link href="http://arxiv.org/abs/2202.10793"/>
        <updated>2023-11-22T04:18:42.179Z</updated>
        <summary type="html"><![CDATA[Yixuan He, Xitong Zhang, Junjie Huang, Benedek Rozemberczki, Mihai
  Cucuringu, Gesine Reinert]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[survex: an R package for explaining machine learning survival models]]></title>
        <id>http://arxiv.org/abs/2308.16113</id>
        <link href="http://arxiv.org/abs/2308.16113"/>
        <updated>2023-11-22T04:18:42.176Z</updated>
        <summary type="html"><![CDATA[Miko{\l}aj Spytek, Mateusz Krzyzi\'nski, Sophie Hanna Langbein
 , Hubert Baniecki, Marvin N. Wright, Przemys{\l}aw Biecek]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Advanced lexicography for diabetes in Japan and China]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61386</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61386&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=advanced-lexicography-for-diabetes-in-japan-and-china"/>
        <updated>2023-11-22T00:33:21.000Z</updated>
        <summary type="html"><![CDATA[This is a followup to "Japanese words that are dying out: focus on diabetes" (11/21/23).  Because it's history of science / medicine for specialists and too technical for the majority of readers, I will not provide transcriptions for all but a few of the most common terms. [The following is a guest post from Nathan Hopson] […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Natural statistical science [#1]]]></title>
        <id>http://xianblog.wordpress.com/?p=54393</id>
        <link href="https://xianblog.wordpress.com/2023/11/22/natural-statistical-science-1/"/>
        <updated>2023-11-21T23:23:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BoJo bamboozled]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61382</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61382&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bojo-bamboozled"/>
        <updated>2023-11-21T21:13:08.000Z</updated>
        <summary type="html"><![CDATA[From Philip Taylor: The British media were flooded yesterday with reports that former Prime Minister Boris Johnson had been “bamboozled” by scientific evidence presented during the Covid-19 pandemic.  My understanding of "bamboozle" has always been that deception must be involved, and this is borne out by the OED, but there was clearly no deception in […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open sourcing Project Guideline: A platform for computer vision accessibility technology]]></title>
        <id>http://blog.research.google/2023/11/open-sourcing-project-guideline.html</id>
        <link href="http://blog.research.google/2023/11/open-sourcing-project-guideline.html"/>
        <updated>2023-11-21T18:09:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Dave Hawkey, Software Engineer, Google Research




Two years ago we announced Project Guideline, a collaboration between Google Research and Guiding Eyes for the Blind that enabled people with visual impairments (e.g., blindness and low-vision) to walk, jog, and run independently. Using only a Google Pixel phone and headphones, Project Guideline leverages on-device machine learning (ML) to navigate users along outdoor paths marked with a painted line. The technology has been tested all over the world and even demonstrated during the opening ceremony at the Tokyo 2020 Paralympic Games.



Since the original announcement, we set out to improve Project Guideline by embedding new features, such as obstacle detection and advanced path planning, to safely and reliably navigate users t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Japanese words that are dying out:  focus on diabetes]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61374</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61374&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=japanese-words-that-are-dying-out-focus-on-diabetes"/>
        <updated>2023-11-21T10:52:50.000Z</updated>
        <summary type="html"><![CDATA[From The Japan Times: A foray into the realm of Japanese ‘dead words’ Trendy buzzwords tend to be most at risk of dying out as they often reflect ideas and trends that are fleeting. By Tadasu TakahashiStaff writer Oct 31, 2023 Sometimes whole languages go extinct, more often certain words within languages cease to exist as […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Calibration of Market Simulations using Neural Density Estimators
  and Embedding Networks]]></title>
        <id>http://arxiv.org/abs/2311.11913</id>
        <link href="http://arxiv.org/abs/2311.11913"/>
        <updated>2023-11-21T03:16:55.119Z</updated>
        <summary type="html"><![CDATA[Namid R. Stillman, Rory Baggott, Justin Lyon, Jianfei Zhang, Dingqiu
  Zhu, Tao Chen, Perukrishnen Vytelingum]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient learning of nonlinear prediction models with time-series
  privileged information]]></title>
        <id>http://arxiv.org/abs/2209.07067</id>
        <link href="http://arxiv.org/abs/2209.07067"/>
        <updated>2023-11-21T03:16:55.106Z</updated>
        <summary type="html"><![CDATA[Bastian Jung, Fredrik D Johansson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Neural Networks for Tiny Machine Learning: A Comprehensive
  Review]]></title>
        <id>http://arxiv.org/abs/2311.11883</id>
        <link href="http://arxiv.org/abs/2311.11883"/>
        <updated>2023-11-21T03:16:55.015Z</updated>
        <summary type="html"><![CDATA[Minh Tri L\^e, Pierre Wolinski, Julyan Arbel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-Supervised Pretraining for Heterogeneous Hypergraph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2311.11368</id>
        <link href="http://arxiv.org/abs/2311.11368"/>
        <updated>2023-11-21T03:16:54.985Z</updated>
        <summary type="html"><![CDATA[Abdalgader Abubaker, Takanori Maehara, Madhav Nimishakavi, Vassilis
  Plachouras]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two kinds of threads pools, and why you need both]]></title>
        <id>https://pythonspeed.com/articles/two-thread-pools/</id>
        <link href="https://pythonspeed.com/articles/two-thread-pools/"/>
        <updated>2023-11-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[When you’re doing large scale data processing with Python, threads are a good way to achieve parallelism.
This is especially true if you’re doing numeric processing, where the global interpreter lock (GIL) is typically not an issue.
And if you’re using threading, thread pools are a good way to make sure you don’t use too many resources.
But how many threads should your thread pool have?
And do you need just one thread pool, or more than one?
In this article we’ll see that for data processing batch jobs:
There are two kinds of thread pools, each for different use cases.
Each kind requires a different configuration.
You might need both.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Asymptotics of ABC when summaries converge at heterogeneous rates]]></title>
        <id>http://xianblog.wordpress.com/?p=54475</id>
        <link href="https://xianblog.wordpress.com/2023/11/21/asymptotics-of-abc-when-summaries-converge-at-heterogeneous-rates/"/>
        <updated>2023-11-20T23:23:47.000Z</updated>
        <summary type="html"><![CDATA[We just posted a new arXival, jointly with Caroline Lawless, Judith Rousseau, and Robin Ryder. This is a significant component of Caroline’s PhD thesis in Oxford, on which we started working during the first COVID lockdown.  In this paper, we extend our results with David Frazier, Gael Martin, both with whom I’ll soon be reunited!, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Xi's peculiar vocabulary]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61371</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61371&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=xis-peculiar-vocabulary"/>
        <updated>2023-11-20T16:53:31.000Z</updated>
        <summary type="html"><![CDATA[From another tweet / X-effusion by the Master Muckraker, Fang Zhouzi / Fang Shimin: “管总”这词是古代白话文，现在基本不用，原意是指某个人或某个部门管各种事务，“一个问题”怎么“管总”？哪个秘书想出来的新用法？ pic.twitter.com/jPdr3KzP6a — 方舟子 (@fangshimin) November 19, 2023 "Guǎnzǒng” zhè cí shì gǔdài báihuàwén, xiànzài jīběn bùyòng, yuányì shì zhǐ mǒu gèrén huò mǒu gè bùmén guǎn gè zhǒng shìwù,“yīgè wèntí” zěnme “guǎn zǒng”? Nǎge mìshū xiǎng chūlái de xīn yòngfǎ" “管总”这词是古代白话文，现在基本不用，原意是指某个人或某个部门管各种事务，“一个问题”怎么“管总”？哪个秘书想出来的新用法？ […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trends in Foreign Language enrollments]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61354</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61354&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=trends-foreign-language-enrollments"/>
        <updated>2023-11-20T11:41:04.000Z</updated>
        <summary type="html"><![CDATA[Karin Fisher, "It’s a Bleak Climate for Foreign Languages as Enrollments Tumble", Chronicle of Higher Education 11/15/2023" Enrollments in foreign-language courses tumbled nearly 17 percent between the fall of 2016 and the fall of 2021, the largest decline in the six decades the Modern Language Association has been conducting its census of American colleges. […] […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer升级之路：15、Key归一化助力长度外推]]></title>
        <id>https://kexue.fm/archives/9859</id>
        <link href="https://kexue.fm/archives/9859"/>
        <updated>2023-11-20T07:51:00.000Z</updated>
        <summary type="html"><![CDATA[大体上，我们可以将目前Transformer的长度外推技术分为两类：一类是事后修改，比如NTK-RoPE、YaRN、ReRoPE等，这类方法的特点是直接修改推理模型，无需微调就能达到一定的长度外...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AutoDiff: combining Auto-encoder and Diffusion model for tabular data
  synthesizing]]></title>
        <id>http://arxiv.org/abs/2310.15479</id>
        <link href="http://arxiv.org/abs/2310.15479"/>
        <updated>2023-11-20T07:14:36.250Z</updated>
        <summary type="html"><![CDATA[Namjoon Suh, Xiaofeng Lin, Din-Yin Hsieh, Merhdad Honarkhah, Guang
  Cheng]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random Forest Kernel for High-Dimension Low Sample Size Classification]]></title>
        <id>http://arxiv.org/abs/2310.14710</id>
        <link href="http://arxiv.org/abs/2310.14710"/>
        <updated>2023-11-20T03:16:18.975Z</updated>
        <summary type="html"><![CDATA[Lucca Portes Cavalheiro, Simon Bernard, Jean Paul Barddal, Laurent
  Heutte]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large
  Language Models]]></title>
        <id>http://arxiv.org/abs/2311.10112</id>
        <link href="http://arxiv.org/abs/2311.10112"/>
        <updated>2023-11-20T03:16:18.039Z</updated>
        <summary type="html"><![CDATA[Zifeng Ding, Heling Cai, Jingpei Wu, Yunpu Ma, Ruotong Liao, Bo Xiong,
  Volker Tresp]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring and Interacting with the Set of Good Sparse Generalized
  Additive Models]]></title>
        <id>http://arxiv.org/abs/2303.16047</id>
        <link href="http://arxiv.org/abs/2303.16047"/>
        <updated>2023-11-20T03:16:18.035Z</updated>
        <summary type="html"><![CDATA[Chudi Zhong, Zhi Chen, Jiachang Liu, Margo Seltzer, Cynthia Rudin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine learning phase transitions: Connections to the Fisher
  information]]></title>
        <id>http://arxiv.org/abs/2311.10710</id>
        <link href="http://arxiv.org/abs/2311.10710"/>
        <updated>2023-11-20T03:16:17.740Z</updated>
        <summary type="html"><![CDATA[Julian Arnold, Niels L\"orch, Flemming Holtorf, Frank Sch\"afer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Surprisal Driven $k$-NN for Robust and Interpretable Nonparametric
  Learning]]></title>
        <id>http://arxiv.org/abs/2311.10246</id>
        <link href="http://arxiv.org/abs/2311.10246"/>
        <updated>2023-11-20T03:16:17.736Z</updated>
        <summary type="html"><![CDATA[Amartya Banerjee, Christopher J. Hazard, Jacob Beel, Cade Mack, Jack
  Xia, Michael Resnick, Will Goddin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mistakes in a fraudulent Chinese letter to the Israeli consul in Chengdu]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61337</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61337&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mistakes-in-a-fraudulent-chinese-letter-to-the-israeli-consul-in-chengdu"/>
        <updated>2023-11-20T00:14:56.000Z</updated>
        <summary type="html"><![CDATA[From the Twitter / X account of the famous popular science writer and muckraker, Fang Zhouzi / Fang Shimin: 以色列领事馆公布的这封“一个陌生中国人的来信”，应该是在电脑上写好、打印出来，然后再抄写。所以有输入错误，把“公元”输入成了“公园”（书写只会把“公园”错成“公元”，不会反过来）。抄写的人写字水平太差，最常见的简单的字“且”“己”“组”都写错了，中国低年级小学生写这些字也不可能错。 pic.twitter.com/3GpUPS5k4b — 方舟子 (@fangshimin) November 16, 2023 Text of Fang Zhouzi's tweet: Yǐsèliè lǐngshìguǎn gōngbù de zhè fēng “yīgè mòshēng Zhōngguó rén de láixìn”, yīnggāi shì zài diànnǎo shàng xiě hǎo, dǎyìn chūlái, ránhòu zài […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stanley Park Brewing]]></title>
        <id>http://xianblog.wordpress.com/?p=53948</id>
        <link href="https://xianblog.wordpress.com/2023/11/20/stanley-park-brewing/"/>
        <updated>2023-11-19T23:23:50.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Grids galore]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61312</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61312&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=grids-galore"/>
        <updated>2023-11-19T06:10:21.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Zhengyuan Wang] Calligraphy Practicing Sheets and the Trussing Structure of Chinese Characters One thing essential for every elementary-level Chinese learner is to learn to write the characters in the same size in one single passage. This is not a unique case that only exists in Chinese. But this can be a […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Extreme simplification and phoneticization]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61315</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61315&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=extreme-simplification-and-phoneticization"/>
        <updated>2023-11-19T05:37:03.000Z</updated>
        <summary type="html"><![CDATA[Probably only Northeastern Chinese could understand. (source) "丿" is a stroke in the Chinese writing system, named "piě 撇" (defined as "a stroke that falls downwards towards the left").  "了" (le) is a suffix that represents perfect tense in MSM. So together, the sound of "piě-le 丿了" is slurredly homophonous to that of 苤蓝 (MSM: […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Frog or chicken]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61308</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61308&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=frog-or-chicken"/>
        <updated>2023-11-19T05:32:58.000Z</updated>
        <summary type="html"><![CDATA[From Charles Belov: While scouting out restaurants on Yelp, I noticed that Harborview Restaurant Yelp page had an item on the menu listed in English as Congee with Bone-in Chicken. However, the menu image, taken in 2022, reads "Congree with stir-fried frog" in Chinese. This appears to have been corrected on the Harborview Restaurant website. The Dim Sum […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[is it necessary to learn summary statistics? [One World ABC seminar]]]></title>
        <id>http://xianblog.wordpress.com/?p=54463</id>
        <link href="https://xianblog.wordpress.com/2023/11/19/is-it-necessary-to-learn-summary-statistics-one-world-abc-seminar/"/>
        <updated>2023-11-18T23:23:18.000Z</updated>
        <summary type="html"><![CDATA[Next week, on 30 November, at 9am (UK time), Yanzhi Chen (Cambridge) will give a One World ABC webinar on Is “It Necessary to Learn Summary Statistics for Likelihood-free Inference?”, a PMLR paper join with Michael Guttman and Adrian Weller: Likelihood-free inference (LFI) is a set of techniques for inference in implicit statistical models. A […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sam Altman and King Blozo]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61319</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61319&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sam-altman-and-king-blozo"/>
        <updated>2023-11-18T10:51:39.000Z</updated>
        <summary type="html"><![CDATA[We're all waiting to learn the story behind Sam Altman's firing as CEO of OpenAI. Or least, many of us are. Meanwhile, there's possible resonance with an on-going drama in the daily Popeye comic strip, concerning the fate of (former) King Blozo of Spinachovia, now the Superintendent of Royal Foot Surfaces:]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Glimpses of Montagne Pelée]]></title>
        <id>http://xianblog.wordpress.com/?p=54331</id>
        <link href="https://xianblog.wordpress.com/2023/11/18/glimpses-of-montagne-pelee/"/>
        <updated>2023-11-17T23:23:02.000Z</updated>
        <summary type="html"><![CDATA[Since we had missed the opportunity to climb Montagne Pelée on our previous trip to Martinique, I was most eager to get there this trip, despite all the schedule constraints. It was however the rain season, with two storm alert issued during our stay, and the weather window was hard to assess. Which is why […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Emerging practices for Society-Centered AI]]></title>
        <id>http://blog.research.google/2023/11/emerging-practices-for-society-centered.html</id>
        <link href="http://blog.research.google/2023/11/emerging-practices-for-society-centered.html"/>
        <updated>2023-11-17T19:36:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Anoop Sinha, Research Director, Technology & Society, and Yossi Matias, Vice President, Google Research




The first of Google’s AI Principles is to “Be socially beneficial.” As AI practitioners, we’re inspired by the transformative potential of AI technologies to benefit society and our shared environment at a scale and swiftness that wasn’t possible before. From helping address the climate crisis to helping transform healthcare, to making the digital world more accessible, our goal is to apply AI responsibly to be helpful to more people around the globe. Achieving global scale requires researchers and communities to think ahead — and act — collectively across the AI ecosystem.



We call this approach Society-Centered AI. It is both an extension and an expansion of Human-Cente…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inversion of walkaway VSP data in the presence of lateral velocity
  heterogeneity]]></title>
        <id>http://arxiv.org/abs/1901.02916</id>
        <link href="http://arxiv.org/abs/1901.02916"/>
        <updated>2023-11-17T05:14:56.118Z</updated>
        <summary type="html"><![CDATA[Vladimir Grechka, Ilya Tsvankin, Pedro Contreras]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Two applications of strong hyperbolicity]]></title>
        <id>http://arxiv.org/abs/1901.00583</id>
        <link href="http://arxiv.org/abs/1901.00583"/>
        <updated>2023-11-17T05:14:56.110Z</updated>
        <summary type="html"><![CDATA[Bogdan Nica]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Law of the SLE tip]]></title>
        <id>http://arxiv.org/abs/2110.11247</id>
        <link href="http://arxiv.org/abs/2110.11247"/>
        <updated>2023-11-17T05:14:56.090Z</updated>
        <summary type="html"><![CDATA[Oleg Butkovsky, Vlad Margarint, Yizheng Yuan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dual relations between line congruences in $\mathbb{R}^3$ and surfaces
  in $\mathbb{R}^4$]]></title>
        <id>http://arxiv.org/abs/1811.07331</id>
        <link href="http://arxiv.org/abs/1811.07331"/>
        <updated>2023-11-17T05:14:56.084Z</updated>
        <summary type="html"><![CDATA[Marcos Craizer, Ronaldo Alves Garcia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Die Hard Holographic Phenomenology of Cuprates]]></title>
        <id>http://arxiv.org/abs/2011.11617</id>
        <link href="http://arxiv.org/abs/2011.11617"/>
        <updated>2023-11-17T05:14:55.850Z</updated>
        <summary type="html"><![CDATA[D.V.Khveshchenko]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spatial Bayesian Neural Networks]]></title>
        <id>http://arxiv.org/abs/2311.09491</id>
        <link href="http://arxiv.org/abs/2311.09491"/>
        <updated>2023-11-17T04:18:43.574Z</updated>
        <summary type="html"><![CDATA[Andrew Zammit-Mangion, Michael D. Kaminski, Ba-Hien Tran, Maurizio
  Filippone, Noel Cressie]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Problem: Learning with Variational Objectives on Measures]]></title>
        <id>http://arxiv.org/abs/2306.11928</id>
        <link href="http://arxiv.org/abs/2306.11928"/>
        <updated>2023-11-17T04:18:43.550Z</updated>
        <summary type="html"><![CDATA[Vivien Cabannes, Carles Domingo-Enrich]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EvoPrompting: Language Models for Code-Level Neural Architecture Search]]></title>
        <id>http://arxiv.org/abs/2302.14838</id>
        <link href="http://arxiv.org/abs/2302.14838"/>
        <updated>2023-11-17T04:18:43.379Z</updated>
        <summary type="html"><![CDATA[Angelica Chen, David M. Dohan, David R. So]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rethinking Fano's Inequality in Ensemble Learning]]></title>
        <id>http://arxiv.org/abs/2205.12683</id>
        <link href="http://arxiv.org/abs/2205.12683"/>
        <updated>2023-11-17T04:18:43.287Z</updated>
        <summary type="html"><![CDATA[Terufumi Morishita, Gaku Morio, Shota Horiguchi, Hiroaki Ozaki, Nobuo
  Nukaga]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Affine Invariance in Continuous-Domain Convolutional Neural Networks]]></title>
        <id>http://arxiv.org/abs/2311.09245</id>
        <link href="http://arxiv.org/abs/2311.09245"/>
        <updated>2023-11-17T04:18:43.224Z</updated>
        <summary type="html"><![CDATA[Ali Mohaddes, Johannes Lederer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Abbreviated and nonstandard kanji]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61304</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61304&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=abbreviated-and-nonstandard-kanji"/>
        <updated>2023-11-17T01:04:28.000Z</updated>
        <summary type="html"><![CDATA[From Nathan Hopson: I have been reading some handwritten documents from the 1960s and 1970s, and have been reminded that even beyond abbreviations, there were still "nonstandard" kanji in use. I guess this took me off guard mostly because these are school publications. On the abbreviated side, the most obvious example is: 第 → 㐧 […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ze kitchen galerie]]></title>
        <id>http://xianblog.wordpress.com/?p=53963</id>
        <link href="https://xianblog.wordpress.com/2023/11/17/ze-kitchen-gallery/"/>
        <updated>2023-11-16T23:23:12.000Z</updated>
        <summary type="html"><![CDATA[A surprise invitation to Ze Kitchen Galerie, an original restaurant in the Latin Quarter serving a fancy fusion cuisine with strong South-East Asia influences. Including a stuffed zucchini flower. If anything, the opposition between the dish and its broth was sometimes too much, as in the white chocolate – wasabi ice cream where the wasabi […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Measure of Maximal Entropy for Finite Horizon Sinai Billiard Maps]]></title>
        <id>http://arxiv.org/abs/1807.02330</id>
        <link href="http://arxiv.org/abs/1807.02330"/>
        <updated>2023-11-16T22:14:32.043Z</updated>
        <summary type="html"><![CDATA[Viviane Baladi, Mark Demers]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dihedral Sieving Phenomena]]></title>
        <id>http://arxiv.org/abs/1710.06517</id>
        <link href="http://arxiv.org/abs/1710.06517"/>
        <updated>2023-11-16T22:14:32.021Z</updated>
        <summary type="html"><![CDATA[Sujit Rao, Joe Suk]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Difference-in-Differences Estimators of Intertemporal Treatment Effects]]></title>
        <id>http://arxiv.org/abs/2007.04267</id>
        <link href="http://arxiv.org/abs/2007.04267"/>
        <updated>2023-11-16T22:14:32.017Z</updated>
        <summary type="html"><![CDATA[Cl\'ement de Chaisemartin, Xavier D'Haultfoeuille]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Asymptotic properties of generalized closed-form maximum likelihood
  estimators]]></title>
        <id>http://arxiv.org/abs/2102.07356</id>
        <link href="http://arxiv.org/abs/2102.07356"/>
        <updated>2023-11-16T22:14:32.006Z</updated>
        <summary type="html"><![CDATA[Pedro L. Ramos, Eduardo Ramos, Francisco A. Rodrigues, Francisco
  Louzada]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Shifted symplectic structures on derived analytic moduli of $\ell$-adic
  local systems and Galois representations]]></title>
        <id>http://arxiv.org/abs/2205.02292</id>
        <link href="http://arxiv.org/abs/2205.02292"/>
        <updated>2023-11-16T22:14:32.002Z</updated>
        <summary type="html"><![CDATA[J.P. Pridham]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: Adversarial testing for generative AI safety]]></title>
        <id>http://blog.research.google/2023/11/responsible-ai-at-google-research_16.html</id>
        <link href="http://blog.research.google/2023/11/responsible-ai-at-google-research_16.html"/>
        <updated>2023-11-16T21:11:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Kathy Meier-Hellstern, Building Responsible AI & Data Systems, Director, Google Research




The Responsible AI and Human-Centered Technology (RAI-HCT) team within Google Research is committed to advancing the theory and practice of responsible human-centered AI through a lens of culturally-aware research, to meet the needs of billions of users today, and blaze the path forward for a better AI future. The BRAIDS (Building Responsible AI Data and Solutions) team within RAI-HCT aims to simplify the adoption of RAI practices through the utilization of scalable tools, high-quality data, streamlined processes, and novel research with a current emphasis on addressing the unique challenges posed by generative AI (GenAI).





GenAI models have enabled unprecedented capabilities leading …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pluperfect]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61292</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61292&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pluperfect"/>
        <updated>2023-11-16T19:39:21.000Z</updated>
        <summary type="html"><![CDATA[Recently, we've had occasion to discuss how waitpersons in restaurants tend to say "perfect" no matter what we order (see, for instance, in the comments here).  Lately, I've noticed how the craze for perfection has spread to the grocery business. I have a habit of carrying cash (my Chinese students barely know what cash is) […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Empiricism as a New Year's resolution]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61300</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61300&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=empiricism-as-a-new-years-resolution"/>
        <updated>2023-11-16T08:25:24.000Z</updated>
        <summary type="html"><![CDATA[Today's xkcd: Mouseover title: "The problems started with my resolution next year to reject temporal causality." Two earlier empiricism jokes can be found in "Learning empiricism", 4/29/2020. For a larger dose of epistemology, without jokes, see "Rationalism vs. Empiricism", The Stanford Encyclopedia of Philosophy.]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerating Generative AI with PyTorch: Segment Anything, Fast]]></title>
        <id>https://pytorch.org/blog/accelerating-generative-ai/</id>
        <link href="https://pytorch.org/blog/accelerating-generative-ai/"/>
        <updated>2023-11-16T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[This post is the first part of a multi-series blog focused on how to accelerate generative AI models with pure, native PyTorch. We are excited to share a breadth of newly released PyTorch performance features alongside practical examples of how these features can be combined to see how far we can push PyTorch native performance.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[🎉 PyTorch Docathon H2 2023 Wrap-up 🎉]]></title>
        <id>https://pytorch.org/blog/pytorch-docathon-h2-2023-wrap/</id>
        <link href="https://pytorch.org/blog/pytorch-docathon-h2-2023-wrap/"/>
        <updated>2023-11-16T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are thrilled to announce the successful completion of the Fall 2023 PyTorch Docathon! The event was a resounding success, and we want to extend our heartfelt gratitude to all the participants who made it possible. Dedication, expertise, and tireless efforts of our open-source contributors have once again helped us to improve PyTorch documentation.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transforming the future of music creation]]></title>
        <id>https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/</id>
        <link href="https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/"/>
        <updated>2023-11-16T07:20:00.000Z</updated>
        <summary type="html"><![CDATA[Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and
  Besov Spaces]]></title>
        <id>http://arxiv.org/abs/2211.14400</id>
        <link href="http://arxiv.org/abs/2211.14400"/>
        <updated>2023-11-16T04:18:46.452Z</updated>
        <summary type="html"><![CDATA[Jonathan W. Siegel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NN2Poly: A polynomial representation for deep feed-forward artificial
  neural networks]]></title>
        <id>http://arxiv.org/abs/2112.11397</id>
        <link href="http://arxiv.org/abs/2112.11397"/>
        <updated>2023-11-16T04:18:46.431Z</updated>
        <summary type="html"><![CDATA[Pablo Morala (1, 2), Jenny Alexandra Cifuentes (3), Rosa E. Lillo
  (1, 2), I\~naki Ucar (1, 2) ((1) uc3m-Santander Big Data Institute,
  Universidad Carlos III de Madrid. Spain., (2) Department of Statistics,
  Universidad Carlos III de Madrid. Spain., (3) ICADE, Department of
  Quantitative Methods, Faculty of Economics, Business Administration,
  Universidad Pontificia Comillas. Spain.)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Error Bounds for Learning with Vector-Valued Random Features]]></title>
        <id>http://arxiv.org/abs/2305.17170</id>
        <link href="http://arxiv.org/abs/2305.17170"/>
        <updated>2023-11-16T04:18:46.428Z</updated>
        <summary type="html"><![CDATA[Samuel Lanthaler, Nicholas H. Nelsen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ExpM+NF: Differentially Private Machine Learning that Surpasses DPSGD]]></title>
        <id>http://arxiv.org/abs/2311.09200</id>
        <link href="http://arxiv.org/abs/2311.09200"/>
        <updated>2023-11-16T04:18:46.260Z</updated>
        <summary type="html"><![CDATA[Robert A. Bridges, Vandy J. Tombs, Christopher B. Stanley]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical learning by sparse deep neural networks]]></title>
        <id>http://arxiv.org/abs/2311.08845</id>
        <link href="http://arxiv.org/abs/2311.08845"/>
        <updated>2023-11-16T04:18:46.139Z</updated>
        <summary type="html"><![CDATA[Felix Abramovich]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[snap snap snap…]]></title>
        <id>http://xianblog.wordpress.com/?p=54050</id>
        <link href="https://xianblog.wordpress.com/2023/11/16/snap-snap-snap/"/>
        <updated>2023-11-15T23:23:36.000Z</updated>
        <summary type="html"><![CDATA[Every few weeks, I get a warning from Firefox (my default browser) that an update is not implemented. This is due to Ubuntu 22.0 adopting the snap technology for handling its packages and their updates. Supposedly helping with handling versions and dependences. This update can be done with the line command sudo snap refresh firefox […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — A Global Optimization and Dataflow Analysis]]></title>
        <id>https://jeremykun.com/?p=120314</id>
        <link href="https://jeremykun.com/2023/11/15/mlir-a-global-optimization-and-dataflow-analysis/"/>
        <updated>2023-11-15T19:20:52.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents In this article we’ll implement a global optimization pass, and show how to use the dataflow analysis framework to verify the results of our optimization. The code for this article is in this pull request, and as usual the commits are organized to be read in order. The noisy arithmetic problem This […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Onomatopoeia in everyday Japanese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61274</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61274&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=onomatopoeia-in-everyday-japanese"/>
        <updated>2023-11-15T12:10:26.000Z</updated>
        <summary type="html"><![CDATA[Of all the languages I know, Japanese is the richest in onomatopoeia (and poorest in swearing).  Here's a brief introduction to reduplicative sound symbolism. ‘Pachi pachi’ or ‘kachi kachi’? Japan launches foreigners’ guide to tricky world of onomatopoeiaAs foreign population reaches record levels, the western prefecture of Mie has compiled a guide for those who […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Empowering the next generation for an AI-enabled world]]></title>
        <id>https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/</id>
        <link href="https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/"/>
        <updated>2023-11-15T10:00:00.000Z</updated>
        <summary type="html"><![CDATA[Experience AI's course and resources are expanding on a global scale]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Adversarial Low-rank Markov Decision Processes with Unknown
  Transition and Full-information Feedback]]></title>
        <id>http://arxiv.org/abs/2311.07876</id>
        <link href="http://arxiv.org/abs/2311.07876"/>
        <updated>2023-11-15T04:18:09.678Z</updated>
        <summary type="html"><![CDATA[Canzhe Zhao, Ruofeng Yang, Baoxiang Wang, Xuezhou Zhang, Shuai Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unbiased Learning of Deep Generative Models with Structured Discrete
  Representations]]></title>
        <id>http://arxiv.org/abs/2306.08230</id>
        <link href="http://arxiv.org/abs/2306.08230"/>
        <updated>2023-11-15T04:18:04.903Z</updated>
        <summary type="html"><![CDATA[Harry Bendekgey, Gabriel Hope, Erik B. Sudderth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Deep Reinforcement Learning Approach to Marginalized Importance
  Sampling with the Successor Representation]]></title>
        <id>http://arxiv.org/abs/2106.06854</id>
        <link href="http://arxiv.org/abs/2106.06854"/>
        <updated>2023-11-15T03:15:43.820Z</updated>
        <summary type="html"><![CDATA[Scott Fujimoto, David Meger, Doina Precup]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PAC-Bayesian Generalization Bounds for Adversarial Generative Models]]></title>
        <id>http://arxiv.org/abs/2302.08942</id>
        <link href="http://arxiv.org/abs/2302.08942"/>
        <updated>2023-11-15T03:15:43.803Z</updated>
        <summary type="html"><![CDATA[Sokhna Diarra Mbacke, Florence Clerc, Pascal Germain]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Scale Prediction with Decision Trees]]></title>
        <id>http://arxiv.org/abs/2104.13881</id>
        <link href="http://arxiv.org/abs/2104.13881"/>
        <updated>2023-11-15T03:15:41.060Z</updated>
        <summary type="html"><![CDATA[Jason M. Klusowski, Peter M. Tian]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Theoretical Understanding of Shallow Vision Transformers: Learning,
  Generalization, and Sample Complexity]]></title>
        <id>http://arxiv.org/abs/2302.06015</id>
        <link href="http://arxiv.org/abs/2302.06015"/>
        <updated>2023-11-15T03:15:41.048Z</updated>
        <summary type="html"><![CDATA[Hongkang Li, Meng Wang, Sijia Liu, Pin-yu Chen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visualizing the Diversity of Representations Learned by Bayesian Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2201.10859</id>
        <link href="http://arxiv.org/abs/2201.10859"/>
        <updated>2023-11-15T03:15:41.044Z</updated>
        <summary type="html"><![CDATA[Dennis Grinwald, Kirill Bykov, Shinichi Nakajima, Marina M.-C. H\"ohne]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anse à voile [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=54305</id>
        <link href="https://xianblog.wordpress.com/2023/11/15/anse-a-voile-jatp/"/>
        <updated>2023-11-14T23:23:07.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scaling multimodal understanding to long videos]]></title>
        <id>http://blog.research.google/2023/11/scaling-multimodal-understanding-to.html</id>
        <link href="http://blog.research.google/2023/11/scaling-multimodal-understanding-to.html"/>
        <updated>2023-11-14T20:28:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Isaac Noble, Software Engineer, Google Research, and Anelia Angelova, Research Scientist, Google DeepMind 





When building machine learning models for real-life applications, we need to consider inputs from multiple modalities in order to capture various aspects of the world around us. For example, audio, video, and text all provide varied and complementary information about a visual input. However, building multimodal models is challenging due to the heterogeneity of the modalities. Some of the modalities might be well synchronized in time (e.g., audio, video) but not aligned with text. Furthermore, the large volume of data in video and audio signals is much larger than that in text, so when combining them in multimodal models, video and audio often cannot be fully consumed a…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beer Battle Bowls]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61267</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61267&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=beer-battle-bowls"/>
        <updated>2023-11-14T17:54:30.000Z</updated>
        <summary type="html"><![CDATA[Mark Metcalf had lunch with his in-laws at a great Cantonese restaurant in Taichung, Taiwan.  They shared a bottle of Táiwān píjiǔ 台灣啤酒 ("Taiwan beer") and were given chilled “Hong Kong style” battle bowls – emblazoned with zhàndòu wǎn 戰鬥碗 ("battle bowl") on the side and with shēng 勝 ("victory") on the inside bottom –  to drink it. Neither Mark […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chinglish trifecta]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61194</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61194&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chinglish-trifecta"/>
        <updated>2023-11-14T17:49:04.000Z</updated>
        <summary type="html"><![CDATA[It's been a while. From Qingchen Li: The sign says: kànhǎo értóng 看好儿童 "take care of / look out for children" wénmíng shāng méi 文明商梅 "be civilized in appreciating the plum blossoms" qǐng wù rùnèi 请勿入内 "no entry" qīngcǎo yīyī 青草依依 "tender green grass" qǐngnín àixī 请您爱惜 "respectfully please cherish it" The fact that we don't […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GraphCast: AI model for faster and more accurate global weather forecasting]]></title>
        <id>https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/</id>
        <link href="https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/"/>
        <updated>2023-11-14T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy]]></summary>
        <author>
            <name>Google DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ghostbuster: Detecting Text Ghostwritten by Large Language Models]]></title>
        <id>http://bair.berkeley.edu/blog/2023/11/14/ghostbuster/</id>
        <link href="http://bair.berkeley.edu/blog/2023/11/14/ghostbuster/"/>
        <updated>2023-11-14T12:30:00.000Z</updated>
        <summary type="html"><![CDATA[The structure of Ghostbuster, our new state-of-the-art method for detecting AI-generated text.


Large language models like ChatGPT write impressively well—so well, in fact, that they’ve become a problem. Students have begun using these models to ghostwrite assignments, leading some schools to ban ChatGPT. In addition, these models are also prone to producing text with factual errors, so wary readers may want to know if generative AI tools have been used to ghostwrite news articles or other sources before trusting them.
What can teachers and consumers do? Existing tools to detect AI-generated text sometimes do poorly on data that differs from what they were trained on. In addition, if these models falsely classify real human writing as AI-generated, they can jeopardize students whose genui…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Asymmetric Certified Robustness via Feature-Convex Neural Networks]]></title>
        <id>http://bair.berkeley.edu/blog/2023/11/14/fcnn/</id>
        <link href="http://bair.berkeley.edu/blog/2023/11/14/fcnn/"/>
        <updated>2023-11-14T09:00:00.000Z</updated>
        <summary type="html"><![CDATA[Asymmetric Certified Robustness via Feature-Convex Neural Networks

TLDR: We propose the asymmetric certified robustness problem, which requires certified robustness for only one class and reflects real-world adversarial scenarios. This focused setting allows us to introduce feature-convex classifiers, which produce closed-form and deterministic certified radii on the order of milliseconds.
Despite their widespread usage, deep learning classifiers are acutely vulnerable to adversarial examples: small, human-imperceptible image perturbations that fool machine learning models into misclassifying the modified input. This weakness severely undermines the reliability of safety-critical processes that incorporate machine learning. Many empirical defenses against adversarial perturbations have be…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mixed Semi-Supervised Generalized-Linear-Regression with applications to
  Deep-Learning and Interpolators]]></title>
        <id>http://arxiv.org/abs/2302.09526</id>
        <link href="http://arxiv.org/abs/2302.09526"/>
        <updated>2023-11-14T03:15:37.971Z</updated>
        <summary type="html"><![CDATA[Oren Yuval, Saharon Rosset]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tackling the Curse of Dimensionality with Physics-Informed Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2307.12306</id>
        <link href="http://arxiv.org/abs/2307.12306"/>
        <updated>2023-11-14T03:15:37.795Z</updated>
        <summary type="html"><![CDATA[Zheyuan Hu, Khemraj Shukla, George Em Karniadakis, Kenji Kawaguchi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-approximability of constructive global $\mathcal{L}^2$ minimizers by
  gradient descent in Deep Learning]]></title>
        <id>http://arxiv.org/abs/2311.07065</id>
        <link href="http://arxiv.org/abs/2311.07065"/>
        <updated>2023-11-14T03:15:37.760Z</updated>
        <summary type="html"><![CDATA[Thomas Chen, Patricia Mu\~noz Ewald]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NVIDIA Is A New Sponsor Of The Scikit-Learn consortium at the Inria Foundation]]></title>
        <id>https://blog.scikit-learn.org/funding/nvidia-is-a-new-sponsor/</id>
        <link href="https://blog.scikit-learn.org/funding/nvidia-is-a-new-sponsor/"/>
        <updated>2023-11-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Author: NVIDIA , François Goupil]]></summary>
        <author>
            <name>scikit-learn Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[call for immediate action to halt attacks on health care in Gaza [reposted]]]></title>
        <id>http://xianblog.wordpress.com/?p=54454</id>
        <link href="https://xianblog.wordpress.com/2023/11/14/call-for-immediate-action-to-halt-attacks-on-health-care-in-gaza-reposted/"/>
        <updated>2023-11-13T23:23:19.000Z</updated>
        <summary type="html"><![CDATA[The regional directors of UNFPA, UNICEF and WHO call for urgent international action to end the ongoing attacks on hospitals in Gaza. We are horrified at the latest reports of attacks on and in the vicinity of Al-Shifa Hospital, Al-Rantissi Naser Paediatric Hospital, Al-Quds Hospital, and others in Gaza city and northern Gaza, killing many, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Coercive Chinese censorship against Thailand]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61244</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61244&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=coercive-chinese-censorship-against-thailand"/>
        <updated>2023-11-13T19:52:07.000Z</updated>
        <summary type="html"><![CDATA["Hurting the feelings of the Chinese people", part 572 From AntC: Joseph Wu (吳釗燮), Taiwan's Foreign Minister, just gave an interview on Thai TV. I thought it a very sober assessment of the current situations (worldwide).  See Taiwan News article here.    Thai TV posted it on Youtube; PRC immediately claimed it "harmed China’s interests […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The history of "artificial intelligence"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61238</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61238&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-history-of-artificial-intelligence"/>
        <updated>2023-11-13T16:29:29.000Z</updated>
        <summary type="html"><![CDATA[The Google Books ngram plot for "artificial intelligence" offers a graph of AI's culturomics: According to the OED, the first use of the term artificial intelligence was in a 13-page grant application by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon, "A proposal for the Dartmouth summer research project on artificial intelligence", written in […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[【生活杂记】炒锅的尽头是铁锅]]></title>
        <id>https://kexue.fm/archives/9855</id>
        <link href="https://kexue.fm/archives/9855"/>
        <updated>2023-11-13T14:37:00.000Z</updated>
        <summary type="html"><![CDATA[很多会下厨的同学估计都纠结过一件事情，那就是炒锅的选择。对于炒锅的纠结，归根结底是不粘与方便的权衡。最简单的不粘锅自然是带涂层的不粘锅，如果家里的热源只有电磁炉，并且炒菜习惯比较温和，那么涂层不...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Eco-Language and the Anthropocene]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61225</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61225&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=eco-language-and-the-anthropocene"/>
        <updated>2023-11-13T12:50:10.000Z</updated>
        <summary type="html"><![CDATA[In his blog post, "Grassland logic, Agrilogistics and Hanspace Cosmologies — Robin Visser’s Disruptive 'Questioning Borders'", Bruce Humes called this new book by Robin Visser to our attention:  Questioning Borders: Ecoliteratures of China and Taiwan (Columbia University Press, 2023). Here's the book description from the press: Indigenous knowledge of local ecosystems often challenges settler-colonial cosmologies […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Marton’s “Polynomial Freiman-Rusza” Conjecture was Settled by the A-Team.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24905</id>
        <link href="https://gilkalai.wordpress.com/2023/11/13/martons-polynomial-freiman-rusza-conjecture-was-settled-by-the-a-team/"/>
        <updated>2023-11-13T11:04:28.000Z</updated>
        <summary type="html"><![CDATA[“If you have a problem, if no one else can help, and if you can find them, maybe you can hire… the A-Team.” (The A-teams of the 1980s television series on the left. Gowers, Green, Manner and Tao on the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Marton’s “Polynomial Freiman-Rusza” Conjecture was Settled by the A-Team.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24905</id>
        <link href="https://gilkalai.wordpress.com/2023/11/13/martons-polynomial-freiman-rusza-conjecture-was-settled-by-the-a-team/"/>
        <updated>2023-11-13T11:04:28.000Z</updated>
        <summary type="html"><![CDATA[“If you have a problem, if no one else can help, and if you can find them, maybe you can hire… the A-Team.” (The A-teams of the 1980s television series on the left. Gowers, Green, Manner and Tao on the … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Reconstruction Attacks with the Neural Tangent Kernel and
  Dataset Distillation]]></title>
        <id>http://arxiv.org/abs/2302.01428</id>
        <link href="http://arxiv.org/abs/2302.01428"/>
        <updated>2023-11-13T04:18:37.759Z</updated>
        <summary type="html"><![CDATA[Noel Loo, Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convolutional neural networks for valid and efficient causal inference]]></title>
        <id>http://arxiv.org/abs/2301.11732</id>
        <link href="http://arxiv.org/abs/2301.11732"/>
        <updated>2023-11-13T04:18:27.069Z</updated>
        <summary type="html"><![CDATA[Mohammad Ghasempour, Niloofar Moosavi, Xavier de Luna]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep quantum neural networks form Gaussian processes]]></title>
        <id>http://arxiv.org/abs/2305.09957</id>
        <link href="http://arxiv.org/abs/2305.09957"/>
        <updated>2023-11-13T04:18:26.915Z</updated>
        <summary type="html"><![CDATA[Diego Garc\'ia-Mart\'in, Martin Larocca, M. Cerezo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Distributionally Robust Skeleton Learning of Discrete Bayesian Networks]]></title>
        <id>http://arxiv.org/abs/2311.06117</id>
        <link href="http://arxiv.org/abs/2311.06117"/>
        <updated>2023-11-13T04:18:26.902Z</updated>
        <summary type="html"><![CDATA[Yeshu Li, Brian D. Ziebart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anytime-Valid Confidence Sequences for Consistent Uncertainty Estimation
  in Early-Exit Neural Networks]]></title>
        <id>http://arxiv.org/abs/2311.05931</id>
        <link href="http://arxiv.org/abs/2311.05931"/>
        <updated>2023-11-13T04:18:26.887Z</updated>
        <summary type="html"><![CDATA[Metod Jazbec, Patrick Forr\'e, Stephan Mandt, Dan Zhang and
  Eric Nalisnick]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[the long way off a small, angry planet]]></title>
        <id>http://xianblog.wordpress.com/?p=54287</id>
        <link href="https://xianblog.wordpress.com/2023/11/13/the-long-way-off-a-small-angry-planet/"/>
        <updated>2023-11-12T23:21:53.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[276 cat facial expressions?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61229</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61229&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=276-cat-facial-expressions"/>
        <updated>2023-11-12T16:35:22.000Z</updated>
        <summary type="html"><![CDATA[Lauren Scott & Brittany Florkiewicz, "Feline Faces: Unraveling the Social Function of Domestic Cat Facial Signals", Behavioral Processes 2023: ABSTRACT: Lately, there has been a growing interest in studying domestic cat facial signals, but most of this research has centered on signals produced during human-cat interactions or pain. The available research on intraspecific facial signaling […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New type of headlinese passivization]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61221</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61221&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=new-type-of-headlinese-passivization"/>
        <updated>2023-11-12T12:29:55.000Z</updated>
        <summary type="html"><![CDATA[From Olive Long: Here's a post containing an interesting passivization on the site formerly known as Twitter ("Philadelphia 76ers guard Kelly Oubre Jr. was a pedestrian struck by a motor vehicle in Center City"). This sort of 'split' passivization ("X was a Y V by Z" from "Z V X[, a Y].") seems at least […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nature snapshots [10 Aug 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=53892</id>
        <link href="https://xianblog.wordpress.com/2023/11/12/nature-snapshots-10-aug-2023/"/>
        <updated>2023-11-11T23:23:40.000Z</updated>
        <summary type="html"><![CDATA[Many gems in the 10 Aug issue I found home back from Western Canada. Starting with the cover theme related to the fascinating paper Solid-body trajectoids shaped to roll along desired pathways by Sobolev et al. which shows that there exist 3D objects corresponding to any infinitely periodic trajectory and furthermore that such objects can […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=54271</id>
        <link href="https://xianblog.wordpress.com/2023/11/11/a-journal-of-the-conquest-war-famine-and-death-year-6/"/>
        <updated>2023-11-10T23:23:39.000Z</updated>
        <summary type="html"><![CDATA[Read the (paper version of) L’art du naufrage by Pascale Quiviger. Very light and rather YA, but still with enough creativity and originality to be enjoyable. Which made me read the second volume as well, Les filles de Mai, which proved an improvement in the scenario and its tension, even though the island-universe is most […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ask Language Log:  The Dry / Solitary Tree]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61200</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61200&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ask-language-log-the-dry-solitary-tree"/>
        <updated>2023-11-10T20:50:35.000Z</updated>
        <summary type="html"><![CDATA[From Adrienne Mayor: I am writing about The Dry Tree or Solitary Tree, associated with Alexander the Great in medieval Alexander Romance and in Marco Polo, who located it in Khorasan. Later, the Bavarian explorer Johannes Schiltberger trekked across Khorasan in about 1405-25 and reported that the Muslims called the tree “Kurrutherek” or “Sirpe,” meanings […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enabling large-scale health studies for the research community]]></title>
        <id>http://blog.research.google/2023/11/enabling-large-scale-health-studies-for.html</id>
        <link href="http://blog.research.google/2023/11/enabling-large-scale-health-studies-for.html"/>
        <updated>2023-11-10T18:05:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Chintan Ghate, Software Engineer, and Diana Mincu, Research Engineer, Google Research




As consumer technologies like fitness trackers and mobile phones become more widely used for health-related data collection, so does the opportunity to leverage these data pathways to study and advance our understanding of medical conditions. We have previously touched upon how our work explores the use of this technology within the context of chronic diseases, in particular multiple sclerosis (MS). This effort leverages the FDA MyStudies platform, an open-source platform used to create clinical study apps, that makes it easier for anyone to run their own studies and collect good quality healthcare data, in a trusted and safe way.


 


Today, we describe the setup that we developed by expan…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The necessary levels of narcissism]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61216</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61216&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-necessary-levels-of-narcissism"/>
        <updated>2023-11-10T16:17:58.000Z</updated>
        <summary type="html"><![CDATA[A recent SMBC strip:  The mouseover title: "I worry that with humanities departments being gutted we are no longer creating the necessary levels of narcissism to preserve civil society." The aftercomic: But surely, societal narcissism levels are unlikely to reach dangerous lows as long as business schools exist?]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["…oscillated in his words"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61197</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61197&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=oscillated-in-his-words"/>
        <updated>2023-11-10T13:14:17.000Z</updated>
        <summary type="html"><![CDATA[Ken Bensinger, "Ramaswamy Seemed to Call Zelensky a Nazi. His Campaign Says That’s Not What He Meant." NYT 11/8/2023: A spokeswoman for Mr. Ramaswamy, Tricia McLaughlin, said that he had not called Mr. Zelensky a Nazi. Instead, Ms. McLaughlin said, he was referring to an event in September in which Mr. Zelensky visited Canada’s Parliament […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adrian’s defence]]></title>
        <id>http://xianblog.wordpress.com/?p=54431</id>
        <link href="https://xianblog.wordpress.com/2023/11/10/adrians-defence/"/>
        <updated>2023-11-10T08:08:36.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Class-Incremental Learning with Generative Classifiers]]></title>
        <id>http://arxiv.org/abs/2104.10093</id>
        <link href="http://arxiv.org/abs/2104.10093"/>
        <updated>2023-11-10T03:15:28.293Z</updated>
        <summary type="html"><![CDATA[Gido M. van de Ven, Zhe Li, Andreas S. Tolias]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Statistical process monitoring of artificial neural networks]]></title>
        <id>http://arxiv.org/abs/2209.07436</id>
        <link href="http://arxiv.org/abs/2209.07436"/>
        <updated>2023-11-10T03:15:28.275Z</updated>
        <summary type="html"><![CDATA[Anna Malinovskaya, Pavlo Mozharovskyi, Philipp Otto]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Uncertainty Wrapper in the medical domain: Establishing transparent
  uncertainty quantification for opaque machine learning models in practice]]></title>
        <id>http://arxiv.org/abs/2311.05245</id>
        <link href="http://arxiv.org/abs/2311.05245"/>
        <updated>2023-11-10T03:15:28.270Z</updated>
        <summary type="html"><![CDATA[Lisa J\"ockel, Michael Kl\"as, Georg Popp, Nadja Hilger, Stephan
  Fricke]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Compression of Overparameterized Deep Models through
  Low-Dimensional Learning Dynamics]]></title>
        <id>http://arxiv.org/abs/2311.05061</id>
        <link href="http://arxiv.org/abs/2311.05061"/>
        <updated>2023-11-10T03:15:28.209Z</updated>
        <summary type="html"><![CDATA[Soo Min Kwon, Zekai Zhang, Dogyoon Song, Laura Balzano, Qing Qu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-learning of semi-supervised learning from tasks with heterogeneous
  attribute spaces]]></title>
        <id>http://arxiv.org/abs/2311.05088</id>
        <link href="http://arxiv.org/abs/2311.05088"/>
        <updated>2023-11-10T03:15:28.173Z</updated>
        <summary type="html"><![CDATA[Tomoharu Iwata, Atsutoshi Kumagai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Novemberly MCMC]]></title>
        <id>http://xianblog.wordpress.com/?p=54414</id>
        <link href="https://xianblog.wordpress.com/2023/11/10/novemberly-mcmc/"/>
        <updated>2023-11-09T23:23:05.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hype over AI and Classical Chinese / Literary Sinitic]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61190</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61190&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hype-over-ai-and-classical-chinese-literary-sinitic"/>
        <updated>2023-11-09T23:09:40.000Z</updated>
        <summary type="html"><![CDATA[From the get-go, I'm dubious about any claims that current AI can fully and accurately translate Classical Chinese / Literary Sinitic (CC/LS) into Modern Standard Mandarin (MSM), much less English or other language, on a practical, functional basis.  Since the following article is from one of China's official propaganda "news" outlets (China Daily [CD]), the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: Context in AI Research (CAIR)]]></title>
        <id>http://blog.research.google/2023/11/responsible-ai-at-google-research.html</id>
        <link href="http://blog.research.google/2023/11/responsible-ai-at-google-research.html"/>
        <updated>2023-11-09T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Katherine Heller, Research Scientist, Google Research, on behalf of the CAIR Team




Artificial intelligence (AI) and related machine learning (ML) technologies are increasingly influential in the world around us, making it imperative that we consider the potential impacts on society and individuals in all aspects of the technology that we create. To these ends, the Context in AI Research (CAIR) team develops novel AI methods in the context of the entire AI pipeline: from data to end-user feedback. The pipeline for building an AI system typically starts with data collection, followed by designing a model to run on that data, deployment of the model in the real world, and lastly, compiling and incorporation of human feedback. Originating in the health space, and now expanded to a…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Overcoming leakage on error-corrected quantum processors]]></title>
        <id>http://blog.research.google/2023/11/overcoming-leakage-on-error-corrected.html</id>
        <link href="http://blog.research.google/2023/11/overcoming-leakage-on-error-corrected.html"/>
        <updated>2023-11-09T19:20:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Kevin Miao and Matt McEwen, Research Scientists, Quantum AI Team




The qubits that make up Google quantum devices are delicate and noisy, so it’s necessary to incorporate error correction procedures that identify and account for qubit errors on the way to building a useful quantum computer. Two of the most prevalent error mechanisms are bit-flip errors (where the energy state of the qubit changes) and phase-flip errors (where the phase of the encoded quantum information changes). Quantum error correction (QEC) promises to address and mitigate these two prominent errors. However, there is an assortment of other error mechanisms that challenges the effectiveness of QEC.



While we want qubits to behave as ideal two-level systems with no loss mechanisms, this is not the case in r…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VQ一下Key，Transformer的复杂度就变成线性了]]></title>
        <id>https://kexue.fm/archives/9844</id>
        <link href="https://kexue.fm/archives/9844"/>
        <updated>2023-11-09T13:10:00.000Z</updated>
        <summary type="html"><![CDATA[Efficient Transformer，泛指一切致力于降低Transformer的二次复杂度的工作，开始特指针对Attention的改进，后来更一般的思路，如傅立叶变换、线性RNN等，也被归...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spectral Evolution and Invariance in Linear-width Neural Networks]]></title>
        <id>http://arxiv.org/abs/2211.06506</id>
        <link href="http://arxiv.org/abs/2211.06506"/>
        <updated>2023-11-09T03:15:35.908Z</updated>
        <summary type="html"><![CDATA[Zhichao Wang, Andrew Engel, Anand Sarwate, Ioana Dumitriu, Tony Chiang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Linear Gaussian Polytree Models with Interventions]]></title>
        <id>http://arxiv.org/abs/2311.04636</id>
        <link href="http://arxiv.org/abs/2311.04636"/>
        <updated>2023-11-09T03:15:35.846Z</updated>
        <summary type="html"><![CDATA[D. Tramontano, L. Waldmann, M. Drton, E. Duarte]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Source Domain Adaptation through Dataset Dictionary Learning in
  Wasserstein Space]]></title>
        <id>http://arxiv.org/abs/2307.14953</id>
        <link href="http://arxiv.org/abs/2307.14953"/>
        <updated>2023-11-09T03:15:35.829Z</updated>
        <summary type="html"><![CDATA[Eduardo Fernandes Montesuma, Fred Ngol\`e Mboula, Antoine Souloumiac]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Certified Data Removal from Machine Learning Models]]></title>
        <id>http://arxiv.org/abs/1911.03030</id>
        <link href="http://arxiv.org/abs/1911.03030"/>
        <updated>2023-11-09T03:15:35.795Z</updated>
        <summary type="html"><![CDATA[Chuan Guo, Tom Goldstein, Awni Hannun, Laurens van der Maaten]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Few-Annotation Learning in Computer Vision: Application to Image
  Classification and Object Detection tasks]]></title>
        <id>http://arxiv.org/abs/2311.04888</id>
        <link href="http://arxiv.org/abs/2311.04888"/>
        <updated>2023-11-09T03:15:35.755Z</updated>
        <summary type="html"><![CDATA[Quentin Bouniot]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[20/11 1pm-2pm: Statistics Seminar - Graphical Models of Intelligent Cause]]></title>
        <id>8a17841b8adb7895018adfd6ce0c4ad1</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b8adb7895018adfd6ce0b4ad0"/>
        <updated>2023-11-09T00:23:09.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 20 Nov '23

	
Where: Stats Common Room

	
Abstract: Graphical models are now widely used to express underlying mechanisms which drive and explain how such mechanisms work. In particular Bayesian Networks and more recently Chain Event Graphs have been used to produce probabilistic predictive models of processes. Such graphs are chosen to be consistent with elicited natural explanations of how and why things happen the way they do in a given domain. Causal algebras are then specified which use this elicited information to determine predictions of what might happen were the system be subjected to various controls.

But how could we extend this work so that it might apply to produce predictive models of what might happen when the decision maker believes that his controls might be resisted? In this talk I will argue that standard causal models then need to be generalised to embed a decision maker's beliefs of the intent capability and the information a resistant adversary might have about the intervention after it has been made. After reviewing recent advances in general forms of Bayesian dynamic causal models I will describe how - using a special form of Adversarial Risk Analysis - we are developing new intelligent algorithms to produce such predictions. The talk will be illustrated throughout by examples of various adversarial threats currently being analysed within the UK.]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[19/02 1pm-2pm: Statistics Seminar - TBD]]></title>
        <id>8a17841b8ba96181018bb1757be51f94</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a1785d88adb7b44018adfff90924f46"/>
        <updated>2023-11-09T00:22:28.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 19 Feb '24

	
Where: Stats Common Room

	
Abstract: TBD]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[22/01 1pm-2pm: Stats Seminar - TBD]]></title>
        <id>8a1785d88ba96480018bb1744fff6836</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a1785d78adb7884018adffec409135c"/>
        <updated>2023-11-09T00:21:11.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 22 Jan '24

	
Where: Stats Common Room

	
Abstract: TBD]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[08/01 1pm-2pm: Statistics Seminar - TBD]]></title>
        <id>8a17841a8ba96485018bb17348124fdf</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841a8ba96485018bb171545c4fdc"/>
        <updated>2023-11-09T00:20:04.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 08 Jan '24

	
Where: Statistics common room

	
Abstract: TBD]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[04/12 1pm-2pm: Statistics Seminar - TBD]]></title>
        <id>8a17841a8adb7b43018adfd7774d1148</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841a8adb7b43018adfd7774d1147"/>
        <updated>2023-11-09T00:16:38.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 04 Dec '23

	
Where: Stats Common Room

	
Abstract:TBD]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[francescoverdose [Jorge does Massilia]]]></title>
        <id>http://xianblog.wordpress.com/?p=54107</id>
        <link href="https://xianblog.wordpress.com/2023/11/09/francescoverdose-jorge-does-massilia/"/>
        <updated>2023-11-08T23:23:51.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[English language flap in Korea]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61183</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61183&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=english-language-flap-in-korea"/>
        <updated>2023-11-08T22:50:32.000Z</updated>
        <summary type="html"><![CDATA[From the Korea Times (11/6/23): Ihn says he was 'very disappointed' after ex-leader Lee spoke to him in English (Yonhap) Before you read the article, it's unlikely that you could begin to surmise what the commotion is all about. The American Korean chief of the ruling People Power Party (PPP)'s innovation committee said Monday he […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT Meets Elchanan Mossel’s Dice Problem]]></title>
        <id>http://gilkalai.wordpress.com/?p=24878</id>
        <link href="https://gilkalai.wordpress.com/2023/11/08/chatgpt-meets-elchanan-mossels-dice-problem/"/>
        <updated>2023-11-08T10:42:44.000Z</updated>
        <summary type="html"><![CDATA[One of the greatest hits of this blog was Elchanan Mossel’s dice problem, asked here and answered here. Here is how chatGPT (the free version) handles the problem. You throw a die until you get 6. What is the expected … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT Meets Elchanan Mossel’s Dice Problem]]></title>
        <id>http://gilkalai.wordpress.com/?p=24878</id>
        <link href="https://gilkalai.wordpress.com/2023/11/08/chatgpt-meets-elchanan-mossels-dice-problem/"/>
        <updated>2023-11-08T10:42:44.000Z</updated>
        <summary type="html"><![CDATA[One of the greatest hits of this blog was Elchanan Mossel’s dice problem, asked here and answered here. Here is how chatGPT (the free version) handles the problem. You throw a die until you get 6. What is the expected … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Comparing Causal Frameworks: Potential Outcomes, Structural Models,
  Graphs, and Abstractions]]></title>
        <id>http://arxiv.org/abs/2306.14351</id>
        <link href="http://arxiv.org/abs/2306.14351"/>
        <updated>2023-11-08T04:17:34.898Z</updated>
        <summary type="html"><![CDATA[Duligur Ibeling, Thomas Icard]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean
  Field Neural Networks]]></title>
        <id>http://arxiv.org/abs/2304.03408</id>
        <link href="http://arxiv.org/abs/2304.03408"/>
        <updated>2023-11-08T04:17:34.894Z</updated>
        <summary type="html"><![CDATA[Blake Bordelon, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Linear Representation Hypothesis and the Geometry of Large Language
  Models]]></title>
        <id>http://arxiv.org/abs/2311.03658</id>
        <link href="http://arxiv.org/abs/2311.03658"/>
        <updated>2023-11-08T04:17:34.801Z</updated>
        <summary type="html"><![CDATA[Kiho Park, Yo Joong Choe, Victor Veitch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimizing Solution-Samplers for Combinatorial Problems: The Landscape
  of Policy-Gradient Methods]]></title>
        <id>http://arxiv.org/abs/2310.05309</id>
        <link href="http://arxiv.org/abs/2310.05309"/>
        <updated>2023-11-08T04:17:34.792Z</updated>
        <summary type="html"><![CDATA[Constantine Caramanis, Dimitris Fotakis, Alkis Kalavasis, Vasilis
  Kontonis, Christos Tzamos]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Outliers with Opposing Signals Have an Outsized Effect on Neural Network
  Optimization]]></title>
        <id>http://arxiv.org/abs/2311.04163</id>
        <link href="http://arxiv.org/abs/2311.04163"/>
        <updated>2023-11-08T04:17:34.785Z</updated>
        <summary type="html"><![CDATA[Elan Rosenfeld, Andrej Risteski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year [minus two fingers]]]></title>
        <id>http://xianblog.wordpress.com/?p=54220</id>
        <link href="https://xianblog.wordpress.com/2023/11/08/a-journal-of-the-conquest-war-famine-and-death-year-minus-two-fingers/"/>
        <updated>2023-11-07T23:23:02.000Z</updated>
        <summary type="html"><![CDATA[Read The House of Shattered Wings, by Aliette de Bodard, which involves a character with two fingers eventually missing. A British Science Fiction Association Award and for once a rather impressive horror story taking place in an alternative 1900’s Paris partly destroyed by a war between Houses run by fallen angels. With connections with French […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alternating updates for efficient transformers]]></title>
        <id>http://blog.research.google/2023/11/alternating-updates-for-efficient.html</id>
        <link href="http://blog.research.google/2023/11/alternating-updates-for-efficient.html"/>
        <updated>2023-11-07T20:34:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Xin Wang, Software Engineer, and Nishanth Dikkala, Research Scientist, Google Research




Contemporary deep learning models have been remarkably successful in many domains, ranging from natural language to computer vision. Transformer neural networks (transformers) are a popular deep learning architecture that today comprise the foundation for most tasks in natural language processing and also are starting to extend to applications in other domains, such as computer vision, robotics, and autonomous driving. Moreover, they form the backbone of all the current state-of-the-art language models.
 

Increasing scale in Transformer networks has led to improved performance and the emergence of behavior not present in smaller networks. However, this increase in scale often comes with pr…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mao and Chinese Character Reform: Revisionist History on CCTV]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61179</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61179&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mao-and-chinese-character-reform-revisionist-history-on-cctv"/>
        <updated>2023-11-07T20:05:34.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by David Moser] Just when you thought CCP propaganda couldn’t get more absurd, China Central Television (CCTV) has aired a short TV series in which Confucius and Karl Marx actually meet up for comradely chat about ideology. In typical fantasy time-travel style, Marx simply appears miraculously at the Yuelu Academy […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch compile to speed up inference on Llama 2]]></title>
        <id>https://pytorch.org/blog/pytorch-compile-to-speed-up-inference/</id>
        <link href="https://pytorch.org/blog/pytorch-compile-to-speed-up-inference/"/>
        <updated>2023-11-07T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[In this blog, we discuss how to improve the inference latencies of the Llama 2 family of models using PyTorch native optimizations such as native fast kernels, compile transformations from torch compile, and tensor parallel for distributed inference. Our approach results in 29ms/token latency for single user requests on the 70B LLaMa model (as measured on 8 A100 GPUs). We are excited to share our findings with the community and make our code available here.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low Tensor Rank Learning of Neural Dynamics]]></title>
        <id>http://arxiv.org/abs/2308.11567</id>
        <link href="http://arxiv.org/abs/2308.11567"/>
        <updated>2023-11-07T03:15:36.190Z</updated>
        <summary type="html"><![CDATA[Arthur Pellegrino, N Alex Cayco-Gajic, Angus Chadwick]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Estimation and inference for transfer learning with high-dimensional
  quantile regression]]></title>
        <id>http://arxiv.org/abs/2211.14578</id>
        <link href="http://arxiv.org/abs/2211.14578"/>
        <updated>2023-11-07T03:15:36.180Z</updated>
        <summary type="html"><![CDATA[Jiayu Huang, Mingqiu Wang, Yuanshan Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Revealing the Mystery behind Chain of Thought: A Theoretical
  Perspective]]></title>
        <id>http://arxiv.org/abs/2305.15408</id>
        <link href="http://arxiv.org/abs/2305.15408"/>
        <updated>2023-11-07T03:15:36.157Z</updated>
        <summary type="html"><![CDATA[Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Theory for Emergence of Complex Skills in Language Models]]></title>
        <id>http://arxiv.org/abs/2307.15936</id>
        <link href="http://arxiv.org/abs/2307.15936"/>
        <updated>2023-11-07T03:15:36.137Z</updated>
        <summary type="html"><![CDATA[Sanjeev Arora, Anirudh Goyal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Architecture Matters: Uncovering Implicit Mechanisms in Graph
  Contrastive Learning]]></title>
        <id>http://arxiv.org/abs/2311.02687</id>
        <link href="http://arxiv.org/abs/2311.02687"/>
        <updated>2023-11-07T03:15:36.106Z</updated>
        <summary type="html"><![CDATA[Xiaojun Guo, Yifei Wang, Zeming Wei, Yisen Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian inference from the ground up [no book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=54094</id>
        <link href="https://xianblog.wordpress.com/2023/11/07/54094/"/>
        <updated>2023-11-06T23:23:18.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rectilinear rectitude]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61173</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61173&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rectilinear-rectitude"/>
        <updated>2023-11-06T12:48:34.000Z</updated>
        <summary type="html"><![CDATA[An alternative name for M Hànzì / J Kanji / K Hanja / C hon3 zi6 漢字 ("sinoglyph; Chinese character") is fāngkuàizì 方塊字 ("square shaped character").  I learned that the very first year of my Chinese language studies more than half a century ago.  From kindergarten and elementary school on up, Chinese children learn to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We need an immediate humanitarian ceasefire in Gaza]]></title>
        <id>http://xianblog.wordpress.com/?p=54409</id>
        <link href="https://xianblog.wordpress.com/2023/11/06/we-need-an-immediate-humanitarian-ceasefire-in-gaza/"/>
        <updated>2023-11-06T10:00:49.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High-Performance Llama 2 Training and Inference with PyTorch/XLA on Cloud TPUs]]></title>
        <id>https://pytorch.org/blog/high-performance-llama-2/</id>
        <link href="https://pytorch.org/blog/high-performance-llama-2/"/>
        <updated>2023-11-06T08:00:00.000Z</updated>
        <summary type="html"><![CDATA[In a landscape where AI innovation is accelerating at an unprecedented pace, Meta’s Llama family of open sourced large language models (LLMs) stands out as a notable breakthrough. Llama marked a significant step forward for LLMs, demonstrating the power of pre-trained architectures for a wide range of applications. Llama 2 further pushed the boundaries of scale and capabilities, inspiring advancements in language understanding, generation, and beyond.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian learning of feature spaces for multitasks problems]]></title>
        <id>http://arxiv.org/abs/2209.03028</id>
        <link href="http://arxiv.org/abs/2209.03028"/>
        <updated>2023-11-06T03:15:41.747Z</updated>
        <summary type="html"><![CDATA[Carlos Sevilla-Salcedo, Ascensi\'on Gallardo-Antol\'in, Vanessa
  G\'omez-Verdejo, Emilio Parrado-Hern\'andez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning nonparametric latent causal graphs with unknown interventions]]></title>
        <id>http://arxiv.org/abs/2306.02899</id>
        <link href="http://arxiv.org/abs/2306.02899"/>
        <updated>2023-11-06T03:15:41.666Z</updated>
        <summary type="html"><![CDATA[Yibo Jiang, Bryon Aragam]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Obtaining Explainable Classification Models using Distributionally
  Robust Optimization]]></title>
        <id>http://arxiv.org/abs/2311.01994</id>
        <link href="http://arxiv.org/abs/2311.01994"/>
        <updated>2023-11-06T03:15:41.640Z</updated>
        <summary type="html"><![CDATA[Sanjeeb Dash, Soumyadip Ghosh, Joao Goncalves, Mark S. Squillante]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SortNet: Learning To Rank By a Neural-Based Sorting Algorithm]]></title>
        <id>http://arxiv.org/abs/2311.01864</id>
        <link href="http://arxiv.org/abs/2311.01864"/>
        <updated>2023-11-06T03:15:41.604Z</updated>
        <summary type="html"><![CDATA[Leonardo Rigutini, Tiziano Papini, Marco Maggini, Franco Scarselli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How a student becomes a teacher: learning and forgetting through
  Spectral methods]]></title>
        <id>http://arxiv.org/abs/2310.12612</id>
        <link href="http://arxiv.org/abs/2310.12612"/>
        <updated>2023-11-06T03:15:41.591Z</updated>
        <summary type="html"><![CDATA[Lorenzo Giambagli, Lorenzo Buffoni, Lorenzo Chicchi, Duccio Fanelli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speculations Concerning the First Ultraintelligent Machine [not a book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=54087</id>
        <link href="https://xianblog.wordpress.com/2023/11/06/speculations-concerning-the-first-ultraintelligent-machine-not-a-book-review/"/>
        <updated>2023-11-05T23:23:51.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Really weird sinographs, part 4:  hyena]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61168</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61168&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=really-weird-sinographs-part-4-hyena"/>
        <updated>2023-11-05T15:10:03.000Z</updated>
        <summary type="html"><![CDATA[In "LOL, ROTFL, IJBO" (11/2/23), all the talk of laughter made me think of the epitome of that particular animal behavior, the hyena.  Of all creatures on earth, the hyena is one of the most curious.  Can you imagine going through life laughing at everything, especially when life is so full of tragedy? Listen:  here, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Covent’ska [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53444</id>
        <link href="https://xianblog.wordpress.com/2023/11/05/coventska-jatp/"/>
        <updated>2023-11-04T23:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Maximum likelihood estimation of autoregressive model parameters]]></title>
        <id>https://parsiad.ca/blog/2023/maximum_likelihood_estimation_of_autoregressive_model_parameters/</id>
        <link href="https://parsiad.ca/blog/2023/maximum_likelihood_estimation_of_autoregressive_model_parameters/"/>
        <updated>2023-11-04T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Got wheels]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61154</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61154&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=got-wheels"/>
        <updated>2023-11-04T16:17:44.000Z</updated>
        <summary type="html"><![CDATA[Sign on a truck in Hong Kong: It says: Lún lún lún輪倫侖lit. "wheel — Lon(don) / kinship / relationship / logic / order / match / peer — (Kun)lun / [alternate form of the previous character, hence having its sound and all of its meanings]" lún 輪 is the Chinese glyph / word for "wheel". […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Marsset]]></title>
        <id>http://xianblog.wordpress.com/?p=54040</id>
        <link href="https://xianblog.wordpress.com/2023/11/04/marsset/"/>
        <updated>2023-11-03T23:22:50.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The changing accents of British English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61128</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61128&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-changing-accents-of-british-english"/>
        <updated>2023-11-03T20:49:23.000Z</updated>
        <summary type="html"><![CDATA[King’s English and Cockney replaced by three new accents, study finds Britons depart from overtly class-based post-war speech epitomised by either clipped vowels or working-class dialects By Charles Hymas, The Telegraph, Home Affairs Editor 30 October 2023 • 6:33pm I vaguely recall an earlier study from about ten years ago that came to similar conclusions (including the emergence of […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Best of both worlds: Achieving scalability and quality in text clustering]]></title>
        <id>http://blog.research.google/2023/11/best-of-both-worlds-achieving.html</id>
        <link href="http://blog.research.google/2023/11/best-of-both-worlds-achieving.html"/>
        <updated>2023-11-03T18:23:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Sara Ahmadian and Mehran Kazemi, Research Scientists, Google Research




Clustering is a fundamental, ubiquitous problem in data mining and unsupervised machine learning, where the goal is to group together similar items. The standard forms of clustering are metric clustering and graph clustering. In metric clustering, a given metric space defines distances between data points, which are grouped together based on their separation. In graph clustering, a given graph connects similar data points through edges, and the clustering process groups data points together based on the connections between them. Both clustering forms are particularly useful for large corpora where class labels can’t be defined. Examples of such corpora are the ever-growing digital text collections of variou…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prince of pronunciation]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61141</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61141&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=prince-of-pronunciation"/>
        <updated>2023-11-03T16:57:44.000Z</updated>
        <summary type="html"><![CDATA[Many people have the (mis)perception that the French (mis)pronounce all languages with a heavy accent.  It turns out that the gold standard for correct pronunciation of borrowed words is a French gentilhomme /ʒɑ̃.ti.jɔm/. How to Pronounce the Trickiest English Words: Ask This Frenchman Millions of Americans, the curious and the insecure, consult Julien Miquel for […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Carsen Stringer - Unsupervised pretraining in biological neural networks]]></title>
        <id>https://mlfoundations.org/talk/carsen/</id>
        <link href="https://mlfoundations.org/talk/carsen/"/>
        <updated>2023-11-03T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Representation learning in neural networks may be implemented with supervised or unsupervised algorithms, distinguished by the presence or absence of reward feedback. Both types of learning are highly effective in artificial neural networks. In biological systems, task learning has been shown to modify sensory neural representations, but it is not known if these changes are due to supervised or unsupervised learning. Here we recorded populations of up to 70,000 neurons simultaneously from primary visual cortex (V1) and higher visual areas (HVA), while animals learned multiple tasks as well as during unrewarded exposure to the same stimuli. We found that most neural changes in task mice were replicated in the mice with unrewarded exposure. These changes were concentrated in the medial HVAs after mice learned to discriminate visual textures from two different classes. In contrast, the changes were widespread across visual areas after mice learned to discriminate between two exemplars of the same visual class. In both tasks, neural representations of the most recently learned exemplar generalized to new exemplars of the same visual category and the behavior of the mice generalized according to the same rule. These specific neural changes were replicated in mice with unrewarded exposure, suggesting that unsupervised learning plays a major role in visual learning. In task mice only, we found a neural population in anterior HVAs encoding a ramping reward prediction signal, potentially involved in the supervised learning. Our neural results predict that unsupervised pretraining may accelerate subsequent task learning, a prediction which we validated with behavioral training experiments.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI insults]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61148</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61148&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-insults"/>
        <updated>2023-11-03T11:26:59.000Z</updated>
        <summary type="html"><![CDATA[No, not what you get by asking GPT-4 for insults — for that, see below… This is the SMBC comic from a few days ago: Mouseover title: "You catastrophic forgetter! You opaque box! You absolute Chinese room!" The aftercomic: GPT-4's response to the prompt "Give me some really good insults": While I understand the desire […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anonymous Learning via Look-Alike Clustering: A Precise Analysis of
  Model Generalization]]></title>
        <id>http://arxiv.org/abs/2310.04015</id>
        <link href="http://arxiv.org/abs/2310.04015"/>
        <updated>2023-11-03T02:22:45.380Z</updated>
        <summary type="html"><![CDATA[Adel Javanmard, Vahab Mirrokni]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inversion of Bayesian Networks]]></title>
        <id>http://arxiv.org/abs/2212.10649</id>
        <link href="http://arxiv.org/abs/2212.10649"/>
        <updated>2023-11-03T02:22:45.373Z</updated>
        <summary type="html"><![CDATA[Jesse van Oostrum, Peter van Hintum, Nihat Ay]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Long Story Short: Omitted Variable Bias in Causal Machine Learning]]></title>
        <id>http://arxiv.org/abs/2112.13398</id>
        <link href="http://arxiv.org/abs/2112.13398"/>
        <updated>2023-11-03T02:22:45.366Z</updated>
        <summary type="html"><![CDATA[Victor Chernozhukov, Carlos Cinelli, Whitney Newey, Amit Sharma,
  Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Learning Gaussian Multi-index Models with Gradient Flow]]></title>
        <id>http://arxiv.org/abs/2310.19793</id>
        <link href="http://arxiv.org/abs/2310.19793"/>
        <updated>2023-11-03T02:22:45.342Z</updated>
        <summary type="html"><![CDATA[Alberto Bietti, Joan Bruna, Loucas Pillaud-Vivien]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Detection of Interacting Variables for Generalized Linear Models via
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2209.08030</id>
        <link href="http://arxiv.org/abs/2209.08030"/>
        <updated>2023-11-03T02:22:41.601Z</updated>
        <summary type="html"><![CDATA[Yevhen Havrylenko, Julia Heger]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Eeeech… [X validated]]]></title>
        <id>http://xianblog.wordpress.com/?p=53666</id>
        <link href="https://xianblog.wordpress.com/2023/11/03/eeeech-x-validated/"/>
        <updated>2023-11-02T23:23:32.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Crispy Rs"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61145</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61145&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=crispy-rs"/>
        <updated>2023-11-02T23:18:50.000Z</updated>
        <summary type="html"><![CDATA[Dan Nosowitz, "The ‘Crispy R’ and Why R Is the Weirdest Letter", Atlas Obscura 11/2/2023: The crispy R is a phenomenon that some linguists had noticed, but which had gone largely unstudied—until the phrase “crispy R” was bestowed on it by Brian Michael Firkus, better known as Trixie Mattel, the winner of the third season […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zero-shot adaptive prompting of large language models]]></title>
        <id>http://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html</id>
        <link href="http://blog.research.google/2023/11/zero-shot-adaptive-prompting-of-large.html"/>
        <updated>2023-11-02T22:01:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Xingchen Wan, Student Researcher, and Ruoxi Sun, Research Scientist, Cloud AI Team




Recent advances in large language models (LLMs) are very promising as reflected in their capability for general problem-solving in few-shot and zero-shot setups, even without explicit training on these tasks. This is impressive because in the few-shot setup, LLMs are presented with only a few question-answer demonstrations prior to being given a test question. Even more challenging is the zero-shot setup, where the LLM is directly prompted with the test question only. 




Even though the few-shot setup has dramatically reduced the amount of data required to adapt a model for a specific use-case, there are still cases where generating sample prompts can be challenging. For example, handcrafting…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LOL, ROTFL, IJBOL]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61137</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61137&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=lol-rotfl-ijbol"/>
        <updated>2023-11-02T09:23:43.000Z</updated>
        <summary type="html"><![CDATA[As Laura Morland said to me in a p.c., I am a "Swiftie" (I admit it, even though I'm a Penn prof), but there are plenty of things about pop culture that I do not know, including IJBOL. What Is IJBOL? A Korean word? A new boy band? This new acronym is replacing LOL and […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Accelerating Inference on x86-64 Machines with oneDNN Graph]]></title>
        <id>https://pytorch.org/blog/accelerating-inference/</id>
        <link href="https://pytorch.org/blog/accelerating-inference/"/>
        <updated>2023-11-02T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Supported in PyTorch 2.0 as a beta feature, oneDNN Graph leverages aggressive fusion patterns to accelerate inference on x86-64 machines, especially Intel® Xeon® Scalable processors.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Online learning in bandits with predicted context]]></title>
        <id>http://arxiv.org/abs/2307.13916</id>
        <link href="http://arxiv.org/abs/2307.13916"/>
        <updated>2023-11-02T05:14:05.276Z</updated>
        <summary type="html"><![CDATA[Yongyi Guo, Ziping Xu, Susan Murphy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
</feed>