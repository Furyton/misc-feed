<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-06-20T14:13:16.946Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Topolects and texts]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59286</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59286&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=topolects-and-texts"/>
        <updated>2023-06-20T14:06:53.000Z</updated>
        <summary type="html"><![CDATA[Illuminating new book from Hong Kong University Press edited by Richard VanNess Simmons: Studies in Colloquial Chinese and Its History:¬† Dialect and Text ISBN : 978-988-8754-09-0 The book also has a Chinese title: H√†ny«î k«íuy«î de l√¨sh«ê y√°nji≈´: fƒÅngy√°n h√© w√©nxi√†n Êº¢Ë™ûÂè£Ë™ûÁöÑÊ≠∑Âè≤Á†îÁ©∂ÔºöÊñπË®ÄËàáÊñáÁçª I would prefer to render this into English as: Studies on the History [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tortured phrases, LLMs, and Goodhart's Law]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59339</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59339&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tortured-phrases-llms-and-goodharts-law"/>
        <updated>2023-06-20T13:55:24.000Z</updated>
        <summary type="html"><![CDATA[A few years ago, I began to notice that the scientific and technical papers relentless spammed at me, by academia.edu and similar outfits, were becoming increasingly surrealistic. And I soon learned that the source for such articles was systems for "article spinning" by "rogeting" ‚Äî automatic random subsitution of (usually inappropriate) synonyms. Those techniques were [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation Methods in Bayesian Analysis [#1]]]></title>
        <id>http://xianblog.wordpress.com/?p=53331</id>
        <link href="https://xianblog.wordpress.com/2023/06/20/approximation-methods-in-bayesian-analysis-1/"/>
        <updated>2023-06-19T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[Interesting first day, if somewhat intense!, with Sylvia Richardson talking of divide & conquer strategies, which we had recently explored in our work on mixtures with Adrien and Judith. Then Jere Koskela (Warwick) on sufficient conditions for consistent inference on trees like Kingman‚Äôs coalescent. And in the afternoon Julia-Adela Palacios on tree estimation, with novel [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stabilized Neural Differential Equations for Learning Constrained
  Dynamics]]></title>
        <id>http://arxiv.org/abs/2306.09739</id>
        <link href="http://arxiv.org/abs/2306.09739"/>
        <updated>2023-06-19T07:14:46.765Z</updated>
        <summary type="html"><![CDATA[Alistair White, Niki Kilbertus, Maximilian Gelbrecht, Niklas Boers]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resolving the Human Subjects Status of Machine Learning's Crowdworkers]]></title>
        <id>http://arxiv.org/abs/2206.04039</id>
        <link href="http://arxiv.org/abs/2206.04039"/>
        <updated>2023-06-19T07:14:46.761Z</updated>
        <summary type="html"><![CDATA[Divyansh Kaushik, Zachary C. Lipton, Alex John London]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enhancing Activity Prediction Models in Drug Discovery with the Ability
  to Understand Human Language]]></title>
        <id>http://arxiv.org/abs/2303.03363</id>
        <link href="http://arxiv.org/abs/2303.03363"/>
        <updated>2023-06-19T07:14:46.756Z</updated>
        <summary type="html"><![CDATA[Philipp Seidl, Andreu Vall, Sepp Hochreiter, G\"unter Klambauer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Collapsed Inference for Bayesian Deep Learning]]></title>
        <id>http://arxiv.org/abs/2306.09686</id>
        <link href="http://arxiv.org/abs/2306.09686"/>
        <updated>2023-06-19T07:14:46.750Z</updated>
        <summary type="html"><![CDATA[Zhe Zeng, Guy Van den Broeck]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trained Transformers Learn Linear Models In-Context]]></title>
        <id>http://arxiv.org/abs/2306.09927</id>
        <link href="http://arxiv.org/abs/2306.09927"/>
        <updated>2023-06-19T07:14:46.650Z</updated>
        <summary type="html"><![CDATA[Ruiqi Zhang, Spencer Frei, Peter L. Bartlett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[no country for old men [Cormac McCarthy]]]></title>
        <id>http://xianblog.wordpress.com/?p=53250</id>
        <link href="https://xianblog.wordpress.com/2023/06/19/no-country-for-old-men-cormac-mccarthy/"/>
        <updated>2023-06-18T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at CVPR 2023]]></title>
        <id>http://ai.googleblog.com/2023/06/google-at-cvpr-2023.html</id>
        <link href="http://ai.googleblog.com/2023/06/google-at-cvpr-2023.html"/>
        <updated>2023-06-18T18:00:00.014Z</updated>
        <summary type="html"><![CDATA[Posted by Shaina Mehta, Program Manager, Google




This week marks the beginning of the premier annual Computer Vision and Pattern Recognition conference (CVPR 2023), held in-person in Vancouver, BC (with additional virtual content). As a leader in computer vision research and a Platinum Sponsor, Google Research will have a strong presence across CVPR 2023 with 90 papers being presented at the main conference and active involvement in over 40 conference workshops and tutorials.




If you are attending CVPR this year, please stop by our booth to chat with our researchers who are actively exploring the latest techniques for application to various areas of machine perception. Our researchers will also be available to talk about and demo several recent efforts, including on-device ML applica‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Time-averaged quantum annealing for weak processes]]></title>
        <id>http://arxiv.org/abs/2306.06008</id>
        <link href="http://arxiv.org/abs/2306.06008"/>
        <updated>2023-06-18T07:13:07.422Z</updated>
        <summary type="html"><![CDATA[Pierre Naz\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal shortcuts to adiabaticity of finite-time and weak processes]]></title>
        <id>http://arxiv.org/abs/2305.17802</id>
        <link href="http://arxiv.org/abs/2305.17802"/>
        <updated>2023-06-18T07:13:06.921Z</updated>
        <summary type="html"><![CDATA[Pierre Naz\'e]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Saturn < Cronus (ŒöœÅœåŒΩŒøœÇ) ‚â† Chronos (ŒßœÅœåŒΩŒøœÇ)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59190</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59190&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=saturn-cronus-%25ce%25ba%25cf%2581%25cf%258c%25ce%25bd%25ce%25bf%25cf%2582-%25e2%2589%25a0-chronos-%25cf%2587%25cf%2581%25cf%258c%25ce%25bd%25ce%25bf%25cf%2582"/>
        <updated>2023-06-18T04:50:29.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Jichang Lulu, with some minor modifications and additions by VHM] You might have seen this ‚Äî the PRC embassy in Poland has given¬†Badiucao's forthcoming exhibition in Warsaw¬†(coorganised by¬†Sinopsis) some very welcome, completely unexpected publicity by trying to have it shut down. Lots of international reporting: The Guardian,¬†Sydney Morning Herald,¬†&c.,¬†&c. [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[webscussion on Bayesian causality]]></title>
        <id>http://xianblog.wordpress.com/?p=53243</id>
        <link href="https://xianblog.wordpress.com/2023/06/18/webscussion-on-bayesian-causality/"/>
        <updated>2023-06-17T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[Today, I attended (most of) and briefly took part in the discussion webinar run by Bayesian Analysis (the journal) and featuring the paper Causal Inference Under Mis-Specification: Adjustment Based on the Propensity Score by David Stephens, Widemberg Nobre, Erica Moodie, and Alexandra M. Schmidt, for which Pierre Jacob and I contributed a written discussion. I [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Throw a photo" in South Florida English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59266</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59266&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=throw-a-photo-in-south-florida-english"/>
        <updated>2023-06-17T20:45:14.000Z</updated>
        <summary type="html"><![CDATA[Article by Phillip M. Carter in The Conversation (6/12/23): "Linguists have identified a new English dialect that‚Äôs emerging in South Florida" Beginning sentences: ‚ÄúWe got down from the car and went inside.‚Äù ‚ÄúI made the line to pay for groceries.‚Äù ‚ÄúHe made a party to celebrate his son‚Äôs birthday.‚Äù These phrases might sound off to [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ancient eggcorns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59277</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59277&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ancient-eggcorns"/>
        <updated>2023-06-17T13:29:57.000Z</updated>
        <summary type="html"><![CDATA[The word eggcorn was originally proposed in a LLOG post almost 20 years ago ‚Äî "Egg corns: folk etymology, malapropism, mondegreen, ???", 9/23/2003.¬† And the word is now recognized by most current English dictionaries and other relevant sources, which gloss it variously, e.g. ‚Äî the¬† Oxford English Dictionary, ("An alteration of a word or phrase [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Coors Light Bear]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59272</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59272&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=coors-light-bear"/>
        <updated>2023-06-17T09:28:04.000Z</updated>
        <summary type="html"><![CDATA[An NFL policy prohibits plays from endorsing alcoholic beverages. So Coors found a linguistic work-around: Last year's commercial promoted the Coors (Flash) Light: I have some inter-related contractual and cultural questions. Are these commercials really consistent, legally, with a contractual agreement not to promote alcoholic beverages? Is is crucial that there actual merch you can [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[shame!]]></title>
        <id>http://xianblog.wordpress.com/?p=53289</id>
        <link href="https://xianblog.wordpress.com/2023/06/17/53289/"/>
        <updated>2023-06-16T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rivers and lakes:  quackery]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59232</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59232&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rivers-and-lakes-quackery"/>
        <updated>2023-06-16T19:03:16.000Z</updated>
        <summary type="html"><![CDATA[Get ready to go a-wanderin'.¬† I'll take you down to the rivers and lakes, and we shall lose ourselves in them, get lost from the hurlyburly hustlebustle of the mundane world.¬† That's what jiƒÅngh√∫ Ê±üÊπñ ("rivers and lakes") is all about.¬† It's where you go to xiƒÅoy√°o y√≥u ÈÄçÈÅôÈÅä ("wander freely / carefreely / leisurely"). [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Her pension for body-hugging gowns‚Ä¶"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59257</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59257&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=her-pension-for-body-hugging-gowns"/>
        <updated>2023-06-16T12:34:28.000Z</updated>
        <summary type="html"><![CDATA[It's been a while since we discussed a new eggcorn, so here's one, from "Beauty and the bleach", The Vintage Woman¬†2020: Blonde bombshell. A phrase so used frequently in our accumulative vernacular that the significance now wanes. This phrase, once a revelation, was brought to our consciousness by Jean Harlow. The original platinum blonde. Her [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WavPool: A New Block for Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.08734</id>
        <link href="http://arxiv.org/abs/2306.08734"/>
        <updated>2023-06-16T07:13:31.376Z</updated>
        <summary type="html"><![CDATA[Samuel D. McDermott, M. Voetberg, Brian Nord]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phase diagram of Stochastic Gradient Descent in high-dimensional
  two-layer neural networks]]></title>
        <id>http://arxiv.org/abs/2202.00293</id>
        <link href="http://arxiv.org/abs/2202.00293"/>
        <updated>2023-06-16T07:13:30.776Z</updated>
        <summary type="html"><![CDATA[Rodrigo Veiga, Ludovic Stephan, Bruno Loureiro, Florent Krzakala,
  Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nonparametric regression using over-parameterized shallow ReLU neural
  networks]]></title>
        <id>http://arxiv.org/abs/2306.08321</id>
        <link href="http://arxiv.org/abs/2306.08321"/>
        <updated>2023-06-16T07:13:30.771Z</updated>
        <summary type="html"><![CDATA[Yunfei Yang, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unbiased Learning of Deep Generative Models with Structured Discrete
  Representations]]></title>
        <id>http://arxiv.org/abs/2306.08230</id>
        <link href="http://arxiv.org/abs/2306.08230"/>
        <updated>2023-06-16T07:13:30.766Z</updated>
        <summary type="html"><![CDATA[Harry Bendekgey, Gabriel Hope, Erik B. Sudderth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visualizing Deep Neural Networks with Topographic Activation Maps]]></title>
        <id>http://arxiv.org/abs/2204.03528</id>
        <link href="http://arxiv.org/abs/2204.03528"/>
        <updated>2023-06-16T07:13:30.619Z</updated>
        <summary type="html"><![CDATA[Valerie Krug, Raihan Kabir Ratul, Christopher Olson, Sebastian Stober]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[üéâ PyTorch Docathon H1 2023 Wrap-up üéâ]]></title>
        <id>https://pytorch.org/blog/docathon-h1-2023-wrap-up/</id>
        <link href="https://pytorch.org/blog/docathon-h1-2023-wrap-up/"/>
        <updated>2023-06-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Thank you to all who participated in our first ever PyTorch Docathon, the results have been nothing short of amazing! We want to extend our sincerest gratitude to all the participants who made this event a resounding success. Your passion, talent, and hard work have left an indelible mark on the PyTorch documentation.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ê¢ØÂ∫¶ÊµÅÔºöÊé¢Á¥¢ÈÄöÂæÄÊúÄÂ∞èÂÄº‰πãË∑Ø]]></title>
        <id>https://kexue.fm/archives/9660</id>
        <link href="https://kexue.fm/archives/9660"/>
        <updated>2023-06-16T02:10:00.000Z</updated>
        <summary type="html"><![CDATA[Âú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Â∞ÜÊé¢ËÆ®‰∏Ä‰∏™Ë¢´Áß∞‰∏∫‚ÄúÊ¢ØÂ∫¶ÊµÅÔºàGradient FlowÔºâ‚ÄùÁöÑÊ¶ÇÂøµ„ÄÇÁÆÄÂçïÊù•ËØ¥ÔºåÊ¢ØÂ∫¶ÊµÅÊòØÂ∞ÜÊàë‰ª¨Âú®Áî®Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ï‰∏≠ÂØªÊâæÊúÄÂ∞èÂÄºÁöÑËøáÁ®ã‰∏≠ÁöÑÂêÑ‰∏™ÁÇπËøûÊé•Ëµ∑Êù•ÔºåÂΩ¢Êàê‰∏ÄÊù°ÈöèÔºàËôöÊãüÁöÑÔºâÊó∂Èó¥ÂèòÂåñÁöÑËΩ®ËøπÔºå...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noctureine 2023]]></title>
        <id>http://xianblog.wordpress.com/?p=53100</id>
        <link href="https://xianblog.wordpress.com/2023/06/16/noctureine-2023/"/>
        <updated>2023-06-15T22:23:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Syllabolic"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59235</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59235&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=syllabolic"/>
        <updated>2023-06-15T21:58:09.000Z</updated>
        <summary type="html"><![CDATA[On June 1 in Iowa, Donald Trump gave a speech in which he attacked Ron DeSantis from several angles. One of them was DeSantis' variation in pronunciation of his last name (see "Pronouncing 'DeSantis'", 6/3/2023), which Trump characterized as "changing his name", while introducing a puzzling (but promising?) new linguistic term, "syllabolic": Your browser does [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speed is all you need: On-device acceleration of large diffusion models via GPU-aware optimizations]]></title>
        <id>http://ai.googleblog.com/2023/06/speed-is-all-you-need-on-device.html</id>
        <link href="http://ai.googleblog.com/2023/06/speed-is-all-you-need-on-device.html"/>
        <updated>2023-06-15T20:53:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Juhyun Lee and Raman Sarokin, Software Engineers, Core Systems & Experiences




The proliferation of large diffusion models for image generation has led to a significant increase in model size and inference workloads. On-device ML inference in mobile environments requires meticulous performance optimization and consideration of trade-offs due to resource constraints. Running inference of large diffusion models (LDMs) on-device, driven by the need for cost efficiency and user privacy, presents even greater challenges due to the substantial memory requirements and computational demands of these models.
 

We address this challenge in our work titled ‚ÄúSpeed Is All You Need: On-Device Acceleration of Large Diffusion Models via GPU-Aware Optimizations‚Äù (to be presented at the CVPR 20‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Cantophone and the state]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59228</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59228&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-cantophone-and-the-state"/>
        <updated>2023-06-15T12:19:22.000Z</updated>
        <summary type="html"><![CDATA[Cantonese ‚Äî its nature, its status, its past, present, and future, its place in the realm of Sinitic languages and in the world ‚Äî has been one of the chief foci of Language Log.¬† Consequently, it is my great pleasure to announce the publication of the three-hundred-and-thirty-fourth issue of Sino-Platonic Papers: ‚ÄúThe Concept of the [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classifier Calibration: A survey on how to assess and improve predicted
  class probabilities]]></title>
        <id>http://arxiv.org/abs/2112.10327</id>
        <link href="http://arxiv.org/abs/2112.10327"/>
        <updated>2023-06-15T07:14:30.613Z</updated>
        <summary type="html"><![CDATA[Telmo Silva Filho, Hao Song, Miquel Perello-Nieto, Raul
  Santos-Rodriguez, Meelis Kull, Peter Flach]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[soon off to CIRM]]></title>
        <id>http://xianblog.wordpress.com/?p=53229</id>
        <link href="https://xianblog.wordpress.com/2023/06/15/soon-off-to-cirm/"/>
        <updated>2023-06-14T22:23:19.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reconstructing indoor spaces with NeRF]]></title>
        <id>http://ai.googleblog.com/2023/06/reconstructing-indoor-spaces-with-nerf.html</id>
        <link href="http://ai.googleblog.com/2023/06/reconstructing-indoor-spaces-with-nerf.html"/>
        <updated>2023-06-14T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[Marcos Seefelder, Software Engineer, and Daniel Duckworth, Research Software Engineer, Google Research




When choosing a venue, we often find ourselves with questions like the following: Does this restaurant have the right vibe for a date? Is there good outdoor seating? Are there enough screens to watch the game? While photos and videos may partially answer questions like these, they are no substitute for feeling like you‚Äôre there, even when visiting in person isn't an option.



Immersive experiences that are interactive, photorealistic, and multi-dimensional stand to bridge this gap and recreate the feel and vibe of a space, empowering users to naturally and intuitively find the information they need. To help with this, Google Maps launched Immersive View, which uses advances in machin‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Tortured syllables"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59186</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59186&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tortured-syllables"/>
        <updated>2023-06-14T15:16:36.000Z</updated>
        <summary type="html"><![CDATA["Language change (about to be?) in progress" (6/12/2023) linked to media commentary on divergent features of Northeast Philadelphia speech, e.g. "Side effect of the highway collapse: A perfect example of Northeast Philly hoagiemouth", Billy Penn 6/11/2-23. Some of the characterization was extremely evaluative: Philadelphians have perfected torturing vowels like medieval Europe perfected torturing people. Every [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Indigenous languages of Taiwan]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59179</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59179&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=indigenous-languages-of-taiwan"/>
        <updated>2023-06-14T11:35:23.000Z</updated>
        <summary type="html"><![CDATA[How many are there? Taiwan‚Äôs unrecognized indigenous tribes are reviving dead languages to achieve recognition There are currently 16 officially recognized indigenous peoples in Taiwan. The Pingpu ‚Äî which comprise 10 groups on the island‚Äôs lowlands ‚Äî are lobbying to make that number 17, and they‚Äôre doing it by reviving lost languages and culture. By [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identification of Nonlinear Latent Hierarchical Models]]></title>
        <id>http://arxiv.org/abs/2306.07916</id>
        <link href="http://arxiv.org/abs/2306.07916"/>
        <updated>2023-06-14T07:13:58.126Z</updated>
        <summary type="html"><![CDATA[Lingjing Kong, Biwei Huang, Feng Xie, Eric Xing, Yuejie Chi, Kun Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solving the Dirichlet problem for the Monge-Amp\`ere equation using
  neural networks]]></title>
        <id>http://arxiv.org/abs/2110.03310</id>
        <link href="http://arxiv.org/abs/2110.03310"/>
        <updated>2023-06-14T07:13:58.121Z</updated>
        <summary type="html"><![CDATA[Kaj Nystr\"om, Matias Vestberg]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fixed points of arbitrarily deep 1-dimensional neural networks]]></title>
        <id>http://arxiv.org/abs/2303.12814</id>
        <link href="http://arxiv.org/abs/2303.12814"/>
        <updated>2023-06-14T07:13:57.895Z</updated>
        <summary type="html"><![CDATA[Andrew Cook, Andy Hammerlindl, Warwick Tucker]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robustly Learning a Single Neuron via Sharpness]]></title>
        <id>http://arxiv.org/abs/2306.07892</id>
        <link href="http://arxiv.org/abs/2306.07892"/>
        <updated>2023-06-14T07:13:57.890Z</updated>
        <summary type="html"><![CDATA[Puqian Wang, Nikos Zarifis, Ilias Diakonikolas, Jelena Diakonikolas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Trio Neural Model for Dynamic Entity Relatedness Ranking]]></title>
        <id>http://arxiv.org/abs/1808.08316</id>
        <link href="http://arxiv.org/abs/1808.08316"/>
        <updated>2023-06-14T07:13:57.681Z</updated>
        <summary type="html"><![CDATA[Tu Nguyen, Tuan Tran, Wolfgang Nejdl]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[astrostat webinar [IAU-IAA]]]></title>
        <id>http://xianblog.wordpress.com/?p=53218</id>
        <link href="https://xianblog.wordpress.com/2023/06/14/astrostat-webinar-iau-iaa/"/>
        <updated>2023-06-13T22:23:28.000Z</updated>
        <summary type="html"><![CDATA[Next Tuesday, June 13, at 16:00 UTC, I am giving a talk on inferring the number of components in a mixture at the international online IAU-IAA Astrostats and Astroinfo seminar. As pointed out by my Cornell friend Tom Loredo, it is unfortunately clashing with the ISI quadrenial Statistical Challenges in Modern Astronomy meeting help at [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enabling delightful user experiences via predictive models of human attention]]></title>
        <id>http://ai.googleblog.com/2023/06/enabling-delightful-user-experiences.html</id>
        <link href="http://ai.googleblog.com/2023/06/enabling-delightful-user-experiences.html"/>
        <updated>2023-06-13T17:18:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Junfeng He, Senior Research Scientist, and Kai Kohlhoff, Staff Research Scientist, Google Research




People have the remarkable ability to take in a tremendous amount of information (estimated to be ~1010 bits/s entering the retina) and selectively attend to a few task-relevant and interesting regions for further processing (e.g., memory, comprehension, action). Modeling human attention (the result of which is often called a saliency model) has therefore been of interest across the fields of neuroscience, psychology, human-computer interaction (HCI) and computer vision. The ability to predict which regions are likely to attract attention has numerous important applications in areas like graphics, photography, image compression and processing, and the measurement of visual quali‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Victorious Secret]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59183</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59183&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=victorious-secret"/>
        <updated>2023-06-13T10:25:10.000Z</updated>
        <summary type="html"><![CDATA[The next event in the Salon Sanctuary concert series is "Victorious Secret: Love Gamed and Gender Untamed in the Sparkling Courts of the Baroque": Before the bars of gender binaries caged the mainstream operatic imagination, a golden age of fluidity guided the vocal soundscape. Virility declared itself with the castrato‚Äôs clarion high notes, while femininity [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beyond the Imitation Game: Quantifying and extrapolating the
  capabilities of language models]]></title>
        <id>http://arxiv.org/abs/2206.04615</id>
        <link href="http://arxiv.org/abs/2206.04615"/>
        <updated>2023-06-13T08:19:00.775Z</updated>
        <summary type="html"><![CDATA[Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb,
  Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adri\`a
  Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea
  Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv,
  Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda
  Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen,
  Andrea Madotto, Andrea Santilli, Andreas Stuhlm\"uller, Andrew Dai, Andrew
  La, Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong,
  Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash
  Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher
  Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla
  Karaka\c{s}, B. Ryan Roberts, Bao Sheng Loe, Barret Zoph, Bart{\l}omiej
  Bojanowski, Batuhan \"Ozyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin
  Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan
  Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta,
  C\'esar Ferri Ram\'irez, Chandan Singh, Charles Rathkopf, Chenlin Meng,
  Chitta Baral, Chiyu Wu, Chris Callison-Burch, Chris Waites, Christian Voigt,
  Christopher D. Manning, Christopher Potts, Cindy Ramirez, Clara E. Rivera,
  Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien
  Sileo, Dan Garrette, Dan Hendrycks, Dan Kilman, Dan Roth, Daniel Freeman,
  Daniel Khashabi, Daniel Levy, Daniel Mosegu\'i Gonz\'alez, Danielle Perszyk,
  Danny Hernandez, Danqi Chen, Daphne Ippolito, Dar Gilboa, David Dohan, David
  Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis
  Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes, Diganta Misra,
  Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader,
  Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth
  Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodola,]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Energy-Dissipative Evolutionary Deep Operator Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.06281</id>
        <link href="http://arxiv.org/abs/2306.06281"/>
        <updated>2023-06-13T08:19:00.296Z</updated>
        <summary type="html"><![CDATA[Jiahao Zhang, Shiheng Zhang, Jie Shen, Guang Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Learning Priors for Safe Bayesian Optimization]]></title>
        <id>http://arxiv.org/abs/2210.00762</id>
        <link href="http://arxiv.org/abs/2210.00762"/>
        <updated>2023-06-13T08:19:00.280Z</updated>
        <summary type="html"><![CDATA[Jonas Rothfuss, Christopher Koenig, Alisa Rupenyan, Andreas Krause]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intensity Profile Projection: A Framework for Continuous-Time
  Representation Learning for Dynamic Networks]]></title>
        <id>http://arxiv.org/abs/2306.06155</id>
        <link href="http://arxiv.org/abs/2306.06155"/>
        <updated>2023-06-13T08:19:00.275Z</updated>
        <summary type="html"><![CDATA[Alexander Modell, Ian Gallagher, Emma Ceccherini, Nick Whiteley and
  Patrick Rubin-Delanchy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Variational Models with Unrolling and Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2209.12651</id>
        <link href="http://arxiv.org/abs/2209.12651"/>
        <updated>2023-06-13T08:19:00.264Z</updated>
        <summary type="html"><![CDATA[Christoph Brauer, Niklas Breustedt, Timo de Wolff, Dirk A. Lorenz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introduction to Queueing Theory and Stochastic Teletraffic Models]]></title>
        <id>http://arxiv.org/abs/1307.2968</id>
        <link href="http://arxiv.org/abs/1307.2968"/>
        <updated>2023-06-13T07:14:02.706Z</updated>
        <summary type="html"><![CDATA[Moshe Zukerman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Effect of driving on coarsening dynamics in phase-separating systems]]></title>
        <id>http://arxiv.org/abs/1905.13396</id>
        <link href="http://arxiv.org/abs/1905.13396"/>
        <updated>2023-06-13T07:14:02.700Z</updated>
        <summary type="html"><![CDATA[D. Tseluiko, M. Alesemi, T.-S. Lin, U. Thiele]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Converse growth estimates for ODEs with slowly growing solutions]]></title>
        <id>http://arxiv.org/abs/1811.08736</id>
        <link href="http://arxiv.org/abs/1811.08736"/>
        <updated>2023-06-13T07:14:02.683Z</updated>
        <summary type="html"><![CDATA[Janne Gr\"ohn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alexandrov geometry: foundations]]></title>
        <id>http://arxiv.org/abs/1903.08539</id>
        <link href="http://arxiv.org/abs/1903.08539"/>
        <updated>2023-06-13T07:14:02.676Z</updated>
        <summary type="html"><![CDATA[Stephanie Alexander, Vitali Kapovitch, Anton Petrunin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Good News for Polynomial Root-finding]]></title>
        <id>http://arxiv.org/abs/1805.12042</id>
        <link href="http://arxiv.org/abs/1805.12042"/>
        <updated>2023-06-13T07:14:02.670Z</updated>
        <summary type="html"><![CDATA[Victor Y. Pan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Is it a rat's head or a duck's neck?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59176</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59176&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=is-it-a-rats-head-or-a-ducks-neck"/>
        <updated>2023-06-13T04:20:49.000Z</updated>
        <summary type="html"><![CDATA[Main dish served as part of a college cafeteria lunch in¬†Nanchang, China: On the left side it says:¬† zh√® b√∫sh√¨ m√°o ma? Ëøô‰∏çÊòØÊØõÂêó "Isn't this hair?" On the right side it reads: ƒÅy√≠ shu≈ç¬†sh√¨ yƒÅr√≤u ÈòøÂß®Ë™™ÊòØÈ¥®ËÇâ "Auntie [i.e., the cafeteria serving lady] says that it's duck meat." The photographs and the captions are from Andrew [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Red Sea [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53157</id>
        <link href="https://xianblog.wordpress.com/2023/06/13/red-sea-jatp/"/>
        <updated>2023-06-12T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Old Sinitic "wheat" and Early Middle Sinitic "camel"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59111</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59111&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=old-sinitic-wheat-and-early-middle-sinitic-camel"/>
        <updated>2023-06-12T20:56:56.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Chris Button] OC uvulars tended to condition rounding (e.g OC q- becoming EMC kw-). In the case of  Å-, we sometimes get m- (for a modern-day example, note howÊÉü, which also had a  Å- onset in Old Chinese, gives an m- reflex in Fuzhou Min). The classic example is [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language change (about to be?) in progress]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59145</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59145&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-change-about-to-be-in-progress"/>
        <updated>2023-06-12T11:48:10.000Z</updated>
        <summary type="html"><![CDATA[Current big news around here is the collapse of an elevated section of Interstate 95 due to a tanker truck fire. As Wikipedia explains, I-95 "is the main north‚Äìsouth Interstate Highway on the East Coast of the United States, running from U.S. Route 1 (US 1) in Miami, Florida, north to the Houlton‚ÄìWoodstock Border Crossing [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning]]></title>
        <id>http://arxiv.org/abs/2211.06530</id>
        <link href="http://arxiv.org/abs/2211.06530"/>
        <updated>2023-06-12T07:14:12.350Z</updated>
        <summary type="html"><![CDATA[Christopher A. Choquette-Choo, H. Brendan McMahan, Keith Rush, and
  Abhradeep Thakurta]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Huber-energy measure quantization]]></title>
        <id>http://arxiv.org/abs/2212.08162</id>
        <link href="http://arxiv.org/abs/2212.08162"/>
        <updated>2023-06-12T07:14:11.384Z</updated>
        <summary type="html"><![CDATA[Gabriel Turinici]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Path Neural Networks: Expressive and Accurate Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.05955</id>
        <link href="http://arxiv.org/abs/2306.05955"/>
        <updated>2023-06-12T07:14:11.314Z</updated>
        <summary type="html"><![CDATA[Gaspard Michel, Giannis Nikolentzos, Johannes Lutzeyer, Michalis
  Vazirgiannis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Credal Self-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2205.15239</id>
        <link href="http://arxiv.org/abs/2205.15239"/>
        <updated>2023-06-12T07:14:11.308Z</updated>
        <summary type="html"><![CDATA[Julian Lienen, Caglar Demir, Eyke H\"ullermeier]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Change-Point Detection in Time Series via Deep Learning]]></title>
        <id>http://arxiv.org/abs/2211.03860</id>
        <link href="http://arxiv.org/abs/2211.03860"/>
        <updated>2023-06-12T07:14:11.201Z</updated>
        <summary type="html"><![CDATA[Jie Li, Paul Fearnhead, Piotr Fryzlewicz, Tengyao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[gamin‚Äô the rankin‚Äô]]></title>
        <id>http://xianblog.wordpress.com/?p=53148</id>
        <link href="https://xianblog.wordpress.com/2023/06/12/gamin-the-rankin/"/>
        <updated>2023-06-11T22:23:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ravens on the garden path]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59146</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59146&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ravens-on-the-garden-path"/>
        <updated>2023-06-11T20:38:33.000Z</updated>
        <summary type="html"><![CDATA[I just ran across a particularly impressive garden path sentence in Bernd Heinrich's book RAVENS IN WINTER (p. 268); it took me several tries to get this sentence to parse grammatically: "Even the wolverine is said to do nothing to drive ravens off that land beside it and steal its food." (Of course parsing is [‚Ä¶]]]></summary>
        <author>
            <name>Sally Thomason</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thai to English translation gets injected with Tamil]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59101</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59101&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=thai-to-english-translation-gets-injected-with-tamil"/>
        <updated>2023-06-11T19:39:16.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Charles Belov] I pasted the following Thai, which I got from a YouTube channel, into Google translate. The results were mostly in English, but Google Translate injected some apparent Tamil as well and then just gives up and leaves some of the Thai untranslated. "‡∏ï‡∏•‡∏≠‡∏î‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏¥‡∏á‡∏°‡∏±‡∏ô‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÄ‡πÄ‡∏•‡πâ‡∏ß‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡πÑ‡∏õ‡∏´‡∏°‡∏î ‡πÄ‡πÄ‡∏•‡πâ‡∏ß‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏°‡∏±‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç‡∏°‡∏±‡∏ô‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢ [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quirky speech-to-text, weird diarization]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59108</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59108&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=quirky-asr-weird-diarization"/>
        <updated>2023-06-11T14:28:01.000Z</updated>
        <summary type="html"><![CDATA[From Daniel Deutsch: We had a long drive yesterday, so we listened to a ‚Äúrobot‚Äù reading the entire indictment. It certainly isn‚Äôt flawless, but I was surprised by how good it is, especially when it gets ‚Äúexcited‚Äù while enacting dialogue. Indeed, the text-to-speech quality is quite good ‚Äî though unfortunately they don't tell us which [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Apostrophes in Hanyu Pinyin]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59105</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59105&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=apostrophes-in-hanyu-pinyin"/>
        <updated>2023-06-11T12:39:45.000Z</updated>
        <summary type="html"><![CDATA[The most famous instance of the use of an apostrophe in Hanyu Pinyin romanization is in the place name "Xi'an", the capital of Shaanxi (the doubled "a" is another story) Province. Xƒ´'ƒÅn Ë•øÂÆâ ‚Äî two characters signifying "Western Peace" If you don't use an apostrophe to separate the syllables, you end up with the monosyllable [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT has a sense of humor (sort of)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59096</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59096&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-has-a-sense-of-humor-sort-of"/>
        <updated>2023-06-11T01:50:18.000Z</updated>
        <summary type="html"><![CDATA[Benj Edwards has a mirthful article in Ars Technica (6/9/23) Researchers discover that ChatGPT prefers repeating 25 jokes over and over When tested, "Over 90% of 1,008 generated jokes were the same 25 jokes." [includes an AI generated image of "a laughing robot"] On Wednesday, two German researchers, Sophie Jentzsch and Kristian Kersting, released a [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[technical steps]]></title>
        <id>http://xianblog.wordpress.com/?p=53198</id>
        <link href="https://xianblog.wordpress.com/2023/06/11/technical-steps/"/>
        <updated>2023-06-10T22:23:32.000Z</updated>
        <summary type="html"><![CDATA[After procrastinating as much as feasible, I switched at last to (K)Ubuntu 22.04, Jammy Jellyfish, after security updates stopped for the 20.04 version. While this proceeded mostly without hiccups, the upgrade stalled when upgrading Firefox, which I had foolishly left open. When I turned it off and completed the upgrade, this erased all of my [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Steak the First"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59077</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59077&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=steak-the-first"/>
        <updated>2023-06-10T21:32:29.000Z</updated>
        <summary type="html"><![CDATA[Enlightening article by Peter Backhaus in The Japan Times (6/9/23): "Za grammar notes: How to properly handle the 'the' in Japanese" Japanese seems to be able to assimilate any English word, including the ubiquitous definite article "the", which is unlike anything in Japanese itself. If there‚Äôs something like a Murphy‚Äôs Law for syntax, the name [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["The beautiful mind paper boxes"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59074</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59074&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-beautiful-mind-paper-boxes"/>
        <updated>2023-06-10T12:51:43.000Z</updated>
        <summary type="html"><![CDATA[The most recent Trump indictment reproduces this exchange of text messages (p. 11) : Trump Employee 2: We can definitely make it work if we move his papers into the lake room? Trump Employee 1: There is still a little room in the shower where his other stuff is. Is it only his papers he [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InternLM]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59071</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59071&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=internlm"/>
        <updated>2023-06-10T11:46:43.000Z</updated>
        <summary type="html"><![CDATA[As I am about to deliver a keynote address to an international conference on Chinese language pedagogy, I receive news of this new LLM that knocks my socks off: InternLM is a multilingual large language model jointly developed by Shanghai AI Lab and SenseTime (with equal contribution), in collaboration with the Chinese University of Hong [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT does Emily Dickinson writing a recipe for Pad Thai (and haiku too)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59030</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59030&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-does-emily-dickinson-writing-a-recipe-for-pad-thai-and-haiku-too"/>
        <updated>2023-06-10T03:02:36.000Z</updated>
        <summary type="html"><![CDATA[From Scott D. Seligman via Facebook: ¬† ChatGPT is really creeping me out. I asked it for a recipe for Pad Thai in the form of an Emily Dickinson poem. I'm no poetry maven, but the damned thing seems to have the ability to turn a phrase, at least some of the time. Below is [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[statistical modeling with R [book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53183</id>
        <link href="https://xianblog.wordpress.com/2023/06/10/statistical-modeling-with-r-book-review/"/>
        <updated>2023-06-09T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[Statistical Modeling with R (A dual frequentist and Bayesian approach for life scientists) is a recent book written by Pablo Inchausti, from Uruguay. In a highly personal and congenial style (witness the preface), with references to (fiction) books that enticed me to buy them. The book was sent to me by the JASA book editor [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Imagen Editor and EditBench: Advancing and evaluating text-guided image inpainting]]></title>
        <id>http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html</id>
        <link href="http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html"/>
        <updated>2023-06-09T19:09:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Su Wang and Ceslee Montgormery, Research Engineers, Google Research





In the last few years, text-to-image generation research has seen an explosion of breakthroughs (notably, Imagen, Parti, DALL-E 2, etc.) that have naturally permeated into related topics. In particular, text-guided image editing (TGIE) is a practical task that involves editing generated and photographed visuals rather than completely redoing them. Quick, automated, and controllable editing is a convenient solution when recreating visuals would be time-consuming or infeasible (e.g., tweaking objects in vacation photos or perfecting fine-grained details on a cute pup generated from scratch). Further, TGIE represents a substantial opportunity to improve training of foundational models themselves. Multimodal mod‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-owning peeve of the week: Compersion]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59056</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59056&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=self-owning-peeve-of-the-week-compersion"/>
        <updated>2023-06-09T13:27:09.000Z</updated>
        <summary type="html"><![CDATA[Email from Florent Moncomble¬†[links added]: A few months ago, the distinguished member of the Acad√©mie fran√ßaise Alain Finkielkraut was featured in a video where he deplored the loss of ‚Äúa word which used to exist in the [French] language and disappeared from it‚Äù, ie. ‚Äúcompersion‚Äù. Apparently, little does he know that ‚Äúcompersion‚Äù was actually coined [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural
  Language Understanding]]></title>
        <id>http://arxiv.org/abs/2306.04933</id>
        <link href="http://arxiv.org/abs/2306.04933"/>
        <updated>2023-06-09T08:18:07.758Z</updated>
        <summary type="html"><![CDATA[Junda Wu, Tong Yu, Rui Wang, Zhao Song, Ruiyi Zhang, Handong Zhao,
  Chaochao Lu, Shuai Li, Ricardo Henao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Large Language Model Annotations for Valid Downstream Statistical
  Inference in Social Science: Design-Based Semi-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2306.04746</id>
        <link href="http://arxiv.org/abs/2306.04746"/>
        <updated>2023-06-09T08:18:07.753Z</updated>
        <summary type="html"><![CDATA[Naoki Egami, Musashi Jacobs-Harukawa, Brandon M. Stewart, Hanying Wei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multitask Learning and Bandits via Robust Statistics]]></title>
        <id>http://arxiv.org/abs/2112.14233</id>
        <link href="http://arxiv.org/abs/2112.14233"/>
        <updated>2023-06-09T08:18:07.741Z</updated>
        <summary type="html"><![CDATA[Kan Xu, Hamsa Bastani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Polynomial Time and Private Learning of Unbounded Gaussian Mixture
  Models]]></title>
        <id>http://arxiv.org/abs/2303.04288</id>
        <link href="http://arxiv.org/abs/2303.04288"/>
        <updated>2023-06-09T08:18:07.736Z</updated>
        <summary type="html"><![CDATA[Jamil Arbas, Hassan Ashtiani, Christopher Liaw]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Meets Sparse Regularization: A Signal Processing
  Perspective]]></title>
        <id>http://arxiv.org/abs/2301.09554</id>
        <link href="http://arxiv.org/abs/2301.09554"/>
        <updated>2023-06-09T08:18:06.909Z</updated>
        <summary type="html"><![CDATA[Rahul Parhi, Robert D. Nowak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The asymptotics of r(4,t)]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"/>
        <updated>2023-06-09T06:17:30.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved‚Ä¶]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The asymptotics of r(4,t)]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"/>
        <updated>2023-06-09T06:17:30.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved‚Ä¶]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[de-MCM‚Äôd]]></title>
        <id>http://xianblog.wordpress.com/?p=53208</id>
        <link href="https://xianblog.wordpress.com/2023/06/09/de-mcmd/"/>
        <updated>2023-06-08T22:23:02.000Z</updated>
        <summary type="html"><![CDATA[This morning I received a message from the MCM 23 conference organisers that my registration [submitted two months ago] was declined for lack of room! I wonder why the organisers did not opt for broadcasting in a second amphitheater, as was done for ISBA in Edinburgh. Unfortunately, we have attained the maximal capacity of the [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Determining Ramsey numbers using finite geometry]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"/>
        <updated>2023-06-08T19:31:29.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Anurag's Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a‚Ä¶]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Determining Ramsey numbers using finite geometry]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"/>
        <updated>2023-06-08T19:31:29.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Anurag's Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a‚Ä¶]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transliterations aplenty]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59014</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59014&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=transliterations-aplenty"/>
        <updated>2023-06-08T16:50:05.000Z</updated>
        <summary type="html"><![CDATA[From Simon Cartoon: Here's something I just saw at a local bakery in Berkeley, CA. Simon explains: We have English, Spanish, and then French in the last position, no issues there. 3rd position is Mandarin Chinese via pinyin: Who is this for? What is the population of people uncomfortable reading in English, but comfortable reading [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We may finally crack Maths. But should we?]]></title>
        <id>6481b5876965110001df8c10</id>
        <link href="https://www.inference.vc/we-may-finally-crack-maths-but-should-we/"/>
        <updated>2023-06-08T15:58:13.000Z</updated>
        <summary type="html"><![CDATA[Automating mathematical theorem proving has been a long standing goal of artificial intelligence and indeed computer science. It's one of the areas I became very interested in recently. This is because I feel we may have the ingredients needed to make very, very significant progress:

a structured search]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is the logical form of that?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59026</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59026&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=what-is-the-logical-form-of-that"/>
        <updated>2023-06-08T13:36:25.000Z</updated>
        <summary type="html"><![CDATA[This post wanders down a series of rabbit holes, from a couple of dead economists, to a dead philosopher, to a dead Supreme Court justice. It all started with Eric Rahim's obituary in the Guardian, which links to the British Academy's obituary for Piero Sraffa, which includes this passage: He also formed a close friendship [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greco-Sinitic œàŒ¨ŒºŒºŒøœÇ /  ÉÀ†a  m…ëkÃö ("desert")]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59024</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59024&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=greco-sinitic-%25cf%2588%25ce%25ac%25ce%25bc%25ce%25bc%25ce%25bf%25cf%2582-%25ca%2583%25cb%25a0a-mak%25cc%259a-desert"/>
        <updated>2023-06-08T12:39:35.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Chau Wu] The psammo- component of the winning word in this year's Scripps National Spelling Bee, psammophile, is of interest to me because it is a good example of European-Sinitic lexical correspondence. The Ancient Greek word ps√°mmos (œàŒ¨ŒºŒºŒøœÇ) means ‚Äòsand‚Äô.¬† When used together with a definite article (·º° œàŒ¨ŒºŒºŒøœÇ), [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Invariance in Policy Optimisation and Partial Identifiability in Reward
  Learning]]></title>
        <id>http://arxiv.org/abs/2203.07475</id>
        <link href="http://arxiv.org/abs/2203.07475"/>
        <updated>2023-06-08T07:13:38.535Z</updated>
        <summary type="html"><![CDATA[Joar Skalse, Matthew Farrugia-Roberts, Stuart Russell, Alessandro
  Abate, Adam Gleave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformers as Statisticians: Provable In-Context Learning with
  In-Context Algorithm Selection]]></title>
        <id>http://arxiv.org/abs/2306.04637</id>
        <link href="http://arxiv.org/abs/2306.04637"/>
        <updated>2023-06-08T07:13:38.518Z</updated>
        <summary type="html"><![CDATA[Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multimodal Learning Without Labeled Multimodal Data: Guarantees and
  Applications]]></title>
        <id>http://arxiv.org/abs/2306.04539</id>
        <link href="http://arxiv.org/abs/2306.04539"/>
        <updated>2023-06-08T07:13:38.512Z</updated>
        <summary type="html"><![CDATA[Paul Pu Liang, Chun Kai Ling, Yun Cheng, Alex Obolenskiy, Yudong Liu,
  Rohan Pandey, Alex Wilf, Louis-Philippe Morency, Ruslan Salakhutdinov]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics,
  Directional Convergence, and Equilibria]]></title>
        <id>http://arxiv.org/abs/2212.02457</id>
        <link href="http://arxiv.org/abs/2212.02457"/>
        <updated>2023-06-08T07:13:38.507Z</updated>
        <summary type="html"><![CDATA[Tengyuan Liang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PILLAR: How to make semi-private learning more effective]]></title>
        <id>http://arxiv.org/abs/2306.03962</id>
        <link href="http://arxiv.org/abs/2306.03962"/>
        <updated>2023-06-08T07:13:38.500Z</updated>
        <summary type="html"><![CDATA[Francesco Pinto, Yaxi Hu, Fanny Yang, Amartya Sanyal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2023‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºö‚ÄúAIÁîüÊàê‰∏éÂûÇÁõ¥Â§ßËØ≠Ë®ÄÊ®°Âûã‚ÄùËÆ∫ÂùõÈáçÁ£ÖÊù•Ë¢≠ÔºÅ]]></title>
        <id>https://www.52nlp.cn/?p=13474</id>
        <link href="https://www.52nlp.cn/2023%e4%b8%96%e7%95%8c%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%a4%a7%e4%bc%9aai%e7%94%9f%e6%88%90%e4%b8%8e%e5%9e%82%e7%9b%b4%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e8%ae%ba"/>
        <updated>2023-06-08T02:23:31.000Z</updated>
        <summary type="html"><![CDATA[ÂΩìÂâçAIÁîüÊàê‰∏éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊåáÊï∞Á∫ßÂèëÂ±ïÔºå‰∏∫Áõ∏ÂÖ≥‰∫ß‰∏öÈìæÂ∏¶Êù•Êñ∞ÁöÑÂèëÂ±ïÂºïÊìéÔºå‰πü‰∏∫AIËêΩÂú∞Â∫îÁî®Â∏¶Êù•Êñ∞ÁöÑÊÉ≥Ë±°Á©∫Èó¥„ÄÇ2023 [‚Ä¶]]]></summary>
        <author>
            <name>ËææËßÇÊï∞ÊçÆ</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Naive Bayes is all you need ?]]></title>
        <id>https://kexue.fm/archives/9648</id>
        <link href="https://kexue.fm/archives/9648"/>
        <updated>2023-06-08T01:25:00.000Z</updated>
        <summary type="html"><![CDATA[ÂæàÊä±Ê≠âÔºåËµ∑‰∫ÜËøô‰πà‰∏™ÂÖ∑ÊúâÊ†áÈ¢òÂÖöÁâπÂæÅÁöÑÈ¢òÁõÆ„ÄÇÂú®ÂÜôÂÆå„ÄäNBCEÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÊâ©Â±ïLLMÁöÑContextÂ§ÑÁêÜÈïøÂ∫¶„Äã‰πãÂêéÔºåÁ¨îËÄÖÂ∞±ËßâÂæóÊú¥Á¥†Ë¥ùÂè∂ÊñØÔºàNaive BayesÔºâË∑üAttentionÊú∫Âà∂ÊúâÂæàÂ§öÁõ∏Âêå...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[uniform spacings]]></title>
        <id>http://xianblog.wordpress.com/?p=53161</id>
        <link href="https://xianblog.wordpress.com/2023/06/08/uniform-spacings/"/>
        <updated>2023-06-07T22:23:28.000Z</updated>
        <summary type="html"><![CDATA[A riddle on uniform spacings!, namely when considering eight iid Uniform (0,1) variates as visiting times and three further iid Uniform (0,1) variates as server availability times, with unit service time, the question being the probability a server is available for a ninth visiting time, T‚Åπ. Which can be decomposed into four cases: at least [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating speech synthesis in many languages with SQuId]]></title>
        <id>http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html</id>
        <link href="http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html"/>
        <updated>2023-06-07T18:07:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Thibault Sellam, Research Scientist, Google





Previously, we presented the 1,000 languages initiative and the Universal Speech Model with the goal of making speech and language technologies available to billions of users around the world. Part of this commitment involves developing high-quality speech synthesis technologies, which build upon projects such as VDTTS and AudioLM, for users that speak many different languages.






listening tests, during which dozens of annotators listen to the utterances one after the other to determine how natural they sound. While humans are still unbeaten at detecting whether a piece of text sounds natural, this process can be impractical ‚Äî especially in the early stages of research projects, when engineers need rapid feedback to test and re‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aligning Language Models with Preferences through f-divergence
  Minimization]]></title>
        <id>http://arxiv.org/abs/2302.08215</id>
        <link href="http://arxiv.org/abs/2302.08215"/>
        <updated>2023-06-07T07:13:39.489Z</updated>
        <summary type="html"><![CDATA[Dongyoung Go, Tomasz Korbak, Germ\'an Kruszewski, Jos Rozen, Nahyeon
  Ryu, Marc Dymetman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Denise: Deep Robust Principal Component Analysis for Positive
  Semidefinite Matrices]]></title>
        <id>http://arxiv.org/abs/2004.13612</id>
        <link href="http://arxiv.org/abs/2004.13612"/>
        <updated>2023-06-07T07:13:39.484Z</updated>
        <summary type="html"><![CDATA[Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen,
  Josef Teichmann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Orthogonal Statistical Learning]]></title>
        <id>http://arxiv.org/abs/1901.09036</id>
        <link href="http://arxiv.org/abs/1901.09036"/>
        <updated>2023-06-07T07:13:39.478Z</updated>
        <summary type="html"><![CDATA[Dylan J. Foster, Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep neural networks architectures from the perspective of manifold
  learning]]></title>
        <id>http://arxiv.org/abs/2306.03406</id>
        <link href="http://arxiv.org/abs/2306.03406"/>
        <updated>2023-06-07T07:13:39.454Z</updated>
        <summary type="html"><![CDATA[German Magai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Join the PyTorch Foundation: Membership Now Open]]></title>
        <id>https://pytorch.org/blog/join-pytorch/</id>
        <link href="https://pytorch.org/blog/join-pytorch/"/>
        <updated>2023-06-07T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[In September 2022, we welcomed PyTorch to the Linux Foundation from Meta, which formed the PyTorch Foundation with founding members AMD, Amazon Web Services (AWS), Google, Meta, Microsoft, and NVIDIA.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unknown language #15]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59005</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59005&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=unknown-language-15"/>
        <updated>2023-06-07T02:46:22.000Z</updated>
        <summary type="html"><![CDATA[Yuan (? dynasty (1271-1368) jade seal in the Bristol Museum: Know what language this is, or even what it says? Yes? Please get back to me. No? Please retweet it until somebody does. (But be aware, it's stumped some quite clever people who've already been asked, so it isn't obvious) Also, advance apologies if it [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding CPUs can help speed up Numba and NumPy code]]></title>
        <id>https://pythonspeed.com/articles/speeding-up-numba/</id>
        <link href="https://pythonspeed.com/articles/speeding-up-numba/"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[When you need to speed up your NumPy processing‚Äîor just reduce your memory usage‚Äîthe Numba just-in-time compiler is a great tool.
It lets you write Python code that gets compiled at runtime to machine code, allowing you to get the kind of speed improvements you‚Äôd get from languages like C, Fortran, or Rust.
Or at least, that‚Äôs the theory.
In practice, your initial Numba code may be no faster than the NumPy equivalent.
But you can do better, once you have a better understanding of how CPUs work.
And this knowledge will help you more broadly with any compiled language.
In this article we‚Äôll:
Consider a simple image-processing problem.
Try, and initially fail, to speed it up with Numba.
We‚Äôll review just a little bit how modern CPUs are so fast, and the limits of compilers.
Based on our new understanding, we‚Äôll then show how we can tweak our code to run 25√ó faster than our original version.
Read more...]]></summary>
        <author>
            <name>Python‚áíSpeed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimising computer systems with more generalised AI tools]]></title>
        <id>https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools</id>
        <link href="https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Based on reinforcement learning, our AI models AlphaZero and MuZero have achieved superhuman performance winning games. Now, they‚Äôre expanding their capabilities to help optimise resources in data centres and advance video compression ‚Äì and most recently, our specialised version of AlphaZero, called AlphaDev, discovered new algorithms that are already accelerating the software applications at the foundations of our digital society.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AlphaDev discovers faster sorting algorithms]]></title>
        <id>https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms</id>
        <link href="https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In our paper published today in Nature, we introduce AlphaDev, an artificial intelligence (AI) system that uses reinforcement learning to discover enhanced computer science algorithms ‚Äì surpassing those honed by scientists and engineers over decades.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[stack overflow on strike]]></title>
        <id>http://xianblog.wordpress.com/?p=53202</id>
        <link href="https://xianblog.wordpress.com/2023/06/07/stack-overflow-on-strike/"/>
        <updated>2023-06-06T22:23:40.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinitic exclamations in English speech]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58949</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58949&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinitic-exclamations-in-english-speech"/>
        <updated>2023-06-06T17:45:45.000Z</updated>
        <summary type="html"><![CDATA[Listen to Malaysian comedian Nigel Ng (aka "Uncle Roger"), who has had his Weibo and bilibili social media accounts banned due to "violation of relevant regulations": The ban comes one day after Ng uploaded this clip to various social media platforms. pic.twitter.com/8Wwf2aTrfZ ‚Äî Aaron Busch (@tripperhead) May 19, 2023 Under the subject line "Uncle Roger [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual captions: Using large language models to augment video conferences with dynamic visuals]]></title>
        <id>http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html</id>
        <link href="http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html"/>
        <updated>2023-06-06T16:58:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ruofei Du, Research Scientist, and Alex Olwal, Senior Staff Research Scientist, Google Augmented Reality




Recent advances in video conferencing have significantly improved remote video communication through features like live captioning and noise cancellation. However, there are various situations where dynamic visual augmentation would be useful to better convey complex and nuanced information. For example, when discussing what to order at a Japanese restaurant, your friends could share visuals that would help you feel more confident about ordering the ‚ÄúSukiyaki‚Äù. Or when talking about your recent family trip to San Francisco, you may want to show a photo from your personal album.




In ‚ÄúVisual Captions: Augmenting Verbal Communication With On-the-fly Visuals‚Äù, presented at ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LLMs as coders?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58977</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58977&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=llms-as-coders"/>
        <updated>2023-06-06T12:19:14.000Z</updated>
        <summary type="html"><![CDATA[I've recently seen many articles like this one, "You probably don't need to learn to code anymore" (Medium 6/5/2023), arguing that Large Language Models will make human programming (and human programmers) unnecessary. These arguments puzzle me, because my experience with LLMs suggests that they can't be relied on even for very simple programming tasks. After [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Bayesian Active Learning for Accelerating Stochastic Simulation]]></title>
        <id>http://arxiv.org/abs/2106.02770</id>
        <link href="http://arxiv.org/abs/2106.02770"/>
        <updated>2023-06-06T07:14:01.826Z</updated>
        <summary type="html"><![CDATA[Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, Yi-An
  Ma, Rose Yu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alignment with human representations supports robust few-shot learning]]></title>
        <id>http://arxiv.org/abs/2301.11990</id>
        <link href="http://arxiv.org/abs/2301.11990"/>
        <updated>2023-06-06T07:14:01.819Z</updated>
        <summary type="html"><![CDATA[Ilia Sucholutsky, Thomas L. Griffiths]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Emergence of Clean-Priority Learning in Early Stopped Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.02533</id>
        <link href="http://arxiv.org/abs/2306.02533"/>
        <updated>2023-06-06T07:14:01.813Z</updated>
        <summary type="html"><![CDATA[Chaoyue Liu, Amirhesam Abedsoltan, Mikhail Belkin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LibAUC: A Deep Learning Library for X-Risk Optimization]]></title>
        <id>http://arxiv.org/abs/2306.03065</id>
        <link href="http://arxiv.org/abs/2306.03065"/>
        <updated>2023-06-06T07:14:01.438Z</updated>
        <summary type="html"><![CDATA[Zhuoning Yuan, Dixian Zhu, Zi-Hao Qiu, Gang Li, Xuanhui Wang, Tianbao
  Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Linear Causal Representations from Interventions under General
  Nonlinear Mixing]]></title>
        <id>http://arxiv.org/abs/2306.02235</id>
        <link href="http://arxiv.org/abs/2306.02235"/>
        <updated>2023-06-06T07:14:01.143Z</updated>
        <summary type="html"><![CDATA[Simon Buchholz, Goutham Rajendran, Elan Rosenfeld, Bryon Aragam,
  Bernhard Sch\"olkopf, Pradeep Ravikumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinitic semiliteracy]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58917</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58917&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinitic-semiliteracy"/>
        <updated>2023-06-06T04:43:50.000Z</updated>
        <summary type="html"><![CDATA[From¬†a story on CNN on "begpackers" in Asia: The photo is captioned, "Professor Stephen Pratt posed as a begpacker to do fieldwork in Hong Kong." The sign says: q«êng bƒÅngzh√π w«í z√†i qu√°n sh√¨ji√® l«öx√≠ng Ë´ãÂπ´Âä©ÊàëÂú®ÂÖ®‰∏ñÁïåÊóÖË°å "Please help me travel around the world" Despite the fractured grammar (the z√†i Âú®* is especially egregious), all the [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of biang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58888</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58888&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-biang"/>
        <updated>2023-06-06T04:34:16.000Z</updated>
        <summary type="html"><![CDATA[Shop sign in Budapest: Don't be cowed by the quixotic orthography.¬† The noodles are delicious, and you can get them right here in Philadelphia, and many other cities around the world. Selected readings "Biangbiang: authentic Xi'an grub in the heart of Philadelphia's University City" (6/9/22) "A Chinese character that is harder to write than 'biang'" [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[remembering May 35th]]></title>
        <id>http://xianblog.wordpress.com/?p=53194</id>
        <link href="https://xianblog.wordpress.com/2023/06/06/remembering-may-35th/"/>
        <updated>2023-06-05T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The (local) unit of intelligence is FLOPs]]></title>
        <id>http://windowsontheory.org/?p=8630</id>
        <link href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/"/>
        <updated>2023-06-05T18:22:58.000Z</updated>
        <summary type="html"><![CDATA[[Crossposting again on¬†Lesswrong and¬†Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it‚Äôs hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure ‚Ä¶ Continue reading The (local) unit of intelligence is¬†FLOPs]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The (local) unit of intelligence is FLOPs]]></title>
        <id>http://windowsontheory.org/?p=8630</id>
        <link href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/"/>
        <updated>2023-06-05T18:22:58.000Z</updated>
        <summary type="html"><![CDATA[[Crossposting again on¬†Lesswrong and¬†Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it‚Äôs hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure ‚Ä¶ Continue reading The (local) unit of intelligence is¬†FLOPs]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bilingual road signs]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58960</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58960&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bilingual-road-signs"/>
        <updated>2023-06-05T12:15:41.000Z</updated>
        <summary type="html"><![CDATA[‚Ä¶in New Zealand. Phil Pennington, "Analysis: National opposed bilingual road signs, so what does the evidence say?", RNZ 62/2023: Analysis ‚Äì Bilingual road signs send a signal ‚Äì that the country values te reo MƒÅori. But going bilingual was confusing and National would not support it, National's Simeon Brown told voters in blue-ribbon Tauranga recently. [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding the Dynamics of Gaussian-Stein Variational
  Gradient Descent]]></title>
        <id>http://arxiv.org/abs/2305.14076</id>
        <link href="http://arxiv.org/abs/2305.14076"/>
        <updated>2023-06-05T07:13:47.914Z</updated>
        <summary type="html"><![CDATA[Tianle Liu, Promit Ghosal, Krishnakumar Balasubramanian, Natesh S.
  Pillai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linked Deep Gaussian Process Emulation for Model Networks]]></title>
        <id>http://arxiv.org/abs/2306.01212</id>
        <link href="http://arxiv.org/abs/2306.01212"/>
        <updated>2023-06-05T07:13:47.903Z</updated>
        <summary type="html"><![CDATA[Deyu Ming, Daniel Williamson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding Generalization of Macro-AUC in Multi-label
  Learning]]></title>
        <id>http://arxiv.org/abs/2305.05248</id>
        <link href="http://arxiv.org/abs/2305.05248"/>
        <updated>2023-06-05T07:13:47.890Z</updated>
        <summary type="html"><![CDATA[Guoqiang Wu, Chongxuan Li, Yilong Yin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Developing A Visual-Interactive Interface for Electronic Health Record
  Labeling: An Explainable Machine Learning Approach]]></title>
        <id>http://arxiv.org/abs/2209.12778</id>
        <link href="http://arxiv.org/abs/2209.12778"/>
        <updated>2023-06-05T07:13:47.871Z</updated>
        <summary type="html"><![CDATA[Donlapark Ponnoprat, Parichart Pattarapanitchai, Phimphaka Taninpong,
  Suthep Suantai, Natthanaphop Isaradech, Thiraphat Tanphiriyakun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hyperparameter Learning under Data Poisoning: Analysis of the Influence
  of Regularization via Multiobjective Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2306.01613</id>
        <link href="http://arxiv.org/abs/2306.01613"/>
        <updated>2023-06-05T07:13:47.865Z</updated>
        <summary type="html"><![CDATA[Javier Carnerero-Cano, Luis Mu\~noz-Gonz\'alez, Phillippa Spencer,
  Emil C. Lupu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[fusing simulation with data science [18-19 July 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=53177</id>
        <link href="https://xianblog.wordpress.com/2023/06/05/fusing-simulation-with-data-science-18-19-july-2023/"/>
        <updated>2023-06-04T22:23:59.000Z</updated>
        <summary type="html"><![CDATA[In collaboration with the Met Office, my friend and Warwick colleague Rito Dutta is co-organising a two-day workshop in Warwick in July on the use of statistics and machine learning tools in weather prediction. Attendance is free, but registration needed for tea breaks.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greater China Co-Prosperity Sushi and Ramen Kitchen]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58924</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58924&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=greater-china-co-prosperity-sushi-and-ramen-kitchen"/>
        <updated>2023-06-04T17:30:33.000Z</updated>
        <summary type="html"><![CDATA[Shouldn‚Äôt that be Zhonghua Pan-Asian Kitchen Ramen Wok Premium Sushi? pic.twitter.com/tTUaWidjL3 ‚Äî James Millward Á±≥ËèØÂÅ• (@JimMillward) June 4, 2023 The small characters at the top of the sign say: H√†nz√∫ Y√†zh≈çu ch√∫f√°ng Ê±âÊóè‰∫öÊ¥≤Âé®Êàø "Han ethnicity Asian kitchen" The wording in large H√†ny«î Pƒ´nyƒ´n ("Sinitic spelling") is HANZU, the roman letter transcription of the first two [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revelation:  Scythians and Shang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58846</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58846&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=revelation-scythians-and-shang"/>
        <updated>2023-06-04T15:48:03.000Z</updated>
        <summary type="html"><![CDATA[I was stunned when I read the following article in the South China Morning Post, both because it was published in Hong Kong, which is now completely under the censorial control of the People's Republic of China (PRC) / Chinese Communist Party (CCP), and because it raises some disturbing political issues and troubling linguistic problems. [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of inventive pinyin: rua]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58832</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58832&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-inventive-pinyin-rua"/>
        <updated>2023-06-04T15:26:32.000Z</updated>
        <summary type="html"><![CDATA[This exercise video shows a woman repeating the syllable "rua" to describe a move that she makes: Problem is that there's no Sinoglyph (h√†nz√¨¬†Êº¢Â≠ó /¬†Ê±âÂ≠ó) for writing that in Modern Standard Mandarin (MSM), although some might claim that it can be written with¬†this character, ru√≥ Êåº¬†("rub; knead; massage"). According to¬†this table, "rua" is not a [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The rise (and fall?) of shiesties]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58927</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58927&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-rise-and-fall-of-shiesties"/>
        <updated>2023-06-04T10:52:10.000Z</updated>
        <summary type="html"><![CDATA[Last month I learned a new word, shiesty ‚Äî which rhymes with feisty, as if it were written "sheisty" ‚Äî because shiesties have been banned on the local transit system ("SEPTA"): Your browser does not support the audio element. Keith, I'm sure if you walked around Philadelphia, live in Philadelphia, work in Philadelphia, you've seen [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Role Of Social Media On Selected Businesses In Nigeria In The Era Of
  Covid-19 Pandemic]]></title>
        <id>http://arxiv.org/abs/2305.19299</id>
        <link href="http://arxiv.org/abs/2305.19299"/>
        <updated>2023-06-04T07:13:27.273Z</updated>
        <summary type="html"><![CDATA[Cajetan Ihemebiri, Elochukwu Ukwandu, Lizzy Ofusori, Comfort
  Olebara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near-Atomic Scale Perspective on the Oxidation of Ti$_3$C$_2$T$_x$
  MXenes: Insights from Atom Probe Tomography]]></title>
        <id>http://arxiv.org/abs/2305.19822</id>
        <link href="http://arxiv.org/abs/2305.19822"/>
        <updated>2023-06-04T07:13:27.240Z</updated>
        <summary type="html"><![CDATA[Mathias Kr\"amer, Bar Favelukis, Ayman A. El-Zoka, Maxim Sokol, Brian
  A. Rosen, Noam Eliaz, Se-Ho Kim, Baptiste Gault]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual Exploratory Data Analysis of the Covid-19 Pandemic in Nigeria:
  Two Years after the Outbreak]]></title>
        <id>http://arxiv.org/abs/2305.19297</id>
        <link href="http://arxiv.org/abs/2305.19297"/>
        <updated>2023-06-04T07:13:27.228Z</updated>
        <summary type="html"><![CDATA[Ugochukwu Orji, Modesta Ezema, Elochukwu Ukwandu, Chikaodili
  Ugwuishiwu, Ezugwu Obianuju, Malachi Egbugha]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[To what extent can control policies influence the epidemic spreading? --
  A data-driven analysis based on the first wave of COVID-19]]></title>
        <id>http://arxiv.org/abs/2305.19544</id>
        <link href="http://arxiv.org/abs/2305.19544"/>
        <updated>2023-06-04T07:13:27.223Z</updated>
        <summary type="html"><![CDATA[Dongyan Zhang, Wanqi Wen, Wuyue Yang, Liangrong Peng, Changjingn
  Zhuge, Liu Hong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Beacon [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53153</id>
        <link href="https://xianblog.wordpress.com/2023/06/04/the-beacon-jatp/"/>
        <updated>2023-06-03T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dog bites man:  Indian wins spelling bee]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58921</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58921&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dog-bites-man-indian-wins-spelling-bee"/>
        <updated>2023-06-03T20:25:55.000Z</updated>
        <summary type="html"><![CDATA[New old news: "Dev Shah wins 2023 Scripps National Spelling Bee by correctly spelling 'psammophile'"Chris BumbacaUSA TODAY (6/1/23) Another year, same story: The 2023 Scripps National Spelling Bee ended the old-fashioned way. Two competitors left on the stage. No spell-off required. Dev Shah, an eighth-grader from Largo, Florida, spelled "psammophile" correctly to win the 95th [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pronouncing "DeSantis"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58876</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58876&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pronouncing-desantis"/>
        <updated>2023-06-03T14:21:21.000Z</updated>
        <summary type="html"><![CDATA[The question of how to pronounce Ron DeSantis' last name ‚Äî and the observation that the candidate, his wife, and his campaign have made different choices at different times ‚Äî is among the more trivial bits of political flotsam recently washing up on the shores of social and political media. In fact the issue has [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinological formatting]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58874</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58874&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinological-formatting"/>
        <updated>2023-06-03T12:02:31.000Z</updated>
        <summary type="html"><![CDATA[I recently received this book: S≈´n Sƒ´mi«éo, Sabine Wilms.¬† Healing Virtue-Power: Medical Ethics and the Doctor's Dao.¬† Whidbey Island WA:¬† Happy Goat Productions, 2022. ISBN:¬† 978-1-7321571-9-4 website As soon as I started to leaf through the volume, I was struck by its unusual format and usages:¬† every Chinese character is accompanied by Hanyu Pinyin phonetic [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tsunami and megathrust earthquake disaster prevention warnings:
  Real-time monitoring of the genesis processes with Physical Wavelets]]></title>
        <id>http://arxiv.org/abs/2305.13249</id>
        <link href="http://arxiv.org/abs/2305.13249"/>
        <updated>2023-06-03T07:12:38.216Z</updated>
        <summary type="html"><![CDATA[Fumihide Takeda]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diagonalization of Polynomial-Time Deterministic Turing Machines Via
  Nondeterministic Turing Machine]]></title>
        <id>http://arxiv.org/abs/2110.06211</id>
        <link href="http://arxiv.org/abs/2110.06211"/>
        <updated>2023-06-03T07:12:38.210Z</updated>
        <summary type="html"><![CDATA[Tianrong Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[van Dantzig seminar]]></title>
        <id>http://xianblog.wordpress.com/?p=53169</id>
        <link href="https://xianblog.wordpress.com/2023/06/03/van-dantzig-seminar/"/>
        <updated>2023-06-02T22:23:48.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Just < Not the same as it was]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58869</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58869&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=just-not-the-same-as-it-was"/>
        <updated>2023-06-02T22:12:54.000Z</updated>
        <summary type="html"><![CDATA[I listened to this Harry Styles song dozens of times on the radio, and every time I heard him sing "You know it's just the same as it was" over and over: It was only after watching the video and reading the subtitles that I realized he was saying "You know it's not the same [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Austronesian languages of Taiwan]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58855</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58855&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=austronesian-languages-of-taiwan"/>
        <updated>2023-06-02T19:27:48.000Z</updated>
        <summary type="html"><![CDATA[Handbook of Formosan Languages (Online): The Indigenous Languages of Taiwan Editors: Paul Jen-kuei Li, Academia SinicaElizabeth Zeitoun, Academia SinicaRik De Busser, National Taiwan Cheng-Chi University Leiden:¬† Brill, 2023 Outright Purchase: ‚Ç¨ 2249 / US dollars 2495Subscription: ‚Ç¨ 350 / US dollars 390 A print version is forthcoming (September 2023 ; 3 vols, ~ 2200 pp.) [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AVFormer: Injecting vision into frozen speech models for zero-shot AV-ASR]]></title>
        <id>http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html</id>
        <link href="http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html"/>
        <updated>2023-06-02T17:02:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Arsha Nagrani and Paul Hongsuck Seo, Research Scientists, Google Research






Automatic speech recognition (ASR) is a well-established technology that is widely adopted for various applications such as conference calls, streamed video transcription and voice commands. While the challenges for this technology are centered around noisy audio inputs, the visual stream in multimodal videos (e.g., TV, online edited videos) can provide strong cues for improving the robustness of ASR systems ‚Äî this is called audiovisual ASR (AV-ASR).
 

Although lip motion can provide strong signals for speech recognition and is the most common area of focus for AV-ASR, the mouth is often not directly visible in videos in the wild (e.g., due to egocentric viewpoints, face coverings, and low resolution‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Historical speech styles]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58857</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58857&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=historical-speech-styles"/>
        <updated>2023-06-02T11:48:13.000Z</updated>
        <summary type="html"><![CDATA[A recent Dinosaur Comics strip¬†features T-Rex imitating (a certain kind of) speech style from the 1940s: Mouseover title: "to t-rex's mind, and mine as well, all of the past takes place around the 1930s. well sure! and why not?" The next strip: Mouseover title: "you want a gender-neutral way to address a room, well here [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Expressive Power of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.00145</id>
        <link href="http://arxiv.org/abs/2306.00145"/>
        <updated>2023-06-02T07:13:25.962Z</updated>
        <summary type="html"><![CDATA[Jan Holstermann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combining Explicit and Implicit Regularization for Efficient Learning in
  Deep Networks]]></title>
        <id>http://arxiv.org/abs/2306.00342</id>
        <link href="http://arxiv.org/abs/2306.00342"/>
        <updated>2023-06-02T07:13:25.957Z</updated>
        <summary type="html"><![CDATA[Dan Zhao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provably Learning Diverse Features in Multi-View Data with Midpoint
  Mixup]]></title>
        <id>http://arxiv.org/abs/2210.13512</id>
        <link href="http://arxiv.org/abs/2210.13512"/>
        <updated>2023-06-02T07:13:25.952Z</updated>
        <summary type="html"><![CDATA[Muthu Chidambaram, Xiang Wang, Chenwei Wu, Rong Ge]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Revealing the Mystery behind Chain of Thought: a Theoretical
  Perspective]]></title>
        <id>http://arxiv.org/abs/2305.15408</id>
        <link href="http://arxiv.org/abs/2305.15408"/>
        <updated>2023-06-02T07:13:25.946Z</updated>
        <summary type="html"><![CDATA[Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Sensible Adversarial Learning of Deep Neural Networks for Image
  Classification]]></title>
        <id>http://arxiv.org/abs/2205.10457</id>
        <link href="http://arxiv.org/abs/2205.10457"/>
        <updated>2023-06-02T07:13:25.730Z</updated>
        <summary type="html"><![CDATA[Jungeum Kim, Xiao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Galton and Watson voluntarily skipping some generations]]></title>
        <id>http://xianblog.wordpress.com/?p=53139</id>
        <link href="https://xianblog.wordpress.com/2023/06/02/galton-and-watson-voluntarily-skipping-some-generations/"/>
        <updated>2023-06-01T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[A riddle on a form of a Galton-Watson process, starting from a single unit, where no one dies but rather, at each of 100 generations, Dog either opts for a Uniform number œÖ of additional units or increments a counter Œ≥ by this number œÖ, its goal being to optimise Œ≥. The solution proposed by [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Know your relatives in Chinese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58807</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58807&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=know-your-relatives-in-chinese"/>
        <updated>2023-06-01T18:38:21.000Z</updated>
        <summary type="html"><![CDATA[Randy Alexander reports that during a guitar lesson, he asked his student: MƒÅmƒÅ de d√¨di de n«ö√©r sh√¨ bi«éom√®i maÔºü Â¶àÂ¶àÁöÑÂºüÂºüÁöÑÂ•≥ÂÑøÊòØË°®Â¶πÂêóÔºü "Is your mother's younger brother's daughter your younger maternal female cousin?" The student replied: w«íyƒõ b√∫t√†i qƒ´ngch«î dƒõngy√≠xi√† Êàë‰πü‰∏çÂ§™Ê∏ÖÊ•öÁ≠â‰∏Ä‰∏ã "I don't quite know either, wait a minute." Here's a screen shot of the student's [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Retrieval-augmented visual-language pre-training]]></title>
        <id>http://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html</id>
        <link href="http://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html"/>
        <updated>2023-06-01T17:25:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ziniu Hu, Student Researcher, and Alireza Fathi, Research Scientist, Google Research, Perception Team





Large-scale models, such as T5, GPT-3, PaLM, Flamingo and PaLI, have demonstrated the ability to store substantial amounts of knowledge when scaled to tens of billions of parameters and trained on large text and image datasets. These models achieve state-of-the-art results on downstream tasks, such as image captioning, visual question answering and open vocabulary recognition. Despite such achievements, these models require a massive volume of data for training and end up with a tremendous number of parameters (billions in many cases), resulting in significant computational requirements. Moreover, the data used to train these models can become outdated, requiring re-training‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multilingual TV series]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58835</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58835&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=multilingual-tv-series"/>
        <updated>2023-06-01T15:13:03.000Z</updated>
        <summary type="html"><![CDATA[Coby Lubliner called my attention to the Belgian Netflix series "Rough Diamonds." It takes place in Antwerp, so the default language is Dutch (Flemish), but the characters move into Yiddish, English¬†and French with the greatest of ease. The subtitles don't indicate the language spoken in any one scene, except that when [Yiddish] appears what is [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Wordectomy"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58838</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58838&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=wordectomy"/>
        <updated>2023-06-01T13:37:16.000Z</updated>
        <summary type="html"><![CDATA[The medical news site MedPage Today¬†has recently added a daily game page, "Wordectomy", in which a medically-relevant Wikipedia article is presented with all letters blanked out except for punctuation and (some) function words, e.g. The instructions: Welcome to Wordectomy ‚Äî a word game from MedPage Today where you try to determine what medical condition is [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low-rank extended Kalman filtering for online learning of neural
  networks from streaming data]]></title>
        <id>http://arxiv.org/abs/2305.19535</id>
        <link href="http://arxiv.org/abs/2305.19535"/>
        <updated>2023-06-01T07:14:05.921Z</updated>
        <summary type="html"><![CDATA[Peter Chang, Gerardo Dur\`an-Mart\'in, Alexander Y Shestopaloff, Matt
  Jones, Kevin Murphy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Active causal structure learning with advice]]></title>
        <id>http://arxiv.org/abs/2305.19588</id>
        <link href="http://arxiv.org/abs/2305.19588"/>
        <updated>2023-06-01T07:14:05.907Z</updated>
        <summary type="html"><![CDATA[Davin Choo, Themis Gouleakis, Arnab Bhattacharyya]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Estimates for Pairwise Learning with Deep ReLU Networks]]></title>
        <id>http://arxiv.org/abs/2305.19640</id>
        <link href="http://arxiv.org/abs/2305.19640"/>
        <updated>2023-06-01T07:14:05.886Z</updated>
        <summary type="html"><![CDATA[Junyu Zhou, Shuo Huang, Han Feng, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What and How does In-Context Learning Learn? Bayesian Model Averaging,
  Parameterization, and Generalization]]></title>
        <id>http://arxiv.org/abs/2305.19420</id>
        <link href="http://arxiv.org/abs/2305.19420"/>
        <updated>2023-06-01T07:14:05.878Z</updated>
        <summary type="html"><![CDATA[Yufeng Zhang, Fengzhuo Zhang, Zhuoran Yang, Zhaoran Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine learning with tree tensor networks, CP rank constraints, and
  tensor dropout]]></title>
        <id>http://arxiv.org/abs/2305.19440</id>
        <link href="http://arxiv.org/abs/2305.19440"/>
        <updated>2023-06-01T07:14:05.872Z</updated>
        <summary type="html"><![CDATA[Hao Chen, Thomas Barthel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[the alpinist [film review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53126</id>
        <link href="https://xianblog.wordpress.com/2023/06/01/the-alpinist-film-review/"/>
        <updated>2023-05-31T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[Watched (with supplementary oxygen) The Alpinist in the plane to Jeddah. It is a documentary (made by the same filmmakers who filmed the Dawn Wall) about the amazing Canadian alpinist Marc-Andr√© Leclerc, who died in 2018 on the Mendenhall Glacier, Alaska, in an avalanche, after achieving extraordinary complex solo climbs as eg on Mount Robbson, [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Questions and Concerns About Google‚Äôs Quantum Supremacy Claim]]></title>
        <id>http://gilkalai.wordpress.com/?p=24142</id>
        <link href="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/"/>
        <updated>2023-05-31T17:36:59.000Z</updated>
        <summary type="html"><![CDATA[Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.¬† Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Questions and Concerns About Google‚Äôs Quantum Supremacy Claim]]></title>
        <id>http://gilkalai.wordpress.com/?p=24142</id>
        <link href="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/"/>
        <updated>2023-05-31T17:36:59.000Z</updated>
        <summary type="html"><![CDATA[Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.¬† Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large sequence models for software development activities]]></title>
        <id>http://ai.googleblog.com/2023/05/large-sequence-models-for-software.html</id>
        <link href="http://ai.googleblog.com/2023/05/large-sequence-models-for-software.html"/>
        <updated>2023-05-31T17:13:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Petros Maniatis and Daniel Tarlow, Research Scientists, Google




Software isn‚Äôt created in one dramatic step. It improves bit by bit, one little step at a time ‚Äî editing, running unit tests, fixing build errors, addressing code reviews, editing some more, appeasing linters, and fixing more errors ‚Äî until finally it becomes good enough to merge into a code repository. Software engineering isn‚Äôt an isolated process, but a dialogue among human developers, code reviewers, bug reporters, software architects and tools, such as compilers, unit tests, linters and static analyzers. 




Today we describe DIDACT (‚Äã‚ÄãDynamic Integrated Developer ACTivity), which is a methodology for training large machine learning (ML) models for software development. The novelty of DIDACT is that it uses ‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ÂÖ≥‰∫éNBCEÊñπÊ≥ïÁöÑ‰∏Ä‰∫õË°•ÂÖÖËØ¥ÊòéÂíåÂàÜÊûê]]></title>
        <id>https://kexue.fm/archives/9632</id>
        <link href="https://kexue.fm/archives/9632"/>
        <updated>2023-05-31T07:38:00.000Z</updated>
        <summary type="html"><![CDATA[‰∏äÂë®Âú®„ÄäNBCEÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÊâ©Â±ïLLMÁöÑContextÂ§ÑÁêÜÈïøÂ∫¶„Äã‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊú¥Á¥†Ë¥ùÂè∂ÊñØÊù•Êâ©Â±ïLLMÁöÑContextÈïøÂ∫¶ÁöÑÊñπÊ°àNBCEÔºàNaive Bayes-based Conte...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the minimax optimality and superiority of deep neural network
  learning over sparse parameter spaces]]></title>
        <id>http://arxiv.org/abs/1905.09195</id>
        <link href="http://arxiv.org/abs/1905.09195"/>
        <updated>2023-05-31T07:13:39.538Z</updated>
        <summary type="html"><![CDATA[Satoshi Hayakawa, Taiji Suzuki]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prediction Error-based Classification for Class-Incremental Learning]]></title>
        <id>http://arxiv.org/abs/2305.18806</id>
        <link href="http://arxiv.org/abs/2305.18806"/>
        <updated>2023-05-31T07:13:39.532Z</updated>
        <summary type="html"><![CDATA[Micha{\l} Zaj\k{a}c, Tinne Tuytelaars, Gido M. van de Ven]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal Approximation Property of Hamiltonian Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.12147</id>
        <link href="http://arxiv.org/abs/2303.12147"/>
        <updated>2023-05-31T07:13:39.527Z</updated>
        <summary type="html"><![CDATA[Muhammad Zakwan, Massimiliano d'Angelo, Giancarlo Ferrari-Trecate]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Prediction with Large Language Models for Multi-Choice
  Question Answering]]></title>
        <id>http://arxiv.org/abs/2305.18404</id>
        <link href="http://arxiv.org/abs/2305.18404"/>
        <updated>2023-05-31T07:13:39.521Z</updated>
        <summary type="html"><![CDATA[Bhawesh Kumar, Charlie Lu, Gauri Gupta, Anil Palepu, David Bellamy,
  Ramesh Raskar, Andrew Beam]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generating with Confidence: Uncertainty Quantification for Black-box
  Large Language Models]]></title>
        <id>http://arxiv.org/abs/2305.19187</id>
        <link href="http://arxiv.org/abs/2305.19187"/>
        <updated>2023-05-31T07:13:39.504Z</updated>
        <summary type="html"><![CDATA[Zhen Lin, Shubhendu Trivedi, Jimeng Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[optimal importance sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53120</id>
        <link href="https://xianblog.wordpress.com/2023/05/31/optimal-importance-sampling/"/>
        <updated>2023-05-30T22:23:27.000Z</updated>
        <summary type="html"><![CDATA[In Stein Œ†-Importance Sampling, Congye Wang et al. (mostly from Newcastle, UK) build an MCMC scheme with invariant distribution Œ† targeting a distribution P, showing that the optimal solution (in terms of a discrepancy) differs from P when the chain is Stein-sampled, e..g. via kernel discrepancies. In terms of densities, the solution is the correction [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mortal Komputation: On Hinton's argument for superhuman AI.]]></title>
        <id>64724f2336605b0001f5e7fa</id>
        <link href="https://www.inference.vc/mortal-computation-hintons/"/>
        <updated>2023-05-30T13:48:52.000Z</updated>
        <summary type="html"><![CDATA[Last week in Cambridge was Hinton bonanza. He visited the university town where he was once an undergraduate in experimental psychology, and gave a series of back-to-back talks, Q&A sessions, interviews, dinners, etc. He was stopped on the street by random passers-by who recognised him from the lecture,]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The contextual lasso: Sparse linear models via deep neural networks]]></title>
        <id>http://arxiv.org/abs/2302.00878</id>
        <link href="http://arxiv.org/abs/2302.00878"/>
        <updated>2023-05-30T07:13:25.154Z</updated>
        <summary type="html"><![CDATA[Ryan Thompson, Amir Dezfouli, Robert Kohn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization Error Bounds for Deep Neural Networks Trained by SGD]]></title>
        <id>http://arxiv.org/abs/2206.03299</id>
        <link href="http://arxiv.org/abs/2206.03299"/>
        <updated>2023-05-30T07:13:24.424Z</updated>
        <summary type="html"><![CDATA[Mingze Wang, Chao Ma]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Two-Layer Neural Networks, One (Giant) Step at a Time]]></title>
        <id>http://arxiv.org/abs/2305.18270</id>
        <link href="http://arxiv.org/abs/2305.18270"/>
        <updated>2023-05-30T07:13:23.287Z</updated>
        <summary type="html"><![CDATA[Yatin Dandi, Florent Krzakala, Bruno Loureiro, Luca Pesce, Ludovic
  Stephan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Implicit Bias of Gradient Descent for Mean Squared Error Regression with
  Two-Layer Wide Neural Networks]]></title>
        <id>http://arxiv.org/abs/2006.07356</id>
        <link href="http://arxiv.org/abs/2006.07356"/>
        <updated>2023-05-30T07:13:23.096Z</updated>
        <summary type="html"><![CDATA[Hui Jin, Guido Mont\'ufar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reward Collapse in Aligning Large Language Models]]></title>
        <id>http://arxiv.org/abs/2305.17608</id>
        <link href="http://arxiv.org/abs/2305.17608"/>
        <updated>2023-05-30T07:13:22.873Z</updated>
        <summary type="html"><![CDATA[Ziang Song, Tianle Cai, Jason D. Lee, Weijie J. Su]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.]]></title>
        <id>http://gilkalai.wordpress.com/?p=23932</id>
        <link href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/"/>
        <updated>2023-05-30T05:38:33.000Z</updated>
        <summary type="html"><![CDATA[(Click to enlarge.) Plan for this post: Prologue: ‚ÄúCan we sleep soundly at night?‚Äù Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.]]></title>
        <id>http://gilkalai.wordpress.com/?p=23932</id>
        <link href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/"/>
        <updated>2023-05-30T05:38:33.000Z</updated>
        <summary type="html"><![CDATA[(Click to enlarge.) Plan for this post: Prologue: ‚ÄúCan we sleep soundly at night?‚Äù Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[reciprocal importance sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53111</id>
        <link href="https://xianblog.wordpress.com/2023/05/30/reciprocal-importance-sampling/"/>
        <updated>2023-05-29T22:23:39.000Z</updated>
        <summary type="html"><![CDATA[In a recent arXival, Metodiev et al. (including my friend Adrian Raftery, who is spending the academic year in Paris) proposed a new version of reciprocal importance sampling, expanding the proposal we made with Darren Wraith (2009) of using a Uniform over an HPD region. It is called THAMES, hence the picture (of London, not [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Manifold Regularization for Memory-Efficient Training of Deep Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.17119</id>
        <link href="http://arxiv.org/abs/2305.17119"/>
        <updated>2023-05-29T07:14:17.605Z</updated>
        <summary type="html"><![CDATA[Shadi Sartipi, Edgar A. Bernal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vecchia Gaussian Process Ensembles on Internal Representations of Deep
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.17063</id>
        <link href="http://arxiv.org/abs/2305.17063"/>
        <updated>2023-05-29T07:14:17.597Z</updated>
        <summary type="html"><![CDATA[Felix Jimenez, Matthias Katzfuss]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Language Models as Tool Makers]]></title>
        <id>http://arxiv.org/abs/2305.17126</id>
        <link href="http://arxiv.org/abs/2305.17126"/>
        <updated>2023-05-29T07:14:16.379Z</updated>
        <summary type="html"><![CDATA[Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Influence of Learning Rule on Representation Dynamics in Wide Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2210.02157</id>
        <link href="http://arxiv.org/abs/2210.02157"/>
        <updated>2023-05-29T07:14:16.372Z</updated>
        <summary type="html"><![CDATA[Blake Bordelon, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Architecture Search for Parameter-Efficient Fine-tuning of Large
  Pre-trained Language Models]]></title>
        <id>http://arxiv.org/abs/2305.16597</id>
        <link href="http://arxiv.org/abs/2305.16597"/>
        <updated>2023-05-29T07:14:16.356Z</updated>
        <summary type="html"><![CDATA[Neal Lawton, Anoop Kumar, Govind Thattai, Aram Galstyan, Greg Ver
  Steeg]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Model-Based Clustering, Classification, and Density Estimation Using mclust in R [not a book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53104</id>
        <link href="https://xianblog.wordpress.com/2023/05/29/model-based-clustering-classification-and-density-estimation-using-mclust-in-r-not-a-book-review/"/>
        <updated>2023-05-28T22:23:16.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Vatnik" ‚Äî ethnic or political slur?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58816</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58816&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=vatnik-ethnic-or-political-slur"/>
        <updated>2023-05-28T13:31:58.000Z</updated>
        <summary type="html"><![CDATA[Adam Taylor, Anastacia Galouchka & Heidi Levine, "Ukrainians fighting outside Bakhmut see Russian mercenaries withdrawing", Washington Post 5/282023: ‚ÄúThe Wagner guys have left and the [regular Russians] have come in,‚Äù said a 26-year-old commander who asked to be identified by his call sign, Chichen. He used an anti-Russian ethnic slur to refer to the troops [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chickee cakes]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58803</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58803&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chickee-cakes"/>
        <updated>2023-05-28T03:27:05.000Z</updated>
        <summary type="html"><![CDATA[Taken at a restaurant in¬†Hangzhou: The big Chinese characters say: Cant. gai1zai2 beng2¬† MSM¬† jƒ´z«éi b«êng È∏°‰ªîÈ•º "phoenix cookie" This is a type of chewy biscuit made with lard, originating in¬†Guangzhou¬†/ Canton.¬† (source)¬† Its original name was¬†Cant. siu2fung6¬†beng2¬†¬†MSM¬†xi«éof√®ng b«êng¬†Â∞èÈ≥≥È§Ö¬†("little phoenix cake"). Here are some¬†recipes for "phoenix cookies".¬† I noticed plenty of fat and sesame, peanuts, [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Natural nested sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53091</id>
        <link href="https://xianblog.wordpress.com/2023/05/28/natural-nested-sampling/"/>
        <updated>2023-05-27T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[‚ÄúThe nested sampling algorithm solves otherwise challenging, high-dimensional integrals by evolving a collection of live points through parameter space. The algorithm was immediately adopted in cosmology because it partially overcomes three of the major difficulties in Markov chain Monte Carlo, the algorithm traditionally used for Bayesian computation. Nested sampling simultaneously returns results for model comparison [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[on control variates]]></title>
        <id>http://xianblog.wordpress.com/?p=52378</id>
        <link href="https://xianblog.wordpress.com/2023/05/27/on-control-variates/"/>
        <updated>2023-05-26T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[A few months ago, I had to write a thesis evaluation of R√©mi Leluc‚Äôs PhD, which contained several novel Monte Carlo proposals on control variates and importance techniques. For instance, Leluc et al. (Statistics and Computing, 2021) revisits the concept of control variables by adding a perspective of control variable selection using LASSO. This prior [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Foundation models for reasoning on charts]]></title>
        <id>http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html</id>
        <link href="http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html"/>
        <updated>2023-05-26T19:08:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Julian Eisenschlos, Research Software Engineer, Google Research





Visual language is the form of communication that relies on pictorial symbols outside of text to convey information. It is ubiquitous in our digital life in the form of iconography, infographics, tables, plots, and charts, extending to the real world in street signs, comic books, food labels, etc. For that reason, having computers better understand this type of media can help with scientific communication and discovery, accessibility, and data transparency.
 

While computer vision models have made tremendous progress using learning-based solutions since the advent of ImageNet, the focus has been on natural images, where all sorts of tasks, such as classification, visual question answering (VQA), captioning, det‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Barkour: Benchmarking animal-level agility with quadruped robots]]></title>
        <id>http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html</id>
        <link href="http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html"/>
        <updated>2023-05-26T16:58:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ken Caluwaerts and Atil Iscen, Research Scientists, Google





Creating robots that exhibit robust and dynamic locomotion capabilities, similar to animals or humans, has been a long-standing goal in the robotics community. In addition to completing tasks quickly and efficiently, agility allows legged robots to move through complex environments that are otherwise difficult to traverse. Researchers at Google have been pursuing agility for multiple years and across various form factors. Yet, while researchers have enabled robots to hike or jump over some obstacles, there is still no generally accepted benchmark that comprehensively measures robot agility or mobility. In contrast, benchmarks are driving forces behind the development of machine learning, such as ImageNet for computer‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Insults, oaths, and curses in the Middle Ages]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58791</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58791&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=insults-oaths-and-curses-in-the-middle-ages"/>
        <updated>2023-05-26T12:37:34.000Z</updated>
        <summary type="html"><![CDATA[From Medievalists.net: "By God‚Äôs Bones: Medieval Swear Words" What were bad words in the Middle Ages? Cursing or swearing in medieval England was really different from today‚Äôs world. May, 2023 The post begins: Some historians have looked into the topic, such as Melissa Mohr, the author of¬†Holy Sh*t: A Brief History of Swearing. In her [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A theory of representation learning gives a deep generalisation of
  kernel methods]]></title>
        <id>http://arxiv.org/abs/2108.13097</id>
        <link href="http://arxiv.org/abs/2108.13097"/>
        <updated>2023-05-26T02:32:49.402Z</updated>
        <summary type="html"><![CDATA[Adam X. Yang, Maxime Robeyns, Edward Milsom, Ben Anson, Nandi Schoots,
  Laurence Aitchison]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment]]></title>
        <id>http://arxiv.org/abs/2304.06767</id>
        <link href="http://arxiv.org/abs/2304.06767"/>
        <updated>2023-05-26T02:32:49.394Z</updated>
        <summary type="html"><![CDATA[Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng
  Zhang, Kashun Shum, Tong Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Theoretical Guarantees of Learning Ensembling Strategies with
  Applications to Time Series Forecasting]]></title>
        <id>http://arxiv.org/abs/2305.15786</id>
        <link href="http://arxiv.org/abs/2305.15786"/>
        <updated>2023-05-26T02:32:49.374Z</updated>
        <summary type="html"><![CDATA[Hilaf Hasson, Danielle C. Maddix, Yuyang Wang, Gaurav Gupta, Youngsuk
  Park]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memory-Based Meta-Learning on Non-Stationary Distributions]]></title>
        <id>http://arxiv.org/abs/2302.03067</id>
        <link href="http://arxiv.org/abs/2302.03067"/>
        <updated>2023-05-26T02:32:49.365Z</updated>
        <summary type="html"><![CDATA[Tim Genewein, Gr\'egoire Del\'etang, Anian Ruoss, Li Kevin Wenliang,
  Elliot Catt, Vincent Dutordoir, Jordi Grau-Moya, Laurent Orseau, Marcus
  Hutter, Joel Veness]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Neural Network Layers Promote Learning Single- and Multiple-Index
  Models]]></title>
        <id>http://arxiv.org/abs/2305.15598</id>
        <link href="http://arxiv.org/abs/2305.15598"/>
        <updated>2023-05-26T02:32:49.357Z</updated>
        <summary type="html"><![CDATA[Suzanna Parkinson, Greg Ongie, Rebecca Willett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially private clustering for large-scale datasets]]></title>
        <id>http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html</id>
        <link href="http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html"/>
        <updated>2023-05-25T23:09:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Vincent Cohen-Addad and  Alessandro Epasto, Research Scientists, Google Research, Graph Mining team




Clustering is a central problem in unsupervised machine learning (ML) with many applications across domains in both industry and academic research more broadly. At its core, clustering consists of the following problem: given a set of data elements, the goal is to partition the data elements into groups such that similar objects are in the same group, while dissimilar objects are in different groups. This problem has been studied in math, computer science, operations research and statistics for more than 60 years in its myriad variants. Two common forms of clustering are metric clustering, in which the elements are points in a metric space, like in the k-means problem, and grap‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EMS 2023, Warsaw]]></title>
        <id>http://xianblog.wordpress.com/?p=53085</id>
        <link href="https://xianblog.wordpress.com/2023/05/26/ems-2023-warsaw/"/>
        <updated>2023-05-25T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google Research at I/O 2023]]></title>
        <id>http://ai.googleblog.com/2023/05/google-research-at-io-2023.html</id>
        <link href="http://ai.googleblog.com/2023/05/google-research-at-io-2023.html"/>
        <updated>2023-05-25T17:03:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by James Manyika, SVP Google Research and Technology & Society, and Jeff Dean, Chief Scientist, Google DeepMind and Google Research




Wednesday, May 10th was an exciting day for the Google Research community as we watched the results of months and years of our foundational and applied work get announced on the Google I/O stage. With the quick pace of announcements on stage, it can be difficult to convey the substantial effort and unique innovations that underlie the technologies we presented. So today, we‚Äôre excited to reveal more about the research efforts behind some of the many exciting announcements at this year's I/O. 


 

PaLM 2 
PaLM 2, is built on advances in compute-optimal scaling, scaled instruction-fine tuning and improved dataset mixture. By fine-tuning and instructi‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Failure to Launch"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58795</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58795&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=failure-to-launch"/>
        <updated>2023-05-25T12:19:56.000Z</updated>
        <summary type="html"><![CDATA[Along with half a million other people, I logged onto Twitter at the designated hour to hear Elon Musk help Ron DeSantis announce his run for U.S. President. After about half an hour of¬† noises, silences, and puzzling graphics, I gave up ‚Äî too early to catch the restart on a different account. This event [‚Ä¶]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Master the essence of solid"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58775</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58775&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=master-the-essence-of-solid"/>
        <updated>2023-05-25T08:48:28.000Z</updated>
        <summary type="html"><![CDATA[From the website for Royal China Group, a famous Chinese restaurant group in London: The problem begins at the beginning:¬† jingcui¬†Á≤æÁ≤π does not mean "master"; it means "essence". The entire text reads as follows: Zh≈çnggu√≥ y«ênsh√≠ w√©nhu√† b√≥d√†jƒ´ngshƒìn,Hu√°ngch√°o n«îl√¨ b√πxi√® y√°nsh«íu zh√®ngz≈çng chu√°nt«íng Yu√®c√†i de fƒìngg√©,b√¨ng z√†i w√®iju√© de l«êngy√π zh≈çng x√∫nqi√∫ t√∫p√≤,zh«éngw√≤ g√πzh≈çng jƒ´ngcu√¨ [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test your intuition 52: Can you predict the ratios of ones?]]></title>
        <id>http://gilkalai.wordpress.com/?p=24359</id>
        <link href="https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/"/>
        <updated>2023-05-25T08:33:58.000Z</updated>
        <summary type="html"><![CDATA[Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice‚Äôs task is to choose, at a certain time of her choice, some number (smaller than the number of unseen ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test your intuition 52: Can you predict the ratios of ones?]]></title>
        <id>http://gilkalai.wordpress.com/?p=24359</id>
        <link href="https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/"/>
        <updated>2023-05-25T08:33:58.000Z</updated>
        <summary type="html"><![CDATA[Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice‚Äôs task is to choose, at a certain time of her choice, some number (smaller than the number of unseen ‚Ä¶ Continue reading ‚Üí]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning for Survival Analysis: A Review]]></title>
        <id>http://arxiv.org/abs/2305.14961</id>
        <link href="http://arxiv.org/abs/2305.14961"/>
        <updated>2023-05-25T07:13:51.339Z</updated>
        <summary type="html"><![CDATA[Simon Wiegrebe, Philipp Kopper, Raphael Sonabend, Andreas Bender]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Masked Bayesian Neural Networks : Theoretical Guarantee and its
  Posterior Inference]]></title>
        <id>http://arxiv.org/abs/2305.14765</id>
        <link href="http://arxiv.org/abs/2305.14765"/>
        <updated>2023-05-25T07:13:51.311Z</updated>
        <summary type="html"><![CDATA[Insung Kong, Dongyoon Yang, Jongjin Lee, Ilsang Ohn, Gyuseung Baek,
  Yongdai Kim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Rate Free Bayesian Inference in Constrained Domains]]></title>
        <id>http://arxiv.org/abs/2305.14943</id>
        <link href="http://arxiv.org/abs/2305.14943"/>
        <updated>2023-05-25T07:13:51.252Z</updated>
        <summary type="html"><![CDATA[Louis Sharrock, Lester Mackey, Christopher Nemeth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Rigorous Link between Deep Ensembles and (Variational) Bayesian
  Methods]]></title>
        <id>http://arxiv.org/abs/2305.15027</id>
        <link href="http://arxiv.org/abs/2305.15027"/>
        <updated>2023-05-25T07:13:50.477Z</updated>
        <summary type="html"><![CDATA[Veit David Wild, Sahra Ghalebikesabi, Dino Sejdinovic, Jeremias
  Knoblauch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test like you Train in Implicit Deep Learning]]></title>
        <id>http://arxiv.org/abs/2305.15042</id>
        <link href="http://arxiv.org/abs/2305.15042"/>
        <updated>2023-05-25T07:13:50.461Z</updated>
        <summary type="html"><![CDATA[Zaccharie Ramzi, Pierre Ablin, Gabriel Peyr\'e, Thomas Moreau]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An early warning system for novel AI risks]]></title>
        <id>https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks</id>
        <link href="https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks"/>
        <updated>2023-05-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[AI researchers already use a range of evaluation benchmarks to identify unwanted behaviours in AI systems, such as AI systems making misleading statements, biased decisions, or repeating copyrighted content. Now, as the AI community builds and deploys increasingly powerful AI, we must expand the evaluation portfolio to include the possibility of extreme risks from general-purpose AI models that have strong skills in manipulation, deception, cyber-offense, or other dangerous capabilities.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stochastic Numerics and Statistical Learning]]></title>
        <id>http://xianblog.wordpress.com/?p=53075</id>
        <link href="https://xianblog.wordpress.com/2023/05/25/stochastic-numerics-and-statistical-learning/"/>
        <updated>2023-05-24T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[This week, I am taking part in the Stochastic Numerics and Statistical Learning workshop, in KAUST, which should prove an interesting experience!]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Decipherment of Linear A]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58786</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58786&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=decipherment-of-linear-a"/>
        <updated>2023-05-24T11:14:27.000Z</updated>
        <summary type="html"><![CDATA[Methodologically, the following communication from Elizabeth J. W. Barber is too important to be left buried in a comment to this post:¬† "ChatGPT does cuneiform studies" (5/21/23) As I showed in my 1974 book, Archaeological Decipherment, there is a mathematical algorithm showing how much text one needs to PROVABLY accomplish a decipherment for what sort [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mind the spikes: Benign overfitting of kernels and neural networks in
  fixed dimension]]></title>
        <id>http://arxiv.org/abs/2305.14077</id>
        <link href="http://arxiv.org/abs/2305.14077"/>
        <updated>2023-05-24T07:13:44.399Z</updated>
        <summary type="html"><![CDATA[Moritz Haas, David Holzm\"uller, Ulrike von Luxburg, Ingo Steinwart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The CoT Collection: Improving Zero-shot and Few-shot Learning of
  Language Models via Chain-of-Thought Fine-Tuning]]></title>
        <id>http://arxiv.org/abs/2305.14045</id>
        <link href="http://arxiv.org/abs/2305.14045"/>
        <updated>2023-05-24T07:13:44.392Z</updated>
        <summary type="html"><![CDATA[Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye,
  Jamin Shin, Minjoon Seo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding]]></title>
        <id>http://arxiv.org/abs/2305.14196</id>
        <link href="http://arxiv.org/abs/2305.14196"/>
        <updated>2023-05-24T07:13:44.382Z</updated>
        <summary type="html"><![CDATA[Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, Omer
  Levy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning with Kernels through RKHM and the Perron-Frobenius
  Operator]]></title>
        <id>http://arxiv.org/abs/2305.13588</id>
        <link href="http://arxiv.org/abs/2305.13588"/>
        <updated>2023-05-24T07:13:44.376Z</updated>
        <summary type="html"><![CDATA[Yuka Hashimoto, Masahiro Ikeda, Hachem Kadri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transferring Learning Trajectories of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.14122</id>
        <link href="http://arxiv.org/abs/2305.14122"/>
        <updated>2023-05-24T07:13:44.370Z</updated>
        <summary type="html"><![CDATA[Daiki Chijiwa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Choosing a good file format for Pandas]]></title>
        <id>https://pythonspeed.com/articles/best-file-format-for-pandas/</id>
        <link href="https://pythonspeed.com/articles/best-file-format-for-pandas/"/>
        <updated>2023-05-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Before you can process your data with Pandas, you need to load it (from disk or remote storage).
There are plenty of data formats supported by Pandas, from CSV, to JSON, to Parquet, and many others as well.
Which should you use?
You don‚Äôt want loading the data to be slow, or use lots of memory: that‚Äôs pure overhead.
Ideally you‚Äôd want a file format that‚Äôs fast, efficient, small, and broadly supported.
You also want to make sure the loaded data has all the right types: numeric types, datetimes, and so on.
Some data formats do a better job at this than others.
While there is no one true answer that works for everyone, this article will try to help you narrow down the field and make an informed decision.
Read more...]]></summary>
        <author>
            <name>Python‚áíSpeed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[art brut]]></title>
        <id>http://xianblog.wordpress.com/?p=53022</id>
        <link href="https://xianblog.wordpress.com/2023/05/24/art-brut-90/"/>
        <updated>2023-05-23T22:23:05.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resolving code review comments with ML]]></title>
        <id>http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html</id>
        <link href="http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html"/>
        <updated>2023-05-23T17:51:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Alexander Fr√∂mmgen, Staff Software Engineer, and Lera Kharatyan, Senior Software Engineer, Core Systems & Experiences


  

Code-change reviews are a critical part of the software development process at scale, taking a significant amount of the code authors‚Äô and the code reviewers‚Äô time. As part of this process, the reviewer inspects the proposed code and asks the author for code changes through comments written in natural language. At Google, we see millions of reviewer comments per year, and authors require an average of ~60 minutes active shepherding time between sending changes for review and finally submitting the change. In our measurements, the required active work time that the code author must do to address reviewer comments grows almost linearly with the number of comme‚Ä¶]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPT-4 + Stable-Diffusion = ?: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models]]></title>
        <id>http://bair.berkeley.edu/blog/2023/05/23/lmd/</id>
        <link href="http://bair.berkeley.edu/blog/2023/05/23/lmd/"/>
        <updated>2023-05-23T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[TL;DR: Text Prompt -> LLM -> Intermediate Representation (such as an image layout) -> Stable Diffusion -> Image.
Recent advancements in text-to-image generation with diffusion models have yielded remarkable results synthesizing highly realistic and diverse images. However, despite their impressive capabilities, diffusion models, such as Stable Diffusion, often struggle to accurately follow the prompts when spatial or common sense reasoning is required.
The following figure lists four scenarios in which Stable Diffusion falls short in generating images that accurately correspond to the given prompts, namely negation, numeracy, and attribute assignment, spatial relationships. In contrast, our method, LLM-grounded Diffusion (LMD), delivers much better prompt understanding in text-to-image gen‚Ä¶]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yann LeCun - Towards Machines that can Learn, Reason, and Plan.]]></title>
        <id>https://mlfoundations.org/talk/lecun/</id>
        <link href="https://mlfoundations.org/talk/lecun/"/>
        <updated>2023-05-23T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[How could machines learn as efficiently as humans and animals? How could machines learn how the world works and acquire common sense? How could machines learn to reason and plan? Current AI architectures, such as Auto-Regressive Large Language Models fall short.  I will propose a modular cognitive architecture that may constitute a path towards answering these questions.  The centerpiece of the architecture is a predictive world model that allows the system to predict the consequences of its actions and to plan a sequence of actions that optimize a set of objectives. The world model employs a Hierarchical Joint Embedding Predictive Architecture (H-JEPA) trained with self-supervised learning. The JEPA learns abstract representations of the percepts that are simultaneously maximally informative and maximally predictable. The corresponding working paper is available here - [A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chinese characters and the messiness of Chinese culture]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58781</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58781&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chinese-characters-and-the-messiness-of-chinese-culture"/>
        <updated>2023-05-23T10:57:23.000Z</updated>
        <summary type="html"><![CDATA[Is it really so? Uncannily and independently, Apollo Wu* sent me the following note before I made this post: H√†nz√¨ b√πr√∫ pƒ´nyƒ´n de guƒÅnji√†n l«êngy√π sh√¨ p√°ix√π, ji«énsu«í h√© r√©ng≈çng zh√¨n√©ng. F√πz√°, f√°nsu«í, n√°n xu√© n√°n y√≤ng sh√¨ w«ímen m√πqi√°n mi√†nl√≠n de k√πnn√°n. H√†nz√¨ de lu√†n, biƒÅozh√¨zhe Zh≈çnggu√≥ w√©nhu√† de lu√†n! Ê±âÂ≠ó ÊØî‰∏ç‰∏ä Â≠óÊØçÊñáÂ≠ó ÁöÑ [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memorization and Optimization in Deep Neural Networks with Minimum
  Over-parameterization]]></title>
        <id>http://arxiv.org/abs/2205.10217</id>
        <link href="http://arxiv.org/abs/2205.10217"/>
        <updated>2023-05-23T07:13:42.300Z</updated>
        <summary type="html"><![CDATA[Simone Bombari, Mohammad Hossein Amani, Marco Mondelli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Discriminative to Kernel Generative Networks for Calibrated
  Inference]]></title>
        <id>http://arxiv.org/abs/2201.13001</id>
        <link href="http://arxiv.org/abs/2201.13001"/>
        <updated>2023-05-23T07:13:42.293Z</updated>
        <summary type="html"><![CDATA[Jayanta Dey, Haoyin Xu, Ashwin De Silva, Will LeVine, Tyler M. Tomita,
  Ali Geisa, Tiffany Chu, Jacob Desman, Joshua T. Vogelstein]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Counterfactual Explanations for Neural Networks With
  Probabilistic Guarantees]]></title>
        <id>http://arxiv.org/abs/2305.11997</id>
        <link href="http://arxiv.org/abs/2305.11997"/>
        <updated>2023-05-23T07:13:42.269Z</updated>
        <summary type="html"><![CDATA[Faisal Hamman, Erfaun Noorani, Saumitra Mishra, Daniele Magazzeni,
  Sanghamitra Dutta]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Not All Semantics are Created Equal: Contrastive Self-supervised
  Learning with Automatic Temperature Individualization]]></title>
        <id>http://arxiv.org/abs/2305.11965</id>
        <link href="http://arxiv.org/abs/2305.11965"/>
        <updated>2023-05-23T07:13:42.257Z</updated>
        <summary type="html"><![CDATA[Zi-Hao Qiu, Quanqi Hu, Zhuoning Yuan, Denny Zhou, Lijun Zhang, Tianbao
  Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive and Robust Multi-Task Learning]]></title>
        <id>http://arxiv.org/abs/2202.05250</id>
        <link href="http://arxiv.org/abs/2202.05250"/>
        <updated>2023-05-23T07:13:42.204Z</updated>
        <summary type="html"><![CDATA[Yaqi Duan, Kaizheng Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NBCEÔºö‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÊãìÂ±ïLLMÁöÑContextÂ§ÑÁêÜÈïøÂ∫¶]]></title>
        <id>https://kexue.fm/archives/9617</id>
        <link href="https://kexue.fm/archives/9617"/>
        <updated>2023-05-23T02:45:00.000Z</updated>
        <summary type="html"><![CDATA[Âú®LLMÊó∂‰ª£ËøòÁé©Êú¥Á¥†Ë¥ùÂè∂ÊñØÔºàNaive BayesÔºâÔºüËøôÂèØËÉΩÊòØËÆ∏Â§öËØªËÄÖÂú®ÁúãÂà∞Ê†áÈ¢òÂêéÁöÑÈ¶ñ‰∏™ÊÉ≥Ê≥ï„ÄÇÁ°ÆÂÆûÂ¶ÇÊ≠§ÔºåÂΩìÂè§ËÄÅÁöÑÊú¥Á¥†Ë¥ùÂè∂ÊñØ‰∏éÂâçÊ≤øÁöÑLLMÁõ∏ÈÅáÊó∂Ôºå‰∫ßÁîü‰∫Ü‰ª§‰∫∫ÊÉäËÆ∂ÁöÑÊïàÊûú‚Äî‚ÄîÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•ÊèêÂçáÁé∞ÊúâLLM...]]></summary>
        <author>
            <name>ËãèÂâëÊûó</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bernoulli factory on a budget]]></title>
        <id>http://xianblog.wordpress.com/?p=53038</id>
        <link href="https://xianblog.wordpress.com/2023/05/23/bernoulli-factory-on-a-budget/"/>
        <updated>2023-05-22T22:23:22.000Z</updated>
        <summary type="html"><![CDATA[A form of Bernoulli factory with limited energy from The Riddler: being given the choice of 0<p<1, what is the minimal number n of throws such that the outcomes of n iid B(p) draws can be partitioned into six groups of equal probability? Running a brute force R code [in the train to Cambridge] and [‚Ä¶]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning sinitic and sinoglyphic "zero"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58778</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58778&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=learning-sinitic-and-sinoglyphic-zero"/>
        <updated>2023-05-22T12:00:04.000Z</updated>
        <summary type="html"><![CDATA[Plus Indic, plus Arabic, Korean, Vietnamese, Hokkien (Taiwanese), Hakka, and Fuzhou (Eastern Min). For an exciting read / ride, be sure to follow the whole thread, travelling through time and space. Èõ∂ originally didn't mean 'zero,' but 'small rain, drizzle.' Makes it easy to learn: Rain Èõ® above, pronunciation ‰ª§ below (ok, tone is different). [‚Ä¶]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-Shot Continual Learning for Conditional Generative Adversarial
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.11400</id>
        <link href="http://arxiv.org/abs/2305.11400"/>
        <updated>2023-05-22T08:19:27.936Z</updated>
        <summary type="html"><![CDATA[Cat P. Le, Juncheng Dong, Ahmed Aloui, Vahid Tarokh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-learning for heterogeneous treatment effect estimation with
  closed-form solvers]]></title>
        <id>http://arxiv.org/abs/2305.11353</id>
        <link href="http://arxiv.org/abs/2305.11353"/>
        <updated>2023-05-22T08:19:27.389Z</updated>
        <summary type="html"><![CDATA[Tomoharu Iwata, Yoichi Chikahara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Real-Time Variational Method for Learning Neural Trajectory and its
  Dynamics]]></title>
        <id>http://arxiv.org/abs/2305.11278</id>
        <link href="http://arxiv.org/abs/2305.11278"/>
        <updated>2023-05-22T08:19:27.383Z</updated>
        <summary type="html"><![CDATA[Matthew Dowling, Yuan Zhao, Il Memming Park]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incorporating Unlabelled Data into Bayesian Neural Networks]]></title>
        <id>http://arxiv.org/abs/2304.01762</id>
        <link href="http://arxiv.org/abs/2304.01762"/>
        <updated>2023-05-22T08:19:27.328Z</updated>
        <summary type="html"><![CDATA[Mrinank Sharma, Tom Rainforth, Yee Whye Teh, Vincent Fortuin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Out of the box acceleration and memory savings of ü§ó decoder models with PyTorch 2.0]]></title>
        <id>https://pytorch.org/blog/out-of-the-box-acceleration/</id>
        <link href="https://pytorch.org/blog/out-of-the-box-acceleration/"/>
        <updated>2023-05-22T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[As part of PyTorch 2.0 release, an accelerated implementation of the attention mechanism as part of the ‚ÄúBetter Transformer‚Äù project (and known in PyTorch as Accelerated Transformers) has been added natively into PyTorch as torch.nn.functional.scaled_dot_product_attention. This implementation leverages fused kernels from FlashAttention and Memory-efficient attention, and supports both training and inference.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
</feed>