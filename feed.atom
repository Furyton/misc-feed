<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-09-08T21:12:46.753Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[Tom Goldstein - Dataset security issues in generative AI]]></title>
        <id>https://mlfoundations.org/talk/tom/</id>
        <link href="https://mlfoundations.org/talk/tom/"/>
        <updated>2023-09-08T14:15:00.000Z</updated>
        <summary type="html"><![CDATA[Machine learning systems are built using large troves of training data that may contain private or copyrighted content. In this talk, I'll survey a number of security issues that arise when sensitive data is used. I'll begin by talking about attack methods that extract private training data from federated learning protocols. Then, I'll discuss data privacy issues that arise when using generative models. These models are often created using a training objective that explicitly promotes their ability to regenerate their training data, causing a host of issues.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Black Hand:  Language Log foretells the future]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60519</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60519&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=black-hand-language-log-foretells-the-future"/>
        <updated>2023-09-08T11:43:48.000Z</updated>
        <summary type="html"><![CDATA[From Brian Miller: I believe it was your comment here on a 2019 use of a phrase in China politics or press “Thus my second surmise was that, by 'black hand', the CCP / PRC mean 'stealthy manipulator who remains totally out of view'.  But how does it get that meaning in Chinese?” I think […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Metric Learning with Chance Constraints]]></title>
        <id>http://arxiv.org/abs/2209.09060</id>
        <link href="http://arxiv.org/abs/2209.09060"/>
        <updated>2023-09-08T02:20:06.402Z</updated>
        <summary type="html"><![CDATA[Yeti Z. Gurbuz, Ogul Can, A. Aydin Alatan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and
  Luck]]></title>
        <id>http://arxiv.org/abs/2309.03800</id>
        <link href="http://arxiv.org/abs/2309.03800"/>
        <updated>2023-09-08T02:20:06.095Z</updated>
        <summary type="html"><![CDATA[Benjamin L. Edelman, Surbhi Goel, Sham Kakade, Eran Malach, Cyril
  Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural lasso: a unifying approach of lasso and neural networks]]></title>
        <id>http://arxiv.org/abs/2309.03770</id>
        <link href="http://arxiv.org/abs/2309.03770"/>
        <updated>2023-09-08T02:20:06.089Z</updated>
        <summary type="html"><![CDATA[David Delgado, Ernesto Curbelo, Danae Carreras]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enhancing Pipeline-Based Conversational Agents with Large Language
  Models]]></title>
        <id>http://arxiv.org/abs/2309.03748</id>
        <link href="http://arxiv.org/abs/2309.03748"/>
        <updated>2023-09-08T02:20:04.935Z</updated>
        <summary type="html"><![CDATA[Mina Foosherian, Hendrik Purwins, Purna Rathnayake, Touhidul Alam, Rui
  Teimao, Klaus-Dieter Thoben]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adversarially Robust Deep Learning with Optimal-Transport-Regularized
  Divergences]]></title>
        <id>http://arxiv.org/abs/2309.03791</id>
        <link href="http://arxiv.org/abs/2309.03791"/>
        <updated>2023-09-08T02:20:04.929Z</updated>
        <summary type="html"><![CDATA[Jeremiah Birrell, Mohammadreza Ebrahimi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[back to horizon]]></title>
        <id>http://xianblog.wordpress.com/?p=54001</id>
        <link href="https://xianblog.wordpress.com/2023/09/08/back-to-horizon/"/>
        <updated>2023-09-07T22:23:22.000Z</updated>
        <summary type="html"><![CDATA[“[the UK rejoining Horizon Europe programme is] fantastic news not just for the UK but for scientists across the EU and for all the people of Europe”. Sir Adrian Smith, president of the Royal Society The EU and the UK Government have come to an agreement on the UK rejoining the Horizon Europe funding programme […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A novel computational fluid dynamics framework for turbulent flow research]]></title>
        <id>http://blog.research.google/2023/09/a-novel-computational-fluid-dynamics.html</id>
        <link href="http://blog.research.google/2023/09/a-novel-computational-fluid-dynamics.html"/>
        <updated>2023-09-07T22:03:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Shantanu Shahane, Software Engineer, and Matthias Ihme, Research Scientist, Athena Team




Turbulence is ubiquitous in environmental and engineering fluid flows, and is encountered routinely in everyday life. A better understanding of these turbulent processes could provide valuable insights across a variety of research areas — improving the prediction of cloud formation by atmospheric transport and the spreading of wildfires by turbulent energy exchange, understanding sedimentation of deposits in rivers, and improving the efficiency of combustion in aircraft engines to reduce emissions, to name a few. However, despite its importance, our current understanding and our ability to reliably predict such flows remains limited. This is mainly attributed to the highly chaotic nature a…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Using Traits]]></title>
        <id>https://jeremykun.com/?p=119774</id>
        <link href="https://jeremykun.com/2023/09/07/mlir-using-traits/"/>
        <updated>2023-09-07T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents Last time we defined a new dialect poly for polynomial arithmetic. This time we’ll spruce up the dialect by adding some pre-defined MLIR traits, and see how the application of traits enables some general purpose passes to optimize poly programs. The code for this article is in this pull request, and as […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On-the-job jargon]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60516</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60516&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=on-the-job-jargon"/>
        <updated>2023-09-07T12:11:31.000Z</updated>
        <summary type="html"><![CDATA[There seem to be a lot of people complaining about it these days, so maybe there's something to worry about here.  Francois Lang, who called this current wave of criticism to my attention asks whether academia is isolated from such horrors. FWIW, here's what it's like in business: "A look at the most annoying workplace […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BytePiece：更纯粹、更高压缩率的Tokenizer]]></title>
        <id>https://kexue.fm/archives/9752</id>
        <link href="https://kexue.fm/archives/9752"/>
        <updated>2023-09-07T07:05:00.000Z</updated>
        <summary type="html"><![CDATA[目前在LLM中最流行的Tokenizer（分词器）应该是Google的SentencePiece了，因为它符合Tokenizer的一些理想特性，比如语言无关、数据驱动等，并且由于它是C++写的，...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Variational Models with Unrolling and Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2209.12651</id>
        <link href="http://arxiv.org/abs/2209.12651"/>
        <updated>2023-09-07T02:19:38.123Z</updated>
        <summary type="html"><![CDATA[Christoph Brauer, Niklas Breustedt, Timo de Wolff, Dirk A. Lorenz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Active Subspaces for Effective and Scalable Uncertainty
  Quantification in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2309.03061</id>
        <link href="http://arxiv.org/abs/2309.03061"/>
        <updated>2023-09-07T02:19:38.046Z</updated>
        <summary type="html"><![CDATA[Sanket Jantre, Nathan M. Urban, Xiaoning Qian, Byung-Jun Yoon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explaining the Behavior of Black-Box Prediction Algorithms with Causal
  Learning]]></title>
        <id>http://arxiv.org/abs/2006.02482</id>
        <link href="http://arxiv.org/abs/2006.02482"/>
        <updated>2023-09-07T02:19:34.348Z</updated>
        <summary type="html"><![CDATA[Numair Sani, Daniel Malinsky, Ilya Shpitser]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Topological Deep Learning Framework for Neural Spike Decoding]]></title>
        <id>http://arxiv.org/abs/2212.05037</id>
        <link href="http://arxiv.org/abs/2212.05037"/>
        <updated>2023-09-07T02:19:34.335Z</updated>
        <summary type="html"><![CDATA[Edward C. Mitchell, Brittany Story, David Boothe, Piotr J.
  Franaszczuk, Vasileios Maroulas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayes-optimal Learning of Deep Random Networks of Extensive-width]]></title>
        <id>http://arxiv.org/abs/2302.00375</id>
        <link href="http://arxiv.org/abs/2302.00375"/>
        <updated>2023-09-07T02:19:34.330Z</updated>
        <summary type="html"><![CDATA[Hugo Cui, Florent Krzakala, Lenka Zdeborov\'a]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[data science ≠ algebra ???]]></title>
        <id>http://xianblog.wordpress.com/?p=53505</id>
        <link href="https://xianblog.wordpress.com/2023/09/07/data-science-%e2%89%a0-algebra/"/>
        <updated>2023-09-06T22:23:43.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Policeman to Tesla driver:  “It Is a Bit Ridiculous, But You Must Obey”]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60508</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60508&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=policeman-to-tesla-driver-it-is-a-bit-ridiculous-but-you-must-obey"/>
        <updated>2023-09-06T21:22:15.000Z</updated>
        <summary type="html"><![CDATA[9月1日，杭州高架禁止特斯拉通行。车主吐槽“这有点搞笑了呀”交警回复“是有点搞笑但是你要服从” pic.twitter.com/z7Tm7cN1Yi — 李老师不是你老师 (@whyyoutouzhele) September 1, 2023 The text says: 9 yuè 1 rì, Hángzhōu gāojià jìnzhǐ Tèsīlā tōngxíng.Chēzhǔ tǔcáo “Zhè yǒudiǎn gǎoxiàole ya”. Jiāojǐng huífù “Shì yǒudiǎn gǎoxiào dànshì nǐ yào fúcóng. 9月1日，杭州高架禁止特斯拉通行。车主吐槽“这有点搞笑了呀”交警回复“是有点搞笑但是你要服从” On September 1, a Tesla was banned from passing through the Hangzhou Elevated Highway.The car owner complained, "This is a bit […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TSMixer: An all-MLP architecture for time series forecasting]]></title>
        <id>http://blog.research.google/2023/09/tsmixer-all-mlp-architecture-for-time.html</id>
        <link href="http://blog.research.google/2023/09/tsmixer-all-mlp-architecture-for-time.html"/>
        <updated>2023-09-06T19:47:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Si-An Chen, Student Researcher, Cloud AI Team, and Chun-Liang Li, Research Scientist, Cloud AI Team




Time series forecasting is critical to various real-world applications, from demand forecasting to pandemic spread prediction. In multivariate time series forecasting (forecasting multiple variants at the same time), one can split existing methods into two categories: univariate models and multivariate models. Univariate models focus on inter-series interactions or temporal patterns that encompass trends and seasonal patterns on a time series with a single variable. Examples of such trends and seasonal patterns might be the way mortgage rates increase due to inflation, and how traffic peaks during rush hour. In addition to inter-series patterns, multivariate models process intr…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graphcore Joins the PyTorch Foundation as a General Member]]></title>
        <id>https://pytorch.org/blog/graphcore-joins-pytorch/</id>
        <link href="https://pytorch.org/blog/graphcore-joins-pytorch/"/>
        <updated>2023-09-06T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[<div type="html"/>]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computing Percentages Easier]]></title>
        <id>https://jeremykun.com/?p=119800</id>
        <link href="https://jeremykun.com/2023/09/05/computing-percentages-easier/"/>
        <updated>2023-09-06T04:47:37.000Z</updated>
        <summary type="html"><![CDATA[Problem: Compute 16% of 25 in your head. Solution: 16% of 25 is equivalent to 25% of 16, which is clearly 4. This is true for all numbers: $x\%$ of $y$ is always equal to $y\%$ of $x$. The first one is $\frac{x}{100} y$ and the second is $\frac{y}{100}x$, and because multiplication is commutative and […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalizations of local bijectivity of Keller maps and a proof of
  $2$-dimensional Jacobian conjecture]]></title>
        <id>http://arxiv.org/abs/1603.01867</id>
        <link href="http://arxiv.org/abs/1603.01867"/>
        <updated>2023-09-06T03:14:50.079Z</updated>
        <summary type="html"><![CDATA[Yucai Su]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Margulis cusps of hyperbolic 4-manifolds]]></title>
        <id>http://arxiv.org/abs/1304.5316</id>
        <link href="http://arxiv.org/abs/1304.5316"/>
        <updated>2023-09-06T03:14:50.073Z</updated>
        <summary type="html"><![CDATA[Viveka Erlandsson, Saeed Zakeri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Pure Degree Sequence Manipulations Forcing Long Cycles in Graphs]]></title>
        <id>http://arxiv.org/abs/1711.04134</id>
        <link href="http://arxiv.org/abs/1711.04134"/>
        <updated>2023-09-06T03:14:50.061Z</updated>
        <summary type="html"><![CDATA[Zhora Nikoghosyan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A discreteness criterion for groups containing parabolic isometries]]></title>
        <id>http://arxiv.org/abs/1304.2298</id>
        <link href="http://arxiv.org/abs/1304.2298"/>
        <updated>2023-09-06T03:14:50.056Z</updated>
        <summary type="html"><![CDATA[Viveka Erlandsson, Saeed Zakeri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physical mechanisms influencing life origin and development.
  Physical-biochemical paradigm of Life]]></title>
        <id>http://arxiv.org/abs/1609.09421</id>
        <link href="http://arxiv.org/abs/1609.09421"/>
        <updated>2023-09-06T03:14:50.045Z</updated>
        <summary type="html"><![CDATA[Yuri K. Shestopaloff]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[400 bright minds]]></title>
        <id>http://xianblog.wordpress.com/?p=53996</id>
        <link href="https://xianblog.wordpress.com/2023/09/06/400-bright-minds/"/>
        <updated>2023-09-05T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[↗↘↗]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60503</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60503&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=%25e2%2586%2597%25e2%2586%2598%25e2%2586%2597"/>
        <updated>2023-09-05T21:52:54.000Z</updated>
        <summary type="html"><![CDATA[That's one of the extreme nicknames for Xi Jinping that are being used to avoid censorship.  It consists of the three tones for his name, Xí Jìnpíng 习近平. Likewise, netizens are referring to him as "2-4-2".  He is also called "N" because that reminds people of ↗↘↗.  Another emerging Xi nickname is “n-butane,” whose chemical […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automated trace collection and analysis]]></title>
        <id>https://pytorch.org/blog/automated-trace-collection/</id>
        <link href="https://pytorch.org/blog/automated-trace-collection/"/>
        <updated>2023-09-05T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[In this blog, we share how we enabled the collection and analysis of PyTorch Profiler traces for training workloads without any user side code instrumentation. We leveraged Dynolog - an open source daemon for CPU and GPU telemetry to collect PyTorch Profiler traces, and analyzed the collected traces using Holistic Trace Analysis - an open source library for analyzing PyTorch Profiler traces. This toolchain has allowed engineers at Meta to accelerate their performance optimization workflows. The keystone to our solution was implementing pre and post hooks for the base Optimizer class in PyTorch. We demo PyTorch trace collection using Dynolog in a short video.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[capture & maybe recapture]]></title>
        <id>http://xianblog.wordpress.com/?p=53568</id>
        <link href="https://xianblog.wordpress.com/2023/09/05/capture-maybe-recapture-estimation/"/>
        <updated>2023-09-04T22:23:42.000Z</updated>
        <summary type="html"><![CDATA[I read population size estimation with capture-recapture in presence of individual misidentification and low recapture arXived by Rémy Fraysse and coauthors on my flight back from Saigon. The setup is one of a capture-recapture experience where potential misidentification (of a recapture individual labelled as new) may occur due to visual identification errors as, e.g., in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tatar Journalism in Tatar]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60494</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60494&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tatar-journalism-in-tatar"/>
        <updated>2023-09-04T12:35:03.000Z</updated>
        <summary type="html"><![CDATA[Tatar Tatars "Tatar Journalists More Likely to Cover Controversial Topics When They Write or Speak in Tatar, One of Their Number Says" Paul Goble, Window on Eurasia — New Series Monday, August 28, 2023            Staunton, Aug. 28 – Tatar journalists are more likely to cover controversial topics when they write or speak in Tatar […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VDM++: Variational Diffusion Models for High-Quality Synthesis]]></title>
        <id>http://arxiv.org/abs/2303.00848</id>
        <link href="http://arxiv.org/abs/2303.00848"/>
        <updated>2023-09-04T02:20:36.085Z</updated>
        <summary type="html"><![CDATA[Diederik P. Kingma, Ruiqi Gao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge Infused Learning (K-IL): Towards Deep Incorporation of
  Knowledge in Deep Learning]]></title>
        <id>http://arxiv.org/abs/1912.00512</id>
        <link href="http://arxiv.org/abs/1912.00512"/>
        <updated>2023-09-04T02:20:36.080Z</updated>
        <summary type="html"><![CDATA[Ugur Kursuncu, Manas Gaur, Amit Sheth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diversified Ensemble of Independent Sub-Networks for Robust
  Self-Supervised Representation Learning]]></title>
        <id>http://arxiv.org/abs/2308.14705</id>
        <link href="http://arxiv.org/abs/2308.14705"/>
        <updated>2023-09-04T02:20:36.074Z</updated>
        <summary type="html"><![CDATA[Amirhossein Vahidi, Lisa Wimmer, H\"useyin Anil G\"und\"uz, Bernd
  Bischl, Eyke H\"ullermeier, Mina Rezaei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Implicit Bias of Adam]]></title>
        <id>http://arxiv.org/abs/2309.00079</id>
        <link href="http://arxiv.org/abs/2309.00079"/>
        <updated>2023-09-04T02:20:36.039Z</updated>
        <summary type="html"><![CDATA[Matias D. Cattaneo, Jason M. Klusowski, Boris Shigida]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SGD learning on neural networks: leap complexity and saddle-to-saddle
  dynamics]]></title>
        <id>http://arxiv.org/abs/2302.11055</id>
        <link href="http://arxiv.org/abs/2302.11055"/>
        <updated>2023-09-04T02:20:36.034Z</updated>
        <summary type="html"><![CDATA[Emmanuel Abbe, Enric Boix-Adsera, Theodor Misiakiewicz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UTMB congratulations!]]></title>
        <id>http://xianblog.wordpress.com/?p=53990</id>
        <link href="https://xianblog.wordpress.com/2023/09/04/utmb-congratulations/"/>
        <updated>2023-09-03T22:23:41.000Z</updated>
        <summary type="html"><![CDATA[Congrats to all runners of the UTMB 2023 this weekend, but most particularly to Alexis Baron a friend and colleague of our daughter in Martinique, who finished 164th in less than 30 hours the 172.2km length and  9967m elevation race.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PRC-style censorship of "Oppenheimer"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60487</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60487&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=prc-style-censorship-of-oppenheimer"/>
        <updated>2023-09-03T12:45:31.000Z</updated>
        <summary type="html"><![CDATA[奥本海默中国大陆版本剪辑情况 pic.twitter.com/Nbjxy5PJ4J — 小径残雪 (@xiaojingcanxue) September 1, 2023 [link to full tweet here] Notice the title of each group of five panels: yuánbǎn 原版 ("original edition") for the uncut version, and jiǎnbǎn ✂️版 [=剪版] (meaning jiǎnjí bǎn 剪輯版) for the censored version — all the more notable for its being written in pen, not typed […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sài Gòn food scene [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53679</id>
        <link href="https://xianblog.wordpress.com/2023/09/03/sai-gon-food-scene-jatp/"/>
        <updated>2023-09-02T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[An additional perk of visiting Sài Gòn last week was in enjoying the rich and diverse food scene there, even though, obviously, I only scratched the surface of the offer there. Among dishes, a morning rice pancake called bunh cuon,   several phos,  sweet sea snails, another broth called bun thang (with blood sausage), a […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Old, Middle, and Modern English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60482</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60482&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=old-middle-and-modern-english"/>
        <updated>2023-09-02T12:14:42.000Z</updated>
        <summary type="html"><![CDATA[The Differences between Old English, Middle English and Modern English By Danièle Cybulskie When people study Shakespeare in high school, I often hear them refer to his language as “Old English.” As far as the language goes, Shakespeare’s English actually falls under the category of “Modern English.” This may be a little hard to believe, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantum-enhanced Markov chain Monte Carlo]]></title>
        <id>http://xianblog.wordpress.com/?p=53575</id>
        <link href="https://xianblog.wordpress.com/2023/09/02/quantum-enhanced-markov-chain-monte-carlo/"/>
        <updated>2023-09-01T22:23:51.000Z</updated>
        <summary type="html"><![CDATA[A rare occurrence of an MCMC paper in Nature!!! David Layden and co-authors published this paper on 12 July, about using a quantum proposal in a Metropolis-Rosenbluth-Hastings simulation of an Ising model. More specifically, based on “quenched dynamics of a transverse-field quantum Ising model20, which can be efficiently simulated on a quantum computer21“, which amounts […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[论文阅读：MHA、MQA、GQA的差异与共性]]></title>
        <id>https://yongyuan.name//blog/mha-mqa-gqa.html</id>
        <link href="https://yongyuan.name//blog/mha-mqa-gqa.html"/>
        <updated>2023-09-01T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[MHA: Attention is All You Need
MQA：Fast Transformer Decoding: One Write-Head is All You Need
GQA: Training Generalized Multi-Query Transformer Models fromMulti-Head Checkpoints
MHA、MQA、GQA差异

MHA：Multi-Head Attention，QKV 三部分有相同数量的头，且一一对应。每次做 Attention，head1 的 QKV 就做好自己运算就可以，输出时各个头加起来就行。
MQA：Multi-Query Attention，让 Q 仍然保持原来的头数，但 K 和 V 只有一个头，相当于所有的 Q 头共享一组 K 和 V 头，所以叫做 Multi-Query 了。
实现改变了会不会影响效果呢？确实会影响但相对它能带来的收益，性能的些微降低是可以接受的。能带来多大的收益呢，实验发现一般能提高 30%-40% 的吞吐。收益主要就是由降低了 KV cache 带来的。实际上 MQA 运算量和 MHA 是差不多的，可理解为读取一组 KV 头之后，给所有 Q 头用，但因为之前提到的内存和计算的不对称，所以是有利的。
GQA：Grouped-Query Attention，是 MHA 和 MQA 的折衷方案，既不想损失性能太多，又想获得 MQA 带来的推理加速好处。具体思想是，不是所有 Q 头共享一组 KV，而是分组一定头数 Q 共享一组 KV，比如上面图片就是两组 Q 共享一组 KV。
MHA、MQA、GQA共性
实际上，MHA、MQA可以看做是GQA两个特例版本：
MQA对应GQA-1，即只有一个分组，对应一个K和V；
MHA对应GQA-H，对应H个head，对应H个K和V；
怎么从MHA模型得到MQA和GQA？

从MHA得到MQA：将MHA中H个head的的K和V，分别做mean pooling后得到一个K和V，用得到的K和V继续训练。
从MHA得到GQA：将MHA中H个head的的K和V，分别做mean pooling后，得到H个K和V，用得到的K和V继续训练。
MHA、MQA、GQA效果
在LLAMA2中，在不同的数据数据集上对比的效果（注意：为了维持参数量一致，对于MQA、GQA的FFN layer的维度，会有一定的拓宽）：]]></summary>
        <author>
            <name>YongYuan's homepage</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Central Asian Turkish languages]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60479</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60479&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=central-asian-turkish-languages"/>
        <updated>2023-09-01T12:33:21.000Z</updated>
        <summary type="html"><![CDATA[I write to announce an exceptional opportunity to learn the Turkish languages of Central Asia. There is a new Turkic course at Penn: TURK 1050.   This is a survey course that introduces students to the main languages spoken in Central Asia: Kazakh, Uzbek, Kyrgyz, Azeri. The language study will facilitate student research in topics like […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Don't speak Japanese loudly outside!"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60476</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60476&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dont-speak-japanese-loudly-outside"/>
        <updated>2023-09-01T01:29:55.000Z</updated>
        <summary type="html"><![CDATA[Advisory to staff of the embassy of Japan in Beijing: ALPS shori mizu no kaiyō hōshutsu kaishi ni tomonau chūi kanki (2023-nen 8 tsuki 25-nichi) ALPS処理水の海洋放出開始に伴う注意喚起（2023年8月25日） Warning regarding the start of ocean discharge of ALPS-treated water (August 25, 2023) Kinō (24-nichi), fusoku no jitai ga hassei suru kanōsei wa haijo dekinai tame chūi shite itadaku […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Open MatSci ML Toolkit: A Flexible Framework for Machine Learning in
  Materials Science]]></title>
        <id>http://arxiv.org/abs/2210.17484</id>
        <link href="http://arxiv.org/abs/2210.17484"/>
        <updated>2023-09-01T01:07:38.561Z</updated>
        <summary type="html"><![CDATA[Santiago Miret, Kin Long Kelvin Lee, Carmelo Gonzales, Marcel Nassar,
  Matthew Spellings]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[0/1 Deep Neural Networks via Block Coordinate Descent]]></title>
        <id>http://arxiv.org/abs/2206.09379</id>
        <link href="http://arxiv.org/abs/2206.09379"/>
        <updated>2023-09-01T01:07:34.775Z</updated>
        <summary type="html"><![CDATA[Hui Zhang, Shenglong Zhou, Geoffrey Ye Li, Naihua Xiu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Optimal Strategies for Temporal Tasks in Stochastic Games]]></title>
        <id>http://arxiv.org/abs/2102.04307</id>
        <link href="http://arxiv.org/abs/2102.04307"/>
        <updated>2023-09-01T01:07:34.769Z</updated>
        <summary type="html"><![CDATA[Alper Kamil Bozkurt, Yu Wang, Michael M. Zavlanos, Miroslav Pajic]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leveraging Image-based Generative Adversarial Networks for Time Series
  Generation]]></title>
        <id>http://arxiv.org/abs/2112.08060</id>
        <link href="http://arxiv.org/abs/2112.08060"/>
        <updated>2023-09-01T01:07:34.763Z</updated>
        <summary type="html"><![CDATA[Justin Hellermann, Stefan Lessmann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GRASP: A Goodness-of-Fit Test for Classification Learning]]></title>
        <id>http://arxiv.org/abs/2209.02064</id>
        <link href="http://arxiv.org/abs/2209.02064"/>
        <updated>2023-09-01T01:07:34.757Z</updated>
        <summary type="html"><![CDATA[Adel Javanmard, Mohammad Mehrabi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the year of fires]]></title>
        <id>http://xianblog.wordpress.com/?p=53752</id>
        <link href="https://xianblog.wordpress.com/2023/09/01/a-journal-of-the-year-of-fires/"/>
        <updated>2023-08-31T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Indeed, the year of the mega-fires in West and East Canada, with Kelowna (and UBC Okanagan where BIRS 23w5106 took place) severely hit. Travelling through BC by car and plane, we saw several wildfire fume clouds, incl. a massive one from the Yellowknife region… Read a few dozen pages of Gene Wolfe’s The Knight, in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No Japanese people or American dogs]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60466</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60466&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=no-japanese-people-or-american-dogs"/>
        <updated>2023-08-31T20:56:32.000Z</updated>
        <summary type="html"><![CDATA[From the Twitter / X account of the famous popular science writer and muckraker, Fang Zhouzi / Fang Shimin: 光禁止“日本人”“美国狗”入内哪够啊，还有欧盟、英国、澳大利亚、加拿大……呢？不如干脆搞一个白名单，只欢迎朝鲜人、俄国狗入内。 pic.twitter.com/fhVu6oMyZx — 方舟子 (@fangshimin) August 31, 2023 The sign says: Rìběn rénMěiguó gǒujìnzhǐ rùnèi 日本人美国狗禁止入内 "Japanese peopleAmerican dogsAre forbidden from entering" It seems that Americans are of a lower order than Japanese.  What did we […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WeatherBench 2: A benchmark for the next generation of data-driven weather models]]></title>
        <id>http://blog.research.google/2023/08/weatherbench-2-benchmark-for-next.html</id>
        <link href="http://blog.research.google/2023/08/weatherbench-2-benchmark-for-next.html"/>
        <updated>2023-08-31T17:14:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Stephan Rasp, Research Scientist, and Carla Bromberg, Program Lead, Google Research





In 1950, weather forecasting started its digital revolution when researchers used the first programmable, general-purpose computer ENIAC to solve mathematical equations describing how weather evolves. In the more than 70 years since, continuous advancements in computing power and improvements to the model formulations have led to steady gains in weather forecast skill: a 7-day forecast today is about as accurate as a 5-day forecast in 2000 and a 3-day forecast in 1980. While improving forecast accuracy at the pace of approximately one day per decade may not seem like a big deal, every day improved is important in far reaching use cases, such as for logistics planning, disaster management, agr…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Get some linguists out here"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60468</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60468&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=get-some-linguists-out-here"/>
        <updated>2023-08-31T12:02:17.000Z</updated>
        <summary type="html"><![CDATA[Email from John B.: Writing to you about a never-expected-to-see sentence, in a novel I’m reading. “And get some linguists out here as fast as you can.” (Well, but why not?) It’s a newly released off the wall novel, The Road to Roswell by Connie Willis. The heroine, Francie, has agreed to be maid of […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Viral vibe]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60461</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60461&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=viral-vibe"/>
        <updated>2023-08-31T10:23:58.000Z</updated>
        <summary type="html"><![CDATA["Chinese Song Streamed Billions of Times for ‘Satirical’ Vibe" By Miho Tamura / Yomiuri Shimbun Correspondent Yomiuri Shimbun (August 29, 2023) Here's the song, with the lyrics in characters, pinyin romanization, and a poor English translation: There are several other inferior English translations on the internet.  I have yet to find one that is serviceable, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch/XLA SPMD: Scale Up Model Training and Serving with Automatic Parallelization]]></title>
        <id>https://pytorch.org/blog/pytorch-xla-spmd/</id>
        <link href="https://pytorch.org/blog/pytorch-xla-spmd/"/>
        <updated>2023-08-31T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today, we are delighted to announce PyTorch/XLA SPMD: the integration of GSPMD into PyTorch with an easy to use API. PyTorch developers seeking superior performance and scale can train and serve the largest neural networks while maximizing utilization of AI accelerators, such as Google Cloud TPUs.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Coagent Networks Revisited]]></title>
        <id>http://arxiv.org/abs/2001.10474</id>
        <link href="http://arxiv.org/abs/2001.10474"/>
        <updated>2023-08-31T02:20:13.444Z</updated>
        <summary type="html"><![CDATA[Modjtaba Shokrian Zini, Mohammad Pedramfar, Matthew Riemer, Ahmadreza
  Moradipari, Miao Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Application of Zone Method based Machine Learning and Physics-Informed
  Neural Networks in Reheating Furnaces]]></title>
        <id>http://arxiv.org/abs/2308.16089</id>
        <link href="http://arxiv.org/abs/2308.16089"/>
        <updated>2023-08-31T02:20:13.399Z</updated>
        <summary type="html"><![CDATA[Ujjal Kr Dutta, Aldo Lipani, Chuan Wang, Yukun Hu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convolutional Analysis Operator Learning: Acceleration and Convergence]]></title>
        <id>http://arxiv.org/abs/1802.05584</id>
        <link href="http://arxiv.org/abs/1802.05584"/>
        <updated>2023-08-31T02:20:13.343Z</updated>
        <summary type="html"><![CDATA[Il Yong Chun, Jeffrey A. Fessler]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment]]></title>
        <id>http://arxiv.org/abs/2304.06767</id>
        <link href="http://arxiv.org/abs/2304.06767"/>
        <updated>2023-08-31T02:20:13.273Z</updated>
        <summary type="html"><![CDATA[Hanze Dong, Wei Xiong, Deepanshu Goyal, Yihan Zhang, Winnie Chow, Rui
  Pan, Shizhe Diao, Jipeng Zhang, Kashun Shum, Tong Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[survex: an R package for explaining machine learning survival models]]></title>
        <id>http://arxiv.org/abs/2308.16113</id>
        <link href="http://arxiv.org/abs/2308.16113"/>
        <updated>2023-08-31T02:20:13.266Z</updated>
        <summary type="html"><![CDATA[Miko{\l}aj Spytek, Mateusz Krzyzi\'nski, Sophie Hanna Langbein
 , Hubert Baniecki, Marvin N. Wright, Przemys{\l}aw Biecek]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Korean words for "bottle gourd"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60457</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60457&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=korean-words-for-bottle-gourd"/>
        <updated>2023-08-30T22:51:10.000Z</updated>
        <summary type="html"><![CDATA[I spent much of the summer in Vermont ensconced in a hermit's cottage reading, writing, and, of course, running through the Green Mountains and verdant woods.  When I left last week to come back for the fall semester at Penn, I brought with me about fifty bottle gourds (Lagenaria siceraria) that had been abandoned by […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ISBA²⁴ [website]]]></title>
        <id>http://xianblog.wordpress.com/?p=53938</id>
        <link href="https://xianblog.wordpress.com/2023/08/31/isba%c2%b2%e2%81%b4-website/"/>
        <updated>2023-08-30T22:24:14.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Modeling and improving text stability in live captions]]></title>
        <id>http://blog.research.google/2023/08/modeling-and-improving-text-stability.html</id>
        <link href="http://blog.research.google/2023/08/modeling-and-improving-text-stability.html"/>
        <updated>2023-08-30T19:34:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Vikas Bahirwani, Research Scientist, and Susan Xu, Software Engineer, Google Augmented Reality





Automatic speech recognition (ASR) technology has made conversations more accessible with live captions in remote conferencing software, mobile applications, and head-worn displays. However, to maintain real-time responsiveness, live caption systems often display interim predictions that are updated as new utterances are received. This can cause text instability (a “flicker” where previously displayed text is updated, shown in the captions on the left in the video below), which can impair users' reading experience due to distraction, fatigue, and difficulty following the conversation.






In “Modeling and Improving Text Stability in Live Captions”, presented at ACM CHI 2023, we f…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Once in a blue moon]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60454</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60454&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=once-in-a-blue-moon"/>
        <updated>2023-08-30T14:17:17.000Z</updated>
        <summary type="html"><![CDATA[From the MIT International Student Office: Blue moons are best known from the phrase “once in a blue moon,” which means “extremely rarely.” The first recorded use of this idiomatic phrase is in an anti-clerical flyer in 1528, published by William Roy and Jeremy Barlowe. In reference to the clerical corruptions, one said in Old […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Empowering Clinicians and Democratizing Data Science: Large Language
  Models Automate Machine Learning for Clinical Studies]]></title>
        <id>http://arxiv.org/abs/2308.14120</id>
        <link href="http://arxiv.org/abs/2308.14120"/>
        <updated>2023-08-30T04:17:23.914Z</updated>
        <summary type="html"><![CDATA[Soroosh Tayebi Arasteh, Tianyu Han, Mahshad Lotfinia, Christiane Kuhl,
  Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Based Residuals in Non-linear Factor Models: Precision
  Matrix Estimation of Returns with Low Signal-to-Noise Ratio]]></title>
        <id>http://arxiv.org/abs/2209.04512</id>
        <link href="http://arxiv.org/abs/2209.04512"/>
        <updated>2023-08-30T04:17:23.909Z</updated>
        <summary type="html"><![CDATA[Mehmet Caner, Maurizio Daniele]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Empirical Bregman Divergence for Uncertain Distance
  Representation]]></title>
        <id>http://arxiv.org/abs/2304.07689</id>
        <link href="http://arxiv.org/abs/2304.07689"/>
        <updated>2023-08-30T04:17:23.640Z</updated>
        <summary type="html"><![CDATA[Zhiyuan Li, Ziru Liu, Anna Zou, Anca L. Ralescu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Theoretical Guarantees of Learning Ensembling Strategies with
  Applications to Time Series Forecasting]]></title>
        <id>http://arxiv.org/abs/2305.15786</id>
        <link href="http://arxiv.org/abs/2305.15786"/>
        <updated>2023-08-30T04:17:23.619Z</updated>
        <summary type="html"><![CDATA[Hilaf Hasson, Danielle C. Maddix, Yuyang Wang, Gaurav Gupta, Youngsuk
  Park]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[differentially private distributed Bayesian linear regression with MCMC]]></title>
        <id>http://xianblog.wordpress.com/?p=53623</id>
        <link href="https://xianblog.wordpress.com/2023/08/30/differentially-private-distributed-bayesian-linear-regression-with-mcmc/"/>
        <updated>2023-08-29T22:23:23.000Z</updated>
        <summary type="html"><![CDATA[An ICML 2023 paper by Barıs¸ Alparslan, Sinan Yıldırım¸ and Ilker Birbil that (re)addresses the issue of privacy when running a Bayesian regression analysis. Resorting to the common notion of differential privacy, imposing a limited variability if a single observation is modified, and a Gaussian randomisation of the observations. “A differentially private algorithm constrains the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[De-Japanification of Japanese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60435</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60435&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=de-japanification-of-japanese"/>
        <updated>2023-08-29T22:22:30.000Z</updated>
        <summary type="html"><![CDATA[This morning in the first class of my course on "Language, Script, and Society in China", I had just spoken about the most frequent morphemes in Mandarin, Taiwanese, and Japanese (the possessive particles de 的, e, and no の) and other common terms that had no fixed characters to write them or had to borrow […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SayTap: Language to quadrupedal locomotion]]></title>
        <id>http://blog.research.google/2023/08/saytap-language-to-quadrupedal.html</id>
        <link href="http://blog.research.google/2023/08/saytap-language-to-quadrupedal.html"/>
        <updated>2023-08-29T19:57:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Yujin Tang and Wenhao Yu, Research Scientists, Google




Simple and effective interaction between human and quadrupedal robots paves the way towards creating intelligent and capable helper robots, forging a future where technology enhances our lives in ways beyond our imagination. Key to such human-robot interaction systems is enabling quadrupedal robots to respond to natural language instructions. Recent developments in large language models (LLMs) have demonstrated the potential to perform high-level planning. Yet, it remains a challenge for LLMs to comprehend low-level commands, such as joint angle targets or motor torques, especially for inherently unstable legged robots, necessitating high-frequency control signals. Consequently, most existing work presumes the provision of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Re-Grand Opening"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60440</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60440&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=re-grand-opening"/>
        <updated>2023-08-29T16:22:55.000Z</updated>
        <summary type="html"><![CDATA[From John Bell: I thought of you and your interest in the oddities of linguistic expression a few days ago when I noticed that the local Safeway supermarket had large signs up saying "RE-GRAND OPENING".   They had recently done some renovation in a corner of the store — enlarging the self-checkout and the Starbucks […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Estimation of Derivatives Using Plug-in Kernel Ridge Regression
  Estimators]]></title>
        <id>http://arxiv.org/abs/2006.01350</id>
        <link href="http://arxiv.org/abs/2006.01350"/>
        <updated>2023-08-29T02:49:37.845Z</updated>
        <summary type="html"><![CDATA[Zejian Liu, Meng Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multilevel orthogonal Bochner function subspaces with applications to
  robust machine learning]]></title>
        <id>http://arxiv.org/abs/2110.01729</id>
        <link href="http://arxiv.org/abs/2110.01729"/>
        <updated>2023-08-29T02:49:37.824Z</updated>
        <summary type="html"><![CDATA[Julio Enrique Castrillon-Candas, Dingning Liu, Sicheng Yang, Mark Kon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-Calibration: Learning of Model Calibration Using Differentiable
  Expected Calibration Error]]></title>
        <id>http://arxiv.org/abs/2106.09613</id>
        <link href="http://arxiv.org/abs/2106.09613"/>
        <updated>2023-08-29T02:49:37.801Z</updated>
        <summary type="html"><![CDATA[Ondrej Bohdal, Yongxin Yang, Timothy Hospedales]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sufficient Invariant Learning for Distribution Shift]]></title>
        <id>http://arxiv.org/abs/2210.13533</id>
        <link href="http://arxiv.org/abs/2210.13533"/>
        <updated>2023-08-29T02:49:37.795Z</updated>
        <summary type="html"><![CDATA[Taero Kim, Sungjun Lim, Kyungwoo Song]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TuneUp: A Simple Improved Training Strategy for Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2210.14843</id>
        <link href="http://arxiv.org/abs/2210.14843"/>
        <updated>2023-08-29T02:49:37.689Z</updated>
        <summary type="html"><![CDATA[Weihua Hu, Kaidi Cao, Kexin Huang, Edward W Huang, Karthik Subbian,
  Kenji Kawaguchi, Jure Leskovec]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Identifying AI-generated images with SynthID]]></title>
        <id>https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid</id>
        <link href="https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid"/>
        <updated>2023-08-29T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today, in partnership with Google Cloud, we’re beta launching SynthID, a new tool for watermarking and identifying AI-generated images. It’s being released to a limited number of Vertex AI customers using Imagen, one of our latest text-to-image models that uses input text to create photorealistic images. This technology embeds a digital watermark directly into the pixels of an image, making it imperceptible to the human eye, but detectable for identification. While generative AI can unlock huge creative potential, it also presents new risks, like creators spreading false information — both intentionally or unintentionally. Being able to identify AI-generated content is critical to empowering people with knowledge of when they’re interacting with generated media, and for helping prevent the spread of misinformation.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayes on the Beach²⁴]]></title>
        <id>http://xianblog.wordpress.com/?p=53928</id>
        <link href="https://xianblog.wordpress.com/2023/08/29/bayes-on-the-beach%c2%b2%e2%81%b4/"/>
        <updated>2023-08-28T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language and politics in Hong Kong: National Security and the promotion of topolect]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60423</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60423&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-and-politics-in-hong-kong-national-security-and-the-promotion-of-topolect"/>
        <updated>2023-08-28T19:20:14.000Z</updated>
        <summary type="html"><![CDATA[From the Hong Kong Language Learning Association: Announcement Regarding Suspension of Hong Kong Language Learning Association Given recent events, wherein personnel from the Hong Kong National Security Department (NSD) visited both my former residence and the residence of my family members for searches and inquiries, alleging a violation of the National Security Law in connection with […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RO-ViT: Region-aware pre-training for open-vocabulary object detection with vision transformers]]></title>
        <id>http://blog.research.google/2023/08/ro-vit-region-aware-pre-training-for.html</id>
        <link href="http://blog.research.google/2023/08/ro-vit-region-aware-pre-training-for.html"/>
        <updated>2023-08-28T16:59:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Dahun Kim and Weicheng Kuo, Research Scientists, Google



The ability to detect objects in the visual world is crucial for computer vision and machine intelligence, enabling applications like adaptive autonomous agents and versatile shopping systems. However, modern object detectors are limited by the manual annotations of their training data, resulting in a vocabulary size significantly smaller than the vast array of objects encountered in reality. To overcome this, the open-vocabulary detection task (OVD) has emerged, utilizing image-text pairs for training and incorporating new category names at test time by associating them with the image content. By treating categories as text embeddings, open-vocabulary detectors can predict a wide range of unseen objects. Various techniqu…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RO-ViT: Region-aware pre-training for open-vocabulary object detection with vision transformers]]></title>
        <id>http://ai.googleblog.com/2023/08/ro-vit-region-aware-pre-training-for.html</id>
        <link href="http://ai.googleblog.com/2023/08/ro-vit-region-aware-pre-training-for.html"/>
        <updated>2023-08-28T16:59:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Dahun Kim and Weicheng Kuo, Research Scientists, Google



The ability to detect objects in the visual world is crucial for computer vision and machine intelligence, enabling applications like adaptive autonomous agents and versatile shopping systems. However, modern object detectors are limited by the manual annotations of their training data, resulting in a vocabulary size significantly smaller than the vast array of objects encountered in reality. To overcome this, the open-vocabulary detection task (OVD) has emerged, utilizing image-text pairs for training and incorporating new category names at test time by associating them with the image content. By treating categories as text embeddings, open-vocabulary detectors can predict a wide range of unseen objects. Various techniqu…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mugshot, racketeering, listless …]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60427</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60427&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mugshot-racketeering-listless"/>
        <updated>2023-08-28T11:57:06.000Z</updated>
        <summary type="html"><![CDATA[Over the past few months, U.S. political events have given Ben Zimmer opportunity for some fun etymologies in his WSJ column: mug shot, racketeering, listless. There are plenty more targets Out There — like candidate, from Latin candidus (“dazzling white, shining, clear”); or debate, originally from Latin dis- (“apart, in different directions”) + battuere (“to […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lion/Tiger优化器训练下的Embedding异常和对策]]></title>
        <id>https://kexue.fm/archives/9736</id>
        <link href="https://kexue.fm/archives/9736"/>
        <updated>2023-08-28T06:44:00.000Z</updated>
        <summary type="html"><![CDATA[打从在《Tiger：一个“抠”到极致的优化器》提出了Tiger优化器之后，Tiger就一直成为了我训练模型的“标配”优化器。最近笔者已经尝试将Tiger用到了70亿参数模型的预训练之中，前期效果...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Reasoning for Physics Informed Neural Networks]]></title>
        <id>http://arxiv.org/abs/2308.13222</id>
        <link href="http://arxiv.org/abs/2308.13222"/>
        <updated>2023-08-28T02:20:34.966Z</updated>
        <summary type="html"><![CDATA[Krzysztof M. Graczyk, Kornel Witkowski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PDSketch: Integrated Planning Domain Programming and Learning]]></title>
        <id>http://arxiv.org/abs/2303.05501</id>
        <link href="http://arxiv.org/abs/2303.05501"/>
        <updated>2023-08-28T02:20:34.959Z</updated>
        <summary type="html"><![CDATA[Jiayuan Mao, Tom\'as Lozano-P\'erez, Joshua B. Tenenbaum, Leslie Pack
  Kaelbling]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kernel Density Matrices for Probabilistic Deep Learning]]></title>
        <id>http://arxiv.org/abs/2305.18204</id>
        <link href="http://arxiv.org/abs/2305.18204"/>
        <updated>2023-08-28T02:20:34.918Z</updated>
        <summary type="html"><![CDATA[Fabio A. Gonz\'alez, Ra\'ul Ramos-Poll\'an, Joseph A. Gallego-Mejia]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Six Lectures on Linearized Neural Networks]]></title>
        <id>http://arxiv.org/abs/2308.13431</id>
        <link href="http://arxiv.org/abs/2308.13431"/>
        <updated>2023-08-28T02:20:34.912Z</updated>
        <summary type="html"><![CDATA[Theodor Misiakiewicz, Andrea Montanari]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A topological model for partial equivariance in deep learning and data
  analysis]]></title>
        <id>http://arxiv.org/abs/2308.13357</id>
        <link href="http://arxiv.org/abs/2308.13357"/>
        <updated>2023-08-28T02:20:34.906Z</updated>
        <summary type="html"><![CDATA[Lucia Ferrari, Patrizio Frosini, Nicola Quercioli, Francesca Tombari]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The geometry of diffusion guidance]]></title>
        <id>https://sander.ai/2023/08/28/geometry.html</id>
        <link href="https://sander.ai/2023/08/28/geometry.html"/>
        <updated>2023-08-27T23:00:00.000Z</updated>
        <summary type="html"><![CDATA[Guidance is a powerful method that can be used to enhance diffusion model sampling. As I’ve discussed in an earlier blog post, it’s almost like a cheat code: it can improve sample quality so much that it’s as if the model had ten times the number of parameters – an order of magnitude improvement, basically for free! This follow-up post provides a geometric interpretation and visualisation of the diffusion sampling procedure, which I’ve found particularly useful to explain how guidance works.]]></summary>
        <author>
            <name>Sander Dieleman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BayesComp²⁵ in Singapore]]></title>
        <id>http://xianblog.wordpress.com/?p=53654</id>
        <link href="https://xianblog.wordpress.com/2023/08/28/bayescomp%c2%b2%e2%81%b5-in-singapore/"/>
        <updated>2023-08-27T22:23:38.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Core socialist values]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60406</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60406&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=core-socialist-values"/>
        <updated>2023-08-27T19:58:05.000Z</updated>
        <summary type="html"><![CDATA["Chinese slogans on London wall hold mirror to society: artist" Zhejiang-born Yique tries to find his place in UK after Brick Lane work TAY HAN NEE, Nikkei Asia Here are the 24 Chinese characters that constitute the twelve disyllabic words that make up the official "Core Socialist Values" of the PRC government: National values Prosperity […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Calimony"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60400</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60400&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=calimony"/>
        <updated>2023-08-27T13:28:59.000Z</updated>
        <summary type="html"><![CDATA[I recently learned about the lexical blend calimony, which refers to a planned multi-million-dollar annual payment from UCLA (the University of California, Los Angeles) to Berkeley (the University of California, Berkeley, known in athletic contexts as "California" or "Cal"). Why will this payment exist? And why is it a metaphorical form of alimony? Short form: […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bilingual book takes top honors at New Zealand Children's Book Awards]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60382</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60382&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bilingual-book-takes-top-honors-at-new-zealand-childrens-book-awards"/>
        <updated>2023-08-27T12:55:14.000Z</updated>
        <summary type="html"><![CDATA[Press comment:   "A bilingual book about the Māori creation story has won the highest accolade in children's literature."   Awards Announcement:   "Te Wehenga: The Separation of Ranginui and Papatūānuku presents the Māori creation pūrākau in a bold design using universal elements recognised across iwi. The bilingual text is poetic, and integrated into the artwork […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[23w5106 [group picture]]]></title>
        <id>http://xianblog.wordpress.com/?p=53766</id>
        <link href="https://xianblog.wordpress.com/2023/08/27/23w5106-group-picture/"/>
        <updated>2023-08-26T22:23:25.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[English accents]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60344</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60344&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=english-accents"/>
        <updated>2023-08-26T13:13:05.000Z</updated>
        <summary type="html"><![CDATA[Entertaining and edifying. As I said recently (last paragraph of this post:  "Irish accents" [8/13/23]), I'm enchanted by all the accents that I've ever heard.  I find them to be endlessly fascinating.   Selected readings "What makes an accent 'good' or 'bad?" (11/17/20) "Dialect vs. accent (vs. language)" (11/30/18) "Mandarin with an English accent" (4/5/23) […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Debate-night pronouns]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60372</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60372&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=debate-night-pronouns"/>
        <updated>2023-08-26T13:13:00.000Z</updated>
        <summary type="html"><![CDATA[In a comment on yesterday's "Debate words" post, I noted that Donald Trump's ratio of I-words to we-words was "off the charts" compared the other eight candidates, and several people have asked me to give all the numbers. There's an idea Out There that such numbers are related to issues of personality and mood, though […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calyampudi Radhakrishna Rao (1920-2023)]]></title>
        <id>http://xianblog.wordpress.com/?p=53899</id>
        <link href="https://xianblog.wordpress.com/2023/08/26/calyampudi-radhakrishna-rao-1920-2023/"/>
        <updated>2023-08-25T22:23:46.000Z</updated>
        <summary type="html"><![CDATA[Just heard that C.R. Rao had passed away on Wednesday. Above is a 1941 picture I photographed while attending the jubilee of the Department of Statistics of the University of Calcuta. Showing R.A. Fisher and P.C. Mahalanobis surrounded by faculty and students from the Department. Including a very young Rao who would a few years […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: Perception Fairness]]></title>
        <id>http://blog.research.google/2023/08/responsible-ai-at-google-research.html</id>
        <link href="http://blog.research.google/2023/08/responsible-ai-at-google-research.html"/>
        <updated>2023-08-25T17:38:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Susanna Ricco and Utsav Prabhu, co-leads, Perception Fairness Team, Google Research





Google’s Responsible AI research is built on a foundation of collaboration — between teams with diverse backgrounds and expertise, between researchers and product developers, and ultimately with the community at large. The Perception Fairness team drives progress by combining deep subject-matter expertise in both computer vision and machine learning (ML) fairness with direct connections to the researchers building the perception systems that power products across Google and beyond. Together, we are working to intentionally design our systems to be inclusive from the ground up, guided by Google’s AI Principles.






Perception Fairness research spans the design, development, and deployment of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: Perception Fairness]]></title>
        <id>http://ai.googleblog.com/2023/08/responsible-ai-at-google-research.html</id>
        <link href="http://ai.googleblog.com/2023/08/responsible-ai-at-google-research.html"/>
        <updated>2023-08-25T17:38:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Susanna Ricco and Utsav Prabhu, co-leads, Perception Fairness Team, Google Research





Google’s Responsible AI research is built on a foundation of collaboration — between teams with diverse backgrounds and expertise, between researchers and product developers, and ultimately with the community at large. The Perception Fairness team drives progress by combining deep subject-matter expertise in both computer vision and machine learning (ML) fairness with direct connections to the researchers building the perception systems that power products across Google and beyond. Together, we are working to intentionally design our systems to be inclusive from the ground up, guided by Google’s AI Principles.






Perception Fairness research spans the design, development, and deployment of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Debate words]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60351</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60351&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=debate-words-3"/>
        <updated>2023-08-25T12:41:38.000Z</updated>
        <summary type="html"><![CDATA[The Transcript Library at rev.com is a great resource — within 24 hours, they had transcripts of Wednesday's Fox News Republican presidential debate, and also of Tucker Carlson's debate night interview with Donald Trump on X. So this morning I downloaded the transcripts, and ran the code that I've used several times over the years […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calligraphic license]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60331</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60331&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=calligraphic-license"/>
        <updated>2023-08-25T03:07:39.000Z</updated>
        <summary type="html"><![CDATA[Shaing tai asked whether I recognized these characters: I didn't recognize the two characters, so I asked several Chinese and Japanese friends, and none of them recognized the characters either.  My curiosity piqued, I figured I might as well take a stab on my own to figure out what they were. The calligraphy was displayed […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[StableDR: Stabilized Doubly Robust Learning for Recommendation on Data
  Missing Not at Random]]></title>
        <id>http://arxiv.org/abs/2205.04701</id>
        <link href="http://arxiv.org/abs/2205.04701"/>
        <updated>2023-08-25T02:20:22.385Z</updated>
        <summary type="html"><![CDATA[Haoxuan Li, Chunyuan Zheng, Peng Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Intentional Forgetting-Driven Self-Healing Method For Deep
  Reinforcement Learning Systems]]></title>
        <id>http://arxiv.org/abs/2308.12445</id>
        <link href="http://arxiv.org/abs/2308.12445"/>
        <updated>2023-08-25T02:20:22.378Z</updated>
        <summary type="html"><![CDATA[Ahmed Haj Yahmed, Rached Bouchoucha, Houssem Ben Braiek, Foutse Khomh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Single-shot Bayesian approximation for neural networks]]></title>
        <id>http://arxiv.org/abs/2308.12785</id>
        <link href="http://arxiv.org/abs/2308.12785"/>
        <updated>2023-08-25T02:20:22.204Z</updated>
        <summary type="html"><![CDATA[Kai Brach, Beate Sick, Oliver D\"urr]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interneurons accelerate learning dynamics in recurrent neural networks
  for statistical adaptation]]></title>
        <id>http://arxiv.org/abs/2209.10634</id>
        <link href="http://arxiv.org/abs/2209.10634"/>
        <updated>2023-08-25T02:20:22.197Z</updated>
        <summary type="html"><![CDATA[David Lipshutz, Cengiz Pehlevan, Dmitri B. Chklovskii]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[making the next meeting more productive]]></title>
        <id>http://xianblog.wordpress.com/?p=53619</id>
        <link href="https://xianblog.wordpress.com/2023/08/25/making-the-next-meeting-more-productive/"/>
        <updated>2023-08-24T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[One of the students’ requests I almost invariably reject is code debugging (and they are warned about it from the start). Here is an illustration why, with an R code sent by a student working this summer on the standard estimators of a Cauchy location parameter, asking for debugging help in order “to make the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to compare a noisy quantum processor to a classical computer]]></title>
        <id>http://blog.research.google/2023/08/how-to-compare-noisy-quantum-processor.html</id>
        <link href="http://blog.research.google/2023/08/how-to-compare-noisy-quantum-processor.html"/>
        <updated>2023-08-24T22:10:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Sergio Boixo and Vadim Smelyanskiy, Principal Scientists, Google Quantum AI Team




A full-scale error-corrected quantum computer will be able to solve some problems that are impossible for classical computers, but building such a device is a huge endeavor. We are proud of the milestones that we have achieved toward a fully error-corrected quantum computer, but that large-scale computer is still some number of years away. Meanwhile, we are using our current noisy quantum processors as flexible platforms for quantum experiments. 



In contrast to an error-corrected quantum computer, experiments in noisy quantum processors are currently limited to a few thousand quantum operations or gates, before noise degrades the quantum state. In 2019 we implemented a specific computational t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to compare a noisy quantum processor to a classical computer]]></title>
        <id>http://ai.googleblog.com/2023/08/how-to-compare-noisy-quantum-processor.html</id>
        <link href="http://ai.googleblog.com/2023/08/how-to-compare-noisy-quantum-processor.html"/>
        <updated>2023-08-24T22:10:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Sergio Boixo and Vadim Smelyanskiy, Principal Scientists, Google Quantum AI Team




A full-scale error-corrected quantum computer will be able to solve some problems that are impossible for classical computers, but building such a device is a huge endeavor. We are proud of the milestones that we have achieved toward a fully error-corrected quantum computer, but that large-scale computer is still some number of years away. Meanwhile, we are using our current noisy quantum processors as flexible platforms for quantum experiments. 



In contrast to an error-corrected quantum computer, experiments in noisy quantum processors are currently limited to a few thousand quantum operations or gates, before noise degrades the quantum state. In 2019 we implemented a specific computational t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teaching language models to reason algorithmically]]></title>
        <id>http://blog.research.google/2023/08/teaching-language-models-to-reason.html</id>
        <link href="http://blog.research.google/2023/08/teaching-language-models-to-reason.html"/>
        <updated>2023-08-24T19:33:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Hattie Zhou, Graduate Student at MILA, Hanie Sedghi, Research Scientist, Google




Large language models (LLMs), such as GPT-3 and PaLM, have shown impressive progress in recent years, which have been driven by scaling up models and training data sizes. Nonetheless, a long standing debate has been whether LLMs can reason symbolically (i.e., manipulating symbols based on logical rules). For example, LLMs are able to perform simple arithmetic operations when numbers are small, but struggle to perform with large numbers. This suggests that LLMs have not learned the underlying rules needed to perform these arithmetic operations. 



While neural networks have powerful pattern matching capabilities, they are prone to overfitting to spurious statistical patterns in the data. This does…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teaching language models to reason algorithmically]]></title>
        <id>http://ai.googleblog.com/2023/08/teaching-language-models-to-reason.html</id>
        <link href="http://ai.googleblog.com/2023/08/teaching-language-models-to-reason.html"/>
        <updated>2023-08-24T19:33:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Hattie Zhou, Graduate Student at MILA, Hanie Sedghi, Research Scientist, Google




Large language models (LLMs), such as GPT-3 and PaLM, have shown impressive progress in recent years, which have been driven by scaling up models and training data sizes. Nonetheless, a long standing debate has been whether LLMs can reason symbolically (i.e., manipulating symbols based on logical rules). For example, LLMs are able to perform simple arithmetic operations when numbers are small, but struggle to perform with large numbers. This suggests that LLMs have not learned the underlying rules needed to perform these arithmetic operations. 



While neural networks have powerful pattern matching capabilities, they are prone to overfitting to spurious statistical patterns in the data. This does…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer升级之路：14、当HWFA遇见ReRoPE]]></title>
        <id>https://kexue.fm/archives/9731</id>
        <link href="https://kexue.fm/archives/9731"/>
        <updated>2023-08-24T10:24:00.000Z</updated>
        <summary type="html"><![CDATA[在上一篇文章《Transformer升级之路：13、逆用Leaky ReRoPE》中，笔者尝试通过在训练阶段逆用Leaky ReRoPE的思路，使得推理阶段的位置编码变为正常的RoPE，从而在达...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Scale Training of Hugging Face Transformers on TPUs With PyTorch/XLA FSDP]]></title>
        <id>https://pytorch.org/blog/large-scale-training-hugging-face/</id>
        <link href="https://pytorch.org/blog/large-scale-training-hugging-face/"/>
        <updated>2023-08-24T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[AI is transforming many industries through advanced capabilities such as understanding and generating language, answering questions, and delivering accurate recommendations. These capabilities are fueled by ever-increasing size and complexity of AI models, which require vast amounts of computing power to train.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vulgar Cantonese elegantly displayed]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60319</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60319&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=vulgar-cantonese-elegantly-displayed"/>
        <updated>2023-08-24T03:03:11.000Z</updated>
        <summary type="html"><![CDATA[This curious Cantonese couplet appeared on Weibo today: Mandarin romanization, hanzi transcription, and glyph by glyph literal translation: gān jiāo jú lí luó yòu yàn jiù diāo lí shī fèi 柑蕉桔梨蘿柚 雁鷲雕狸獅狒 “mandarin orange*, banana / plantain, tangerine*, pear, turnip**, pomelo” “wild goose, vulture, eagle, fox***, lion, baboon****” *The Sinitic terminology for "mandarin orange", "tangerine", and other […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The car hit cheese bacon mushroom face, part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60314</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60314&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-car-hit-cheese-bacon-mushroom-face-part-2"/>
        <updated>2023-08-24T02:57:17.000Z</updated>
        <summary type="html"><![CDATA[Todd Wilbur shared this menu item on Facebook: This is a veritable masterpiece of Chinglish, covering several of the usual types of mistranslation inherent in the genre.  To unpack the crash, let's begin with the standard Language Log romanization, transcription, and translation: chēdǎ zhīshì yānròu mógū miàn 车打芝士腌肉蘑菇面 "cheddar cheese bacon mushroom noodles" All the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantifying degeneracy in singular models via the learning coefficient]]></title>
        <id>http://arxiv.org/abs/2308.12108</id>
        <link href="http://arxiv.org/abs/2308.12108"/>
        <updated>2023-08-24T02:19:09.913Z</updated>
        <summary type="html"><![CDATA[Edmund Lau, Daniel Murfet, Susan Wei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Learn Financial Networks for Optimising Momentum Strategies]]></title>
        <id>http://arxiv.org/abs/2308.12212</id>
        <link href="http://arxiv.org/abs/2308.12212"/>
        <updated>2023-08-24T02:19:09.895Z</updated>
        <summary type="html"><![CDATA[Xingyue (Stacy) Pu, Stefan Zohren, Stephen Roberts, Xiaowen Dong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A multiobjective continuation method to compute the regularization path
  of deep neural networks]]></title>
        <id>http://arxiv.org/abs/2308.12044</id>
        <link href="http://arxiv.org/abs/2308.12044"/>
        <updated>2023-08-24T02:19:09.890Z</updated>
        <summary type="html"><![CDATA[Augustina C. Amakor, Konstantin Sontag, Sebastian Peitz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Will More Expressive Graph Neural Networks do Better on Generative
  Tasks?]]></title>
        <id>http://arxiv.org/abs/2308.11978</id>
        <link href="http://arxiv.org/abs/2308.11978"/>
        <updated>2023-08-24T02:19:09.858Z</updated>
        <summary type="html"><![CDATA[Xiandong Zou, Xiangyu Zhao, Pietro Li\`o, Yiren Zhao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Critical Learning Periods Emerge Even in Deep Linear Networks]]></title>
        <id>http://arxiv.org/abs/2308.12221</id>
        <link href="http://arxiv.org/abs/2308.12221"/>
        <updated>2023-08-24T02:19:09.787Z</updated>
        <summary type="html"><![CDATA[Michael Kleinman, Alessandro Achille, Stefano Soatto]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[smoky sunset [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53842</id>
        <link href="https://xianblog.wordpress.com/2023/08/24/smoky-sunset-jatp/"/>
        <updated>2023-08-23T22:23:00.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Doom-lexing]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60323</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60323&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=doom-lexing"/>
        <updated>2023-08-23T20:33:58.000Z</updated>
        <summary type="html"><![CDATA[Yesterday, Randoh Sallihall from unscramblerer.com sent this note: Susie Dent has an ever growing Twitter following of 1,1 million unique word lovers to whom she shares her daily word of the day. Word search engine Unscramblerer.com went through Susie Dent's whole Twitter history and analyzed what are the most liked, shared and commented words of […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EvoPruneDeepTL: An Evolutionary Pruning Model for Transfer Learning
  based Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2202.03844</id>
        <link href="http://arxiv.org/abs/2202.03844"/>
        <updated>2023-08-23T03:15:13.514Z</updated>
        <summary type="html"><![CDATA[Javier Poyatos, Daniel Molina, Aritz. D. Martinez, Javier Del Ser,
  Francisco Herrera]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Information Theory-Guided Heuristic Progressive Multi-View Coding]]></title>
        <id>http://arxiv.org/abs/2109.02344</id>
        <link href="http://arxiv.org/abs/2109.02344"/>
        <updated>2023-08-23T03:15:13.512Z</updated>
        <summary type="html"><![CDATA[Jiangmeng Li, Wenwen Qiang, Hang Gao, Bing Su, Farid Razzak, Jie Hu,
  Changwen Zheng, Hui Xiong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Calibrating and Improving Graph Contrastive Learning]]></title>
        <id>http://arxiv.org/abs/2101.11525</id>
        <link href="http://arxiv.org/abs/2101.11525"/>
        <updated>2023-08-23T03:15:13.511Z</updated>
        <summary type="html"><![CDATA[Kaili Ma, Haochen Yang, Han Yang, Yongqiang Chen, James Cheng]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Learn Graph Topologies]]></title>
        <id>http://arxiv.org/abs/2110.09807</id>
        <link href="http://arxiv.org/abs/2110.09807"/>
        <updated>2023-08-23T03:15:13.510Z</updated>
        <summary type="html"><![CDATA[Xingyue Pu, Tianyue Cao, Xiaoyun Zhang, Xiaowen Dong, Siheng Chen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FRAug: Tackling Federated Learning with Non-IID Features via
  Representation Augmentation]]></title>
        <id>http://arxiv.org/abs/2205.14900</id>
        <link href="http://arxiv.org/abs/2205.14900"/>
        <updated>2023-08-23T03:15:13.292Z</updated>
        <summary type="html"><![CDATA[Haokun Chen, Ahmed Frikha, Denis Krompass, Jindong Gu, Volker Tresp]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Waterless, emission-free toilet that Chairman Xi saw]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60288</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60288&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=waterless-emission-free-toilet-that-chairman-xi-saw"/>
        <updated>2023-08-23T01:31:20.000Z</updated>
        <summary type="html"><![CDATA[(see in particular the second item) If this isn't dictator status, I don't know what ishttps://t.co/A4guMzG4m1 — Bumboclott (@Bumboclott) June 29, 2023 The poster board on the bottom left shows Xi inspecting the hallowed hardware on an earlier visit.  It says: Zhè shì Xí Zhǔxí kànguò de mǎtǒng 这是习主席看过的马桶 "This is the toilet that Chairman […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Metlakatla trail [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53811</id>
        <link href="https://xianblog.wordpress.com/2023/08/23/metlakatla-trail-jatp/"/>
        <updated>2023-08-22T22:21:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language to rewards for robotic skill synthesis]]></title>
        <id>http://blog.research.google/2023/08/language-to-rewards-for-robotic-skill.html</id>
        <link href="http://blog.research.google/2023/08/language-to-rewards-for-robotic-skill.html"/>
        <updated>2023-08-22T18:47:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Wenhao Yu and Fei Xia, Research Scientists, Google






Empowering end-users to interactively teach robots to perform novel tasks is a crucial capability for their successful integration into real-world applications. For example, a user may want to teach a robot dog to perform a new trick, or teach a manipulator robot how to organize a lunch box based on user preferences. The recent advancements in large language models (LLMs) pre-trained on extensive internet data have shown a promising path towards achieving this goal. Indeed, researchers have explored diverse ways of leveraging LLMs for robotics, from step-by-step planning and goal-oriented dialogue to robot-code-writing agents. 



While these methods impart new modes of compositional generalization, they focus on using lang…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language to rewards for robotic skill synthesis]]></title>
        <id>http://ai.googleblog.com/2023/08/language-to-rewards-for-robotic-skill.html</id>
        <link href="http://ai.googleblog.com/2023/08/language-to-rewards-for-robotic-skill.html"/>
        <updated>2023-08-22T18:47:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Wenhao Yu and Fei Xia, Research Scientists, Google






Empowering end-users to interactively teach robots to perform novel tasks is a crucial capability for their successful integration into real-world applications. For example, a user may want to teach a robot dog to perform a new trick, or teach a manipulator robot how to organize a lunch box based on user preferences. The recent advancements in large language models (LLMs) pre-trained on extensive internet data have shown a promising path towards achieving this goal. Indeed, researchers have explored diverse ways of leveraging LLMs for robotics, from step-by-step planning and goal-oriented dialogue to robot-code-writing agents. 



While these methods impart new modes of compositional generalization, they focus on using lang…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ron's Princibles]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60291</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60291&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rons-princibles"/>
        <updated>2023-08-22T17:28:36.000Z</updated>
        <summary type="html"><![CDATA[Sunday's post on "Listless vessels" opened with this clip: Your browser does not support the audio element. The movement has got to be about what are you trying to achieve on behalf of the American people and that's got to be based in principle uh because if you're not rooted in principle uh if all […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Parameter-Efficient Learning Approach to Arabic Dialect Identification
  with Pre-Trained General-Purpose Speech Model]]></title>
        <id>http://arxiv.org/abs/2305.11244</id>
        <link href="http://arxiv.org/abs/2305.11244"/>
        <updated>2023-08-22T02:19:22.867Z</updated>
        <summary type="html"><![CDATA[Srijith Radhakrishnan, Chao-Han Huck Yang, Sumeer Ahmad Khan, Narsis
  A. Kiani, David Gomez-Cabrero, Jesper N. Tegner]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Rate Schedules in the Presence of Distribution Shift]]></title>
        <id>http://arxiv.org/abs/2303.15634</id>
        <link href="http://arxiv.org/abs/2303.15634"/>
        <updated>2023-08-22T02:19:22.850Z</updated>
        <summary type="html"><![CDATA[Matthew Fahrbach, Adel Javanmard, Vahab Mirrokni, Pratik Worah]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Toward Transparent AI: A Survey on Interpreting the Inner Structures of
  Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2207.13243</id>
        <link href="http://arxiv.org/abs/2207.13243"/>
        <updated>2023-08-22T02:19:22.682Z</updated>
        <summary type="html"><![CDATA[Tilman R\"auker, Anson Ho, Stephen Casper, Dylan Hadfield-Menell]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes
  based on a Hybrid Spectral Method and the Harmonic Oscillator]]></title>
        <id>http://arxiv.org/abs/2302.09580</id>
        <link href="http://arxiv.org/abs/2302.09580"/>
        <updated>2023-08-22T02:19:22.670Z</updated>
        <summary type="html"><![CDATA[Dionissios T.Hristopulos]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GradientCoin: A Peer-to-Peer Decentralized Large Language Models]]></title>
        <id>http://arxiv.org/abs/2308.10502</id>
        <link href="http://arxiv.org/abs/2308.10502"/>
        <updated>2023-08-22T02:19:22.473Z</updated>
        <summary type="html"><![CDATA[Yeqi Gao, Zhao Song, Junze Yin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The President [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53836</id>
        <link href="https://xianblog.wordpress.com/2023/08/22/the-president-jatp/"/>
        <updated>2023-08-21T22:23:41.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Defining a New Dialect]]></title>
        <id>https://jeremykun.com/?p=119602</id>
        <link href="https://jeremykun.com/2023/08/21/mlir-defining-a-new-dialect/"/>
        <updated>2023-08-21T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents In the last article in the series, we migrated the passes we had written to use the tablegen code generation framework. That was a preface to using tablegen to define dialects. In this article we’ll define a dialect that represents arithmetic on single-variable polynomials, with coefficients in $\mathbb{Z} / 2^{32} \mathbb{Z}$ (32-bit […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Tocharian Trek:  PIE and migration across Eurasia]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60244</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60244&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-tocharian-trek-pie-and-migration-across-eurasia"/>
        <updated>2023-08-21T14:29:48.000Z</updated>
        <summary type="html"><![CDATA[In recent weeks and months, Language Log has been quite active in discussions on Tocharian and its relationship to other members of Indo-European.  Today's post takes a different approach from this post made just yesterday and many earlier posts. "Europe's ancient languages shed light on a great migration and weather vocabulary" by Ali Jones, Horizon: […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at Interspeech 2023]]></title>
        <id>http://blog.research.google/2023/08/google-at-interspeech-2023.html</id>
        <link href="http://blog.research.google/2023/08/google-at-interspeech-2023.html"/>
        <updated>2023-08-21T07:33:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Catherine Armato, Program Manager, Google




This week, the 24th Annual Conference of the International Speech Communication Association (INTERSPEECH 2023) is being held in Dublin, Ireland, representing one of the world’s most extensive conferences on research and technology of spoken language understanding and processing. Experts in speech-related research fields gather to take part in oral presentations and poster sessions and to build collaborations across the globe.




We are excited to be a Platinum Sponsor of INTERSPEECH 2023, where we will be showcasing more than 20 research publications and supporting a number of workshops and special sessions. We welcome in-person attendees to drop by the Google Research booth to meet our researchers and participate in Q&As and demonst…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at Interspeech 2023]]></title>
        <id>http://ai.googleblog.com/2023/08/google-at-interspeech-2023.html</id>
        <link href="http://ai.googleblog.com/2023/08/google-at-interspeech-2023.html"/>
        <updated>2023-08-21T07:33:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Catherine Armato, Program Manager, Google




This week, the 24th Annual Conference of the International Speech Communication Association (INTERSPEECH 2023) is being held in Dublin, Ireland, representing one of the world’s most extensive conferences on research and technology of spoken language understanding and processing. Experts in speech-related research fields gather to take part in oral presentations and poster sessions and to build collaborations across the globe.




We are excited to be a Platinum Sponsor of INTERSPEECH 2023, where we will be showcasing more than 20 research publications and supporting a number of workshops and special sessions. We welcome in-person attendees to drop by the Google Research booth to meet our researchers and participate in Q&As and demonst…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The rightness of the Riemann Hypothesis]]></title>
        <id>http://arxiv.org/abs/1608.03199</id>
        <link href="http://arxiv.org/abs/1608.03199"/>
        <updated>2023-08-21T05:13:37.677Z</updated>
        <summary type="html"><![CDATA[Shaoyong Lai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Strong boundedness of simply connected split Chevalley groups defined
  over rings]]></title>
        <id>http://arxiv.org/abs/2004.05039</id>
        <link href="http://arxiv.org/abs/2004.05039"/>
        <updated>2023-08-21T05:13:37.670Z</updated>
        <summary type="html"><![CDATA[Alexander Alois Trost]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A certain structure of Artin groups and the isomorphism conjecture]]></title>
        <id>http://arxiv.org/abs/1811.11589</id>
        <link href="http://arxiv.org/abs/1811.11589"/>
        <updated>2023-08-21T05:13:37.663Z</updated>
        <summary type="html"><![CDATA[S. K. Roushon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantisation of derived Poisson structures]]></title>
        <id>http://arxiv.org/abs/1708.00496</id>
        <link href="http://arxiv.org/abs/1708.00496"/>
        <updated>2023-08-21T05:13:37.655Z</updated>
        <summary type="html"><![CDATA[J.P.Pridham]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lie, associative and commutative quasi-isomorphism]]></title>
        <id>http://arxiv.org/abs/1904.03585</id>
        <link href="http://arxiv.org/abs/1904.03585"/>
        <updated>2023-08-21T05:13:37.458Z</updated>
        <summary type="html"><![CDATA[Ricardo Campos, Dan Petersen, Daniel Robert-Nicoud, Felix Wierstra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FeDXL: Provable Federated Learning for Deep X-Risk Optimization]]></title>
        <id>http://arxiv.org/abs/2210.14396</id>
        <link href="http://arxiv.org/abs/2210.14396"/>
        <updated>2023-08-21T03:14:40.027Z</updated>
        <summary type="html"><![CDATA[Zhishuai Guo, Rong Jin, Jiebo Luo, Tianbao Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model
  And Gaussian Mixture Embedding For Neural Network]]></title>
        <id>http://arxiv.org/abs/2308.09444</id>
        <link href="http://arxiv.org/abs/2308.09444"/>
        <updated>2023-08-21T03:14:40.020Z</updated>
        <summary type="html"><![CDATA[Weiguo Lu, Xuan Wu, Deng Ding, Gangnan Yuan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solving PDEs on Spheres with Physics-Informed Convolutional Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2308.09605</id>
        <link href="http://arxiv.org/abs/2308.09605"/>
        <updated>2023-08-21T03:14:38.699Z</updated>
        <summary type="html"><![CDATA[Guanhang Lei, Zhen Lei, Lei Shi, Chenyu Zeng, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on
  GLMs and multi-index models]]></title>
        <id>http://arxiv.org/abs/2308.08977</id>
        <link href="http://arxiv.org/abs/2308.08977"/>
        <updated>2023-08-21T03:14:38.692Z</updated>
        <summary type="html"><![CDATA[Elizabeth Collins-Woodfin, Courtney Paquette, Elliot Paquette, Inbar
  Seroussi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noise Sensitivity and Stability of Deep Neural Networks for Binary
  Classification]]></title>
        <id>http://arxiv.org/abs/2308.09374</id>
        <link href="http://arxiv.org/abs/2308.09374"/>
        <updated>2023-08-21T03:14:38.671Z</updated>
        <summary type="html"><![CDATA[Johan Jonasson, Jeffrey E. Steif, Olof Zetterqvist]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=53509</id>
        <link href="https://xianblog.wordpress.com/2023/08/21/a-journal-of-the-conquest-war-famine-and-death-year-3/"/>
        <updated>2023-08-20T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[Read at last the (disappointing) last tome of Christelle Dabos’ The Mirror Visitor, The Storm of Echoes, as I find the unravelling of the story unbearably slow and poorly constructed, contrasting with the earlier volumes where the universe building was central to the appeal of the series. Here it is collapsing, literally and figuratively. Without […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Val de Montferrand [bergerie de l’Hortus]]]></title>
        <id>http://xianblog.wordpress.com/?p=53028</id>
        <link href="https://xianblog.wordpress.com/2023/08/20/val-de-montferrand-bergerie-de-lhortus/"/>
        <updated>2023-08-20T18:20:43.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Listless vessels]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60245</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60245&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=listless-vessels"/>
        <updated>2023-08-20T15:11:05.000Z</updated>
        <summary type="html"><![CDATA[In an interview on Friday ("DeSantis plans to do what Trump couldn't | Full Interview with Will Witt", The Florida Standard 8/18/2023), Ron DeSantis referred to (some of?) Donald Trump's followers as "listless vessels": Your browser does not support the audio element. The movement has got to be about what are you trying to achieve […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The origins and affinities of Tocharian]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60225</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60225&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-origins-and-affinities-of-tocharian"/>
        <updated>2023-08-20T13:23:38.000Z</updated>
        <summary type="html"><![CDATA[I asked several IEist colleagues: Of all the IE languages, which one is Tocharian closest to? Celtic? Germanic? Answers received: James P. Mallory: I can't answer that but since almost all the phylogenies have it leaving after Anatolian one could argue that it does not actually have any close relatives, i.e., it was never really […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A sign of the future?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60221</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60221&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-sign-of-the-future"/>
        <updated>2023-08-19T12:03:58.000Z</updated>
        <summary type="html"><![CDATA[Anemona Hartocollis, "Slashing Its Budget, West Virginia University Asks, What Is Essential?", NYT 8/18/2023: The state’s flagship school will no longer teach world languages or creative writing — a sign, its president says, of the future at many public universities. Christian Adams wants to be an immigration or labor lawyer, so he planned to major […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Axing languages and linguistics at West Virginia University]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60207</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60207&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=axing-languages-and-linguistics-at-west-virginia-university"/>
        <updated>2023-08-19T11:39:22.000Z</updated>
        <summary type="html"><![CDATA[From M. Paul Shore: Article that appeared on the Washington Post website this morning (and is therefore likely to appear in tomorrow's print edition) about the recently proposed demise of, among other things, the Department of World Languages, Literatures and Linguistics at West Virginia University's flagship Morgantown campus (note that that department name really should be […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kelowna two weeks later]]></title>
        <id>http://xianblog.wordpress.com/?p=53819</id>
        <link href="https://xianblog.wordpress.com/2023/08/19/kelowna-two-weeks-later/"/>
        <updated>2023-08-18T22:23:14.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI hype #∞]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60209</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60209&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-hype"/>
        <updated>2023-08-18T19:37:27.000Z</updated>
        <summary type="html"><![CDATA[In social and even mass media, you may have seen coverage of a recent paper by Joshua Harrison et al., "A Practical Deep Learning-Based Acoustic Side Channel Attack on Keyboards". Some samples of the clickbait: "A.I. can identify keystrokes by just the sound of your typing and steal information with 95% accuracy, new research shows", […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Autonomous visual information seeking with large language models]]></title>
        <id>http://blog.research.google/2023/08/autonomous-visual-information-seeking.html</id>
        <link href="http://blog.research.google/2023/08/autonomous-visual-information-seeking.html"/>
        <updated>2023-08-18T18:28:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Ziniu Hu, Student Researcher, and Alireza Fathi, Research Scientist, Google Research, Perception Team




There has been great progress towards adapting large language models (LLMs) to accommodate multimodal inputs for tasks including image captioning, visual question answering (VQA), and open vocabulary recognition. Despite such achievements, current state-of-the-art visual language models (VLMs) perform inadequately on visual information seeking datasets, such as Infoseek and OK-VQA, where external knowledge is required to answer the questions. 
 






Examples of visual information seeking queries where external knowledge is required to answer the question. Images are taken from the OK-VQA dataset.

AVIS: Autonomous Visual Information Seeking with Large Language Models”, we i…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Autonomous visual information seeking with large language models]]></title>
        <id>http://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html</id>
        <link href="http://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html"/>
        <updated>2023-08-18T18:28:00.004Z</updated>
        <summary type="html"><![CDATA[Posted by Ziniu Hu, Student Researcher, and Alireza Fathi, Research Scientist, Google Research, Perception Team




There has been great progress towards adapting large language models (LLMs) to accommodate multimodal inputs for tasks including image captioning, visual question answering (VQA), and open vocabulary recognition. Despite such achievements, current state-of-the-art visual language models (VLMs) perform inadequately on visual information seeking datasets, such as Infoseek and OK-VQA, where external knowledge is required to answer the questions. 
 






Examples of visual information seeking queries where external knowledge is required to answer the question. Images are taken from the OK-VQA dataset.

AVIS: Autonomous Visual Information Seeking with Large Language Models”, we i…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nasality]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60201</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60201&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=nasality"/>
        <updated>2023-08-18T08:58:13.000Z</updated>
        <summary type="html"><![CDATA[Acoustically and phonetically, how do you account for its similarity in music and linguistics?   Selected readings "'Sound' at the center, 'horn' at the periphery: the shawm and its eastern cousins, part 2" (11/19/22) "The shawm and its eastern cousins" (11/16/15) "Allergese" (4/30/15) "Drawl from all over? (9/20/12)]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Canmore Xing [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53806</id>
        <link href="https://xianblog.wordpress.com/2023/08/18/canmore-xing-jatp/"/>
        <updated>2023-08-17T22:23:32.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Max-affine regression via first-order methods]]></title>
        <id>http://arxiv.org/abs/2308.08070</id>
        <link href="http://arxiv.org/abs/2308.08070"/>
        <updated>2023-08-17T21:11:57.321Z</updated>
        <summary type="html"><![CDATA[Seonho Kim, Kiryung Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simple online learning with consistency oracle]]></title>
        <id>http://arxiv.org/abs/2308.08055</id>
        <link href="http://arxiv.org/abs/2308.08055"/>
        <updated>2023-08-17T21:11:56.583Z</updated>
        <summary type="html"><![CDATA[Alexander Kozachinskiy, Tomasz Steifer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classification of Data Generated by Gaussian Mixture Models Using Deep
  ReLU Networks]]></title>
        <id>http://arxiv.org/abs/2308.08030</id>
        <link href="http://arxiv.org/abs/2308.08030"/>
        <updated>2023-08-17T21:11:56.566Z</updated>
        <summary type="html"><![CDATA[Tian-Yi Zhou, Xiaoming Huo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Ability of Interpolating Deep Convolutional Neural Networks]]></title>
        <id>http://arxiv.org/abs/2210.14184</id>
        <link href="http://arxiv.org/abs/2210.14184"/>
        <updated>2023-08-17T21:11:56.561Z</updated>
        <summary type="html"><![CDATA[Tian-Yi Zhou, Xiaoming Huo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural network pruning with combinatorial optimization]]></title>
        <id>http://blog.research.google/2023/08/neural-network-pruning-with.html</id>
        <link href="http://blog.research.google/2023/08/neural-network-pruning-with.html"/>
        <updated>2023-08-17T18:08:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Hussein Hazimeh, Research Scientist, Athena Team, and Riade Benbaki, Graduate Student at MIT





Modern neural networks have achieved impressive performance across a variety of applications, such as language, mathematical reasoning, and vision. However, these networks often use large architectures that require lots of computational resources. This can make it impractical to serve such models to users, especially in resource-constrained environments like wearables and smartphones. A widely used approach to mitigate the inference costs of pre-trained networks is to prune them by removing some of their weights, in a way that doesn’t significantly affect utility. In standard neural networks, each weight defines a connection between two neurons. So after weights are pruned, the input…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural network pruning with combinatorial optimization]]></title>
        <id>http://ai.googleblog.com/2023/08/neural-network-pruning-with.html</id>
        <link href="http://ai.googleblog.com/2023/08/neural-network-pruning-with.html"/>
        <updated>2023-08-17T18:08:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Hussein Hazimeh, Research Scientist, Athena Team, and Riade Benbaki, Graduate Student at MIT





Modern neural networks have achieved impressive performance across a variety of applications, such as language, mathematical reasoning, and vision. However, these networks often use large architectures that require lots of computational resources. This can make it impractical to serve such models to users, especially in resource-constrained environments like wearables and smartphones. A widely used approach to mitigate the inference costs of pre-trained networks is to prune them by removing some of their weights, in a way that doesn’t significantly affect utility. In standard neural networks, each weight defines a connection between two neurons. So after weights are pruned, the input…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pork Lion Bone]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60183</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60183&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pork-lion-bone"/>
        <updated>2023-08-17T15:12:12.000Z</updated>
        <summary type="html"><![CDATA[Seen by François Lang at the meat counter at The Great Wall in Rockville, MD: François remarks:  "It took me a minute to realize that the sign meant 'Loin Bone'!" The Chinese characters say: lónggǔ 龍骨 "dragon bone" In different contexts, that can also mean "keel (beam along the underside of a ship’s hull); fossil bones […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Teaching Taiwanese in France]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60198</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60198&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=teaching-taiwanese-in-france"/>
        <updated>2023-08-17T13:07:58.000Z</updated>
        <summary type="html"><![CDATA[Taiwanese may be fading in Taiwan (see "Selected Readings" below; except for foreign diplomats and the like!), but in France it is thriving: "Language of our own: Fun Taiwanese classes gain popularity in France" By Tseng Ting-hsuan and James Lo, Focus Taiwan (8/10/2023) In a classroom in Paris, Taiwan's top envoy to France François Wu […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reflections on “Making the Atomic Bomb”]]></title>
        <id>http://windowsontheory.org/?p=8674</id>
        <link href="https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/"/>
        <updated>2023-08-17T02:47:58.000Z</updated>
        <summary type="html"><![CDATA[[Cross posted on lesswrong; see here for my prior writings]  [it appears almost certain that in the immediate future, it would be] possible to set up a nuclear chain reaction in a large mass of uranium by which vast amounts of power and large quantities of new radium-like elements would be generated. Letter from Albert Einstein (prepared by … Continue reading Reflections on “Making the Atomic Bomb”]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reflections on “Making the Atomic Bomb”]]></title>
        <id>http://windowsontheory.org/?p=8674</id>
        <link href="https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/"/>
        <updated>2023-08-17T02:47:58.000Z</updated>
        <summary type="html"><![CDATA[[Cross posted on lesswrong; see here for my prior writings]  [it appears almost certain that in the immediate future, it would be] possible to set up a nuclear chain reaction in a large mass of uranium by which vast amounts of power and large quantities of new radium-like elements would be generated. Letter from Albert Einstein (prepared by … Continue reading Reflections on “Making the Atomic Bomb”]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mike’s obituary in the IMS Bulletin]]></title>
        <id>http://xianblog.wordpress.com/?p=53703</id>
        <link href="https://xianblog.wordpress.com/2023/08/17/mikes-obituary-in-the-ims-bulletin/"/>
        <updated>2023-08-16T22:23:17.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stan Carey on "greenlit"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60190</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60190&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=stan-carey-on-greenlit"/>
        <updated>2023-08-16T12:17:49.000Z</updated>
        <summary type="html"><![CDATA[From Stan Carey at Sentence First, a lucid and deeply empirical dive into the question "Has ‘greenlit’ been greenlighted?". Stan explores a wide variety of relevant corpus data, both historical and otherwise, providing a lovely illustration of how accessible such resources have become. And at the end, one of his commenters points him to an […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[misty Grassy Bay [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53800</id>
        <link href="https://xianblog.wordpress.com/2023/08/16/misty-grassy-bay-jatp/"/>
        <updated>2023-08-15T22:23:39.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[STUDY: Socially aware temporally causal decoder recommender systems]]></title>
        <id>http://blog.research.google/2023/08/study-socially-aware-temporally-causal.html</id>
        <link href="http://blog.research.google/2023/08/study-socially-aware-temporally-causal.html"/>
        <updated>2023-08-15T19:59:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Eltayeb Ahmed, Research Engineer, and Subhrajit Roy, Senior Research Scientist, Google Research




Reading has many benefits for young students, such as better linguistic and life skills, and reading for pleasure has been shown to correlate with academic success. Furthermore students have reported improved emotional wellbeing from reading, as well as better general knowledge and better understanding of other cultures. With the vast amount of reading material both online and off, finding age-appropriate, relevant and engaging content can be a challenging task, but helping students do so is a necessary step to engage them in reading. Effective recommendations that present students with relevant reading material helps keep students reading, and this is where machine learning (ML) c…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[STUDY: Socially aware temporally causal decoder recommender systems]]></title>
        <id>http://ai.googleblog.com/2023/08/study-socially-aware-temporally-causal.html</id>
        <link href="http://ai.googleblog.com/2023/08/study-socially-aware-temporally-causal.html"/>
        <updated>2023-08-15T19:59:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Eltayeb Ahmed, Research Engineer, and Subhrajit Roy, Senior Research Scientist, Google Research




Reading has many benefits for young students, such as better linguistic and life skills, and reading for pleasure has been shown to correlate with academic success. Furthermore students have reported improved emotional wellbeing from reading, as well as better general knowledge and better understanding of other cultures. With the vast amount of reading material both online and off, finding age-appropriate, relevant and engaging content can be a challenging task, but helping students do so is a necessary step to engage them in reading. Effective recommendations that present students with relevant reading material helps keep students reading, and this is where machine learning (ML) c…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bilingual wordplay on a Taipei sign]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60178</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60178&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bilingual-wordplay-on-a-taipei-sign"/>
        <updated>2023-08-15T12:56:42.000Z</updated>
        <summary type="html"><![CDATA[From Tom Mazanac: I came across this sign on the subway recently: Tom explains: It's an ad for the waterpark (which my children love), but what struck me most was the bilingual wordplay in the middle: 夏天Want to 水, above which is written "1 2 3", which I think is supposed to sound like "want to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Probabilistic Analysis of Edge Elimination for Euclidean TSP]]></title>
        <id>http://arxiv.org/abs/1809.10469</id>
        <link href="http://arxiv.org/abs/1809.10469"/>
        <updated>2023-08-15T03:14:32.337Z</updated>
        <summary type="html"><![CDATA[Xianghui Zhong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Smoothing finite group actions on three-manifolds]]></title>
        <id>http://arxiv.org/abs/1901.11127</id>
        <link href="http://arxiv.org/abs/1901.11127"/>
        <updated>2023-08-15T03:14:32.317Z</updated>
        <summary type="html"><![CDATA[John Pardon]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Generalised Colouring Numbers of Graphs that Exclude a Fixed
  Minor]]></title>
        <id>http://arxiv.org/abs/1602.09052</id>
        <link href="http://arxiv.org/abs/1602.09052"/>
        <updated>2023-08-15T03:14:32.300Z</updated>
        <summary type="html"><![CDATA[Jan van den Heuvel, Patrice Ossona de Mendez, Daniel Quiroz, Roman
  Rabinovich, Sebastian Siebertz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Proper equivariant stable homotopy theory]]></title>
        <id>http://arxiv.org/abs/1908.00779</id>
        <link href="http://arxiv.org/abs/1908.00779"/>
        <updated>2023-08-15T03:14:32.294Z</updated>
        <summary type="html"><![CDATA[Dieter Degrijse, Markus Hausmann, Wolfgang L\"uck, Irakli Patchkoria,
  Stefan Schwede]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The eight Cayley-Dickson doubling products]]></title>
        <id>http://arxiv.org/abs/1707.07318</id>
        <link href="http://arxiv.org/abs/1707.07318"/>
        <updated>2023-08-15T03:14:32.272Z</updated>
        <summary type="html"><![CDATA[John W. Bales]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Approximation and Non-parametric Estimation of ResNet-type Convolutional
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/1903.10047</id>
        <link href="http://arxiv.org/abs/1903.10047"/>
        <updated>2023-08-15T02:18:45.906Z</updated>
        <summary type="html"><![CDATA[Kenta Oono, Taiji Suzuki]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PAC-Bayesian Generalization Bounds for Adversarial Generative Models]]></title>
        <id>http://arxiv.org/abs/2302.08942</id>
        <link href="http://arxiv.org/abs/2302.08942"/>
        <updated>2023-08-15T02:18:45.900Z</updated>
        <summary type="html"><![CDATA[Sokhna Diarra Mbacke, Florence Clerc, Pascal Germain]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of
  Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation]]></title>
        <id>http://arxiv.org/abs/2308.06422</id>
        <link href="http://arxiv.org/abs/2308.06422"/>
        <updated>2023-08-15T02:18:45.879Z</updated>
        <summary type="html"><![CDATA[Seyedarmin Azizi, Mahdi Nazemi, Arash Fayyazi, Massoud Pedram]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via
  Mixed-Effect Models and Hierarchical Clustering]]></title>
        <id>http://arxiv.org/abs/2308.06399</id>
        <link href="http://arxiv.org/abs/2308.06399"/>
        <updated>2023-08-15T02:18:45.872Z</updated>
        <summary type="html"><![CDATA[Lorenzo Vallegi, Marco Scutari, Federico Mattia Stefanini]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prince Rupert murals]]></title>
        <id>http://xianblog.wordpress.com/?p=53793</id>
        <link href="https://xianblog.wordpress.com/2023/08/15/prince-rupert-murals/"/>
        <updated>2023-08-14T22:23:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The new, enhanced / advanced quiet luxury language of pèihuò 配货]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60159</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60159&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-new-enhanced-advanced-quiet-luxury-language-of-peihuo-%25e9%2585%258d%25e8%25b4%25a7"/>
        <updated>2023-08-14T17:57:54.000Z</updated>
        <summary type="html"><![CDATA["Pèihuò 配货" is not a new term to me.  I knew it quite a while ago as it is used in supply chain studies with the meaning of "distribution; prepare goods for delivery according to an order"), as in the expression "pèihuò zhōngxīn 配货中心" ("distribution center").  Now, though, it has morphed into something altogether different. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DARPA/Dartmouth one/won …]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60168</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60168&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=darpa-dartmouth-one-won"/>
        <updated>2023-08-14T11:17:31.000Z</updated>
        <summary type="html"><![CDATA[Despite the evidence of my most recent relevant post, the best current speech-to-text systems still make mistakes that a literate and informed human wouldn't. In this recent YouTube video on the history of robotics research, the automatic closed-captioning system renders "DARPA" as "Dartmouth": The audio is clear enough: Your browser does not support the audio […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer升级之路：13、逆用Leaky ReRoPE]]></title>
        <id>https://kexue.fm/archives/9728</id>
        <link href="https://kexue.fm/archives/9728"/>
        <updated>2023-08-14T03:53:00.000Z</updated>
        <summary type="html"><![CDATA[上周在《Transformer升级之路：12、无限外推的ReRoPE？》中，笔者提出了ReRoPE和Leaky ReRoPE，诸多实验结果表明，它们能够在几乎不损失训练效果的情况下免微调地扩展L...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Application of Artificial Neural Networks for Investigation of Pressure
  Filtration Performance, a Zinc Leaching Filter Cake Moisture Modeling]]></title>
        <id>http://arxiv.org/abs/2308.06138</id>
        <link href="http://arxiv.org/abs/2308.06138"/>
        <updated>2023-08-14T02:19:10.155Z</updated>
        <summary type="html"><![CDATA[Masoume Kazemi, Davood Moradkhani, Alireza A. Alipour]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trained Transformers Learn Linear Models In-Context]]></title>
        <id>http://arxiv.org/abs/2306.09927</id>
        <link href="http://arxiv.org/abs/2306.09927"/>
        <updated>2023-08-14T02:19:10.147Z</updated>
        <summary type="html"><![CDATA[Ruiqi Zhang, Spencer Frei, Peter L. Bartlett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Collaborative Learning with a Drone Orchestrator]]></title>
        <id>http://arxiv.org/abs/2303.02266</id>
        <link href="http://arxiv.org/abs/2303.02266"/>
        <updated>2023-08-14T02:19:10.125Z</updated>
        <summary type="html"><![CDATA[Mahdi Boloursaz Mashhadi, Mahnoosh Mahdavimoghadam, Rahim Tafazolli,
  Walid Saad]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Law of Data Separation in Deep Learning]]></title>
        <id>http://arxiv.org/abs/2210.17020</id>
        <link href="http://arxiv.org/abs/2210.17020"/>
        <updated>2023-08-14T02:19:10.119Z</updated>
        <summary type="html"><![CDATA[Hangfeng He, Weijie J. Su]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a storm is coming [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53787</id>
        <link href="https://xianblog.wordpress.com/2023/08/14/a-storm-is-coming-jatp/"/>
        <updated>2023-08-13T22:23:40.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language and politics: The use of English "OR" in Chinese official propaganda]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60134</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60134&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-and-politics-the-use-of-english-or-in-chinese-official-propaganda"/>
        <updated>2023-08-13T15:37:15.000Z</updated>
        <summary type="html"><![CDATA[From the weibo of People's Daily  (Rénmín rìbào 人民日報): Here are all four pairs of questions separated by English "OR": 1. jūnshì àihàozhě ？OR jiāndié guāncháshào ？ 军事爱好者？ OR 间谍观察哨？ "Military enthusiasts? OR Spy observation sentinel?" 2. wǎngluò jiāoyǒu ？OR wǎngluò gōulián ? 网络交友？ OR 网络勾连？ "Online dating / friend-making? OR Online colluding?" 3. xuéshù jiāoliú ？OR qièmì […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Elevator etiquette and rules (lots of 'em)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60113</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60113&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=elevator-etiquette-and-rules-lots-of-em"/>
        <updated>2023-08-13T15:32:32.000Z</updated>
        <summary type="html"><![CDATA[On the inside (N.B.) doors of a lift in Wuhan (yes that [in]famous Wuhan): I will first romanize, transcribe, and translate all six of the signs, from top left to bottom right, then I will provide annotations and explanations: 1. yánjìn pāidǎ 严禁拍打 "slapping / swatting / flapping / patting / tapping / thwacking / beating / […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Irish accents]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60156</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60156&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=irish-accents"/>
        <updated>2023-08-13T13:15:17.000Z</updated>
        <summary type="html"><![CDATA["Lost in translation — navigating accents in a changing world" Joe Horgan, Irish Post (8/7/23) An engaging story: WHEN I first started associating with English people I had to translate when my father spoke to them. I’d grown up in a very large Irish community in an immigrant area in an English city and it […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Structural and Optical Properties of Spin-Coated Mn$_3$O$_4$ Thin Films
  of Different Coating Layers]]></title>
        <id>http://arxiv.org/abs/2308.05728</id>
        <link href="http://arxiv.org/abs/2308.05728"/>
        <updated>2023-08-13T01:04:49.952Z</updated>
        <summary type="html"><![CDATA[Vidit Pandey, Mohd Salman Siddiqui, Sandeep Munjal, Tufail Ahmad]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Preemptive Detection of Fake Accounts on Social Networks via Multi-Class
  Preferential Attachment Classifiers]]></title>
        <id>http://arxiv.org/abs/2308.05353</id>
        <link href="http://arxiv.org/abs/2308.05353"/>
        <updated>2023-08-13T01:04:49.930Z</updated>
        <summary type="html"><![CDATA[Adam Breuer, Nazanin Khosravani, Michael Tingley, Bradford Cottel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gauged $SU(3)_F$ and loop induced quark and lepton masses]]></title>
        <id>http://arxiv.org/abs/2308.05642</id>
        <link href="http://arxiv.org/abs/2308.05642"/>
        <updated>2023-08-13T01:04:49.923Z</updated>
        <summary type="html"><![CDATA[Gurucharan Mohanta, Ketan M. Patel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[classic postcard [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53769</id>
        <link href="https://xianblog.wordpress.com/2023/08/13/classic-postcard-jatp/"/>
        <updated>2023-08-12T22:23:02.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Text orientation ambiguity]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60150</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60150&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=text-orientation-ambiguity"/>
        <updated>2023-08-12T19:47:25.000Z</updated>
        <summary type="html"><![CDATA[Perhaps Victor can point us to an analogous ambiguity in Chinese poetico-political history: The source is this tweet. (oO this X?). Although I don't think I've seen it before, this pattern should be pretty common: BAD NAME1 NAME2 GOOD]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[More on LLMs' current problem-solving abilities]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60141</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60141&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=more-on-llms-current-problem-solving-abilities"/>
        <updated>2023-08-12T16:46:45.000Z</updated>
        <summary type="html"><![CDATA[It's hard to keep up with the waves of hype and anti-hype in the LLM space these days. Here's something from a few weeks ago that I missed — Xiaoxuan Wang et al., "SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models", arxiv.org 7/20/2023: Abstract: Recent advances in large language models (LLMs) have demonstrated […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Voilà!]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60120</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60120&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=voila"/>
        <updated>2023-08-12T14:38:39.000Z</updated>
        <summary type="html"><![CDATA[I've always been fond of this pretty, little word, but I seldom use it in my own speech (maybe once every five or ten years), because it seems too triumphant.  This morning, however, after a long, numerical list of steps that some colleagues and I need to take, followed by a conclusion we wished to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Golden dawn [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53760</id>
        <link href="https://xianblog.wordpress.com/2023/08/12/golden-dawn-jatp/"/>
        <updated>2023-08-11T22:23:46.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The state of speech-to-text]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60122</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60122&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-state-of-speech-to-text"/>
        <updated>2023-08-11T21:05:39.000Z</updated>
        <summary type="html"><![CDATA[…if you haven't noticed, is good. There are many applications, from conversing with Siri and Alexa and Google Assistant, to getting voicemail in textual form, to automatically generated subtitles, and so on. For linguists, one parochial (but important) application is accurate automatic transcription of speech corpora, and the example that motivates this post comes from […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cheerful news in difficult times: David Conlon and Jeck Lim settled Kupitz’s planar discrepancy problem for pseudolines.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24665</id>
        <link href="https://gilkalai.wordpress.com/2023/08/11/cheerful-news-in-difficult-times-david-conlon-and-jeck-lim-settled-kupitzs-planar-discrepancy-problem-for-pseudolines/"/>
        <updated>2023-08-11T10:56:48.000Z</updated>
        <summary type="html"><![CDATA[Small updates. I wrote a post about the overwhelming mathematical activities in the lat week of April 2023 and the following weeks were as exciting. It was difficult to follow all the activities (not to mention blogging about them). Let … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cheerful news in difficult times: David Conlon and Jeck Lim settled Kupitz’s planar discrepancy problem for pseudolines.]]></title>
        <id>http://gilkalai.wordpress.com/?p=24665</id>
        <link href="https://gilkalai.wordpress.com/2023/08/11/cheerful-news-in-difficult-times-david-conlon-and-jeck-lim-settled-kupitzs-planar-discrepancy-problem-for-pseudolines/"/>
        <updated>2023-08-11T10:56:48.000Z</updated>
        <summary type="html"><![CDATA[Small updates. I wrote a post about the overwhelming mathematical activities in the lat week of April 2023 and the following weeks were as exciting. It was difficult to follow all the activities (not to mention blogging about them). Let … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning ground states of gapped quantum Hamiltonians with Kernel
  Methods]]></title>
        <id>http://arxiv.org/abs/2303.08902</id>
        <link href="http://arxiv.org/abs/2303.08902"/>
        <updated>2023-08-11T02:18:06.059Z</updated>
        <summary type="html"><![CDATA[Clemens Giuliani, Filippo Vicentini, Riccardo Rossi, Giuseppe Carleo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Networks for Scalar Input and Functional Output]]></title>
        <id>http://arxiv.org/abs/2208.05776</id>
        <link href="http://arxiv.org/abs/2208.05776"/>
        <updated>2023-08-11T02:18:05.885Z</updated>
        <summary type="html"><![CDATA[Sidi Wu, C\'edric Beaulac, Jiguo Cao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Updating Clinical Risk Stratification Models Using Rank-Based
  Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team
  Performance]]></title>
        <id>http://arxiv.org/abs/2308.05619</id>
        <link href="http://arxiv.org/abs/2308.05619"/>
        <updated>2023-08-11T02:18:05.874Z</updated>
        <summary type="html"><![CDATA[Erkin \"Otle\c{s}, Brian T. Denton, Jenna Wiens]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ta Mother Noodle]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60106</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60106&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ta-mother-noodle"/>
        <updated>2023-08-10T23:25:27.000Z</updated>
        <summary type="html"><![CDATA[Sign on a noodle shop in Xindan, Taiwan: (Via Google Street View) Mark Swofford has written a nice post about this on Pinyin News:  "Mother-effing noodles". As anyone who has studied more than a few months of Chinese or is a regular Language Log reader knows, "his mother's" (tāmā de) is China's "national swear" (see […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[wood and orphan bears]]></title>
        <id>http://xianblog.wordpress.com/?p=53780</id>
        <link href="https://xianblog.wordpress.com/2023/08/11/wood-and-orphan-bears/"/>
        <updated>2023-08-10T22:23:35.000Z</updated>
        <summary type="html"><![CDATA[On the trail to Burgess Pass,we passed this wooden structure that had something bearish in it (at least in my short-sighted view!). And the day after, saw this 21 year old grizzly bear in an orphan bear refuge where he had spent most of his life after his mother was killed by a hunter. Magnificent […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Using Tablegen for Passes]]></title>
        <id>https://jeremykun.com/?p=119631</id>
        <link href="https://jeremykun.com/2023/08/10/mlir-using-tablegen-for-passes/"/>
        <updated>2023-08-10T21:41:45.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents In the last article in this series, we defined some custom lowering passes that modified an MLIR program. Notably, we accomplished that by implementing the required interfaces of the MLIR API directly. This is not the way that most MLIR developers work. Instead, they use a code generation tool called tablegen to […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Writing Our First Pass]]></title>
        <id>https://jeremykun.com/?p=119490</id>
        <link href="https://jeremykun.com/2023/08/10/mlir-writing-our-first-pass/"/>
        <updated>2023-08-10T21:39:42.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents This series is an introduction to MLIR and an onboarding tutorial for the HEIR project. Last time we saw how to run and test a basic lowering. This time we will write some simple passes to illustrate the various parts of the MLIR API and the pass infrastructure. As mentioned previously, the […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Running and Testing a Lowering]]></title>
        <id>https://jeremykun.com/?p=119430</id>
        <link href="https://jeremykun.com/2023/08/10/mlir-running-and-testing-a-lowering/"/>
        <updated>2023-08-10T21:36:13.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents Last time, we covered a Bazel build system setup for an MLIR project. This time we’ll give an overview of a simple lowering and show how end-to-end tests work in MLIR. All of the code for this article is contained in this pull request on GitHub, and the commits are nicely organized […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLIR — Getting Started]]></title>
        <id>https://jeremykun.com/?p=119363</id>
        <link href="https://jeremykun.com/2023/08/10/mlir-getting-started/"/>
        <updated>2023-08-10T21:32:33.000Z</updated>
        <summary type="html"><![CDATA[Table of Contents As we announced recently, my team at Google has started a new effort to build production-worthy engineering tools for Fully Homomorphic Encryption (FHE). One focal point of this, and one which I’ll be focusing on as long as Google is willing to pay me to do so, is building out a compiler […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chinese and Japanese Terms for Food Textures]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60110</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60110&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chinese-and-japanese-terms-for-food-textures"/>
        <updated>2023-08-10T20:19:31.000Z</updated>
        <summary type="html"><![CDATA[Catching up on some oldish e-mail, I came upon this interesting one from Francois Lang dated 5/9/23: According to an article in yesterday's NYT, "A 2008 report in the Journal of Texture Studies lists 144 Chinese terms for food texture".   The NYT article also says "In Japan, such terms number more than 400. 'Too […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google’s Recent FHE work, and starting HEIR]]></title>
        <id>https://jeremykun.com/?p=119694</id>
        <link href="https://jeremykun.com/2023/08/10/googles-recent-fhe-work-and-starting-heir/"/>
        <updated>2023-08-10T19:22:29.000Z</updated>
        <summary type="html"><![CDATA[Today my team at Google published an article on Google’s Developers Blog with some updates on what we’ve been doing with fully homomorphic encryption (FHE). There’s fun stuff in there, including work on video processing FHE, compiling ML models to FHE, an FHE implementation for TPUs, and improvements to the compiler I wrote about earlier […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PIE *gene- *gwen-]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60080</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60080&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pie-gene-gwen"/>
        <updated>2023-08-10T08:40:20.000Z</updated>
        <summary type="html"><![CDATA[I asked several Indo-Europeanist colleagues: In Hittite, Tocharian, Indo-Iranian (Indic and Persian), Greek, Albanian, Germanic, Armenian, Celtic, Anatolian, Italic, Lithuanian, Balto-Slavic, Macedonian, Phrygian, and other IE languages, do you ever find reflexes (derivatives) of these two PIE roots in close association / linkage with each other? PIE root *gene- "give birth, beget," with derivatives referring […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
</feed>