<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-06-10T09:13:50.815Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[ChatGPT does Emily Dickinson writing a recipe for Pad Thai (and haiku too)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59030</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59030&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-does-emily-dickinson-writing-a-recipe-for-pad-thai-and-haiku-too"/>
        <updated>2023-06-10T03:02:36.000Z</updated>
        <summary type="html"><![CDATA[From Scott D. Seligman via Facebook:   ChatGPT is really creeping me out. I asked it for a recipe for Pad Thai in the form of an Emily Dickinson poem. I'm no poetry maven, but the damned thing seems to have the ability to turn a phrase, at least some of the time. Below is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[statistical modeling with R [book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53183</id>
        <link href="https://xianblog.wordpress.com/2023/06/10/statistical-modeling-with-r-book-review/"/>
        <updated>2023-06-09T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[Statistical Modeling with R (A dual frequentist and Bayesian approach for life scientists) is a recent book written by Pablo Inchausti, from Uruguay. In a highly personal and congenial style (witness the preface), with references to (fiction) books that enticed me to buy them. The book was sent to me by the JASA book editor […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Imagen Editor and EditBench: Advancing and evaluating text-guided image inpainting]]></title>
        <id>http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html</id>
        <link href="http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html"/>
        <updated>2023-06-09T19:09:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Su Wang and Ceslee Montgormery, Research Engineers, Google Research





In the last few years, text-to-image generation research has seen an explosion of breakthroughs (notably, Imagen, Parti, DALL-E 2, etc.) that have naturally permeated into related topics. In particular, text-guided image editing (TGIE) is a practical task that involves editing generated and photographed visuals rather than completely redoing them. Quick, automated, and controllable editing is a convenient solution when recreating visuals would be time-consuming or infeasible (e.g., tweaking objects in vacation photos or perfecting fine-grained details on a cute pup generated from scratch). Further, TGIE represents a substantial opportunity to improve training of foundational models themselves. Multimodal mod…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-owning peeve of the week: Compersion]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59056</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59056&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=self-owning-peeve-of-the-week-compersion"/>
        <updated>2023-06-09T13:27:09.000Z</updated>
        <summary type="html"><![CDATA[Email from Florent Moncomble [links added]: A few months ago, the distinguished member of the Académie française Alain Finkielkraut was featured in a video where he deplored the loss of “a word which used to exist in the [French] language and disappeared from it”, ie. “compersion”. Apparently, little does he know that “compersion” was actually coined […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural
  Language Understanding]]></title>
        <id>http://arxiv.org/abs/2306.04933</id>
        <link href="http://arxiv.org/abs/2306.04933"/>
        <updated>2023-06-09T08:18:07.758Z</updated>
        <summary type="html"><![CDATA[Junda Wu, Tong Yu, Rui Wang, Zhao Song, Ruiyi Zhang, Handong Zhao,
  Chaochao Lu, Shuai Li, Ricardo Henao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Large Language Model Annotations for Valid Downstream Statistical
  Inference in Social Science: Design-Based Semi-Supervised Learning]]></title>
        <id>http://arxiv.org/abs/2306.04746</id>
        <link href="http://arxiv.org/abs/2306.04746"/>
        <updated>2023-06-09T08:18:07.753Z</updated>
        <summary type="html"><![CDATA[Naoki Egami, Musashi Jacobs-Harukawa, Brandon M. Stewart, Hanying Wei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multitask Learning and Bandits via Robust Statistics]]></title>
        <id>http://arxiv.org/abs/2112.14233</id>
        <link href="http://arxiv.org/abs/2112.14233"/>
        <updated>2023-06-09T08:18:07.741Z</updated>
        <summary type="html"><![CDATA[Kan Xu, Hamsa Bastani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Polynomial Time and Private Learning of Unbounded Gaussian Mixture
  Models]]></title>
        <id>http://arxiv.org/abs/2303.04288</id>
        <link href="http://arxiv.org/abs/2303.04288"/>
        <updated>2023-06-09T08:18:07.736Z</updated>
        <summary type="html"><![CDATA[Jamil Arbas, Hassan Ashtiani, Christopher Liaw]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Meets Sparse Regularization: A Signal Processing
  Perspective]]></title>
        <id>http://arxiv.org/abs/2301.09554</id>
        <link href="http://arxiv.org/abs/2301.09554"/>
        <updated>2023-06-09T08:18:06.909Z</updated>
        <summary type="html"><![CDATA[Rahul Parhi, Robert D. Nowak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The asymptotics of r(4,t)]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"/>
        <updated>2023-06-09T06:17:30.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved…]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The asymptotics of r(4,t)]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"/>
        <updated>2023-06-09T06:17:30.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved…]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[de-MCM’d]]></title>
        <id>http://xianblog.wordpress.com/?p=53208</id>
        <link href="https://xianblog.wordpress.com/2023/06/09/de-mcmd/"/>
        <updated>2023-06-08T22:23:02.000Z</updated>
        <summary type="html"><![CDATA[This morning I received a message from the MCM 23 conference organisers that my registration [submitted two months ago] was declined for lack of room! I wonder why the organisers did not opt for broadcasting in a second amphitheater, as was done for ISBA in Edinburgh. Unfortunately, we have attained the maximal capacity of the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Determining Ramsey numbers using finite geometry]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"/>
        <updated>2023-06-08T19:31:29.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Anurag's Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a…]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Determining Ramsey numbers using finite geometry]]></title>
        <id>http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/</id>
        <link href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"/>
        <updated>2023-06-08T19:31:29.000Z</updated>
        <summary type="html"><![CDATA[Originally posted on Anurag's Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a…]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transliterations aplenty]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59014</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59014&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=transliterations-aplenty"/>
        <updated>2023-06-08T16:50:05.000Z</updated>
        <summary type="html"><![CDATA[From Simon Cartoon: Here's something I just saw at a local bakery in Berkeley, CA. Simon explains: We have English, Spanish, and then French in the last position, no issues there. 3rd position is Mandarin Chinese via pinyin: Who is this for? What is the population of people uncomfortable reading in English, but comfortable reading […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[We may finally crack Maths. But should we?]]></title>
        <id>6481b5876965110001df8c10</id>
        <link href="https://www.inference.vc/we-may-finally-crack-maths-but-should-we/"/>
        <updated>2023-06-08T15:58:13.000Z</updated>
        <summary type="html"><![CDATA[Automating mathematical theorem proving has been a long standing goal of artificial intelligence and indeed computer science. It's one of the areas I became very interested in recently. This is because I feel we may have the ingredients needed to make very, very significant progress:

a structured search]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is the logical form of that?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59026</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59026&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=what-is-the-logical-form-of-that"/>
        <updated>2023-06-08T13:36:25.000Z</updated>
        <summary type="html"><![CDATA[This post wanders down a series of rabbit holes, from a couple of dead economists, to a dead philosopher, to a dead Supreme Court justice. It all started with Eric Rahim's obituary in the Guardian, which links to the British Academy's obituary for Piero Sraffa, which includes this passage: He also formed a close friendship […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greco-Sinitic ψάμμος / ʃˠa  mɑk̚ ("desert")]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59024</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59024&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=greco-sinitic-%25cf%2588%25ce%25ac%25ce%25bc%25ce%25bc%25ce%25bf%25cf%2582-%25ca%2583%25cb%25a0a-mak%25cc%259a-desert"/>
        <updated>2023-06-08T12:39:35.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by Chau Wu] The psammo- component of the winning word in this year's Scripps National Spelling Bee, psammophile, is of interest to me because it is a good example of European-Sinitic lexical correspondence. The Ancient Greek word psámmos (ψάμμος) means ‘sand’.  When used together with a definite article (ἡ ψάμμος), […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Invariance in Policy Optimisation and Partial Identifiability in Reward
  Learning]]></title>
        <id>http://arxiv.org/abs/2203.07475</id>
        <link href="http://arxiv.org/abs/2203.07475"/>
        <updated>2023-06-08T07:13:38.535Z</updated>
        <summary type="html"><![CDATA[Joar Skalse, Matthew Farrugia-Roberts, Stuart Russell, Alessandro
  Abate, Adam Gleave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformers as Statisticians: Provable In-Context Learning with
  In-Context Algorithm Selection]]></title>
        <id>http://arxiv.org/abs/2306.04637</id>
        <link href="http://arxiv.org/abs/2306.04637"/>
        <updated>2023-06-08T07:13:38.518Z</updated>
        <summary type="html"><![CDATA[Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multimodal Learning Without Labeled Multimodal Data: Guarantees and
  Applications]]></title>
        <id>http://arxiv.org/abs/2306.04539</id>
        <link href="http://arxiv.org/abs/2306.04539"/>
        <updated>2023-06-08T07:13:38.512Z</updated>
        <summary type="html"><![CDATA[Paul Pu Liang, Chun Kai Ling, Yun Cheng, Alex Obolenskiy, Yudong Liu,
  Rohan Pandey, Alex Wilf, Louis-Philippe Morency, Ruslan Salakhutdinov]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics,
  Directional Convergence, and Equilibria]]></title>
        <id>http://arxiv.org/abs/2212.02457</id>
        <link href="http://arxiv.org/abs/2212.02457"/>
        <updated>2023-06-08T07:13:38.507Z</updated>
        <summary type="html"><![CDATA[Tengyuan Liang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PILLAR: How to make semi-private learning more effective]]></title>
        <id>http://arxiv.org/abs/2306.03962</id>
        <link href="http://arxiv.org/abs/2306.03962"/>
        <updated>2023-06-08T07:13:38.500Z</updated>
        <summary type="html"><![CDATA[Francesco Pinto, Yaxi Hu, Fanny Yang, Amartya Sanyal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2023世界人工智能大会“AI生成与垂直大语言模型”论坛重磅来袭！]]></title>
        <id>https://www.52nlp.cn/?p=13474</id>
        <link href="https://www.52nlp.cn/2023%e4%b8%96%e7%95%8c%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%a4%a7%e4%bc%9aai%e7%94%9f%e6%88%90%e4%b8%8e%e5%9e%82%e7%9b%b4%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e8%ae%ba"/>
        <updated>2023-06-08T02:23:31.000Z</updated>
        <summary type="html"><![CDATA[当前AI生成与大语言模型的指数级发展，为相关产业链带来新的发展引擎，也为AI落地应用带来新的想象空间。2023 […]]]></summary>
        <author>
            <name>达观数据</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Naive Bayes is all you need ?]]></title>
        <id>https://kexue.fm/archives/9648</id>
        <link href="https://kexue.fm/archives/9648"/>
        <updated>2023-06-08T01:25:00.000Z</updated>
        <summary type="html"><![CDATA[很抱歉，起了这么个具有标题党特征的题目。在写完《NBCE：使用朴素贝叶斯扩展LLM的Context处理长度》之后，笔者就觉得朴素贝叶斯（Naive Bayes）跟Attention机制有很多相同...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[uniform spacings]]></title>
        <id>http://xianblog.wordpress.com/?p=53161</id>
        <link href="https://xianblog.wordpress.com/2023/06/08/uniform-spacings/"/>
        <updated>2023-06-07T22:23:28.000Z</updated>
        <summary type="html"><![CDATA[A riddle on uniform spacings!, namely when considering eight iid Uniform (0,1) variates as visiting times and three further iid Uniform (0,1) variates as server availability times, with unit service time, the question being the probability a server is available for a ninth visiting time, T⁹. Which can be decomposed into four cases: at least […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating speech synthesis in many languages with SQuId]]></title>
        <id>http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html</id>
        <link href="http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html"/>
        <updated>2023-06-07T18:07:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Thibault Sellam, Research Scientist, Google





Previously, we presented the 1,000 languages initiative and the Universal Speech Model with the goal of making speech and language technologies available to billions of users around the world. Part of this commitment involves developing high-quality speech synthesis technologies, which build upon projects such as VDTTS and AudioLM, for users that speak many different languages.






listening tests, during which dozens of annotators listen to the utterances one after the other to determine how natural they sound. While humans are still unbeaten at detecting whether a piece of text sounds natural, this process can be impractical — especially in the early stages of research projects, when engineers need rapid feedback to test and re…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aligning Language Models with Preferences through f-divergence
  Minimization]]></title>
        <id>http://arxiv.org/abs/2302.08215</id>
        <link href="http://arxiv.org/abs/2302.08215"/>
        <updated>2023-06-07T07:13:39.489Z</updated>
        <summary type="html"><![CDATA[Dongyoung Go, Tomasz Korbak, Germ\'an Kruszewski, Jos Rozen, Nahyeon
  Ryu, Marc Dymetman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Denise: Deep Robust Principal Component Analysis for Positive
  Semidefinite Matrices]]></title>
        <id>http://arxiv.org/abs/2004.13612</id>
        <link href="http://arxiv.org/abs/2004.13612"/>
        <updated>2023-06-07T07:13:39.484Z</updated>
        <summary type="html"><![CDATA[Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen,
  Josef Teichmann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Orthogonal Statistical Learning]]></title>
        <id>http://arxiv.org/abs/1901.09036</id>
        <link href="http://arxiv.org/abs/1901.09036"/>
        <updated>2023-06-07T07:13:39.478Z</updated>
        <summary type="html"><![CDATA[Dylan J. Foster, Vasilis Syrgkanis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep neural networks architectures from the perspective of manifold
  learning]]></title>
        <id>http://arxiv.org/abs/2306.03406</id>
        <link href="http://arxiv.org/abs/2306.03406"/>
        <updated>2023-06-07T07:13:39.454Z</updated>
        <summary type="html"><![CDATA[German Magai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Join the PyTorch Foundation: Membership Now Open]]></title>
        <id>https://pytorch.org/blog/join-pytorch/</id>
        <link href="https://pytorch.org/blog/join-pytorch/"/>
        <updated>2023-06-07T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[In September 2022, we welcomed PyTorch to the Linux Foundation from Meta, which formed the PyTorch Foundation with founding members AMD, Amazon Web Services (AWS), Google, Meta, Microsoft, and NVIDIA.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unknown language #15]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=59005</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=59005&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=unknown-language-15"/>
        <updated>2023-06-07T02:46:22.000Z</updated>
        <summary type="html"><![CDATA[Yuan (? dynasty (1271-1368) jade seal in the Bristol Museum: Know what language this is, or even what it says? Yes? Please get back to me. No? Please retweet it until somebody does. (But be aware, it's stumped some quite clever people who've already been asked, so it isn't obvious) Also, advance apologies if it […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding CPUs can help speed up Numba and NumPy code]]></title>
        <id>https://pythonspeed.com/articles/speeding-up-numba/</id>
        <link href="https://pythonspeed.com/articles/speeding-up-numba/"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[When you need to speed up your NumPy processing—or just reduce your memory usage—the Numba just-in-time compiler is a great tool.
It lets you write Python code that gets compiled at runtime to machine code, allowing you to get the kind of speed improvements you’d get from languages like C, Fortran, or Rust.
Or at least, that’s the theory.
In practice, your initial Numba code may be no faster than the NumPy equivalent.
But you can do better, once you have a better understanding of how CPUs work.
And this knowledge will help you more broadly with any compiled language.
In this article we’ll:
Consider a simple image-processing problem.
Try, and initially fail, to speed it up with Numba.
We’ll review just a little bit how modern CPUs are so fast, and the limits of compilers.
Based on our new understanding, we’ll then show how we can tweak our code to run 25× faster than our original version.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimising computer systems with more generalised AI tools]]></title>
        <id>https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools</id>
        <link href="https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Based on reinforcement learning, our AI models AlphaZero and MuZero have achieved superhuman performance winning games. Now, they’re expanding their capabilities to help optimise resources in data centres and advance video compression – and most recently, our specialised version of AlphaZero, called AlphaDev, discovered new algorithms that are already accelerating the software applications at the foundations of our digital society.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AlphaDev discovers faster sorting algorithms]]></title>
        <id>https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms</id>
        <link href="https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms"/>
        <updated>2023-06-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[In our paper published today in Nature, we introduce AlphaDev, an artificial intelligence (AI) system that uses reinforcement learning to discover enhanced computer science algorithms – surpassing those honed by scientists and engineers over decades.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[stack overflow on strike]]></title>
        <id>http://xianblog.wordpress.com/?p=53202</id>
        <link href="https://xianblog.wordpress.com/2023/06/07/stack-overflow-on-strike/"/>
        <updated>2023-06-06T22:23:40.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinitic exclamations in English speech]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58949</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58949&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinitic-exclamations-in-english-speech"/>
        <updated>2023-06-06T17:45:45.000Z</updated>
        <summary type="html"><![CDATA[Listen to Malaysian comedian Nigel Ng (aka "Uncle Roger"), who has had his Weibo and bilibili social media accounts banned due to "violation of relevant regulations": The ban comes one day after Ng uploaded this clip to various social media platforms. pic.twitter.com/8Wwf2aTrfZ — Aaron Busch (@tripperhead) May 19, 2023 Under the subject line "Uncle Roger […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual captions: Using large language models to augment video conferences with dynamic visuals]]></title>
        <id>http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html</id>
        <link href="http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html"/>
        <updated>2023-06-06T16:58:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ruofei Du, Research Scientist, and Alex Olwal, Senior Staff Research Scientist, Google Augmented Reality




Recent advances in video conferencing have significantly improved remote video communication through features like live captioning and noise cancellation. However, there are various situations where dynamic visual augmentation would be useful to better convey complex and nuanced information. For example, when discussing what to order at a Japanese restaurant, your friends could share visuals that would help you feel more confident about ordering the “Sukiyaki”. Or when talking about your recent family trip to San Francisco, you may want to show a photo from your personal album.




In “Visual Captions: Augmenting Verbal Communication With On-the-fly Visuals”, presented at …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LLMs as coders?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58977</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58977&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=llms-as-coders"/>
        <updated>2023-06-06T12:19:14.000Z</updated>
        <summary type="html"><![CDATA[I've recently seen many articles like this one, "You probably don't need to learn to code anymore" (Medium 6/5/2023), arguing that Large Language Models will make human programming (and human programmers) unnecessary. These arguments puzzle me, because my experience with LLMs suggests that they can't be relied on even for very simple programming tasks. After […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Bayesian Active Learning for Accelerating Stochastic Simulation]]></title>
        <id>http://arxiv.org/abs/2106.02770</id>
        <link href="http://arxiv.org/abs/2106.02770"/>
        <updated>2023-06-06T07:14:01.826Z</updated>
        <summary type="html"><![CDATA[Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, Yi-An
  Ma, Rose Yu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Alignment with human representations supports robust few-shot learning]]></title>
        <id>http://arxiv.org/abs/2301.11990</id>
        <link href="http://arxiv.org/abs/2301.11990"/>
        <updated>2023-06-06T07:14:01.819Z</updated>
        <summary type="html"><![CDATA[Ilia Sucholutsky, Thomas L. Griffiths]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Emergence of Clean-Priority Learning in Early Stopped Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.02533</id>
        <link href="http://arxiv.org/abs/2306.02533"/>
        <updated>2023-06-06T07:14:01.813Z</updated>
        <summary type="html"><![CDATA[Chaoyue Liu, Amirhesam Abedsoltan, Mikhail Belkin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LibAUC: A Deep Learning Library for X-Risk Optimization]]></title>
        <id>http://arxiv.org/abs/2306.03065</id>
        <link href="http://arxiv.org/abs/2306.03065"/>
        <updated>2023-06-06T07:14:01.438Z</updated>
        <summary type="html"><![CDATA[Zhuoning Yuan, Dixian Zhu, Zi-Hao Qiu, Gang Li, Xuanhui Wang, Tianbao
  Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Linear Causal Representations from Interventions under General
  Nonlinear Mixing]]></title>
        <id>http://arxiv.org/abs/2306.02235</id>
        <link href="http://arxiv.org/abs/2306.02235"/>
        <updated>2023-06-06T07:14:01.143Z</updated>
        <summary type="html"><![CDATA[Simon Buchholz, Goutham Rajendran, Elan Rosenfeld, Bryon Aragam,
  Bernhard Sch\"olkopf, Pradeep Ravikumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinitic semiliteracy]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58917</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58917&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinitic-semiliteracy"/>
        <updated>2023-06-06T04:43:50.000Z</updated>
        <summary type="html"><![CDATA[From a story on CNN on "begpackers" in Asia: The photo is captioned, "Professor Stephen Pratt posed as a begpacker to do fieldwork in Hong Kong." The sign says: qǐng bāngzhù wǒ zài quán shìjiè lǚxíng 請幫助我在全世界旅行 "Please help me travel around the world" Despite the fractured grammar (the zài 在* is especially egregious), all the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of biang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58888</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58888&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-biang"/>
        <updated>2023-06-06T04:34:16.000Z</updated>
        <summary type="html"><![CDATA[Shop sign in Budapest: Don't be cowed by the quixotic orthography.  The noodles are delicious, and you can get them right here in Philadelphia, and many other cities around the world. Selected readings "Biangbiang: authentic Xi'an grub in the heart of Philadelphia's University City" (6/9/22) "A Chinese character that is harder to write than 'biang'" […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[remembering May 35th]]></title>
        <id>http://xianblog.wordpress.com/?p=53194</id>
        <link href="https://xianblog.wordpress.com/2023/06/06/remembering-may-35th/"/>
        <updated>2023-06-05T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The (local) unit of intelligence is FLOPs]]></title>
        <id>http://windowsontheory.org/?p=8630</id>
        <link href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/"/>
        <updated>2023-06-05T18:22:58.000Z</updated>
        <summary type="html"><![CDATA[[Crossposting again on Lesswrong and Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it’s hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure … Continue reading The (local) unit of intelligence is FLOPs]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The (local) unit of intelligence is FLOPs]]></title>
        <id>http://windowsontheory.org/?p=8630</id>
        <link href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/"/>
        <updated>2023-06-05T18:22:58.000Z</updated>
        <summary type="html"><![CDATA[[Crossposting again on Lesswrong and Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it’s hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure … Continue reading The (local) unit of intelligence is FLOPs]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bilingual road signs]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58960</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58960&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bilingual-road-signs"/>
        <updated>2023-06-05T12:15:41.000Z</updated>
        <summary type="html"><![CDATA[…in New Zealand. Phil Pennington, "Analysis: National opposed bilingual road signs, so what does the evidence say?", RNZ 62/2023: Analysis – Bilingual road signs send a signal – that the country values te reo Māori. But going bilingual was confusing and National would not support it, National's Simeon Brown told voters in blue-ribbon Tauranga recently. […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding the Dynamics of Gaussian-Stein Variational
  Gradient Descent]]></title>
        <id>http://arxiv.org/abs/2305.14076</id>
        <link href="http://arxiv.org/abs/2305.14076"/>
        <updated>2023-06-05T07:13:47.914Z</updated>
        <summary type="html"><![CDATA[Tianle Liu, Promit Ghosal, Krishnakumar Balasubramanian, Natesh S.
  Pillai]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linked Deep Gaussian Process Emulation for Model Networks]]></title>
        <id>http://arxiv.org/abs/2306.01212</id>
        <link href="http://arxiv.org/abs/2306.01212"/>
        <updated>2023-06-05T07:13:47.903Z</updated>
        <summary type="html"><![CDATA[Deyu Ming, Daniel Williamson]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Understanding Generalization of Macro-AUC in Multi-label
  Learning]]></title>
        <id>http://arxiv.org/abs/2305.05248</id>
        <link href="http://arxiv.org/abs/2305.05248"/>
        <updated>2023-06-05T07:13:47.890Z</updated>
        <summary type="html"><![CDATA[Guoqiang Wu, Chongxuan Li, Yilong Yin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Developing A Visual-Interactive Interface for Electronic Health Record
  Labeling: An Explainable Machine Learning Approach]]></title>
        <id>http://arxiv.org/abs/2209.12778</id>
        <link href="http://arxiv.org/abs/2209.12778"/>
        <updated>2023-06-05T07:13:47.871Z</updated>
        <summary type="html"><![CDATA[Donlapark Ponnoprat, Parichart Pattarapanitchai, Phimphaka Taninpong,
  Suthep Suantai, Natthanaphop Isaradech, Thiraphat Tanphiriyakun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hyperparameter Learning under Data Poisoning: Analysis of the Influence
  of Regularization via Multiobjective Bilevel Optimization]]></title>
        <id>http://arxiv.org/abs/2306.01613</id>
        <link href="http://arxiv.org/abs/2306.01613"/>
        <updated>2023-06-05T07:13:47.865Z</updated>
        <summary type="html"><![CDATA[Javier Carnerero-Cano, Luis Mu\~noz-Gonz\'alez, Phillippa Spencer,
  Emil C. Lupu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[fusing simulation with data science [18-19 July 2023]]]></title>
        <id>http://xianblog.wordpress.com/?p=53177</id>
        <link href="https://xianblog.wordpress.com/2023/06/05/fusing-simulation-with-data-science-18-19-july-2023/"/>
        <updated>2023-06-04T22:23:59.000Z</updated>
        <summary type="html"><![CDATA[In collaboration with the Met Office, my friend and Warwick colleague Rito Dutta is co-organising a two-day workshop in Warwick in July on the use of statistics and machine learning tools in weather prediction. Attendance is free, but registration needed for tea breaks.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Greater China Co-Prosperity Sushi and Ramen Kitchen]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58924</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58924&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=greater-china-co-prosperity-sushi-and-ramen-kitchen"/>
        <updated>2023-06-04T17:30:33.000Z</updated>
        <summary type="html"><![CDATA[Shouldn’t that be Zhonghua Pan-Asian Kitchen Ramen Wok Premium Sushi? pic.twitter.com/tTUaWidjL3 — James Millward 米華健 (@JimMillward) June 4, 2023 The small characters at the top of the sign say: Hànzú Yàzhōu chúfáng 汉族亚洲厨房 "Han ethnicity Asian kitchen" The wording in large Hànyǔ Pīnyīn ("Sinitic spelling") is HANZU, the roman letter transcription of the first two […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revelation:  Scythians and Shang]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58846</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58846&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=revelation-scythians-and-shang"/>
        <updated>2023-06-04T15:48:03.000Z</updated>
        <summary type="html"><![CDATA[I was stunned when I read the following article in the South China Morning Post, both because it was published in Hong Kong, which is now completely under the censorial control of the People's Republic of China (PRC) / Chinese Communist Party (CCP), and because it raises some disturbing political issues and troubling linguistic problems. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of inventive pinyin: rua]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58832</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58832&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-inventive-pinyin-rua"/>
        <updated>2023-06-04T15:26:32.000Z</updated>
        <summary type="html"><![CDATA[This exercise video shows a woman repeating the syllable "rua" to describe a move that she makes: Problem is that there's no Sinoglyph (hànzì 漢字 / 汉字) for writing that in Modern Standard Mandarin (MSM), although some might claim that it can be written with this character, ruó 挼 ("rub; knead; massage"). According to this table, "rua" is not a […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The rise (and fall?) of shiesties]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58927</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58927&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-rise-and-fall-of-shiesties"/>
        <updated>2023-06-04T10:52:10.000Z</updated>
        <summary type="html"><![CDATA[Last month I learned a new word, shiesty — which rhymes with feisty, as if it were written "sheisty" — because shiesties have been banned on the local transit system ("SEPTA"): Your browser does not support the audio element. Keith, I'm sure if you walked around Philadelphia, live in Philadelphia, work in Philadelphia, you've seen […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Role Of Social Media On Selected Businesses In Nigeria In The Era Of
  Covid-19 Pandemic]]></title>
        <id>http://arxiv.org/abs/2305.19299</id>
        <link href="http://arxiv.org/abs/2305.19299"/>
        <updated>2023-06-04T07:13:27.273Z</updated>
        <summary type="html"><![CDATA[Cajetan Ihemebiri, Elochukwu Ukwandu, Lizzy Ofusori, Comfort
  Olebara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Near-Atomic Scale Perspective on the Oxidation of Ti$_3$C$_2$T$_x$
  MXenes: Insights from Atom Probe Tomography]]></title>
        <id>http://arxiv.org/abs/2305.19822</id>
        <link href="http://arxiv.org/abs/2305.19822"/>
        <updated>2023-06-04T07:13:27.240Z</updated>
        <summary type="html"><![CDATA[Mathias Kr\"amer, Bar Favelukis, Ayman A. El-Zoka, Maxim Sokol, Brian
  A. Rosen, Noam Eliaz, Se-Ho Kim, Baptiste Gault]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual Exploratory Data Analysis of the Covid-19 Pandemic in Nigeria:
  Two Years after the Outbreak]]></title>
        <id>http://arxiv.org/abs/2305.19297</id>
        <link href="http://arxiv.org/abs/2305.19297"/>
        <updated>2023-06-04T07:13:27.228Z</updated>
        <summary type="html"><![CDATA[Ugochukwu Orji, Modesta Ezema, Elochukwu Ukwandu, Chikaodili
  Ugwuishiwu, Ezugwu Obianuju, Malachi Egbugha]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[To what extent can control policies influence the epidemic spreading? --
  A data-driven analysis based on the first wave of COVID-19]]></title>
        <id>http://arxiv.org/abs/2305.19544</id>
        <link href="http://arxiv.org/abs/2305.19544"/>
        <updated>2023-06-04T07:13:27.223Z</updated>
        <summary type="html"><![CDATA[Dongyan Zhang, Wanqi Wen, Wuyue Yang, Liangrong Peng, Changjingn
  Zhuge, Liu Hong]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Beacon [jatp]]]></title>
        <id>http://xianblog.wordpress.com/?p=53153</id>
        <link href="https://xianblog.wordpress.com/2023/06/04/the-beacon-jatp/"/>
        <updated>2023-06-03T22:23:04.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dog bites man:  Indian wins spelling bee]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58921</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58921&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dog-bites-man-indian-wins-spelling-bee"/>
        <updated>2023-06-03T20:25:55.000Z</updated>
        <summary type="html"><![CDATA[New old news: "Dev Shah wins 2023 Scripps National Spelling Bee by correctly spelling 'psammophile'"Chris BumbacaUSA TODAY (6/1/23) Another year, same story: The 2023 Scripps National Spelling Bee ended the old-fashioned way. Two competitors left on the stage. No spell-off required. Dev Shah, an eighth-grader from Largo, Florida, spelled "psammophile" correctly to win the 95th […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pronouncing "DeSantis"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58876</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58876&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pronouncing-desantis"/>
        <updated>2023-06-03T14:21:21.000Z</updated>
        <summary type="html"><![CDATA[The question of how to pronounce Ron DeSantis' last name — and the observation that the candidate, his wife, and his campaign have made different choices at different times — is among the more trivial bits of political flotsam recently washing up on the shores of social and political media. In fact the issue has […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sinological formatting]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58874</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58874&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sinological-formatting"/>
        <updated>2023-06-03T12:02:31.000Z</updated>
        <summary type="html"><![CDATA[I recently received this book: Sūn Sīmiǎo, Sabine Wilms.  Healing Virtue-Power: Medical Ethics and the Doctor's Dao.  Whidbey Island WA:  Happy Goat Productions, 2022. ISBN:  978-1-7321571-9-4 website As soon as I started to leaf through the volume, I was struck by its unusual format and usages:  every Chinese character is accompanied by Hanyu Pinyin phonetic […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tsunami and megathrust earthquake disaster prevention warnings:
  Real-time monitoring of the genesis processes with Physical Wavelets]]></title>
        <id>http://arxiv.org/abs/2305.13249</id>
        <link href="http://arxiv.org/abs/2305.13249"/>
        <updated>2023-06-03T07:12:38.216Z</updated>
        <summary type="html"><![CDATA[Fumihide Takeda]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diagonalization of Polynomial-Time Deterministic Turing Machines Via
  Nondeterministic Turing Machine]]></title>
        <id>http://arxiv.org/abs/2110.06211</id>
        <link href="http://arxiv.org/abs/2110.06211"/>
        <updated>2023-06-03T07:12:38.210Z</updated>
        <summary type="html"><![CDATA[Tianrong Lin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[van Dantzig seminar]]></title>
        <id>http://xianblog.wordpress.com/?p=53169</id>
        <link href="https://xianblog.wordpress.com/2023/06/03/van-dantzig-seminar/"/>
        <updated>2023-06-02T22:23:48.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Just < Not the same as it was]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58869</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58869&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=just-not-the-same-as-it-was"/>
        <updated>2023-06-02T22:12:54.000Z</updated>
        <summary type="html"><![CDATA[I listened to this Harry Styles song dozens of times on the radio, and every time I heard him sing "You know it's just the same as it was" over and over: It was only after watching the video and reading the subtitles that I realized he was saying "You know it's not the same […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Austronesian languages of Taiwan]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58855</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58855&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=austronesian-languages-of-taiwan"/>
        <updated>2023-06-02T19:27:48.000Z</updated>
        <summary type="html"><![CDATA[Handbook of Formosan Languages (Online): The Indigenous Languages of Taiwan Editors: Paul Jen-kuei Li, Academia SinicaElizabeth Zeitoun, Academia SinicaRik De Busser, National Taiwan Cheng-Chi University Leiden:  Brill, 2023 Outright Purchase: € 2249 / US dollars 2495Subscription: € 350 / US dollars 390 A print version is forthcoming (September 2023 ; 3 vols, ~ 2200 pp.) […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AVFormer: Injecting vision into frozen speech models for zero-shot AV-ASR]]></title>
        <id>http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html</id>
        <link href="http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html"/>
        <updated>2023-06-02T17:02:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Arsha Nagrani and Paul Hongsuck Seo, Research Scientists, Google Research






Automatic speech recognition (ASR) is a well-established technology that is widely adopted for various applications such as conference calls, streamed video transcription and voice commands. While the challenges for this technology are centered around noisy audio inputs, the visual stream in multimodal videos (e.g., TV, online edited videos) can provide strong cues for improving the robustness of ASR systems — this is called audiovisual ASR (AV-ASR).
 

Although lip motion can provide strong signals for speech recognition and is the most common area of focus for AV-ASR, the mouth is often not directly visible in videos in the wild (e.g., due to egocentric viewpoints, face coverings, and low resolution…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Historical speech styles]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58857</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58857&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=historical-speech-styles"/>
        <updated>2023-06-02T11:48:13.000Z</updated>
        <summary type="html"><![CDATA[A recent Dinosaur Comics strip features T-Rex imitating (a certain kind of) speech style from the 1940s: Mouseover title: "to t-rex's mind, and mine as well, all of the past takes place around the 1930s. well sure! and why not?" The next strip: Mouseover title: "you want a gender-neutral way to address a room, well here […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Expressive Power of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2306.00145</id>
        <link href="http://arxiv.org/abs/2306.00145"/>
        <updated>2023-06-02T07:13:25.962Z</updated>
        <summary type="html"><![CDATA[Jan Holstermann]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combining Explicit and Implicit Regularization for Efficient Learning in
  Deep Networks]]></title>
        <id>http://arxiv.org/abs/2306.00342</id>
        <link href="http://arxiv.org/abs/2306.00342"/>
        <updated>2023-06-02T07:13:25.957Z</updated>
        <summary type="html"><![CDATA[Dan Zhao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provably Learning Diverse Features in Multi-View Data with Midpoint
  Mixup]]></title>
        <id>http://arxiv.org/abs/2210.13512</id>
        <link href="http://arxiv.org/abs/2210.13512"/>
        <updated>2023-06-02T07:13:25.952Z</updated>
        <summary type="html"><![CDATA[Muthu Chidambaram, Xiang Wang, Chenwei Wu, Rong Ge]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Revealing the Mystery behind Chain of Thought: a Theoretical
  Perspective]]></title>
        <id>http://arxiv.org/abs/2305.15408</id>
        <link href="http://arxiv.org/abs/2305.15408"/>
        <updated>2023-06-02T07:13:25.946Z</updated>
        <summary type="html"><![CDATA[Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Sensible Adversarial Learning of Deep Neural Networks for Image
  Classification]]></title>
        <id>http://arxiv.org/abs/2205.10457</id>
        <link href="http://arxiv.org/abs/2205.10457"/>
        <updated>2023-06-02T07:13:25.730Z</updated>
        <summary type="html"><![CDATA[Jungeum Kim, Xiao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Galton and Watson voluntarily skipping some generations]]></title>
        <id>http://xianblog.wordpress.com/?p=53139</id>
        <link href="https://xianblog.wordpress.com/2023/06/02/galton-and-watson-voluntarily-skipping-some-generations/"/>
        <updated>2023-06-01T22:23:10.000Z</updated>
        <summary type="html"><![CDATA[A riddle on a form of a Galton-Watson process, starting from a single unit, where no one dies but rather, at each of 100 generations, Dog either opts for a Uniform number υ of additional units or increments a counter γ by this number υ, its goal being to optimise γ. The solution proposed by […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Know your relatives in Chinese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58807</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58807&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=know-your-relatives-in-chinese"/>
        <updated>2023-06-01T18:38:21.000Z</updated>
        <summary type="html"><![CDATA[Randy Alexander reports that during a guitar lesson, he asked his student: Māmā de dìdi de nǚér shì biǎomèi ma？ 妈妈的弟弟的女儿是表妹吗？ "Is your mother's younger brother's daughter your younger maternal female cousin?" The student replied: wǒyě bútài qīngchǔ děngyíxià 我也不太清楚等一下 "I don't quite know either, wait a minute." Here's a screen shot of the student's […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Retrieval-augmented visual-language pre-training]]></title>
        <id>http://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html</id>
        <link href="http://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html"/>
        <updated>2023-06-01T17:25:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ziniu Hu, Student Researcher, and Alireza Fathi, Research Scientist, Google Research, Perception Team





Large-scale models, such as T5, GPT-3, PaLM, Flamingo and PaLI, have demonstrated the ability to store substantial amounts of knowledge when scaled to tens of billions of parameters and trained on large text and image datasets. These models achieve state-of-the-art results on downstream tasks, such as image captioning, visual question answering and open vocabulary recognition. Despite such achievements, these models require a massive volume of data for training and end up with a tremendous number of parameters (billions in many cases), resulting in significant computational requirements. Moreover, the data used to train these models can become outdated, requiring re-training…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multilingual TV series]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58835</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58835&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=multilingual-tv-series"/>
        <updated>2023-06-01T15:13:03.000Z</updated>
        <summary type="html"><![CDATA[Coby Lubliner called my attention to the Belgian Netflix series "Rough Diamonds." It takes place in Antwerp, so the default language is Dutch (Flemish), but the characters move into Yiddish, English and French with the greatest of ease. The subtitles don't indicate the language spoken in any one scene, except that when [Yiddish] appears what is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Wordectomy"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58838</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58838&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=wordectomy"/>
        <updated>2023-06-01T13:37:16.000Z</updated>
        <summary type="html"><![CDATA[The medical news site MedPage Today has recently added a daily game page, "Wordectomy", in which a medically-relevant Wikipedia article is presented with all letters blanked out except for punctuation and (some) function words, e.g. The instructions: Welcome to Wordectomy — a word game from MedPage Today where you try to determine what medical condition is […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low-rank extended Kalman filtering for online learning of neural
  networks from streaming data]]></title>
        <id>http://arxiv.org/abs/2305.19535</id>
        <link href="http://arxiv.org/abs/2305.19535"/>
        <updated>2023-06-01T07:14:05.921Z</updated>
        <summary type="html"><![CDATA[Peter Chang, Gerardo Dur\`an-Mart\'in, Alexander Y Shestopaloff, Matt
  Jones, Kevin Murphy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Active causal structure learning with advice]]></title>
        <id>http://arxiv.org/abs/2305.19588</id>
        <link href="http://arxiv.org/abs/2305.19588"/>
        <updated>2023-06-01T07:14:05.907Z</updated>
        <summary type="html"><![CDATA[Davin Choo, Themis Gouleakis, Arnab Bhattacharyya]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Estimates for Pairwise Learning with Deep ReLU Networks]]></title>
        <id>http://arxiv.org/abs/2305.19640</id>
        <link href="http://arxiv.org/abs/2305.19640"/>
        <updated>2023-06-01T07:14:05.886Z</updated>
        <summary type="html"><![CDATA[Junyu Zhou, Shuo Huang, Han Feng, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What and How does In-Context Learning Learn? Bayesian Model Averaging,
  Parameterization, and Generalization]]></title>
        <id>http://arxiv.org/abs/2305.19420</id>
        <link href="http://arxiv.org/abs/2305.19420"/>
        <updated>2023-06-01T07:14:05.878Z</updated>
        <summary type="html"><![CDATA[Yufeng Zhang, Fengzhuo Zhang, Zhuoran Yang, Zhaoran Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Machine learning with tree tensor networks, CP rank constraints, and
  tensor dropout]]></title>
        <id>http://arxiv.org/abs/2305.19440</id>
        <link href="http://arxiv.org/abs/2305.19440"/>
        <updated>2023-06-01T07:14:05.872Z</updated>
        <summary type="html"><![CDATA[Hao Chen, Thomas Barthel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[the alpinist [film review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53126</id>
        <link href="https://xianblog.wordpress.com/2023/06/01/the-alpinist-film-review/"/>
        <updated>2023-05-31T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[Watched (with supplementary oxygen) The Alpinist in the plane to Jeddah. It is a documentary (made by the same filmmakers who filmed the Dawn Wall) about the amazing Canadian alpinist Marc-André Leclerc, who died in 2018 on the Mendenhall Glacier, Alaska, in an avalanche, after achieving extraordinary complex solo climbs as eg on Mount Robbson, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Questions and Concerns About Google’s Quantum Supremacy Claim]]></title>
        <id>http://gilkalai.wordpress.com/?p=24142</id>
        <link href="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/"/>
        <updated>2023-05-31T17:36:59.000Z</updated>
        <summary type="html"><![CDATA[Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.  Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Questions and Concerns About Google’s Quantum Supremacy Claim]]></title>
        <id>http://gilkalai.wordpress.com/?p=24142</id>
        <link href="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/"/>
        <updated>2023-05-31T17:36:59.000Z</updated>
        <summary type="html"><![CDATA[Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.  Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large sequence models for software development activities]]></title>
        <id>http://ai.googleblog.com/2023/05/large-sequence-models-for-software.html</id>
        <link href="http://ai.googleblog.com/2023/05/large-sequence-models-for-software.html"/>
        <updated>2023-05-31T17:13:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Petros Maniatis and Daniel Tarlow, Research Scientists, Google




Software isn’t created in one dramatic step. It improves bit by bit, one little step at a time — editing, running unit tests, fixing build errors, addressing code reviews, editing some more, appeasing linters, and fixing more errors — until finally it becomes good enough to merge into a code repository. Software engineering isn’t an isolated process, but a dialogue among human developers, code reviewers, bug reporters, software architects and tools, such as compilers, unit tests, linters and static analyzers. 




Today we describe DIDACT (​​Dynamic Integrated Developer ACTivity), which is a methodology for training large machine learning (ML) models for software development. The novelty of DIDACT is that it uses …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[关于NBCE方法的一些补充说明和分析]]></title>
        <id>https://kexue.fm/archives/9632</id>
        <link href="https://kexue.fm/archives/9632"/>
        <updated>2023-05-31T07:38:00.000Z</updated>
        <summary type="html"><![CDATA[上周在《NBCE：使用朴素贝叶斯扩展LLM的Context处理长度》中，我们介绍了一种基于朴素贝叶斯来扩展LLM的Context长度的方案NBCE（Naive Bayes-based Conte...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the minimax optimality and superiority of deep neural network
  learning over sparse parameter spaces]]></title>
        <id>http://arxiv.org/abs/1905.09195</id>
        <link href="http://arxiv.org/abs/1905.09195"/>
        <updated>2023-05-31T07:13:39.538Z</updated>
        <summary type="html"><![CDATA[Satoshi Hayakawa, Taiji Suzuki]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prediction Error-based Classification for Class-Incremental Learning]]></title>
        <id>http://arxiv.org/abs/2305.18806</id>
        <link href="http://arxiv.org/abs/2305.18806"/>
        <updated>2023-05-31T07:13:39.532Z</updated>
        <summary type="html"><![CDATA[Micha{\l} Zaj\k{a}c, Tinne Tuytelaars, Gido M. van de Ven]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal Approximation Property of Hamiltonian Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2303.12147</id>
        <link href="http://arxiv.org/abs/2303.12147"/>
        <updated>2023-05-31T07:13:39.527Z</updated>
        <summary type="html"><![CDATA[Muhammad Zakwan, Massimiliano d'Angelo, Giancarlo Ferrari-Trecate]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Prediction with Large Language Models for Multi-Choice
  Question Answering]]></title>
        <id>http://arxiv.org/abs/2305.18404</id>
        <link href="http://arxiv.org/abs/2305.18404"/>
        <updated>2023-05-31T07:13:39.521Z</updated>
        <summary type="html"><![CDATA[Bhawesh Kumar, Charlie Lu, Gauri Gupta, Anil Palepu, David Bellamy,
  Ramesh Raskar, Andrew Beam]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generating with Confidence: Uncertainty Quantification for Black-box
  Large Language Models]]></title>
        <id>http://arxiv.org/abs/2305.19187</id>
        <link href="http://arxiv.org/abs/2305.19187"/>
        <updated>2023-05-31T07:13:39.504Z</updated>
        <summary type="html"><![CDATA[Zhen Lin, Shubhendu Trivedi, Jimeng Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[optimal importance sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53120</id>
        <link href="https://xianblog.wordpress.com/2023/05/31/optimal-importance-sampling/"/>
        <updated>2023-05-30T22:23:27.000Z</updated>
        <summary type="html"><![CDATA[In Stein Π-Importance Sampling, Congye Wang et al. (mostly from Newcastle, UK) build an MCMC scheme with invariant distribution Π targeting a distribution P, showing that the optimal solution (in terms of a discrepancy) differs from P when the chain is Stein-sampled, e..g. via kernel discrepancies. In terms of densities, the solution is the correction […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mortal Komputation: On Hinton's argument for superhuman AI.]]></title>
        <id>64724f2336605b0001f5e7fa</id>
        <link href="https://www.inference.vc/mortal-computation-hintons/"/>
        <updated>2023-05-30T13:48:52.000Z</updated>
        <summary type="html"><![CDATA[Last week in Cambridge was Hinton bonanza. He visited the university town where he was once an undergraduate in experimental psychology, and gave a series of back-to-back talks, Q&A sessions, interviews, dinners, etc. He was stopped on the street by random passers-by who recognised him from the lecture,]]></summary>
        <author>
            <name>Ferenc Huszar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The contextual lasso: Sparse linear models via deep neural networks]]></title>
        <id>http://arxiv.org/abs/2302.00878</id>
        <link href="http://arxiv.org/abs/2302.00878"/>
        <updated>2023-05-30T07:13:25.154Z</updated>
        <summary type="html"><![CDATA[Ryan Thompson, Amir Dezfouli, Robert Kohn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization Error Bounds for Deep Neural Networks Trained by SGD]]></title>
        <id>http://arxiv.org/abs/2206.03299</id>
        <link href="http://arxiv.org/abs/2206.03299"/>
        <updated>2023-05-30T07:13:24.424Z</updated>
        <summary type="html"><![CDATA[Mingze Wang, Chao Ma]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Two-Layer Neural Networks, One (Giant) Step at a Time]]></title>
        <id>http://arxiv.org/abs/2305.18270</id>
        <link href="http://arxiv.org/abs/2305.18270"/>
        <updated>2023-05-30T07:13:23.287Z</updated>
        <summary type="html"><![CDATA[Yatin Dandi, Florent Krzakala, Bruno Loureiro, Luca Pesce, Ludovic
  Stephan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Implicit Bias of Gradient Descent for Mean Squared Error Regression with
  Two-Layer Wide Neural Networks]]></title>
        <id>http://arxiv.org/abs/2006.07356</id>
        <link href="http://arxiv.org/abs/2006.07356"/>
        <updated>2023-05-30T07:13:23.096Z</updated>
        <summary type="html"><![CDATA[Hui Jin, Guido Mont\'ufar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reward Collapse in Aligning Large Language Models]]></title>
        <id>http://arxiv.org/abs/2305.17608</id>
        <link href="http://arxiv.org/abs/2305.17608"/>
        <updated>2023-05-30T07:13:22.873Z</updated>
        <summary type="html"><![CDATA[Ziang Song, Tianle Cai, Jason D. Lee, Weijie J. Su]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.]]></title>
        <id>http://gilkalai.wordpress.com/?p=23932</id>
        <link href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/"/>
        <updated>2023-05-30T05:38:33.000Z</updated>
        <summary type="html"><![CDATA[(Click to enlarge.) Plan for this post: Prologue: “Can we sleep soundly at night?” Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.]]></title>
        <id>http://gilkalai.wordpress.com/?p=23932</id>
        <link href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/"/>
        <updated>2023-05-30T05:38:33.000Z</updated>
        <summary type="html"><![CDATA[(Click to enlarge.) Plan for this post: Prologue: “Can we sleep soundly at night?” Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[reciprocal importance sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53111</id>
        <link href="https://xianblog.wordpress.com/2023/05/30/reciprocal-importance-sampling/"/>
        <updated>2023-05-29T22:23:39.000Z</updated>
        <summary type="html"><![CDATA[In a recent arXival, Metodiev et al. (including my friend Adrian Raftery, who is spending the academic year in Paris) proposed a new version of reciprocal importance sampling, expanding the proposal we made with Darren Wraith (2009) of using a Uniform over an HPD region. It is called THAMES, hence the picture (of London, not […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Manifold Regularization for Memory-Efficient Training of Deep Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.17119</id>
        <link href="http://arxiv.org/abs/2305.17119"/>
        <updated>2023-05-29T07:14:17.605Z</updated>
        <summary type="html"><![CDATA[Shadi Sartipi, Edgar A. Bernal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vecchia Gaussian Process Ensembles on Internal Representations of Deep
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.17063</id>
        <link href="http://arxiv.org/abs/2305.17063"/>
        <updated>2023-05-29T07:14:17.597Z</updated>
        <summary type="html"><![CDATA[Felix Jimenez, Matthias Katzfuss]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Language Models as Tool Makers]]></title>
        <id>http://arxiv.org/abs/2305.17126</id>
        <link href="http://arxiv.org/abs/2305.17126"/>
        <updated>2023-05-29T07:14:16.379Z</updated>
        <summary type="html"><![CDATA[Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Influence of Learning Rule on Representation Dynamics in Wide Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2210.02157</id>
        <link href="http://arxiv.org/abs/2210.02157"/>
        <updated>2023-05-29T07:14:16.372Z</updated>
        <summary type="html"><![CDATA[Blake Bordelon, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Architecture Search for Parameter-Efficient Fine-tuning of Large
  Pre-trained Language Models]]></title>
        <id>http://arxiv.org/abs/2305.16597</id>
        <link href="http://arxiv.org/abs/2305.16597"/>
        <updated>2023-05-29T07:14:16.356Z</updated>
        <summary type="html"><![CDATA[Neal Lawton, Anoop Kumar, Govind Thattai, Aram Galstyan, Greg Ver
  Steeg]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Model-Based Clustering, Classification, and Density Estimation Using mclust in R [not a book review]]]></title>
        <id>http://xianblog.wordpress.com/?p=53104</id>
        <link href="https://xianblog.wordpress.com/2023/05/29/model-based-clustering-classification-and-density-estimation-using-mclust-in-r-not-a-book-review/"/>
        <updated>2023-05-28T22:23:16.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Vatnik" — ethnic or political slur?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58816</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58816&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=vatnik-ethnic-or-political-slur"/>
        <updated>2023-05-28T13:31:58.000Z</updated>
        <summary type="html"><![CDATA[Adam Taylor, Anastacia Galouchka & Heidi Levine, "Ukrainians fighting outside Bakhmut see Russian mercenaries withdrawing", Washington Post 5/282023: “The Wagner guys have left and the [regular Russians] have come in,” said a 26-year-old commander who asked to be identified by his call sign, Chichen. He used an anti-Russian ethnic slur to refer to the troops […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chickee cakes]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58803</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58803&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chickee-cakes"/>
        <updated>2023-05-28T03:27:05.000Z</updated>
        <summary type="html"><![CDATA[Taken at a restaurant in Hangzhou: The big Chinese characters say: Cant. gai1zai2 beng2  MSM  jīzǎi bǐng 鸡仔饼 "phoenix cookie" This is a type of chewy biscuit made with lard, originating in Guangzhou / Canton.  (source)  Its original name was Cant. siu2fung6 beng2  MSM xiǎofèng bǐng 小鳳餅 ("little phoenix cake"). Here are some recipes for "phoenix cookies".  I noticed plenty of fat and sesame, peanuts, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Natural nested sampling]]></title>
        <id>http://xianblog.wordpress.com/?p=53091</id>
        <link href="https://xianblog.wordpress.com/2023/05/28/natural-nested-sampling/"/>
        <updated>2023-05-27T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[“The nested sampling algorithm solves otherwise challenging, high-dimensional integrals by evolving a collection of live points through parameter space. The algorithm was immediately adopted in cosmology because it partially overcomes three of the major difficulties in Markov chain Monte Carlo, the algorithm traditionally used for Bayesian computation. Nested sampling simultaneously returns results for model comparison […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[on control variates]]></title>
        <id>http://xianblog.wordpress.com/?p=52378</id>
        <link href="https://xianblog.wordpress.com/2023/05/27/on-control-variates/"/>
        <updated>2023-05-26T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[A few months ago, I had to write a thesis evaluation of Rémi Leluc’s PhD, which contained several novel Monte Carlo proposals on control variates and importance techniques. For instance, Leluc et al. (Statistics and Computing, 2021) revisits the concept of control variables by adding a perspective of control variable selection using LASSO. This prior […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Foundation models for reasoning on charts]]></title>
        <id>http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html</id>
        <link href="http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html"/>
        <updated>2023-05-26T19:08:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Julian Eisenschlos, Research Software Engineer, Google Research





Visual language is the form of communication that relies on pictorial symbols outside of text to convey information. It is ubiquitous in our digital life in the form of iconography, infographics, tables, plots, and charts, extending to the real world in street signs, comic books, food labels, etc. For that reason, having computers better understand this type of media can help with scientific communication and discovery, accessibility, and data transparency.
 

While computer vision models have made tremendous progress using learning-based solutions since the advent of ImageNet, the focus has been on natural images, where all sorts of tasks, such as classification, visual question answering (VQA), captioning, det…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Barkour: Benchmarking animal-level agility with quadruped robots]]></title>
        <id>http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html</id>
        <link href="http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html"/>
        <updated>2023-05-26T16:58:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Ken Caluwaerts and Atil Iscen, Research Scientists, Google





Creating robots that exhibit robust and dynamic locomotion capabilities, similar to animals or humans, has been a long-standing goal in the robotics community. In addition to completing tasks quickly and efficiently, agility allows legged robots to move through complex environments that are otherwise difficult to traverse. Researchers at Google have been pursuing agility for multiple years and across various form factors. Yet, while researchers have enabled robots to hike or jump over some obstacles, there is still no generally accepted benchmark that comprehensively measures robot agility or mobility. In contrast, benchmarks are driving forces behind the development of machine learning, such as ImageNet for computer…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Insults, oaths, and curses in the Middle Ages]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58791</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58791&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=insults-oaths-and-curses-in-the-middle-ages"/>
        <updated>2023-05-26T12:37:34.000Z</updated>
        <summary type="html"><![CDATA[From Medievalists.net: "By God’s Bones: Medieval Swear Words" What were bad words in the Middle Ages? Cursing or swearing in medieval England was really different from today’s world. May, 2023 The post begins: Some historians have looked into the topic, such as Melissa Mohr, the author of Holy Sh*t: A Brief History of Swearing. In her […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A theory of representation learning gives a deep generalisation of
  kernel methods]]></title>
        <id>http://arxiv.org/abs/2108.13097</id>
        <link href="http://arxiv.org/abs/2108.13097"/>
        <updated>2023-05-26T02:32:49.402Z</updated>
        <summary type="html"><![CDATA[Adam X. Yang, Maxime Robeyns, Edward Milsom, Ben Anson, Nandi Schoots,
  Laurence Aitchison]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment]]></title>
        <id>http://arxiv.org/abs/2304.06767</id>
        <link href="http://arxiv.org/abs/2304.06767"/>
        <updated>2023-05-26T02:32:49.394Z</updated>
        <summary type="html"><![CDATA[Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng
  Zhang, Kashun Shum, Tong Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Theoretical Guarantees of Learning Ensembling Strategies with
  Applications to Time Series Forecasting]]></title>
        <id>http://arxiv.org/abs/2305.15786</id>
        <link href="http://arxiv.org/abs/2305.15786"/>
        <updated>2023-05-26T02:32:49.374Z</updated>
        <summary type="html"><![CDATA[Hilaf Hasson, Danielle C. Maddix, Yuyang Wang, Gaurav Gupta, Youngsuk
  Park]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memory-Based Meta-Learning on Non-Stationary Distributions]]></title>
        <id>http://arxiv.org/abs/2302.03067</id>
        <link href="http://arxiv.org/abs/2302.03067"/>
        <updated>2023-05-26T02:32:49.365Z</updated>
        <summary type="html"><![CDATA[Tim Genewein, Gr\'egoire Del\'etang, Anian Ruoss, Li Kevin Wenliang,
  Elliot Catt, Vincent Dutordoir, Jordi Grau-Moya, Laurent Orseau, Marcus
  Hutter, Joel Veness]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Neural Network Layers Promote Learning Single- and Multiple-Index
  Models]]></title>
        <id>http://arxiv.org/abs/2305.15598</id>
        <link href="http://arxiv.org/abs/2305.15598"/>
        <updated>2023-05-26T02:32:49.357Z</updated>
        <summary type="html"><![CDATA[Suzanna Parkinson, Greg Ongie, Rebecca Willett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially private clustering for large-scale datasets]]></title>
        <id>http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html</id>
        <link href="http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html"/>
        <updated>2023-05-25T23:09:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Vincent Cohen-Addad and  Alessandro Epasto, Research Scientists, Google Research, Graph Mining team




Clustering is a central problem in unsupervised machine learning (ML) with many applications across domains in both industry and academic research more broadly. At its core, clustering consists of the following problem: given a set of data elements, the goal is to partition the data elements into groups such that similar objects are in the same group, while dissimilar objects are in different groups. This problem has been studied in math, computer science, operations research and statistics for more than 60 years in its myriad variants. Two common forms of clustering are metric clustering, in which the elements are points in a metric space, like in the k-means problem, and grap…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EMS 2023, Warsaw]]></title>
        <id>http://xianblog.wordpress.com/?p=53085</id>
        <link href="https://xianblog.wordpress.com/2023/05/26/ems-2023-warsaw/"/>
        <updated>2023-05-25T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google Research at I/O 2023]]></title>
        <id>http://ai.googleblog.com/2023/05/google-research-at-io-2023.html</id>
        <link href="http://ai.googleblog.com/2023/05/google-research-at-io-2023.html"/>
        <updated>2023-05-25T17:03:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by James Manyika, SVP Google Research and Technology & Society, and Jeff Dean, Chief Scientist, Google DeepMind and Google Research




Wednesday, May 10th was an exciting day for the Google Research community as we watched the results of months and years of our foundational and applied work get announced on the Google I/O stage. With the quick pace of announcements on stage, it can be difficult to convey the substantial effort and unique innovations that underlie the technologies we presented. So today, we’re excited to reveal more about the research efforts behind some of the many exciting announcements at this year's I/O. 


 

PaLM 2 
PaLM 2, is built on advances in compute-optimal scaling, scaled instruction-fine tuning and improved dataset mixture. By fine-tuning and instructi…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Failure to Launch"?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58795</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58795&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=failure-to-launch"/>
        <updated>2023-05-25T12:19:56.000Z</updated>
        <summary type="html"><![CDATA[Along with half a million other people, I logged onto Twitter at the designated hour to hear Elon Musk help Ron DeSantis announce his run for U.S. President. After about half an hour of  noises, silences, and puzzling graphics, I gave up — too early to catch the restart on a different account. This event […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Master the essence of solid"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58775</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58775&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=master-the-essence-of-solid"/>
        <updated>2023-05-25T08:48:28.000Z</updated>
        <summary type="html"><![CDATA[From the website for Royal China Group, a famous Chinese restaurant group in London: The problem begins at the beginning:  jingcui 精粹 does not mean "master"; it means "essence". The entire text reads as follows: Zhōngguó yǐnshí wénhuà bódàjīngshēn,Huángcháo nǔlì bùxiè yánshǒu zhèngzōng chuántǒng Yuècài de fēnggé,bìng zài wèijué de lǐngyù zhōng xúnqiú túpò,zhǎngwò gùzhōng jīngcuì […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test your intuition 52: Can you predict the ratios of ones?]]></title>
        <id>http://gilkalai.wordpress.com/?p=24359</id>
        <link href="https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/"/>
        <updated>2023-05-25T08:33:58.000Z</updated>
        <summary type="html"><![CDATA[Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice’s task is to choose, at a certain time of her choice, some number (smaller than the number of unseen … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test your intuition 52: Can you predict the ratios of ones?]]></title>
        <id>http://gilkalai.wordpress.com/?p=24359</id>
        <link href="https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/"/>
        <updated>2023-05-25T08:33:58.000Z</updated>
        <summary type="html"><![CDATA[Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice’s task is to choose, at a certain time of her choice, some number (smaller than the number of unseen … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning for Survival Analysis: A Review]]></title>
        <id>http://arxiv.org/abs/2305.14961</id>
        <link href="http://arxiv.org/abs/2305.14961"/>
        <updated>2023-05-25T07:13:51.339Z</updated>
        <summary type="html"><![CDATA[Simon Wiegrebe, Philipp Kopper, Raphael Sonabend, Andreas Bender]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Masked Bayesian Neural Networks : Theoretical Guarantee and its
  Posterior Inference]]></title>
        <id>http://arxiv.org/abs/2305.14765</id>
        <link href="http://arxiv.org/abs/2305.14765"/>
        <updated>2023-05-25T07:13:51.311Z</updated>
        <summary type="html"><![CDATA[Insung Kong, Dongyoon Yang, Jongjin Lee, Ilsang Ohn, Gyuseung Baek,
  Yongdai Kim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Rate Free Bayesian Inference in Constrained Domains]]></title>
        <id>http://arxiv.org/abs/2305.14943</id>
        <link href="http://arxiv.org/abs/2305.14943"/>
        <updated>2023-05-25T07:13:51.252Z</updated>
        <summary type="html"><![CDATA[Louis Sharrock, Lester Mackey, Christopher Nemeth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Rigorous Link between Deep Ensembles and (Variational) Bayesian
  Methods]]></title>
        <id>http://arxiv.org/abs/2305.15027</id>
        <link href="http://arxiv.org/abs/2305.15027"/>
        <updated>2023-05-25T07:13:50.477Z</updated>
        <summary type="html"><![CDATA[Veit David Wild, Sahra Ghalebikesabi, Dino Sejdinovic, Jeremias
  Knoblauch]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Test like you Train in Implicit Deep Learning]]></title>
        <id>http://arxiv.org/abs/2305.15042</id>
        <link href="http://arxiv.org/abs/2305.15042"/>
        <updated>2023-05-25T07:13:50.461Z</updated>
        <summary type="html"><![CDATA[Zaccharie Ramzi, Pierre Ablin, Gabriel Peyr\'e, Thomas Moreau]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An early warning system for novel AI risks]]></title>
        <id>https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks</id>
        <link href="https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks"/>
        <updated>2023-05-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[AI researchers already use a range of evaluation benchmarks to identify unwanted behaviours in AI systems, such as AI systems making misleading statements, biased decisions, or repeating copyrighted content. Now, as the AI community builds and deploys increasingly powerful AI, we must expand the evaluation portfolio to include the possibility of extreme risks from general-purpose AI models that have strong skills in manipulation, deception, cyber-offense, or other dangerous capabilities.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stochastic Numerics and Statistical Learning]]></title>
        <id>http://xianblog.wordpress.com/?p=53075</id>
        <link href="https://xianblog.wordpress.com/2023/05/25/stochastic-numerics-and-statistical-learning/"/>
        <updated>2023-05-24T22:23:33.000Z</updated>
        <summary type="html"><![CDATA[This week, I am taking part in the Stochastic Numerics and Statistical Learning workshop, in KAUST, which should prove an interesting experience!]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Decipherment of Linear A]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58786</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58786&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=decipherment-of-linear-a"/>
        <updated>2023-05-24T11:14:27.000Z</updated>
        <summary type="html"><![CDATA[Methodologically, the following communication from Elizabeth J. W. Barber is too important to be left buried in a comment to this post:  "ChatGPT does cuneiform studies" (5/21/23) As I showed in my 1974 book, Archaeological Decipherment, there is a mathematical algorithm showing how much text one needs to PROVABLY accomplish a decipherment for what sort […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mind the spikes: Benign overfitting of kernels and neural networks in
  fixed dimension]]></title>
        <id>http://arxiv.org/abs/2305.14077</id>
        <link href="http://arxiv.org/abs/2305.14077"/>
        <updated>2023-05-24T07:13:44.399Z</updated>
        <summary type="html"><![CDATA[Moritz Haas, David Holzm\"uller, Ulrike von Luxburg, Ingo Steinwart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The CoT Collection: Improving Zero-shot and Few-shot Learning of
  Language Models via Chain-of-Thought Fine-Tuning]]></title>
        <id>http://arxiv.org/abs/2305.14045</id>
        <link href="http://arxiv.org/abs/2305.14045"/>
        <updated>2023-05-24T07:13:44.392Z</updated>
        <summary type="html"><![CDATA[Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye,
  Jamin Shin, Minjoon Seo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding]]></title>
        <id>http://arxiv.org/abs/2305.14196</id>
        <link href="http://arxiv.org/abs/2305.14196"/>
        <updated>2023-05-24T07:13:44.382Z</updated>
        <summary type="html"><![CDATA[Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, Omer
  Levy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning with Kernels through RKHM and the Perron-Frobenius
  Operator]]></title>
        <id>http://arxiv.org/abs/2305.13588</id>
        <link href="http://arxiv.org/abs/2305.13588"/>
        <updated>2023-05-24T07:13:44.376Z</updated>
        <summary type="html"><![CDATA[Yuka Hashimoto, Masahiro Ikeda, Hachem Kadri]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transferring Learning Trajectories of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.14122</id>
        <link href="http://arxiv.org/abs/2305.14122"/>
        <updated>2023-05-24T07:13:44.370Z</updated>
        <summary type="html"><![CDATA[Daiki Chijiwa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Choosing a good file format for Pandas]]></title>
        <id>https://pythonspeed.com/articles/best-file-format-for-pandas/</id>
        <link href="https://pythonspeed.com/articles/best-file-format-for-pandas/"/>
        <updated>2023-05-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Before you can process your data with Pandas, you need to load it (from disk or remote storage).
There are plenty of data formats supported by Pandas, from CSV, to JSON, to Parquet, and many others as well.
Which should you use?
You don’t want loading the data to be slow, or use lots of memory: that’s pure overhead.
Ideally you’d want a file format that’s fast, efficient, small, and broadly supported.
You also want to make sure the loaded data has all the right types: numeric types, datetimes, and so on.
Some data formats do a better job at this than others.
While there is no one true answer that works for everyone, this article will try to help you narrow down the field and make an informed decision.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[art brut]]></title>
        <id>http://xianblog.wordpress.com/?p=53022</id>
        <link href="https://xianblog.wordpress.com/2023/05/24/art-brut-90/"/>
        <updated>2023-05-23T22:23:05.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Resolving code review comments with ML]]></title>
        <id>http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html</id>
        <link href="http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html"/>
        <updated>2023-05-23T17:51:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Alexander Frömmgen, Staff Software Engineer, and Lera Kharatyan, Senior Software Engineer, Core Systems & Experiences


  

Code-change reviews are a critical part of the software development process at scale, taking a significant amount of the code authors’ and the code reviewers’ time. As part of this process, the reviewer inspects the proposed code and asks the author for code changes through comments written in natural language. At Google, we see millions of reviewer comments per year, and authors require an average of ~60 minutes active shepherding time between sending changes for review and finally submitting the change. In our measurements, the required active work time that the code author must do to address reviewer comments grows almost linearly with the number of comme…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPT-4 + Stable-Diffusion = ?: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models]]></title>
        <id>http://bair.berkeley.edu/blog/2023/05/23/lmd/</id>
        <link href="http://bair.berkeley.edu/blog/2023/05/23/lmd/"/>
        <updated>2023-05-23T15:00:00.000Z</updated>
        <summary type="html"><![CDATA[TL;DR: Text Prompt -> LLM -> Intermediate Representation (such as an image layout) -> Stable Diffusion -> Image.
Recent advancements in text-to-image generation with diffusion models have yielded remarkable results synthesizing highly realistic and diverse images. However, despite their impressive capabilities, diffusion models, such as Stable Diffusion, often struggle to accurately follow the prompts when spatial or common sense reasoning is required.
The following figure lists four scenarios in which Stable Diffusion falls short in generating images that accurately correspond to the given prompts, namely negation, numeracy, and attribute assignment, spatial relationships. In contrast, our method, LLM-grounded Diffusion (LMD), delivers much better prompt understanding in text-to-image gen…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yann LeCun - Towards Machines that can Learn, Reason, and Plan.]]></title>
        <id>https://mlfoundations.org/talk/lecun/</id>
        <link href="https://mlfoundations.org/talk/lecun/"/>
        <updated>2023-05-23T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[How could machines learn as efficiently as humans and animals? How could machines learn how the world works and acquire common sense? How could machines learn to reason and plan? Current AI architectures, such as Auto-Regressive Large Language Models fall short.  I will propose a modular cognitive architecture that may constitute a path towards answering these questions.  The centerpiece of the architecture is a predictive world model that allows the system to predict the consequences of its actions and to plan a sequence of actions that optimize a set of objectives. The world model employs a Hierarchical Joint Embedding Predictive Architecture (H-JEPA) trained with self-supervised learning. The JEPA learns abstract representations of the percepts that are simultaneously maximally informative and maximally predictable. The corresponding working paper is available here - [A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chinese characters and the messiness of Chinese culture]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58781</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58781&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chinese-characters-and-the-messiness-of-chinese-culture"/>
        <updated>2023-05-23T10:57:23.000Z</updated>
        <summary type="html"><![CDATA[Is it really so? Uncannily and independently, Apollo Wu* sent me the following note before I made this post: Hànzì bùrú pīnyīn de guānjiàn lǐngyù shì páixù, jiǎnsuǒ hé réngōng zhìnéng. Fùzá, fánsuǒ, nán xué nán yòng shì wǒmen mùqián miànlín de kùnnán. Hànzì de luàn, biāozhìzhe Zhōngguó wénhuà de luàn! 汉字 比不上 字母文字 的 […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memorization and Optimization in Deep Neural Networks with Minimum
  Over-parameterization]]></title>
        <id>http://arxiv.org/abs/2205.10217</id>
        <link href="http://arxiv.org/abs/2205.10217"/>
        <updated>2023-05-23T07:13:42.300Z</updated>
        <summary type="html"><![CDATA[Simone Bombari, Mohammad Hossein Amani, Marco Mondelli]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Discriminative to Kernel Generative Networks for Calibrated
  Inference]]></title>
        <id>http://arxiv.org/abs/2201.13001</id>
        <link href="http://arxiv.org/abs/2201.13001"/>
        <updated>2023-05-23T07:13:42.293Z</updated>
        <summary type="html"><![CDATA[Jayanta Dey, Haoyin Xu, Ashwin De Silva, Will LeVine, Tyler M. Tomita,
  Ali Geisa, Tiffany Chu, Jacob Desman, Joshua T. Vogelstein]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Counterfactual Explanations for Neural Networks With
  Probabilistic Guarantees]]></title>
        <id>http://arxiv.org/abs/2305.11997</id>
        <link href="http://arxiv.org/abs/2305.11997"/>
        <updated>2023-05-23T07:13:42.269Z</updated>
        <summary type="html"><![CDATA[Faisal Hamman, Erfaun Noorani, Saumitra Mishra, Daniele Magazzeni,
  Sanghamitra Dutta]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Not All Semantics are Created Equal: Contrastive Self-supervised
  Learning with Automatic Temperature Individualization]]></title>
        <id>http://arxiv.org/abs/2305.11965</id>
        <link href="http://arxiv.org/abs/2305.11965"/>
        <updated>2023-05-23T07:13:42.257Z</updated>
        <summary type="html"><![CDATA[Zi-Hao Qiu, Quanqi Hu, Zhuoning Yuan, Denny Zhou, Lijun Zhang, Tianbao
  Yang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive and Robust Multi-Task Learning]]></title>
        <id>http://arxiv.org/abs/2202.05250</id>
        <link href="http://arxiv.org/abs/2202.05250"/>
        <updated>2023-05-23T07:13:42.204Z</updated>
        <summary type="html"><![CDATA[Yaqi Duan, Kaizheng Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NBCE：使用朴素贝叶斯拓展LLM的Context处理长度]]></title>
        <id>https://kexue.fm/archives/9617</id>
        <link href="https://kexue.fm/archives/9617"/>
        <updated>2023-05-23T02:45:00.000Z</updated>
        <summary type="html"><![CDATA[在LLM时代还玩朴素贝叶斯（Naive Bayes）？这可能是许多读者在看到标题后的首个想法。确实如此，当古老的朴素贝叶斯与前沿的LLM相遇时，产生了令人惊讶的效果——我们可以直接提升现有LLM...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bernoulli factory on a budget]]></title>
        <id>http://xianblog.wordpress.com/?p=53038</id>
        <link href="https://xianblog.wordpress.com/2023/05/23/bernoulli-factory-on-a-budget/"/>
        <updated>2023-05-22T22:23:22.000Z</updated>
        <summary type="html"><![CDATA[A form of Bernoulli factory with limited energy from The Riddler: being given the choice of 0<p<1, what is the minimal number n of throws such that the outcomes of n iid B(p) draws can be partitioned into six groups of equal probability? Running a brute force R code [in the train to Cambridge] and […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning sinitic and sinoglyphic "zero"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58778</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58778&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=learning-sinitic-and-sinoglyphic-zero"/>
        <updated>2023-05-22T12:00:04.000Z</updated>
        <summary type="html"><![CDATA[Plus Indic, plus Arabic, Korean, Vietnamese, Hokkien (Taiwanese), Hakka, and Fuzhou (Eastern Min). For an exciting read / ride, be sure to follow the whole thread, travelling through time and space. 零 originally didn't mean 'zero,' but 'small rain, drizzle.' Makes it easy to learn: Rain 雨 above, pronunciation 令 below (ok, tone is different). […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-Shot Continual Learning for Conditional Generative Adversarial
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.11400</id>
        <link href="http://arxiv.org/abs/2305.11400"/>
        <updated>2023-05-22T08:19:27.936Z</updated>
        <summary type="html"><![CDATA[Cat P. Le, Juncheng Dong, Ahmed Aloui, Vahid Tarokh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-learning for heterogeneous treatment effect estimation with
  closed-form solvers]]></title>
        <id>http://arxiv.org/abs/2305.11353</id>
        <link href="http://arxiv.org/abs/2305.11353"/>
        <updated>2023-05-22T08:19:27.389Z</updated>
        <summary type="html"><![CDATA[Tomoharu Iwata, Yoichi Chikahara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Real-Time Variational Method for Learning Neural Trajectory and its
  Dynamics]]></title>
        <id>http://arxiv.org/abs/2305.11278</id>
        <link href="http://arxiv.org/abs/2305.11278"/>
        <updated>2023-05-22T08:19:27.383Z</updated>
        <summary type="html"><![CDATA[Matthew Dowling, Yuan Zhao, Il Memming Park]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incorporating Unlabelled Data into Bayesian Neural Networks]]></title>
        <id>http://arxiv.org/abs/2304.01762</id>
        <link href="http://arxiv.org/abs/2304.01762"/>
        <updated>2023-05-22T08:19:27.328Z</updated>
        <summary type="html"><![CDATA[Mrinank Sharma, Tom Rainforth, Yee Whye Teh, Vincent Fortuin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Out of the box acceleration and memory savings of 🤗 decoder models with PyTorch 2.0]]></title>
        <id>https://pytorch.org/blog/out-of-the-box-acceleration/</id>
        <link href="https://pytorch.org/blog/out-of-the-box-acceleration/"/>
        <updated>2023-05-22T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[As part of PyTorch 2.0 release, an accelerated implementation of the attention mechanism as part of the “Better Transformer” project (and known in PyTorch as Accelerated Transformers) has been added natively into PyTorch as torch.nn.functional.scaled_dot_product_attention. This implementation leverages fused kernels from FlashAttention and Memory-efficient attention, and supports both training and inference.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Italy no-no’s]]></title>
        <id>http://xianblog.wordpress.com/?p=52979</id>
        <link href="https://xianblog.wordpress.com/2023/05/22/italy-no-nos/"/>
        <updated>2023-05-21T22:23:12.000Z</updated>
        <summary type="html"><![CDATA[The Lonely Planet blog has a list of prohibitions on tourists’ activities when visiting some Italian cities. Like Venice, Rome or Milan (below). Most of which is sort of obvious, like not walking around shirtless or barefoot away from beaches, feed the pigeons (although our kids did when visiting Venice for the first time!), hold […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hack of the year: 1980]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58767</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58767&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hack-of-the-year-1980"/>
        <updated>2023-05-21T15:00:41.000Z</updated>
        <summary type="html"><![CDATA[I recently stumbled on this 5/10/2023 Medium article by David Brock, "A Backup of Historical Proportions" — which reminded me of the Xerox Palo Alto Research Center ("PARC") and the Xerox Alto. Those were the people and the machine that invented interactive GUIs on bit-mapped displays, the computer mouse, and so on — though it […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ChatGPT does cuneiform studies]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58745</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58745&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=chatgpt-does-cuneiform-studies"/>
        <updated>2023-05-21T10:32:21.000Z</updated>
        <summary type="html"><![CDATA[We have seen ChatGPT tell stories (and variants of the stories it tells), fancify Coleridge's famous poem on Xanadu, pose a serious challenge to the Great Firewall of China, mimic VHM, write Haiku, and perform all manner of amazing feats.  In a forthcoming post, we will witness its efforts to translate Chinese poetry.  Today, we […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[foxhuntshire]]></title>
        <id>http://xianblog.wordpress.com/?p=53034</id>
        <link href="https://xianblog.wordpress.com/2023/05/21/foxhuntshire/"/>
        <updated>2023-05-20T22:23:42.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Château Balac [Haut-Médoc]]]></title>
        <id>http://xianblog.wordpress.com/?p=52447</id>
        <link href="https://xianblog.wordpress.com/2023/05/20/chateau-balac-haut-medoc/"/>
        <updated>2023-05-20T18:20:23.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI comic strip creation?]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58752</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58752&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-comic-strip-creation"/>
        <updated>2023-05-20T15:02:30.000Z</updated>
        <summary type="html"><![CDATA[Today's Tank McNamara: Of course the joke in this strip is the seven fingers on Tank's right hand, and the eight fingers on his left hand. A quick web search for {ai comic generator} turns out lots of options. As far as I can tell, these are all systems for creating images, not image sequences […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Romanisation 'gives clarity'"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58734</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58734&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=romanisation-gives-clarity"/>
        <updated>2023-05-20T04:48:59.000Z</updated>
        <summary type="html"><![CDATA[As we have pointed out countless times on Language Log, if one wishes to learn a Sinitic language, one can concentrate on the characters (writing system), one can rely exclusively on romanization or other phoneticization, or one can devise various means for combining the two approaches.  Here is a clever, fun method for learning Cantonese […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPT as an “Intelligence Forklift.”]]></title>
        <id>http://windowsontheory.org/?p=8615</id>
        <link href="https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/"/>
        <updated>2023-05-19T21:16:17.000Z</updated>
        <summary type="html"><![CDATA[[See my post with Edelman on AI takeover and Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.]  One challenge for considering the implications of “artificial intelligence,” especially of the “general” variety, is that we don’t have a consensus definition of intelligence. The Oxford Companion … Continue reading GPT as an “Intelligence Forklift.”]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GPT as an “Intelligence Forklift.”]]></title>
        <id>http://windowsontheory.org/?p=8615</id>
        <link href="https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/"/>
        <updated>2023-05-19T21:16:17.000Z</updated>
        <summary type="html"><![CDATA[[See my post with Edelman on AI takeover and Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.]  One challenge for considering the implications of “artificial intelligence,” especially of the “general” variety, is that we don’t have a consensus definition of intelligence. The Oxford Companion … Continue reading GPT as an “Intelligence Forklift.”]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[互联网技术比游戏后端技术领先十年吗？]]></title>
        <id>https://www.skywind.me/blog/?p=2719</id>
        <link href="https://www.skywind.me/blog/archives/2719"/>
        <updated>2023-05-19T17:14:00.000Z</updated>
        <summary type="html"><![CDATA[最近时间线上看到不少人在论战，做互联网的人觉得游戏服务端发展很慢，而互联网技术日新月异，觉得似乎互联网技术领先了游戏后端技术十年，这个结论显然是武断的，互联网就是发展到今天，就是任意一台互联网的服务器拿出来，其复杂度也远远比不上游戏服务器，即便各种 C/C++ 开发的互联网基建项目。 同时没有意识到游戏玩家之间交互性的复杂性与实时性是大部分互联网项目无法比较的。话分两头说，看到一些做游戏后端的同学觉得互联网更简单，电商之类的更是 CRUD 的增删改查，比起游戏服务器落后十年不止。 我觉得游戏服务端的同学实属没必要和这个互联网的人一般见识，不管不顾的也跟着说什么游戏服务端比互联网先进十年什么的，这是另一个极端了，一些情况也需要正视： 1）游戏服务端足够复杂，但是发展太慢，祖传代码修修补补跑个十多年的不要太多。能用固然是好事，但没有新观念的引入，导致可用性和开发效率一直没有太多提升。 2）各自闭门造车，没有形成行业标准与合力，这个项目的代码，很难在另一个项目共享，相互之间缺少支持和协同。 3）互联网后端随便拎出一个服务来（包括各种 C/C++ 基建）大概率都没有游戏服务端复杂，但最近十年日新月异，形成了很强的互相组合互相增强的态势。 我上面指的是互联网基建项目，不是互联网 CRUD，实话实说，游戏服务器的确很复杂很难，可能 ARPG 里砍一刀这种小事情，想砍的有手感，做互联网的也不一定能理解背后的复杂度有多少。但互联网近十年的发展，让其整体可用性，效能，开发效率，都上了很多个台阶，不应一味忽视。 如果继续觉得游戏服务端领先互联网十年可以直接右转了，开放心态的话我也可以多聊一些（点击下方 more 阅读更多）： 举个例子，音视频领域的基建，并不比游戏服务端简单： 1）一路高清视频 720-1080p 的，差不多每秒钟 2MB/s 的数据量，同时在线 100w 的，整个网络每秒钟至少有 2T/s 的数据量在跑着，不但不分服，而且玩家遍布世界每个角落，还要不卡不掉不延迟，这个数据量比起游戏的消息要大好几个数量级吧？在把这 2T/s 数据安排明白妥当的同时，还得保证延迟不能超过 500ms，超过就没法玩了。 2）一个房间的人数少的是 2-4 人，多的上千人，遍布 4-5 个国家，你一屏幕打开，可以同时看到 50 个人的视频，虽然是小窗口，但是你拉住任意小窗口，快速拉大到全屏，看不到明显的清晰度梯度切换带来的抖动，如何实现呢？ 3）全球上百个机房协同工作，组成一张很大的网络，一会这个机房出问题，一会那里线路阻塞了，能做到动态自如的切换，让用户几乎感觉不到，也不容易吧？ 4）更新无需停机，停服，即便一个 1000 人的房间后面的服务器更新，可能你都感觉不出来，视频的房间也算是有状态的，这种平滑的切换，不算简单吧？ 5）弱网情况下，开着车接着视频，不停切换基站，60% 的丢包情况下，虽然会卡一些，但如果要保证基础可用，也还是有点技术含量的吧。 ６）服务端跑视频编码器，即便有现成开源的也需要自己花大力气二次开发，编码器方面的积累，你不搞个四五年，你入不了手吧？这方面的知识日新月异，每年都有新标准，更新比游戏快多了。 ７）后端图象增强，允许带宽不足用户发送比较差的视频，增强成比较清晰的视频，这个 AI 增强技术，比 DLSS 1/2 复杂好几个台阶。 8）即便不是实时通信，点播，看着简单，也有很多挑战的地方，比如你客户端看短视频，不停的手指往上滑，连续划十个，不卡，秒出，丝滑切换，光这一点数据量有多大？客户端该怎么管理资源？服务端从接入服务，调度服务，到 CDN 和传输协议，要做多少项优化呢？ […]
The post 互联网技术比游戏后端技术领先十年吗？ appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Making ML models differentially private: Best practices and open challenges]]></title>
        <id>http://ai.googleblog.com/2023/05/making-ml-models-differentially-private.html</id>
        <link href="http://ai.googleblog.com/2023/05/making-ml-models-differentially-private.html"/>
        <updated>2023-05-19T16:59:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Natalia Ponomareva and Alex Kurakin, Staff Software Engineers, Google Research






Large machine learning (ML) models are ubiquitous in modern applications: from spam filters to recommender systems and virtual assistants. These models achieve remarkable performance partially due to the abundance of available training data. However, these data can sometimes contain private information, including personal identifiable information, copyright material, etc. Therefore, protecting the privacy of the training data is critical to practical, applied ML.  



Differential Privacy (DP) is one of the most widely accepted technologies that allows reasoning about data anonymization in a formal way. In the context of an ML model, DP can guarantee that each individual user's contribution will …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Timothy Lillicrap - Model-based reinforcement learning and the future of language models]]></title>
        <id>https://mlfoundations.org/talk/lilicrap/</id>
        <link href="https://mlfoundations.org/talk/lilicrap/"/>
        <updated>2023-05-19T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Large language models are capable of an incredible array of tasks. Language models are pre-trained on large amounts of text data from the internet. Then they are fine-tuned on instruction following and further improved by optimizing human preferences. The resulting models are imperfect but are nevertheless able to hold conversations, solve problems, and use tools. How quickly will these models continue to improve? There are a variety of opinions. The answer to this question is also important because language models are poised to make significant changes to the way we live and work. Some researchers think we’ve hit a plateau in performance and that progress will stall without a breakthrough. Others predict the arrival of general intelligence within a couple of years.Putting aside the question of AGI, I will argue that rapid progress in model capabilities will continue without the need for a breakthrough. I will draw connections between language model research and the past decade of work in deep reinforcement learning, especially the Go & Starcraft projects.
These projects followed a similar methodology - models were pre-trained using data collected from game databases. Then they were improved iteratively with reinforcement learning. Viewed from the vantage point of model-based reinforcement learning, optimization of language models is in its infancy. Put simply, there are clear experiments which are likely to create much better models. Why haven’t these experiments been run already? Since performant language models are large and reward is derived from human preferences, experiments require extensive coordination of people and compute. Given economic incentives, we can expect researchers to overcome these hurdles. There is therefore good reason to believe that language model capabilities will continue to improve rapidly. This motivates increased investment in AI safety research, policy, and governance.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Epistemic Neural Networks]]></title>
        <id>http://arxiv.org/abs/2107.08924</id>
        <link href="http://arxiv.org/abs/2107.08924"/>
        <updated>2023-05-19T07:13:19.926Z</updated>
        <summary type="html"><![CDATA[Ian Osband, Zheng Wen, Seyed Mohammad Asghari, Vikranth Dwaracherla,
  Morteza Ibrahimi, Xiuyuan Lu, Benjamin Van Roy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample
  Complexity for Learning Single Index Models]]></title>
        <id>http://arxiv.org/abs/2305.10633</id>
        <link href="http://arxiv.org/abs/2305.10633"/>
        <updated>2023-05-19T07:13:19.919Z</updated>
        <summary type="html"><![CDATA[Alex Damian, Eshaan Nichani, Rong Ge, Jason D. Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified machine learning: Open-set learning with augmented category by
  exploiting unlabelled data (Open-LACU)]]></title>
        <id>http://arxiv.org/abs/2002.01368</id>
        <link href="http://arxiv.org/abs/2002.01368"/>
        <updated>2023-05-19T07:13:19.894Z</updated>
        <summary type="html"><![CDATA[Emile R. Engelbrecht, Johan A. du Preez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Measure of the Complexity of Neural Representations based on Partial
  Information Decomposition]]></title>
        <id>http://arxiv.org/abs/2209.10438</id>
        <link href="http://arxiv.org/abs/2209.10438"/>
        <updated>2023-05-19T07:13:19.888Z</updated>
        <summary type="html"><![CDATA[David A. Ehrlich, Andreas C. Schneider, Viola Priesemann, Michael
  Wibral, Abdullah Makkeh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[French coast]]></title>
        <id>http://xianblog.wordpress.com/?p=53019</id>
        <link href="https://xianblog.wordpress.com/2023/05/19/french-coast/"/>
        <updated>2023-05-18T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse video tubes for joint video and image vision transformers]]></title>
        <id>http://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html</id>
        <link href="http://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html"/>
        <updated>2023-05-18T21:08:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by AJ Piergiovanni and Anelia Angelova, Research Scientists, Google








Video understanding is a challenging problem that requires reasoning about both spatial information (e.g., for objects in a scene, including their locations and relations) and temporal information for activities or events shown in a video. There are many video understanding applications and tasks, such as understanding the semantic content of web videos and robot perception. However, current works, such as ViViT and TimeSFormer, densely process the video and require significant compute, especially as model size plus video length and resolution increase. 



In “Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video Learning”, to be presented at CVPR 2023, we introduce a simple technique that tur…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Responsible AI at Google Research: PAIR]]></title>
        <id>http://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html</id>
        <link href="http://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html"/>
        <updated>2023-05-18T17:12:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Lucas Dixon and Michael Terry, co-leads, PAIR, Google Research




PAIR (People + AI Research) first launched in 2017 with the belief that “AI can go much further — and be more useful to all of us — if we build systems with people in mind at the start of the process.” We continue to focus on making AI more understandable, interpretable, fun, and usable by more people around the world. It’s a mission that is particularly timely given the emergence of generative AI and chatbots.



Today, PAIR is part of the Responsible AI and Human-Centered Technology team within Google Research, and our work spans this larger research space: We advance foundational research on human-AI interaction (HAI) and machine learning (ML); we publish educational materials, including the PAIR Guidebook and …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[基于量子化假设推导模型的尺度定律（Scaling Law）]]></title>
        <id>https://kexue.fm/archives/9607</id>
        <link href="https://kexue.fm/archives/9607"/>
        <updated>2023-05-18T12:55:00.000Z</updated>
        <summary type="html"><![CDATA[尺度定律（Scaling Law），指的是模型能力与模型尺度之间的渐近关系。具体来说，模型能力我们可以简单理解为模型的损失函数，模型尺度可以指模型参数量、训练数据量、训练步数等，所谓尺度定律，就...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stratified Learning: A General-Purpose Statistical Method for Improved
  Learning under Covariate Shift]]></title>
        <id>http://arxiv.org/abs/2106.11211</id>
        <link href="http://arxiv.org/abs/2106.11211"/>
        <updated>2023-05-18T07:13:31.695Z</updated>
        <summary type="html"><![CDATA[Maximilian Autenrieth, David A. van Dyk, Roberto Trotta, David C.
  Stenning]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep quantum neural networks form Gaussian processes]]></title>
        <id>http://arxiv.org/abs/2305.09957</id>
        <link href="http://arxiv.org/abs/2305.09957"/>
        <updated>2023-05-18T07:13:31.666Z</updated>
        <summary type="html"><![CDATA[Diego Garc\'ia-Mart\'in, Martin Larocca, M. Cerezo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Active Learning in Symbolic Regression Performance with Physical
  Constraints]]></title>
        <id>http://arxiv.org/abs/2305.10379</id>
        <link href="http://arxiv.org/abs/2305.10379"/>
        <updated>2023-05-18T07:13:30.762Z</updated>
        <summary type="html"><![CDATA[Jorge Medina, Andrew D. White]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning curves for deep structured Gaussian feature models]]></title>
        <id>http://arxiv.org/abs/2303.00564</id>
        <link href="http://arxiv.org/abs/2303.00564"/>
        <updated>2023-05-18T07:13:30.755Z</updated>
        <summary type="html"><![CDATA[Jacob A. Zavatone-Veth, Cengiz Pehlevan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[grasshoppers for pythons]]></title>
        <id>http://xianblog.wordpress.com/?p=53069</id>
        <link href="https://xianblog.wordpress.com/2023/05/18/grasshoppers-for-pythons/"/>
        <updated>2023-05-17T22:23:17.000Z</updated>
        <summary type="html"><![CDATA[Following my earlier post on the terrible performances of ChatGPT for a grasshopping riddle, Bob Carpenter sent me his interaction with GPT4, using the same entry. Here is the python code outcome he obtained. The code is running  and the answer is correct. BC: Thanks. Can you write a python program to simulate the final […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Phở]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58720</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58720&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pho"/>
        <updated>2023-05-17T13:34:32.000Z</updated>
        <summary type="html"><![CDATA[Since about the 90s, pho has been popping up all over the place.  It has been especially conspicuous after the turn of the millennium, and I think it adapted well to the pandemic as a quick and ready kind of street food.  I've often wondered whether it had anything to do with French "fire" or […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up Learning Quantum States through Group Equivariant
  Convolutional Quantum Ans\"atze]]></title>
        <id>http://arxiv.org/abs/2112.07611</id>
        <link href="http://arxiv.org/abs/2112.07611"/>
        <updated>2023-05-17T07:13:38.489Z</updated>
        <summary type="html"><![CDATA[Han Zheng, Zimu Li, Junyu Liu, Sergii Strelchuk, Risi Kondor]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph neural networks-based Scheduler for Production planning problems
  using Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2009.03836</id>
        <link href="http://arxiv.org/abs/2009.03836"/>
        <updated>2023-05-17T07:13:38.479Z</updated>
        <summary type="html"><![CDATA[Mohammed Sharafath Abdul Hameed, Andreas Schwung]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Expressivity of Shallow and Deep Neural Networks for Polynomial
  Approximation]]></title>
        <id>http://arxiv.org/abs/2303.03544</id>
        <link href="http://arxiv.org/abs/2303.03544"/>
        <updated>2023-05-17T07:13:38.456Z</updated>
        <summary type="html"><![CDATA[Itai Shapira]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning from Aggregated Data: Curated Bags versus Random Bags]]></title>
        <id>http://arxiv.org/abs/2305.09557</id>
        <link href="http://arxiv.org/abs/2305.09557"/>
        <updated>2023-05-17T07:13:37.498Z</updated>
        <summary type="html"><![CDATA[Lin Chen, Thomas Fu, Amin Karbasi, Vahab Mirrokni]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning-Rate-Free Learning by D-Adaptation]]></title>
        <id>http://arxiv.org/abs/2301.07733</id>
        <link href="http://arxiv.org/abs/2301.07733"/>
        <updated>2023-05-17T07:13:37.479Z</updated>
        <summary type="html"><![CDATA[Aaron Defazio, Konstantin Mishchenko]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Festschift for Sylvia]]></title>
        <id>http://xianblog.wordpress.com/?p=53043</id>
        <link href="https://xianblog.wordpress.com/2023/05/17/53043/"/>
        <updated>2023-05-16T22:23:17.000Z</updated>
        <summary type="html"><![CDATA[At Sylvia Richardson’s career celebration last Friday, I gave a talk on How many components in a mixture? which was most relevant given Sylvia’s contributions to mixture inference over the years, including her highly influential 1997 Read Paper with Peter Green. The other talks highlighted the many facets of Sylvia to the field and the […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using reinforcement learning for dynamic planning in open-ended conversations]]></title>
        <id>http://ai.googleblog.com/2023/05/using-reinforcement-learning-for.html</id>
        <link href="http://ai.googleblog.com/2023/05/using-reinforcement-learning-for.html"/>
        <updated>2023-05-16T19:22:00.001Z</updated>
        <summary type="html"><![CDATA[Posted by Deborah Cohen, Staff Research Scientist, and Craig Boutilier, Principal Scientist, Google Research




As virtual assistants become ubiquitous, users increasingly interact with them to learn about new topics or obtain recommendations and expect them to deliver capabilities beyond narrow dialogues of one or two turns. Dynamic planning, namely the capability to look ahead and replan based on the flow of the conversation, is an essential ingredient for the making of engaging conversations with the deeper, open-ended interactions that users expect.
 

While large language models (LLMs) are now beating state-of-the-art approaches in many natural language processing benchmarks, they are typically trained to output the next best response, rather than planning ahead, which is required fo…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Quid pro crow"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58724</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58724&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=quid-pro-crow"/>
        <updated>2023-05-16T13:42:43.000Z</updated>
        <summary type="html"><![CDATA[In Maria Bartiromo's recent interview with James Comer (R-KY), there's an interesting speech error — "quid pro crow" for "quid pro quo": This being Language Log rather than Making Fun Of Politicians Log, I'm going to start by assuming that this was a slip of the tongue rather than an inadequate command of legal Latin […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CCP scamming with a Taiwanese-like accent]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58702</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58702&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ccp-scamming-with-a-taiwanese-like-accent"/>
        <updated>2023-05-16T11:40:37.000Z</updated>
        <summary type="html"><![CDATA[Topolects matter: Taiwanese buys anti-CCP book, gets scam call from Chinese propagandist: Caller posing as Eslite Bookstore’s ‘marketing department’ tells consumer book content inappropriate By Stephanie Chiang, Taiwan News, Staff Reporter (5/14/23) Before delving into the substance of this report, I should mention that Eslite is a huge, and hugely influential, bookstore in Taiwan. AntC, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Guided Deep Kernel Learning]]></title>
        <id>http://arxiv.org/abs/2302.09574</id>
        <link href="http://arxiv.org/abs/2302.09574"/>
        <updated>2023-05-16T07:14:20.124Z</updated>
        <summary type="html"><![CDATA[Idan Achituve, Gal Chechik, Ethan Fetaya]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating Self-Supervised Learning via Risk Decomposition]]></title>
        <id>http://arxiv.org/abs/2302.03068</id>
        <link href="http://arxiv.org/abs/2302.03068"/>
        <updated>2023-05-16T07:14:20.117Z</updated>
        <summary type="html"><![CDATA[Yann Dubois, Tatsunori Hashimoto, Percy Liang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentiable Neural Networks with RePU Activation: with Applications
  to Score Estimation and Isotonic Regression]]></title>
        <id>http://arxiv.org/abs/2305.00608</id>
        <link href="http://arxiv.org/abs/2305.00608"/>
        <updated>2023-05-16T07:14:20.110Z</updated>
        <summary type="html"><![CDATA[Guohao Shen, Yuling Jiao, Yuanyuan Lin, Jian Huang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Topological Interpretability for Deep-Learning]]></title>
        <id>http://arxiv.org/abs/2305.08642</id>
        <link href="http://arxiv.org/abs/2305.08642"/>
        <updated>2023-05-16T07:14:20.072Z</updated>
        <summary type="html"><![CDATA[Adam Spannaus, Heidi A.Hanson, Lynne Penberthy, Georgia Tourassi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch Conference 2023: Join us in San Francisco October 16-17]]></title>
        <id>https://pytorch.org/blog/pytorch-conference-2023/</id>
        <link href="https://pytorch.org/blog/pytorch-conference-2023/"/>
        <updated>2023-05-16T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[<div type="html"/>]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[more [grass]hope]]></title>
        <id>http://xianblog.wordpress.com/?p=53063</id>
        <link href="https://xianblog.wordpress.com/2023/05/16/more-grasshope/"/>
        <updated>2023-05-15T22:23:34.000Z</updated>
        <summary type="html"><![CDATA[Following my earlier post on the terrible performances of ChatGPT for a grasshopping riddle, Bob Carpenter sent me his interaction with GPT4, using the same entry. Here is the outcome he obtained. The answer is correct, but the reasoning is wrong. GPT4: This is a classic problem of infinite series and expected values in probability […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Larger language models do in-context learning differently]]></title>
        <id>http://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html</id>
        <link href="http://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html"/>
        <updated>2023-05-15T20:59:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Jerry Wei, Student Researcher, and Denny Zhou, Principal Scientist, Google Research




There have recently been tremendous advances in language models, partly because they can perform tasks with strong performance via in-context learning (ICL), a process whereby models are prompted with a few examples of input-label pairs before performing the task on an unseen evaluation example. In general, models’ success at in-context learning is enabled by:
 


Their use of semantic prior knowledge from pre-training to predict labels while following the format of in-context examples (e.g., seeing examples of movie reviews with “positive sentiment” and “negative sentiment” as labels and performing sentiment analysis using prior knowledge).


Learning the input-label mappings in context from …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Consensus and subjectivity of skin tone annotation for ML fairness]]></title>
        <id>http://ai.googleblog.com/2023/05/consensus-and-subjectivity-of-skin-tone_15.html</id>
        <link href="http://ai.googleblog.com/2023/05/consensus-and-subjectivity-of-skin-tone_15.html"/>
        <updated>2023-05-15T17:16:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Candice Schumann, Software Engineer, and Gbolahan O. Olanubi, User Experience Researcher, Google Research




Skin tone is an observable characteristic that is subjective, perceived differently by individuals (e.g., depending on their location or culture) and thus is complicated to annotate. That said, the ability to reliably and accurately annotate skin tone is highly important in computer vision. This became apparent in 2018, when the Gender Shades study highlighted that computer vision systems struggled to detect people with darker skin tones, and performed particularly poorly for women with darker skin tones. The study highlights the importance for computer researchers and practitioners to evaluate their technologies across the full range of skin tones and at intersections of…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI Anchorman "@EdisonGPT"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58706</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58706&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-anchorman-edisongpt"/>
        <updated>2023-05-15T11:52:37.000Z</updated>
        <summary type="html"><![CDATA[The future of news? 🚨 BREAKING!!! Just when we thought we'd defeated the #CensorshipIndustrialComplex and @TuckerCarlson rose again on @Twitter, @elonmusk appoints #LindaYaccarino as new #TwitterCEO. Can an Executive Chair from the #WEF lead the revolution?#BreakingNews #EdisonThrustwell #WTF pic.twitter.com/uHt7NjCiO6 — Edison Thrustwell (@EdisonGPT) May 12, 2023 That's the first "Edison Thrustwell" tweet that I saw. […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sperm whale talk]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58687</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58687&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=sperm-whale-talk"/>
        <updated>2023-05-15T09:04:22.000Z</updated>
        <summary type="html"><![CDATA[Animal communication is not a favorite topic here at Language Log, but according to the following account, one project concerning it seems serious and is being conducted by credible scientists.  Although their claims for its ultimate significance may be inflated, I believe the research they are undertaking is worth considering, especially after hearing the clicks […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable Coupling of Deep Learning with Logical Reasoning]]></title>
        <id>http://arxiv.org/abs/2305.07617</id>
        <link href="http://arxiv.org/abs/2305.07617"/>
        <updated>2023-05-15T07:15:23.838Z</updated>
        <summary type="html"><![CDATA[Marianne Defresne, Sophie Barbe, Thomas Schiex]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Aleatoric uncertainty for Errors-in-Variables models in deep regression]]></title>
        <id>http://arxiv.org/abs/2105.09095</id>
        <link href="http://arxiv.org/abs/2105.09095"/>
        <updated>2023-05-15T07:15:21.022Z</updated>
        <summary type="html"><![CDATA[J\"org Martin, Clemens Elster]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[COVID-19 diagnosis by routine blood tests using machine learning]]></title>
        <id>http://arxiv.org/abs/2006.03476</id>
        <link href="http://arxiv.org/abs/2006.03476"/>
        <updated>2023-05-15T07:15:20.992Z</updated>
        <summary type="html"><![CDATA[Matja\v{z} Kukar, Gregor Gun\v{c}ar, Toma\v{z} Vovko, Simon Podnar,
  Peter \v{C}ernel\v{c}, Miran Brvar, Mateja Zalaznik, Mateja Notar, Sa\v{s}o
  Mo\v{s}kon, Marko Notar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chez Guy**(*)]]></title>
        <id>http://xianblog.wordpress.com/?p=52858</id>
        <link href="https://xianblog.wordpress.com/2023/05/15/chez-guy/"/>
        <updated>2023-05-14T22:23:37.000Z</updated>
        <summary type="html"><![CDATA[While I rarely enter company sweepstakes and lotteries (and correlatively never win!), I answered a contest from my credit card company around the 2022 Beijing Winter Olympics, and won the prize of having a Chinese dinner cooked at home by a chef, news that I first treated as a spam for being so improbable. The […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Mama ŠČ!"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58691</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58691&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mama-sc"/>
        <updated>2023-05-14T13:37:33.000Z</updated>
        <summary type="html"><![CDATA[Among the entries in the  2023 Eurovision Song Contest,  there's one of particular linguistic and political interest — from Croatia, Let 3's Mama ŠČ!: [The video of the song's final Eurovision performance is blocked (at least for now) in the U.S. …] The Croatian lyrics and an English translation are available on genius.com, and the […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mathematical parking]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58671</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58671&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mathematical-parking"/>
        <updated>2023-05-14T03:36:45.000Z</updated>
        <summary type="html"><![CDATA[Sign on the campus of Zhōngguó kēxué jìshù dàxué 中国科学技术大学 (University of Science and Technology of China) telling people how to park: tíng hǎo chēliàng de hánglièshì 停好车辆的行列式* ("park your vehicles well according to rows and columns")*matrix determinant zuò hǎo xiūyǎng de wéijīfēn 做好修养的微积分* ("cultivate yourself well to gradually accumulate points [i.e., merit]")*calculus Parking according to one's profession. Selected […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[grass hopping on the wrong fgpt]]></title>
        <id>http://xianblog.wordpress.com/?p=52986</id>
        <link href="https://xianblog.wordpress.com/2023/05/14/grass-hopping-on-the-wrong-fgpt/"/>
        <updated>2023-05-13T22:23:23.000Z</updated>
        <summary type="html"><![CDATA[Checking the R coding abilities of ChatGPT, I entered the latest Riddler puzzle that asks for the expected value of the stationary distribution of a slowing-down random walk over the real line when the N-th jump from x is to x±2-N. Which is ½ since the limiting distribution is uniform over (-1,1). The first proposed […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Iowa town names]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58680</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58680&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=iowa-town-names"/>
        <updated>2023-05-13T14:04:03.000Z</updated>
        <summary type="html"><![CDATA[I'm in Ames, home of Iowa State University.  The next town down the road is Nevada.  What?  Yes, but it's /nəˈveɪdə/ nə-VAY-də, not /nɪˈvædə/ nih-VAD-ə; Spanish: [neˈβaða], and the locals I've met know the difference.  The same thing holds for Madrid, which is on the other side of Ames; it is /ˈmædrɪd/, not /məˈdrɪd/ mə-DRID, Spanish: [maˈðɾið]. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zen again]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58677</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58677&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=zen-again"/>
        <updated>2023-05-13T11:31:10.000Z</updated>
        <summary type="html"><![CDATA[From Nancy Friedman: I'm writing about "zen" in brand names and corporate lingo, having been amused by an email from Medium (where I'm a contributing writer) touting the platform's updates as "Project Zen"–a name chosen "because that's our goal: a zen-like reading experience."   I'm not sure I know what a "zen-like reading experience" is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[operation precisely impossible]]></title>
        <id>http://xianblog.wordpress.com/?p=52971</id>
        <link href="https://xianblog.wordpress.com/2023/05/13/operation-precisely-impossible/"/>
        <updated>2023-05-12T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Since the solution to the previous riddle from The Riddler on the maximum of  different terms in the composed operation a∅b∅c∅d∅e∅f depending on the bracketing ordering and the meaning of each ∅ among one of the six elementary operations got posted today as 974,860, I got back to my R code to understand why it […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[F-VLM: Open-vocabulary object detection upon frozen vision and language models]]></title>
        <id>http://ai.googleblog.com/2023/05/f-vlm-open-vocabulary-object-detection.html</id>
        <link href="http://ai.googleblog.com/2023/05/f-vlm-open-vocabulary-object-detection.html"/>
        <updated>2023-05-12T20:56:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Weicheng Kuo and Anelia Angelova, Research Scientists, Google Research






Detection is a fundamental vision task that aims to localize and recognize objects in an image. However, the data collection process of manually annotating bounding boxes or instance masks is tedious and costly, which limits the modern detection vocabulary size to roughly 1,000 object classes. This is orders of magnitude smaller than the vocabulary people use to describe the visual world and leaves out many categories. Recent vision and language models (VLMs), such as CLIP, have demonstrated improved open-vocabulary visual recognition capabilities through learning from Internet-scale image-text pairs. These VLMs are applied to zero-shot classification using frozen model weights without the need for fine-…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enabling conversational interaction on mobile with LLMs]]></title>
        <id>http://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html</id>
        <link href="http://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html"/>
        <updated>2023-05-12T17:03:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Bryan Wang, Student Researcher, and Yang Li, Research Scientist, Google Research





Intelligent assistants on mobile devices have significantly advanced language-based interactions for performing simple daily tasks, such as setting a timer or turning on a flashlight. Despite the progress, these assistants still face limitations in supporting conversational interactions in mobile user interfaces (UIs), where many user tasks are performed. For example, they cannot answer a user's question about specific information displayed on a screen. An agent would need to have a computational understanding of graphical user interfaces (GUIs) to achieve such capabilities. 



Prior research has investigated several important technical building blocks to enable conversational interaction with …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Yejin Choi - Common Sense: the Dark Matter of Language and Intelligence]]></title>
        <id>https://mlfoundations.org/talk/choi/</id>
        <link href="https://mlfoundations.org/talk/choi/"/>
        <updated>2023-05-12T14:15:00.000Z</updated>
        <summary type="html"><![CDATA[Scale appears to be the winning recipe in today's leaderboards. And yet, extreme-scale neural models are (un)surprisingly brittle and make errors that are often nonsensical and even counterintuitive. In this talk, I will argue for the importance of knowledge, especially commonsense knowledge, as well as inference-time reasoning algorithms, and demonstrate how smaller models developed in academia can still have an edge over larger industry-scale models, if powered with knowledge and/or reasoning algorithms.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[-tucky]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=58650</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=58650&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=tucky"/>
        <updated>2023-05-12T10:15:06.000Z</updated>
        <summary type="html"><![CDATA[Last weekend, I was in Omaha for the annual Berkshire-Hathaway Shareholders Meeting.  Not that I am a shareholder of Berkshire-Hathaway, but simply because I was curious to see two nonagenarian financial wizards hold forth in front of 20,000 enthusiastic fans for a whole day.  I wasn't disappointed, though I must confess that I didn't understand […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer升级之路：9、一种全局长度外推的新思路]]></title>
        <id>https://kexue.fm/archives/9603</id>
        <link href="https://kexue.fm/archives/9603"/>
        <updated>2023-05-12T09:11:00.000Z</updated>
        <summary type="html"><![CDATA[说到Transformer无法处理超长序列的原因，大家的第一反应通常都是Self Attention的二次复杂度。但事实上，即便忽略算力限制，常规的Transformer也无法处理超长序列，因为...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[07/06 1pm-2pm: CRiSM Seminar]]></title>
        <id>8a1785d7880083fb01880ee837704378</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9"/>
        <updated>2023-05-12T07:41:19.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Wed, 07 Jun '23

	
Where: MB0.07]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[21/06 1pm-2pm: CRiSM Seminar]]></title>
        <id>8a1785d7880083fb01880ee837704379</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9"/>
        <updated>2023-05-12T07:41:19.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Wed, 21 Jun '23

	
Where: MB0.07]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Risk-limiting Financial Audits via Weighted Sampling without Replacement]]></title>
        <id>http://arxiv.org/abs/2305.06884</id>
        <link href="http://arxiv.org/abs/2305.06884"/>
        <updated>2023-05-12T07:13:34.006Z</updated>
        <summary type="html"><![CDATA[Shubhanshu Shekhar, Ziyu Xu, Zachary C. Lipton, Pierre J. Liang,
  Aaditya Ramdas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convergence Rates for Learning Linear Operators from Noisy Data]]></title>
        <id>http://arxiv.org/abs/2108.12515</id>
        <link href="http://arxiv.org/abs/2108.12515"/>
        <updated>2023-05-12T07:13:33.665Z</updated>
        <summary type="html"><![CDATA[Maarten V. de Hoop, Nikola B. Kovachki, Nicholas H. Nelsen, Andrew M.
  Stuart]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Fine-Gray: Monotonic neural networks for competing risks]]></title>
        <id>http://arxiv.org/abs/2305.06703</id>
        <link href="http://arxiv.org/abs/2305.06703"/>
        <updated>2023-05-12T07:13:33.622Z</updated>
        <summary type="html"><![CDATA[Vincent Jeanselme, Chang Ho Yoon, Brian Tom, Jessica Barrett]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization bounds for neural ordinary differential equations and
  deep residual networks]]></title>
        <id>http://arxiv.org/abs/2305.06648</id>
        <link href="http://arxiv.org/abs/2305.06648"/>
        <updated>2023-05-12T07:13:33.615Z</updated>
        <summary type="html"><![CDATA[Pierre Marion]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.06986</id>
        <link href="http://arxiv.org/abs/2305.06986"/>
        <updated>2023-05-12T07:13:33.598Z</updated>
        <summary type="html"><![CDATA[Eshaan Nichani, Alex Damian, Jason D. Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language Identification: Building an End-to-End AI Solution using PyTorch]]></title>
        <id>https://pytorch.org/blog/language-identification/</id>
        <link href="https://pytorch.org/blog/language-identification/"/>
        <updated>2023-05-12T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Language Identification is the process of identifying the primary language from multiple audio input samples. In natural language processing (NLP), language identification is an important problem and a challenging issue. There are many language-related tasks such as entering text on your phone, finding news articles you enjoy, or discovering answers to questions that you may have. All these tasks are powered by NLP models. To decide which model to invoke at a particular point in time, we must perform language identification.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CIRM, Luminy, 1995]]></title>
        <id>http://xianblog.wordpress.com/?p=53001</id>
        <link href="https://xianblog.wordpress.com/2023/05/12/cirm-luminy-1995/"/>
        <updated>2023-05-11T22:23:15.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
</feed>