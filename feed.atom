<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Furyton.github.io/misc-feed/index.html</id>
    <title>osmos::feed</title>
    <updated>2023-10-22T23:14:00.526Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="https://Furyton.github.io/misc-feed/index.html"/>
    <link rel="self" href="https://Furyton.github.io/misc-feed/feed.atom"/>
    <entry>
        <title type="html"><![CDATA[back to the future [no need!]]]></title>
        <id>http://xianblog.wordpress.com/?p=54126</id>
        <link href="https://xianblog.wordpress.com/2023/10/23/back-to-the-future-no-need/"/>
        <updated>2023-10-22T22:23:53.000Z</updated>
        <summary type="html"><![CDATA[A news entry in Nature of 25 Sept 23 is reporting on the grim period of Earth, 250 millions year away! By that time, continents will have drifted back, reunited into a new Pangaea supercontinent, Pangaea Ultima, which is likely to form around the equator, producing a deadly place where most life will go extinct. […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Frater studiorum: Tsu-Lin Mei (1933-2023)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61041</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61041&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=frater-studiorum-tsu-lin-mei-1933-2023"/>
        <updated>2023-10-22T20:19:13.000Z</updated>
        <summary type="html"><![CDATA[It is with deep sadness that I report the passing on October 14, 2023 of Tsu-Lin Mei, professor of Chinese historical linguistics at Cornell University.  Tsu-Lin was born on February 14, 1933 at the Peking Union Medical College Hospital in Beijing. He received his B.A. from Oberlin College in 1954, his M.A. (in Mathematics) from Harvard […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[从梯度最大化看Attention的Scale操作]]></title>
        <id>https://kexue.fm/archives/9812</id>
        <link href="https://kexue.fm/archives/9812"/>
        <updated>2023-10-22T09:35:00.000Z</updated>
        <summary type="html"><![CDATA[我们知道，Scaled-Dot Product Attention的Scale因子是$\frac{1}{\sqrt{d}}$，其中$d$是$\boldsymbol{q},\boldsymbol{...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[帧同步游戏中使用 Run-Ahead 隐藏输入延迟]]></title>
        <id>https://www.skywind.me/blog/?p=2746</id>
        <link href="https://www.skywind.me/blog/archives/2746"/>
        <updated>2023-10-22T03:05:00.000Z</updated>
        <summary type="html"><![CDATA[帧同步可以轻松解决高互动的联网游戏（如格斗，RTS 等）的同步问题，但该方案对延迟很敏感，现在一般省内服务器延迟差不多 10-15ms （1帧），跨省一般 40ms （2-3 帧），在此情况下，使用 Run-Ahead 机制可以有效的掩盖延迟的体感，让用玩家立马看到自己的操作反馈。 该机制有很多其他名字比如：预测回滚（prediction and rollback），或者时间曲力（time warp），名字取的天花乱坠的，很多文章也只是云里雾里说一半天，结果还没说清楚，所以本文打算最简短的句子说清楚这个概念，并给出可以实际操作的实现步骤。 我觉得用 Run-Ahead 这个质朴的名字更容易说明这个算法背后的思想：提前运行，这个概念不光用在游戏同步里，也早已用在游戏模拟器中，为了便于理解，先说一下模拟器中的情况（更简单）。 RetroArch 使用 Run-Ahead 隐藏输入延迟，一般需要设置一下 Run-Ahead 的帧数，比如 0 是关闭，1 是提前运行一帧，2 是提前运行两帧，一般设置用 1，一般不会超过 2 ，设置太高游戏表现会很奇怪： 运行时 RetroArch 为每帧保存快照，假定的是用户输入有持续性，那么运行时当前帧使用上一帧用户的输入作为本帧输入（假设 runahead 设置为 1），然后接着往下运行，如果用户新输入来了，一律把它算作当前帧-1 的输入，然后再去对比历史如果和上一帧所尝试假定的输入一致就继续，否则快照回退到上一帧，重新用新的输入去运行，然后再快进到当前帧。 通常手柄或键盘都有 5ms 左右的输入延迟（部分设备如 switch 的 pro 手柄延迟高达 15ms），再加上操作系统处理的延迟，投递到模拟器进程里，从按下到真正开始处理也许也差不多 1 帧的时间了，RetroArch 用这个功能，也只有用户真实输入和预测输入不一致时才会触发，由于间隔很短，所以即使纠正也难看出来，最终在模拟器上达到了物理设备一样的超低延迟体验。 理解了模拟器的 Run-Ahead 实现，其实在帧同步里的原理也就差不多了，无外乎是用远程的旧输入，搭配本地刚采集到的新输入，作为预测帧的输入值，产生新帧，不匹配了再回滚。 帧同步里引入类似 Run-Ahead 的机制，要求游戏最近所有状态都可以被快速保存、复制和恢复，实现有很多种，你可以用状态的反复前进、后退来实现，但是 BUG 率太高了，这里给出一个更简易的实现方式： […]
The post 帧同步游戏中使用 Run-Ahead 隐藏输入延迟 appeared first on Skywind Inside.]]></summary>
        <author>
            <name>skywind</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Your work has been cited! [who is U?!]]]></title>
        <id>http://xianblog.wordpress.com/?p=53626</id>
        <link href="https://xianblog.wordpress.com/2023/10/22/your-work-has-been-cited-who-is-u/"/>
        <updated>2023-10-21T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Calling all linguists"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61043</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61043&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=calling-all-linguists"/>
        <updated>2023-10-21T20:15:43.000Z</updated>
        <summary type="html"><![CDATA[Kevin Drum, "Calling all linguists", 10/20/2023: You know what I'd like? I'd like a qualified linguist with a good ear to listen to a Joe Biden speech and report back. A couple of weeks ago I spent some time doing this, and Biden's problem is that his speech really does sound a little slurred at […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five Riddles כמה חידות]]></title>
        <id>http://gilkalai.wordpress.com/?p=24747</id>
        <link href="https://gilkalai.wordpress.com/2023/10/21/five-riddles-%d7%9b%d7%9e%d7%94-%d7%97%d7%99%d7%93%d7%95%d7%aa/"/>
        <updated>2023-10-21T18:58:13.000Z</updated>
        <summary type="html"><![CDATA[Here are five riddles. I learned them from Maya Bar-Hillel. Can you solve them? (We had several earlier posts with riddles, such as Two Math Riddles; Greg’s Dinosaurs Riddle; and The Ultimate Riddle. ) Two old friends are standing together … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Five Riddles כמה חידות]]></title>
        <id>http://gilkalai.wordpress.com/?p=24747</id>
        <link href="https://gilkalai.wordpress.com/2023/10/21/five-riddles-%d7%9b%d7%9e%d7%94-%d7%97%d7%99%d7%93%d7%95%d7%aa/"/>
        <updated>2023-10-21T18:58:13.000Z</updated>
        <summary type="html"><![CDATA[Here are five riddles. I learned them from Maya Bar-Hillel. Can you solve them? (We had several earlier posts with riddles, such as Two Math Riddles; Greg’s Dinosaurs Riddle; and The Ultimate Riddle. ) Two old friends are standing together … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[More AI shenanigans]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61032</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61032&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=more-ai-shenanigans"/>
        <updated>2023-10-21T10:55:45.000Z</updated>
        <summary type="html"><![CDATA[Since When Does Eric Adams Speak Spanish, Yiddish and Mandarin? He doesn’t. But New York City is using artificial intelligence to send robocalls featuring the mayor’s voice in many languages. By Emma G. Fitzsimmons and Jeffery C. Mays, NYT (Oct. 20, 2023) The calls to New Yorkers have a familiar ring to them. They all […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bidirectional Temporal Diffusion Model for Temporally Consistent Human
  Animation]]></title>
        <id>http://arxiv.org/abs/2307.00574</id>
        <link href="http://arxiv.org/abs/2307.00574"/>
        <updated>2023-10-21T02:18:57.873Z</updated>
        <summary type="html"><![CDATA[Tserendorj Adiya, Sanghun Kim, Jung Eun Lee, Jae Shin Yoon, Hwasup
  Lim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[a journal of the conquest, war, famine, and death year]]></title>
        <id>http://xianblog.wordpress.com/?p=54022</id>
        <link href="https://xianblog.wordpress.com/2023/10/21/a-journal-of-the-conquest-war-famine-and-death-year-5/"/>
        <updated>2023-10-20T22:23:47.000Z</updated>
        <summary type="html"><![CDATA[Read Jen Williams’ The Winnowing Flame trilogy, induced by two British Fantasy Awards associated with the first two volumes. This is quite a disappointing series, the more one goes through the story. At the start, while I found the story rather simplistic in its world building and in repeating the all-too-common pattern of a very […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pinyin vs. English]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61028</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61028&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=pinyin-vs-english"/>
        <updated>2023-10-20T11:37:44.000Z</updated>
        <summary type="html"><![CDATA[I knew that in the future it would come to this.  More than forty years ago, I predicted that one day China would have to make a choice between Hanyu Pinyin and English when it comes to phonetic writing.  As we say in Mandarin, "guǒrán 果然" ("as expected / it turns out")…. It seems that […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Discriminative to Kernel Density Networks for Calibrated Inference]]></title>
        <id>http://arxiv.org/abs/2201.13001</id>
        <link href="http://arxiv.org/abs/2201.13001"/>
        <updated>2023-10-20T02:21:10.392Z</updated>
        <summary type="html"><![CDATA[Jayanta Dey, Will LeVine, Haoyin Xu, Ashwin De Silva, Tyler M. Tomita,
  Ali Geisa, Tiffany Chu, Jacob Desman, Joshua T. Vogelstein]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Piecewise Deterministic Markov Processes for Bayesian Neural Networks]]></title>
        <id>http://arxiv.org/abs/2302.08724</id>
        <link href="http://arxiv.org/abs/2302.08724"/>
        <updated>2023-10-20T02:21:10.375Z</updated>
        <summary type="html"><![CDATA[Ethan Goan, Dimitri Perrin, Kerrie Mengersen, Clinton Fookes]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics-informed neural networks in the recreation of hydrodynamic
  simulations from dark matter]]></title>
        <id>http://arxiv.org/abs/2303.14090</id>
        <link href="http://arxiv.org/abs/2303.14090"/>
        <updated>2023-10-20T02:21:10.371Z</updated>
        <summary type="html"><![CDATA[Zhenyu Dai, Ben Moews, Ricardo Vilalta, Romeel Dave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Seeking the Truth Beyond the Data. An Unsupervised Machine Learning
  Approach]]></title>
        <id>http://arxiv.org/abs/2207.06949</id>
        <link href="http://arxiv.org/abs/2207.06949"/>
        <updated>2023-10-20T02:21:10.366Z</updated>
        <summary type="html"><![CDATA[Dimitrios Saligkaras, Vasileios E. Papageorgiou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[URL: A Representation Learning Benchmark for Transferable Uncertainty
  Estimates]]></title>
        <id>http://arxiv.org/abs/2307.03810</id>
        <link href="http://arxiv.org/abs/2307.03810"/>
        <updated>2023-10-20T02:21:10.361Z</updated>
        <summary type="html"><![CDATA[Michael Kirchhof, B\'alint Mucs\'anyi, Seong Joon Oh and
  Enkelejda Kasneci]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arrowleaf Cellars [pinot noir]]]></title>
        <id>http://xianblog.wordpress.com/?p=53943</id>
        <link href="https://xianblog.wordpress.com/2023/10/20/arrowleaf-cellars-pinot-noir/"/>
        <updated>2023-10-19T22:23:08.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI and the law, part 2]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61019</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61019&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-and-the-law-part-2"/>
        <updated>2023-10-19T19:52:35.000Z</updated>
        <summary type="html"><![CDATA[Here we go again, but this time on a grander and more dramatic scale: Pras Michel of Fugees seeks new trial, contends former attorney used AI for closing argument The hip-hop artist convicted on campaign finance and foreign influence charges seeks to set aside the jury’s guilty verdicts. By Josh Bernstein, Politico (1016/23) Notice the […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subject-specific Deep Neural Networks for Count Data with
  High-cardinality Categorical Features]]></title>
        <id>http://arxiv.org/abs/2310.11654</id>
        <link href="http://arxiv.org/abs/2310.11654"/>
        <updated>2023-10-19T03:15:18.882Z</updated>
        <summary type="html"><![CDATA[Hangbin Lee, Il Do Ha, Changha Hwang, Youngjo Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Flow Networks in Continual Learning]]></title>
        <id>http://arxiv.org/abs/2310.12001</id>
        <link href="http://arxiv.org/abs/2310.12001"/>
        <updated>2023-10-19T03:15:18.839Z</updated>
        <summary type="html"><![CDATA[Mateusz Pyla, Kamil Deja, Bart{\l}omiej Twardowski, Tomasz Trzci\'nski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Online Learning with Offline Datasets for Infinite Horizon
  MDPs: A Bayesian Approach]]></title>
        <id>http://arxiv.org/abs/2310.11531</id>
        <link href="http://arxiv.org/abs/2310.11531"/>
        <updated>2023-10-19T03:15:18.821Z</updated>
        <summary type="html"><![CDATA[Dengwang Tang, Rahul Jain, Botao Hao, Zheng Wen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A General Theoretical Paradigm to Understand Learning from Human
  Preferences]]></title>
        <id>http://arxiv.org/abs/2310.12036</id>
        <link href="http://arxiv.org/abs/2310.12036"/>
        <updated>2023-10-19T03:15:18.809Z</updated>
        <summary type="html"><![CDATA[Mohammad Gheshlaghi Azar, Mark Rowland, Bilal Piot, Daniel
  Guo, Daniele Calandriello, Michal Valko, R\'emi Munos]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SQ Lower Bounds for Learning Mixtures of Linear Classifiers]]></title>
        <id>http://arxiv.org/abs/2310.11876</id>
        <link href="http://arxiv.org/abs/2310.11876"/>
        <updated>2023-10-19T03:15:18.794Z</updated>
        <summary type="html"><![CDATA[Ilias Diakonikolas, Daniel M. Kane, Yuxin Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating social and ethical risks from generative AI]]></title>
        <id>https://www.deepmind.com/blog/evaluating-social-and-ethical-risks-from-generative-ai</id>
        <link href="https://www.deepmind.com/blog/evaluating-social-and-ethical-risks-from-generative-ai"/>
        <updated>2023-10-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Generative AI systems are already being used to write books, create graphic designs, assist medical practitioners, and are becoming increasingly capable. To ensure these systems are developed and deployed responsibly requires carefully evaluating the potential ethical and social risks they may pose.In our paper, we propose a three-layered framework for evaluating the social and ethical risks of AI systems. This framework includes evaluations of AI system capability, human interaction, and systemic impacts.We also map the current state of safety evaluations and find three main gaps: context, specific risks, and multimodality. To help close these gaps, we call for repurposing existing evaluation methods for generative AI and for implementing a comprehensive approach to evaluation, as in our case study on misinformation. This approach integrates findings like how likely the AI system is to provide factually incorrect information, with insights on how people use that system, and in what context. Multi-layered evaluations can draw conclusions beyond model capability and indicate whether harm — in this case, misinformation — actually occurs and spreads. To make any technology work as intended, both social and technical challenges must be solved. So to better assess AI system safety, these different layers of context must be taken into account. Here, we build upon earlier research identifying the potential risks of large-scale language models, such as privacy leaks, job automation, misinformation, and more — and introduce a way of comprehensively evaluating these risks going forward.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[minimize harm to civilians and civilian objects and refrain from unlawful attacks or the collective punishment of civilians [reposted from Amnesty International]]]></title>
        <id>http://xianblog.wordpress.com/?p=54260</id>
        <link href="https://xianblog.wordpress.com/2023/10/19/minimize-harm-to-civilians-and-civilian-objects-and-refrain-from-unlawful-attacks-or-the-collective-punishment-of-civilians-reposted-from-amnesty-international/"/>
        <updated>2023-10-18T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sad Update]]></title>
        <id>http://gilkalai.wordpress.com/?p=24719</id>
        <link href="https://gilkalai.wordpress.com/2023/10/19/sad-update/"/>
        <updated>2023-10-18T21:07:25.000Z</updated>
        <summary type="html"><![CDATA[Dear all, as you probably know, Israel was gravely attacked on Saturday, October, 7 2023 by Hamas terrorists coming from the Gaza streak. More than a thousand civilians including many children and babies were murdered and more than a hundred … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sad Update]]></title>
        <id>http://gilkalai.wordpress.com/?p=24719</id>
        <link href="https://gilkalai.wordpress.com/2023/10/19/sad-update/"/>
        <updated>2023-10-18T21:07:25.000Z</updated>
        <summary type="html"><![CDATA[Dear all, as you probably know, Israel was gravely attacked on Saturday, October, 7 2023 by Hamas terrorists coming from the Gaza streak. More than a thousand civilians including many children and babies were murdered and more than a hundred … Continue reading →]]></summary>
        <author>
            <name>Gil Kalai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flip over when you finish]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=61014</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=61014&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=flip-over-when-you-finish"/>
        <updated>2023-10-18T20:13:36.000Z</updated>
        <summary type="html"><![CDATA[From shaing tai, via a group on Facebook, photograph taken at the New Otani Inn in Tokyo: Treating the lines one at a time, from top to bottom, except for the English lines, which are left to speak for themselves: Shokuji chū desu 食事中です (I am) in the process of eating (lit., "in the middle of […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards the Fundamental Limits of Knowledge Transfer over Finite Domains]]></title>
        <id>http://arxiv.org/abs/2310.07838</id>
        <link href="http://arxiv.org/abs/2310.07838"/>
        <updated>2023-10-18T02:22:11.932Z</updated>
        <summary type="html"><![CDATA[Qingyue Zhao, Banghua Zhu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding deep neural networks through the lens of their
  non-linearity]]></title>
        <id>http://arxiv.org/abs/2310.11439</id>
        <link href="http://arxiv.org/abs/2310.11439"/>
        <updated>2023-10-18T02:22:11.738Z</updated>
        <summary type="html"><![CDATA[Quentin Bouniot, Ievgen Redko, Anton Mallasto, Charlotte Laclau, Karol
  Arndt, Oliver Struckmeier, Markus Heinonen, Ville Kyrki, Samuel Kaski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wide Neural Networks as Gaussian Processes: Lessons from Deep
  Equilibrium Models]]></title>
        <id>http://arxiv.org/abs/2310.10767</id>
        <link href="http://arxiv.org/abs/2310.10767"/>
        <updated>2023-10-18T02:22:11.720Z</updated>
        <summary type="html"><![CDATA[Tianxiang Gao, Xiaokai Huo, Hailiang Liu, Hongyang Gao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Densely Connected $G$-invariant Deep Neural Networks with Signed
  Permutation Representations]]></title>
        <id>http://arxiv.org/abs/2303.04614</id>
        <link href="http://arxiv.org/abs/2303.04614"/>
        <updated>2023-10-18T02:21:54.835Z</updated>
        <summary type="html"><![CDATA[Devanshu Agrawal, James Ostrowski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Language Models Are Latent Variable Models: Explaining and Finding
  Good Demonstrations for In-Context Learning]]></title>
        <id>http://arxiv.org/abs/2301.11916</id>
        <link href="http://arxiv.org/abs/2301.11916"/>
        <updated>2023-10-18T02:21:54.828Z</updated>
        <summary type="html"><![CDATA[Xinyi Wang, Wanrong Zhu, Michael Saxon, Mark Steyvers, William Yang
  Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When should you upgrade to Python 3.12?]]></title>
        <id>https://pythonspeed.com/articles/upgrade-python-3.12/</id>
        <link href="https://pythonspeed.com/articles/upgrade-python-3.12/"/>
        <updated>2023-10-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Python 3.12 is out now–but should you switch to it immediately?
And if you shouldn’t upgrade just yet, when should you?
Immediately after the release, you may not want to upgrade just yet.
But from December 2023 and onwards, upgrading is definitely worth trying.
To understand why, we need to consider Python packaging, the software development process, and take a look at the history of past releases.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Speeding up Cython with SIMD]]></title>
        <id>https://pythonspeed.com/articles/faster-cython-simd/</id>
        <link href="https://pythonspeed.com/articles/faster-cython-simd/"/>
        <updated>2023-10-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Cython allows you to write compiled extensions for Python, by translating Python-y code to C or C++.
Often you’ll use it to speed up your software, and it’s especially useful for implementing small data science or scientific computing algorithms.
But what happens when Cython is too slow?
Often there’s still speed improvements you can do.
In a previous article we focused on examples of optimizing your code to take advantage of things like instruction-level parallelism.
In this article, we’ll focus on another CPU feature, Single Instruction Multiple Data or SIMD, specifically in the context of Cython.
As well see, in some situations using SIMD can happen with only minimal changes to your code.
Parts of this article are excerpted from a book I’m working on that will help teach you how to optimize low-level code, the kind of code you’d write with Cython, C, or Rust.
The goal is to help data scientists and scientists who normally write Python to understand how to make their compiled code faster.
Read more...]]></summary>
        <author>
            <name>Python⇒Speed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wok talk: enlarging the scope]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60996</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60996&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=wok-talk-enlarging-the-scope"/>
        <updated>2023-10-17T23:07:17.000Z</updated>
        <summary type="html"><![CDATA[Following up on "Wok talk: a real-life retronym!" (10/16/23), Jim Millward remarks: My wife (Punjabi background) and her family call the "wok-shaped pan" they use for cooking vegetable or meat dishes "kurai" (that's my phoneticization–it could be aspirated or unaspirated k / g, I'm not good at hearing the difference).  I've seen these and we've […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[off to Martinique [#2]]]></title>
        <id>http://xianblog.wordpress.com/?p=54132</id>
        <link href="https://xianblog.wordpress.com/2023/10/18/off-to-martinique-2/"/>
        <updated>2023-10-17T22:23:03.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Goal Representations for Instruction Following]]></title>
        <id>http://bair.berkeley.edu/blog/2023/10/17/grif/</id>
        <link href="http://bair.berkeley.edu/blog/2023/10/17/grif/"/>
        <updated>2023-10-17T14:35:00.000Z</updated>
        <summary type="html"><![CDATA[Goal Representations for Instruction Following



Figure title. Figure caption. This image is centered and set to 50%
page width. -->


A longstanding goal of the field of robot learning has been to create generalist agents that can perform tasks for humans. Natural language has the potential to be an easy-to-use interface for humans to specify arbitrary tasks, but it is difficult to train robots to follow language instructions. Approaches like language-conditioned behavioral cloning (LCBC) train policies to directly imitate expert actions conditioned on language, but require humans to annotate all training trajectories and generalize poorly across scenes and behaviors. Meanwhile, recent goal-conditioned approaches perform much better at general manipulation tasks, but do not enable easy t…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Compound pejoratives]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60998</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60998&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=compound-pejoratives"/>
        <updated>2023-10-17T12:45:28.000Z</updated>
        <summary type="html"><![CDATA[[This has been drifting down my too-long to-blog list for almost 16 months — but better late than never, I guess, and the world could use some pejorative-flavored humor…]  Colin Morris, "Compound pejoratives on Reddit – from buttface to wankpuffin", 6/28/2022: I collected lists of around 70 prefixes and 70 suffixes (collectively, “affixes”) that can […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Compiling NumPy code into C++ or CUDA via torch.compile]]></title>
        <id>https://pytorch.org/blog/compiling-numpy-code/</id>
        <link href="https://pytorch.org/blog/compiling-numpy-code/"/>
        <updated>2023-10-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Quansight engineers have implemented support for tracing through NumPy code via torch.compile in PyTorch 2.1. This feature leverages PyTorch’s compiler to generate efficient fused vectorized code without having to modify your original NumPy code. Even more, it also allows for executing NumPy code on CUDA just by running it through torch.compile under torch.device("cuda")!]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Huawei Joins the PyTorch Foundation as a Premier Member]]></title>
        <id>https://pytorch.org/blog/huawei-joins-pytorch/</id>
        <link href="https://pytorch.org/blog/huawei-joins-pytorch/"/>
        <updated>2023-10-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Today, the PyTorch Foundation, a neutral home for the deep learning community to collaborate on the open source PyTorch framework and ecosystem, announced that Huawei has joined as a premier member.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lightning AI Joins the PyTorch Foundation as a Premier Member]]></title>
        <id>https://pytorch.org/blog/lightning-ai-joins-pytorch/</id>
        <link href="https://pytorch.org/blog/lightning-ai-joins-pytorch/"/>
        <updated>2023-10-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[The PyTorch Foundation, a neutral home for the deep learning community to collaborate on the open source PyTorch framework and ecosystem, is announcing today that Lightning AI has joined as a premier member.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch Edge: Enabling On-Device Inference Across Mobile and Edge Devices with ExecuTorch]]></title>
        <id>https://pytorch.org/blog/pytorch-edge/</id>
        <link href="https://pytorch.org/blog/pytorch-edge/"/>
        <updated>2023-10-17T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Other contributors: Dave Bort, Kimish Patel, Mergen Nachin, Orion Reblitz-Richardson, Andrew Caples]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wok talk: a real-life retronym!]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60948</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60948&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=wok-talk-a-real-life-retronym"/>
        <updated>2023-10-17T03:27:13.000Z</updated>
        <summary type="html"><![CDATA[From François Lang: Since you're a Sinologist, I thought you might be amused by a retronym that I had to coin.   My wife (59 YO) was born and grew up in Beijing, and came to the US in the 80s to do her PhD at Cornell. Since she's Chinese, the only stovetop cooking vessel […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Deep learning model of upstream and downstream brain regions Based
  on Memory Generation-Consolidation-Loss, Synaptic Strength Rebalance and
  mnemonic spiral]]></title>
        <id>http://arxiv.org/abs/2203.11740</id>
        <link href="http://arxiv.org/abs/2203.11740"/>
        <updated>2023-10-17T03:15:25.030Z</updated>
        <summary type="html"><![CDATA[Jun-Bo Tao, Bai-Qing Sun, Wei-Dong Zhu, Shi-You Qu, Ling-Kun Chen,
  Jia-Qiang Li, Guo-Qi Li, Chong Wu, Yu Xiong, Jiaxuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding]]></title>
        <id>http://arxiv.org/abs/2305.14196</id>
        <link href="http://arxiv.org/abs/2305.14196"/>
        <updated>2023-10-17T03:15:25.011Z</updated>
        <summary type="html"><![CDATA[Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, Omer
  Levy]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The CoT Collection: Improving Zero-shot and Few-shot Learning of
  Language Models via Chain-of-Thought Fine-Tuning]]></title>
        <id>http://arxiv.org/abs/2305.14045</id>
        <link href="http://arxiv.org/abs/2305.14045"/>
        <updated>2023-10-17T03:15:24.986Z</updated>
        <summary type="html"><![CDATA[Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye,
  Jamin Shin, Minjoon Seo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Med-HALT: Medical Domain Hallucination Test for Large Language Models]]></title>
        <id>http://arxiv.org/abs/2307.15343</id>
        <link href="http://arxiv.org/abs/2307.15343"/>
        <updated>2023-10-17T03:15:24.913Z</updated>
        <summary type="html"><![CDATA[Ankit Pal, Logesh Kumar Umapathi, Malaikannan Sankarasubbu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring the Power of Graph Neural Networks in Solving Linear
  Optimization Problems]]></title>
        <id>http://arxiv.org/abs/2310.10603</id>
        <link href="http://arxiv.org/abs/2310.10603"/>
        <updated>2023-10-17T03:15:24.903Z</updated>
        <summary type="html"><![CDATA[Chendi Qian, Didier Ch\'etelat, Christopher Morris]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In the paper there is y instead of x]]></title>
        <id>http://xianblog.wordpress.com/?p=54199</id>
        <link href="https://xianblog.wordpress.com/2023/10/17/in-the-paper-there-is-y-instead-of-x/"/>
        <updated>2023-10-16T22:23:11.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Read vs. spontaneous speech]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60956</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60956&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=read-vs-spontaneous-speech"/>
        <updated>2023-10-16T12:07:52.000Z</updated>
        <summary type="html"><![CDATA[Across the many disciplines that analyze language, there's surprisingly little focus on the properties of natural, spontaneous speech, as opposed to read (or memorized and performed) speech. But of course that dichotomy is an oversimplification — there are many linguistic registers, many ways to read each of the many styles of text, and even more […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rethinking the Role of PPO in RLHF]]></title>
        <id>http://bair.berkeley.edu/blog/2023/10/16/p3o/</id>
        <link href="http://bair.berkeley.edu/blog/2023/10/16/p3o/"/>
        <updated>2023-10-16T09:00:00.000Z</updated>
        <summary type="html"><![CDATA[Rethinking the Role of PPO in RLHF

TL;DR: In RLHF, there’s tension between the reward learning phase, which uses human preference in the form of comparisons, and the RL fine-tuning phase, which optimizes a single, non-comparative reward. What if we performed RL in a comparative way?
Figure 1:
 This diagram illustrates the difference between reinforcement learning from absolute feedback and relative feedback. By incorporating a new component - pairwise policy gradient, we can unify the reward modeling stage and RL stage, enabling direct updates based on pairwise responses.



Large Language Models (LLMs) have powered increasingly capable virtual assistants, such as GPT-4, Claude-2, Bard and Bing Chat. These systems can respond to complex user queries, write code, and even produce poetry. T…]]></summary>
        <author>
            <name>The Berkeley Artificial Intelligence Research Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[随机分词再探：从Viterbi Sampling到完美采样算法]]></title>
        <id>https://kexue.fm/archives/9811</id>
        <link href="https://kexue.fm/archives/9811"/>
        <updated>2023-10-16T08:16:00.000Z</updated>
        <summary type="html"><![CDATA[在文章《随机分词浅探：从Viterbi Decoding到Viterbi Sampling》中，笔者提出了一种名为“Viterbi Sampling”的随机分词算法，它只是在求最优解的Viter...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adam-family Methods with Decoupled Weight Decay in Deep Learning]]></title>
        <id>http://arxiv.org/abs/2310.08858</id>
        <link href="http://arxiv.org/abs/2310.08858"/>
        <updated>2023-10-16T02:23:54.304Z</updated>
        <summary type="html"><![CDATA[Kuangyu Ding, Nachuan Xiao, Kim-Chuan Toh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks]]></title>
        <id>http://arxiv.org/abs/2310.03684</id>
        <link href="http://arxiv.org/abs/2310.03684"/>
        <updated>2023-10-16T02:23:54.219Z</updated>
        <summary type="html"><![CDATA[Alexander Robey, Eric Wong, Hamed Hassani, George J. Pappas]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Subspace Adaptation Prior for Few-Shot Learning]]></title>
        <id>http://arxiv.org/abs/2310.09028</id>
        <link href="http://arxiv.org/abs/2310.09028"/>
        <updated>2023-10-16T02:23:54.214Z</updated>
        <summary type="html"><![CDATA[Mike Huisman, Aske Plaat, Jan N. van Rijn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep
  Models]]></title>
        <id>http://arxiv.org/abs/2310.09250</id>
        <link href="http://arxiv.org/abs/2310.09250"/>
        <updated>2023-10-16T02:23:54.099Z</updated>
        <summary type="html"><![CDATA[Lin Chen, Michal Lukasik, Wittawat Jitkrittum, Chong You, Sanjiv Kumar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complementary Domain Adaptation and Generalization for Unsupervised
  Continual Domain Shift Learning]]></title>
        <id>http://arxiv.org/abs/2303.15833</id>
        <link href="http://arxiv.org/abs/2303.15833"/>
        <updated>2023-10-16T02:23:54.093Z</updated>
        <summary type="html"><![CDATA[Wonguk Cho, Jinha Park, Taesup Kim]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pacific [far]Northwest]]></title>
        <id>http://xianblog.wordpress.com/?p=53847</id>
        <link href="https://xianblog.wordpress.com/2023/10/16/pacific-farnorthwest/"/>
        <updated>2023-10-15T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[The last week of our BCations was spent in Prince Rupert, 54⁰18’W, on Kaien Island, almost the northernest coastal spot before Alaska. (Although Stewart, 55⁰56’W, may qualify.) With a much more oceanic [and cooler] weather than in farther south, still warm enough to swim in the ocean. And an interesting airport since it sits on […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hypercorrect Mandarin tones]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60937</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60937&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hypercorrect-mandarin-tones"/>
        <updated>2023-10-15T14:55:13.000Z</updated>
        <summary type="html"><![CDATA[Here are two examples.  The first is the (in)famous one about the "Lion-Eating Poet in the Stone Den": This is supposed to show that tones and characters are sine quibus non for intelligibility in Sinitic, except that nobody — but nobody — talks like this.  Without a character script, it's gibberish, and most Chinese throughout […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Eat their young"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60932</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60932&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=eat-their-young"/>
        <updated>2023-10-15T13:21:49.000Z</updated>
        <summary type="html"><![CDATA[In "Trump Short-Circuits in New Video as Concerns Grow Over Cognitive Decline", Meidas Touch 10/14/2023, Brett Meiselas presents the apparent mis-use of an idiom as evidence of neurodegeneration: A new video posted by Donald Trump to his social media account is the latest in a series of clips of the former president that have raised […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI and the law]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60925</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60925&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ai-and-the-law"/>
        <updated>2023-10-15T13:10:59.000Z</updated>
        <summary type="html"><![CDATA[Article in LAist (10/12/230; This Prolific LA Eviction Law Firm Was Caught Faking Cases In Court. Did They Misuse AI? Dennis Block runs what he says is California’s “leading eviction law firm.” A judge said legal citations submitted in Block's name for a recent case were fake. Six legal experts told LAist the errors likely […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arnak Dalalyan at the RSS Journal Webinar]]></title>
        <id>http://xianblog.wordpress.com/?p=54209</id>
        <link href="https://xianblog.wordpress.com/2023/10/15/arnak-dalalyan-at-the-rss-journal-webinar/"/>
        <updated>2023-10-14T22:23:37.000Z</updated>
        <summary type="html"><![CDATA[My friend and CREST colleague Arnak Dalalyan will (re)present [online] a Read Paper at the RSS on 31 October with my friends Hani Doss and Alain Durmus as discussants: ‘Theoretical Guarantees for Approximate Sampling and Log-Concave Densities’ Arnak Dalalyan ENSAE Paris, France Sampling from various kinds of distributions is an issue of paramount importance in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Socks, a matching game based on an additive combinatorics problem]]></title>
        <id>https://jeremykun.com/?p=120042</id>
        <link href="https://jeremykun.com/2023/10/14/socks-a-matching-game-based-on-an-additive-combinatorics-problem/"/>
        <updated>2023-10-14T13:00:00.000Z</updated>
        <summary type="html"><![CDATA[Can you find a set of cards among these six, such that the socks on the chosen cards can be grouped into matching pairs? (Duplicate pairs of the same sock are OK) This is the objective of the game Socks, a card game originally designed by Anna Varvak, a math professor at Soka University of […]]]></summary>
        <author>
            <name>Jeremy Kun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SwinCross: Cross-modal Swin Transformer for Head-and-Neck Tumor
  Segmentation in PET/CT Images]]></title>
        <id>http://arxiv.org/abs/2302.03861</id>
        <link href="http://arxiv.org/abs/2302.03861"/>
        <updated>2023-10-14T02:18:49.684Z</updated>
        <summary type="html"><![CDATA[Gary Y. Li, Junyu Chen, Se-In Jang, Kuang Gong, Quanzheng Li]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hubert Reeves (1932-2023)]]></title>
        <id>http://xianblog.wordpress.com/?p=54253</id>
        <link href="https://xianblog.wordpress.com/2023/10/14/hubert-reeves-1932-2023/"/>
        <updated>2023-10-13T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Batch calibration: Rethinking calibration for in-context learning and prompt engineering]]></title>
        <id>http://blog.research.google/2023/10/batch-calibration-rethinking.html</id>
        <link href="http://blog.research.google/2023/10/batch-calibration-rethinking.html"/>
        <updated>2023-10-13T18:01:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Han Zhou, Student Researcher, and Subhrajit Roy, Senior Research Scientist, Google Research





Prompting large language models (LLMs) has become an efficient learning paradigm for adapting LLMs to a new task by conditioning on human-designed instructions. The remarkable in-context learning (ICL) ability of LLMs also leads to efficient few-shot learners that can generalize from few-shot input-label pairs. However, the predictions of LLMs are highly sensitive and even biased to the choice of templates, label spaces (such as yes/no, true/false, correct/incorrect), and demonstration examples, resulting in unexpected performance degradation and barriers for pursuing robust LLM applications. To address this problem, calibration methods have been developed to mitigate the effects of t…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Emmanuel Abbe - Logic Reasoning and Generalization on the Unseen]]></title>
        <id>https://mlfoundations.org/talk/abbe/</id>
        <link href="https://mlfoundations.org/talk/abbe/"/>
        <updated>2023-10-13T14:00:00.000Z</updated>
        <summary type="html"><![CDATA[Transformers have become the dominant neural network architecture in deep learning. While they are state of the art in language and vision tasks, their performance is less convincing in so-called “reasoning” tasks. In this talk, we consider the “generalization on the unseen (GOTU)" objective to test the reasoning capabilities of neural networks, primarily Transformers on Boolean/logic tasks. We first give experimental results showing that such networks have a strong “minimal degree bias" - they tend to find specific interpolators having low degree, in agreement with the “leap complexity” picture derived for classic generalization. Using basic concepts from Boolean Fourier analysis and algebraic geometry, we then characterize such minimal degree profile interpolators and prove two theorems about the convergence of (S)GD to such interpolators on basic architectures. Since the minimal degree profile is not desirable in many reasoning tasks, we discuss various methods to correct this bias and improve consequently the reasoning capabilities. Based primarily on joint works with S. Bengio, A. Lotfi, K. Rizk and E. Adsera-Boix, T. Misiakiewicz.]]></summary>
        <author>
            <name>Harvard ML Foundations</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Autoarticulation]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60917</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60917&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=autoarticulation"/>
        <updated>2023-10-13T11:43:35.000Z</updated>
        <summary type="html"><![CDATA[As Language Log readers are undoubtedly aware, I am prey to mondegreens, earworms, and other imaginary auditory oddities.  Lately, the last half year or so, I've been occasionally subject to what, faute de mieux, I've taken to calling "autoarticulation", modeled after "autosuggestion". It doesn't last very long, doesn't repeat on an endless loop, and is […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EMO：基于最优传输思想设计的分类损失函数]]></title>
        <id>https://kexue.fm/archives/9797</id>
        <link href="https://kexue.fm/archives/9797"/>
        <updated>2023-10-13T09:06:00.000Z</updated>
        <summary type="html"><![CDATA[众所周知，分类任务的标准损失是交叉熵（Cross Entropy，等价于最大似然MLE，即Maximum Likelihood Estimation），它有着简单高效的特点，但在某些场景下也暴露...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flash-Decoding for long-context inference]]></title>
        <id>https://pytorch.org/blog/flash-decoding/</id>
        <link href="https://pytorch.org/blog/flash-decoding/"/>
        <updated>2023-10-13T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially Private Non-convex Learning for Multi-layer Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2310.08425</id>
        <link href="http://arxiv.org/abs/2310.08425"/>
        <updated>2023-10-13T02:24:56.147Z</updated>
        <summary type="html"><![CDATA[Hanpu Shen, Cheng-Long Wang, Zihang Xiang, Yiming Ying, Di
  Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement]]></title>
        <id>http://arxiv.org/abs/2310.07831</id>
        <link href="http://arxiv.org/abs/2310.07831"/>
        <updated>2023-10-13T02:24:56.142Z</updated>
        <summary type="html"><![CDATA[Aaron Defazio, Ashok Cutkosky, Harsh Mehta, Konstantin
  Mishchenko]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Theory of Non-Linear Feature Learning with One Gradient Step in
  Two-Layer Neural Networks]]></title>
        <id>http://arxiv.org/abs/2310.07891</id>
        <link href="http://arxiv.org/abs/2310.07891"/>
        <updated>2023-10-13T02:24:56.138Z</updated>
        <summary type="html"><![CDATA[Behrad Moniri, Donghwan Lee, Hamed Hassani, Edgar Dobriban]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Feature Learning and Generalization in Deep Networks with Orthogonal
  Weights]]></title>
        <id>http://arxiv.org/abs/2310.07765</id>
        <link href="http://arxiv.org/abs/2310.07765"/>
        <updated>2023-10-13T02:24:56.133Z</updated>
        <summary type="html"><![CDATA[Hannah Day, Yonatan Kahn, Daniel A. Roberts]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformers as Decision Makers: Provable In-Context Reinforcement
  Learning via Supervised Pretraining]]></title>
        <id>http://arxiv.org/abs/2310.08566</id>
        <link href="http://arxiv.org/abs/2310.08566"/>
        <updated>2023-10-13T02:24:53.412Z</updated>
        <summary type="html"><![CDATA[Licong Lin, Yu Bai, Song Mei]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[preserving civilian lives is essential [reposted Guardian editorial]]]></title>
        <id>http://xianblog.wordpress.com/?p=54238</id>
        <link href="https://xianblog.wordpress.com/2023/10/13/preserving-civilian-lives-is-essential-reposted-guardian-editorial/"/>
        <updated>2023-10-12T22:23:18.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Developing industrial use cases for physical simulation on future error-corrected quantum computers]]></title>
        <id>http://blog.research.google/2023/10/developing-industrial-use-cases-for.html</id>
        <link href="http://blog.research.google/2023/10/developing-industrial-use-cases-for.html"/>
        <updated>2023-10-12T20:56:00.002Z</updated>
        <summary type="html"><![CDATA[Posted by Nicholas Rubin, Senior Research Scientist, and Ryan Babbush, Head of Quantum Algorithms, Quantum AI Team





If you’ve paid attention to the quantum computing space, you’ve heard the claim that in the future, quantum computers will solve certain problems exponentially more efficiently than classical computers can. They have the potential to transform many industries, from pharmaceuticals to energy.



For the most part, these claims have rested on arguments about the asymptotic scaling of algorithms as the problem size approaches infinity, but this tells us very little about the practical performance of quantum computers for finite-sized problems. We want to be more concrete: Exactly which problems are quantum computers more suited to tackle than their classical counterparts, an…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ox Demolition]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60911</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60911&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=ox-demolition"/>
        <updated>2023-10-12T12:47:04.000Z</updated>
        <summary type="html"><![CDATA[From AntC: The black Chinese writing on a yellow background says: tuòhuāng niú jiànzhù qīngchāi gōnsī 拓荒牛建筑清拆公司 "bull / ox /bovine for opening up / reclaiming (waste)land for agriculture construction and demolition company" AntC, who sent this photograph to me, also included the following remarks: In my neighbourhood there’s a straggling cluster of Chinese/Asian businesses […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Machine Learning Approach for Modelling Parking Duration in Urban
  Land-use]]></title>
        <id>http://arxiv.org/abs/2008.01674</id>
        <link href="http://arxiv.org/abs/2008.01674"/>
        <updated>2023-10-12T02:19:40.575Z</updated>
        <summary type="html"><![CDATA[Janak Parmar, Pritikana Das, Sanjaykumar Dave]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Change-Point Detection in Time Series via Deep Learning]]></title>
        <id>http://arxiv.org/abs/2211.03860</id>
        <link href="http://arxiv.org/abs/2211.03860"/>
        <updated>2023-10-12T02:19:40.545Z</updated>
        <summary type="html"><![CDATA[Jie Li, Paul Fearnhead, Piotr Fryzlewicz, Tengyao Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Equivariant Transfer Learning from Pretrained Models]]></title>
        <id>http://arxiv.org/abs/2305.09900</id>
        <link href="http://arxiv.org/abs/2305.09900"/>
        <updated>2023-10-12T02:19:40.521Z</updated>
        <summary type="html"><![CDATA[Sourya Basu, Pulkit Katdare, Prasanna Sattigeri, Vijil
  Chenthamarakshan, Katherine Driggs-Campbell, Payel Das, Lav R. Varshney]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge Rumination for Pre-trained Language Models]]></title>
        <id>http://arxiv.org/abs/2305.08732</id>
        <link href="http://arxiv.org/abs/2305.08732"/>
        <updated>2023-10-12T02:19:40.468Z</updated>
        <summary type="html"><![CDATA[Yunzhi Yao, Peng Wang, Shengyu Mao, Chuanqi Tan, Fei Huang, Huajun
  Chen, Ningyu Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Double-Descent in Reinforcement Learning with LSTD and Random
  Features]]></title>
        <id>http://arxiv.org/abs/2310.05518</id>
        <link href="http://arxiv.org/abs/2310.05518"/>
        <updated>2023-10-12T02:19:40.400Z</updated>
        <summary type="html"><![CDATA[David Brellmann, Elo\"ise Berthier, David Filliat, Goran Frehse]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[learning ABC summaries with autoencoders [webinar]]]></title>
        <id>http://xianblog.wordpress.com/?p=54081</id>
        <link href="https://xianblog.wordpress.com/2023/10/12/learning-abc-summaries-with-autoencoders-webinar/"/>
        <updated>2023-10-11T22:23:30.000Z</updated>
        <summary type="html"><![CDATA[The next One World ABC seminar will take place this Thursday, September 28, at 9am UK time and on-line. Speaker: Carlo Albert, Swiss Federal Institute of Aquatic Science and Technology Title: Learning summary statistics for Bayesian inference with Autoencoders Abstract: In order for ABC to give accurate results and be efficient, we need summary statistics […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What and How does In-Context Learning Learn? Bayesian Model Averaging,
  Parameterization, and Generalization]]></title>
        <id>http://arxiv.org/abs/2305.19420</id>
        <link href="http://arxiv.org/abs/2305.19420"/>
        <updated>2023-10-11T14:14:40.172Z</updated>
        <summary type="html"><![CDATA[Yufeng Zhang, Fengzhuo Zhang, Zhuoran Yang, Zhaoran Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Language Models Streamline Automated Machine Learning for Clinical
  Studies]]></title>
        <id>http://arxiv.org/abs/2308.14120</id>
        <link href="http://arxiv.org/abs/2308.14120"/>
        <updated>2023-10-11T14:14:40.156Z</updated>
        <summary type="html"><![CDATA[Soroosh Tayebi Arasteh, Tianyu Han, Mahshad Lotfinia, Christiane Kuhl,
  Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding Transfer Learning and Gradient-Based Meta-Learning
  Techniques]]></title>
        <id>http://arxiv.org/abs/2310.06148</id>
        <link href="http://arxiv.org/abs/2310.06148"/>
        <updated>2023-10-11T14:14:40.149Z</updated>
        <summary type="html"><![CDATA[Mike Huisman, Aske Plaat, Jan N. van Rijn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Layer-wise Equivariances Automatically using Gradients]]></title>
        <id>http://arxiv.org/abs/2310.06131</id>
        <link href="http://arxiv.org/abs/2310.06131"/>
        <updated>2023-10-11T14:14:40.144Z</updated>
        <summary type="html"><![CDATA[Tycho F.A. van der Ouderaa, Alexander Immer, Mark van der Wilk]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mitigating Simplicity Bias in Deep Learning for Improved OOD
  Generalization and Robustness]]></title>
        <id>http://arxiv.org/abs/2310.06161</id>
        <link href="http://arxiv.org/abs/2310.06161"/>
        <updated>2023-10-11T14:14:40.074Z</updated>
        <summary type="html"><![CDATA[Bhavya Vasudeva, Kameron Shahabi, Vatsal Sharan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open letter to the Harvard community]]></title>
        <id>http://windowsontheory.org/?p=8694</id>
        <link href="https://windowsontheory.org/2023/10/11/open-letter-to-the-harvard-community/"/>
        <updated>2023-10-11T13:15:42.000Z</updated>
        <summary type="html"><![CDATA[This is a copy of the open letter that has been signed by well over 100 faculty at the time I am posting this. The full letter and list of signatories can be found on https://bit.ly/harvard-against-terrorism We are faculty at Harvard who are deeply concerned about the events in the Middle East, as well as … Continue reading Open letter to the Harvard community]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open letter to the Harvard community]]></title>
        <id>http://windowsontheory.org/?p=8694</id>
        <link href="https://windowsontheory.org/2023/10/11/open-letter-to-the-harvard-community/"/>
        <updated>2023-10-11T13:15:42.000Z</updated>
        <summary type="html"><![CDATA[This is a copy of the open letter that has been signed by well over 100 faculty at the time I am posting this. The full letter and list of signatories can be found on https://bit.ly/harvard-against-terrorism We are faculty at Harvard who are deeply concerned about the events in the Middle East, as well as … Continue reading Open letter to the Harvard community]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ML Model Server Resource Saving - Transition From High-Cost GPUs to Intel CPUs and oneAPI powered Software with performance]]></title>
        <id>https://pytorch.org/blog/ml-model-server-resource-saving/</id>
        <link href="https://pytorch.org/blog/ml-model-server-resource-saving/"/>
        <updated>2023-10-11T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Reviewers: Yunsang Ju(Naver GplaceAI Leader), Min Jean Cho(Intel), Jing Xu(Intel), Mark Saroufim(Meta)]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Men's Treaming]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60883</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60883&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mens-treaming"/>
        <updated>2023-10-11T04:36:45.000Z</updated>
        <summary type="html"><![CDATA[From Nick Tursi in Qatar: The sign says: ḥilāqat al-rijāl = “men’s shaving” For "Men's Trimming". That elongation of the short "i" is common among non-native speakers. Mauritians ask "where do you leave" (for "live"). Selected readings "A new way to resolve paradoxes" (10 /8/22) "Ockham's broom" (10/17/09) [Thanks to Devin Stewart, Joe Lowry, and […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[European particles matter]]></title>
        <id>http://xianblog.wordpress.com/?p=54075</id>
        <link href="https://xianblog.wordpress.com/2023/10/11/european-particles-matter/"/>
        <updated>2023-10-10T22:23:29.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Standardizing a random vector and applications]]></title>
        <id>https://parsiad.ca/blog/2023/standardizing_a_random_vector_and_applications/</id>
        <link href="https://parsiad.ca/blog/2023/standardizing_a_random_vector_and_applications/"/>
        <updated>2023-10-10T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Standardizing a random vector and applications to sampling a multivariate random normal distribution]]></title>
        <id>https://parsiad.ca/blog/2023/uncorrelating_correlated_random_normal_variables/</id>
        <link href="https://parsiad.ca/blog/2023/uncorrelating_correlated_random_normal_variables/"/>
        <updated>2023-10-10T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Motivation]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Real-time Audio-visual Speech Recognition]]></title>
        <id>https://pytorch.org/blog/real-time-speech-rec/</id>
        <link href="https://pytorch.org/blog/real-time-speech-rec/"/>
        <updated>2023-10-10T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Audio-Visual Speech Recognition (AV-ASR, or AVSR) is the task of transcribing text from audio and visual streams, which has recently attracted a lot of research attention due to its robustness to noise. The vast majority of work to date has focused on developing AV-ASR models for non-streaming recognition; studies on streaming AV-ASR are very limited.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Happy Hangul Day!]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60891</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60891&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=happy-hangul-day"/>
        <updated>2023-10-09T22:42:43.000Z</updated>
        <summary type="html"><![CDATA[Language wars, the Korean edition "Foreign words dominate signboards, restaurant menus in Korea", omonatheydidn't, LiveJournal (10/8/23; page loaded 10/9/23); source: The Korea Times Trendy use of foreign languages apparently sparks outrage in Korea as well. A Seoul-based office worker surnamed Kim, 35, was perplexed at being unable to locate the Japanese restaurant he had reserved […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian inference and conformal prediction]]></title>
        <id>http://xianblog.wordpress.com/?p=54191</id>
        <link href="https://xianblog.wordpress.com/2023/10/10/bayesian-inference-and-conformal-prediction/"/>
        <updated>2023-10-09T22:23:13.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Letter to Harvard President Claudine Gay]]></title>
        <id>http://windowsontheory.org/?p=8687</id>
        <link href="https://windowsontheory.org/2023/10/09/letter-to-harvard-president-claudine-gay/"/>
        <updated>2023-10-09T20:45:27.000Z</updated>
        <summary type="html"><![CDATA[Dear President Gay, Recent days have been harrowing for both me and every other Israeli or Jewish person on the Harvard campus. On October 7th, Hamas launched a premeditated attack on the Israeli population. Hundreds of terrorists infiltrated Israeli towns and houses. Children were killed in front of their parents; entire families were executed. Grandmothers, … Continue reading Letter to Harvard President Claudine Gay]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Letter to Harvard President Claudine Gay]]></title>
        <id>http://windowsontheory.org/?p=8687</id>
        <link href="https://windowsontheory.org/2023/10/09/letter-to-harvard-president-claudine-gay/"/>
        <updated>2023-10-09T20:45:27.000Z</updated>
        <summary type="html"><![CDATA[Dear President Gay, Recent days have been harrowing for both me and every other Israeli or Jewish person on the Harvard campus. On October 7th, Hamas launched a premeditated attack on the Israeli population. Hundreds of terrorists infiltrated Israeli towns and houses. Children were killed in front of their parents; entire families were executed. Grandmothers, … Continue reading Letter to Harvard President Claudine Gay]]></summary>
        <author>
            <name>Boaz Barak</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SANPO: A Scene understanding, Accessibility, Navigation, Pathfinding, & Obstacle avoidance dataset]]></title>
        <id>http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html</id>
        <link href="http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html"/>
        <updated>2023-10-09T19:17:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Sagar M. Waghmare, Senior Software Engineer, and Kimberly Wilber, Software Engineer, Google Research, Perception Team




As most people navigate their everyday world, they process visual input from the environment using an eye-level perspective. Unlike robots and self-driving cars, people don't have any "out-of-body" sensors to help guide them. Instead, a person’s sensory input is completely "egocentric", or "from the self." This also applies to new technologies that understand the world around us from a human-like perspective, e.g., robots navigating through unknown buildings, AR glasses that highlight objects, or assistive technology to help people run independently.





In computer vision, scene understanding is the subfield that studies how visible objects relate to the sce…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How cats purr]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60886</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60886&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-cats-purr"/>
        <updated>2023-10-09T10:22:17.000Z</updated>
        <summary type="html"><![CDATA[The sound of a cat's purr is a familiar one: Your browser does not support the audio element. But this familiar sound raises at least two interesting biophysical questions. In the first place, cats purr both while breathing out and breathing in, while most people can only produce voiced sounds (= laryngeal oscillations) while breathing […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Occitan and Oenology]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60878</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60878&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=occitan-and-oenology"/>
        <updated>2023-10-09T01:29:55.000Z</updated>
        <summary type="html"><![CDATA[[This is a guest post by François Lang] Picpoul (AKA Piquepoul, or Picapoll) is a white wine grape best known in the south of France.  The grape is known for its intense acidity, and many wine references claim that its name derives from the Occitan for "lip stinger". But I can't find any justification for […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[sweet 60’s]]></title>
        <id>http://xianblog.wordpress.com/?p=54064</id>
        <link href="https://xianblog.wordpress.com/2023/10/09/sweet-60s/"/>
        <updated>2023-10-08T22:23:26.000Z</updated>
        <summary type="html"><![CDATA[The traditional group picture at the end of Eric Moulines’ 60th anniversary celebration, at IHP, Paris. Some of the participants had already left (and I am carefully hidding in the background). Among the celebrating talks reflecting the huge thematic diversity of EM’s carreer, Patrick Flandrin gave a great historical account of a certain Édouard-Léon Scott […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[预训练一下，Transformer的长序列成绩还能涨不少！]]></title>
        <id>https://kexue.fm/archives/9787</id>
        <link href="https://kexue.fm/archives/9787"/>
        <updated>2023-10-08T07:09:00.000Z</updated>
        <summary type="html"><![CDATA[作为LLM的主流模型架构，Transformer在各类任务上的总体表现都出色，大多数情况下，Transformer的槽点只是它的平方复杂度，而不是效果——除了一个名为Long Range Are...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[computational statistics position at U of Toronto]]></title>
        <id>http://xianblog.wordpress.com/?p=54184</id>
        <link href="https://xianblog.wordpress.com/2023/10/08/computational-statistics-position-at-u-of-toronto/"/>
        <updated>2023-10-07T22:23:38.000Z</updated>
        <summary type="html"><![CDATA[Another Canadian assistant professor opening in computational statistics, with a call for candidates from the University of Toronto, with deadline 20 November 2023: Candidates must have earned a PhD degree in Statistics or a related area by the time of appointment, or shortly thereafter, with a demonstrated record of excellence in research and teaching. Experience […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nobel Prize winner Jon Fosse writes in Nynorsk, a minority writing system]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60870</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60870&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=nobel-prize-winner-jon-fosse-writes-in-nynorsk-a-minority-writing-system"/>
        <updated>2023-10-07T11:38:06.000Z</updated>
        <summary type="html"><![CDATA["The Nobel literature prize goes to Norway’s Jon Fosse, who once wrote a novel in a single sentence" By DAVID KEYTON, MIKE CORDER and JILL LAWLESS, AP (10/5/23) … While Fosse is the fourth Norwegian writer to get the Nobel literature prize, he is the first in nearly a century and the first who writes in […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[un/a post/e à/at U de/of Montréal]]></title>
        <id>http://xianblog.wordpress.com/?p=54180</id>
        <link href="https://xianblog.wordpress.com/2023/10/07/un-a-post-e-a-at-u-de-of-montreal/"/>
        <updated>2023-10-06T22:23:48.000Z</updated>
        <summary type="html"><![CDATA[A new assistant professor position in Statistics/Machine learning is opening at UdeM, the University of Montréal, with deadline 11 November 2023: The Department of Mathematics and Statistics invites applications for a full-time, tenure-track position of Assistant Professor in Statistics and Machine Learning. The successful candidate, depending on his or her expertise and interest, could be […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Noncommutative Poisson vertex algebras and Courant-Dorfman algebras]]></title>
        <id>http://arxiv.org/abs/2106.00270</id>
        <link href="http://arxiv.org/abs/2106.00270"/>
        <updated>2023-10-06T21:12:33.945Z</updated>
        <summary type="html"><![CDATA[Luis \'Alvarez-C\'onsul, David Fern\'andez, Reimundo Heluani]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Constructing abelian varieties from rank 2 Galois representations]]></title>
        <id>http://arxiv.org/abs/2208.01999</id>
        <link href="http://arxiv.org/abs/2208.01999"/>
        <updated>2023-10-06T21:12:33.918Z</updated>
        <summary type="html"><![CDATA[Raju Krishnamoorthy, Jinbang Yang, Kang Zuo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Twisted conjugacy in soluble arithmetic groups]]></title>
        <id>http://arxiv.org/abs/2007.02988</id>
        <link href="http://arxiv.org/abs/2007.02988"/>
        <updated>2023-10-06T21:12:33.895Z</updated>
        <summary type="html"><![CDATA[Paula Macedo Lins de Araujo, Yuri Santos Rego]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New reducible configurations for graph multicoloring with application to
  the experimental resolution of McDiarmid-Reed's Conjecture (extended version)]]></title>
        <id>http://arxiv.org/abs/1812.01911</id>
        <link href="http://arxiv.org/abs/1812.01911"/>
        <updated>2023-10-06T21:12:33.875Z</updated>
        <summary type="html"><![CDATA[Jean-Christophe Godin, Olivier Togni]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Principles of modern physics imply basic model of the universe]]></title>
        <id>http://arxiv.org/abs/physics/0107050</id>
        <link href="http://arxiv.org/abs/physics/0107050"/>
        <updated>2023-10-06T21:12:33.849Z</updated>
        <summary type="html"><![CDATA[Craig Philpot]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Keereezmy"; "Kill his mind"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60856</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60856&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=keereezmy-kill-his-mind"/>
        <updated>2023-10-06T11:32:28.000Z</updated>
        <summary type="html"><![CDATA[As I explained here in February of this year: One time on an expedition around the western part of the Taklamakan Desert in the center of Asia more than a decade ago, the Chinese driver played Lady Gaga's "Poker Face" scores of times.  He had other discs, but he only played that song, and he […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Inferential Reproducibility of Machine Learning Research]]></title>
        <id>http://arxiv.org/abs/2302.04054</id>
        <link href="http://arxiv.org/abs/2302.04054"/>
        <updated>2023-10-06T02:21:46.667Z</updated>
        <summary type="html"><![CDATA[Michael Hagmann, Philipp Meier, Stefan Riezler]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantitative CLTs in Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2307.06092</id>
        <link href="http://arxiv.org/abs/2307.06092"/>
        <updated>2023-10-06T02:21:46.631Z</updated>
        <summary type="html"><![CDATA[Stefano Favaro, Boris Hanin, Domenico Marinucci, Ivan Nourdin,
  Giovanni Peccati]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explaining Emergent In-Context Learning as Kernel Regression]]></title>
        <id>http://arxiv.org/abs/2305.12766</id>
        <link href="http://arxiv.org/abs/2305.12766"/>
        <updated>2023-10-06T02:21:43.656Z</updated>
        <summary type="html"><![CDATA[Chi Han, Ziqi Wang, Han Zhao, Heng Ji]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse Deep Learning for Time Series Data: Theory and Applications]]></title>
        <id>http://arxiv.org/abs/2310.03243</id>
        <link href="http://arxiv.org/abs/2310.03243"/>
        <updated>2023-10-06T02:21:43.478Z</updated>
        <summary type="html"><![CDATA[Mingxuan Zhang, Yan Sun, Faming Liang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Energy-Based Prior Model with Diffusion-Amortized MCMC]]></title>
        <id>http://arxiv.org/abs/2310.03218</id>
        <link href="http://arxiv.org/abs/2310.03218"/>
        <updated>2023-10-06T02:21:43.472Z</updated>
        <summary type="html"><![CDATA[Peiyu Yu, Yaxuan Zhu, Sirui Xie, Xiaojian Ma, Ruiqi Gao, Song-Chun
  Zhu, Ying Nian Wu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mostly Monte Carlo Se[a]minar]]></title>
        <id>http://xianblog.wordpress.com/?p=54204</id>
        <link href="https://xianblog.wordpress.com/2023/10/06/mostly-monte-carlo-seaminar/"/>
        <updated>2023-10-05T22:23:38.000Z</updated>
        <summary type="html"><![CDATA[A brand new monthly series of Parisian seminars on the theory and practice of Monte Carlo in statistics and data science, in conjunction with our ERC OCEAN project. To kick start the series the organisers, Joshua Bon and Andrea Bertazzi, first postdocs in the project, will present some of their work on Friday 13 October, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computational Complexity of Learning Neural Networks: Smoothness and
  Degeneracy]]></title>
        <id>http://arxiv.org/abs/2302.07426</id>
        <link href="http://arxiv.org/abs/2302.07426"/>
        <updated>2023-10-05T02:23:40.316Z</updated>
        <summary type="html"><![CDATA[Amit Daniely, Nathan Srebro, Gal Vardi]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computing high-dimensional optimal transport by flow neural networks]]></title>
        <id>http://arxiv.org/abs/2305.11857</id>
        <link href="http://arxiv.org/abs/2305.11857"/>
        <updated>2023-10-05T02:23:39.939Z</updated>
        <summary type="html"><![CDATA[Chen Xu, Xiuyuan Cheng, Yao Xie]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PersA-FL: Personalized Asynchronous Federated Learning]]></title>
        <id>http://arxiv.org/abs/2210.01176</id>
        <link href="http://arxiv.org/abs/2210.01176"/>
        <updated>2023-10-05T02:23:39.824Z</updated>
        <summary type="html"><![CDATA[Mohammad Taha Toghani, Soomin Lee, C\'esar A. Uribe]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unified Transfer Learning Models for High-Dimensional Linear Regression]]></title>
        <id>http://arxiv.org/abs/2307.00238</id>
        <link href="http://arxiv.org/abs/2307.00238"/>
        <updated>2023-10-05T02:23:39.572Z</updated>
        <summary type="html"><![CDATA[Shuo Shuo Liu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[No(t/n)]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60825</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60825&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=not-n"/>
        <updated>2023-10-05T01:12:47.000Z</updated>
        <summary type="html"><![CDATA[That's bù 不, plus = a-, il-, im-, in-, ir-, un-, non- prefixes in English. It can enter into Mandarin contractions, such as bù 不 ("not") + yòng 用 ("use") = béng ("needn't), and the two Sinoglyphs used to write the constituent morphosyllables can fuse to become béng 甭 ("needn't). Here's a whole slew of such […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trajectory balance: Improved credit assignment in GFlowNets]]></title>
        <id>http://arxiv.org/abs/2201.13259</id>
        <link href="http://arxiv.org/abs/2201.13259"/>
        <updated>2023-10-05T01:04:49.684Z</updated>
        <summary type="html"><![CDATA[Nikolay Malkin, Moksh Jain, Emmanuel Bengio, Chen Sun, Yoshua Bengio]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks]]></title>
        <id>http://arxiv.org/abs/2110.14053</id>
        <link href="http://arxiv.org/abs/2110.14053"/>
        <updated>2023-10-05T01:04:48.366Z</updated>
        <summary type="html"><![CDATA[Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth McMillan,
  Risto Miikkulainen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the efficiency of Stochastic Quasi-Newton Methods for Deep Learning]]></title>
        <id>http://arxiv.org/abs/2205.09121</id>
        <link href="http://arxiv.org/abs/2205.09121"/>
        <updated>2023-10-05T01:04:45.186Z</updated>
        <summary type="html"><![CDATA[Mahsa Yousefi, Angeles Martinez]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Naive Exploration is Optimal for Online LQR]]></title>
        <id>http://arxiv.org/abs/2001.09576</id>
        <link href="http://arxiv.org/abs/2001.09576"/>
        <updated>2023-10-05T01:04:45.181Z</updated>
        <summary type="html"><![CDATA[Max Simchowitz, Dylan J. Foster]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Implicit Regularization of ReLU Neural Networks Characterizes the
  Learned Function -- Part I: the 1-D Case of Two Layers with Random First
  Layer]]></title>
        <id>http://arxiv.org/abs/1911.02903</id>
        <link href="http://arxiv.org/abs/1911.02903"/>
        <updated>2023-10-05T01:04:45.174Z</updated>
        <summary type="html"><![CDATA[Jakob Heiss, Josef Teichmann, Hanna Wutte]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Argentan half-marathon [1:30:55, 25/165, 2/9M5M, 23⁰]]]></title>
        <id>http://xianblog.wordpress.com/?p=54173</id>
        <link href="https://xianblog.wordpress.com/2023/10/05/argentan-half-marathon-13055-25-165-2-9m5m-23%e2%81%b0/"/>
        <updated>2023-10-04T22:23:56.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scalable spherical CNNs for scientific applications]]></title>
        <id>http://blog.research.google/2023/10/scalable-spherical-cnns-for-scientific.html</id>
        <link href="http://blog.research.google/2023/10/scalable-spherical-cnns-for-scientific.html"/>
        <updated>2023-10-04T17:26:00.003Z</updated>
        <summary type="html"><![CDATA[Posted by Carlos Esteves and Ameesh Makadia, Research Scientists, Google Research, Athena Team




Typical deep learning models for computer vision, like convolutional neural networks (CNNs) and vision transformers (ViT), process signals assuming planar (flat) spaces. For example, digital images are represented as a grid of pixels on a plane. However, this type of data makes up only a fraction of the data we encounter in scientific applications. Variables sampled from the Earth's atmosphere, like temperature and humidity, are naturally represented on the sphere. Some kinds of cosmological data and panoramic photos are also spherical signals, and are better treated as such. 



Using methods designed for planar images to process spherical signals is problematic for a couple of reasons. Firs…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hyper-inclusive we]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60828</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60828&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hyper-inclusive-we"/>
        <updated>2023-10-04T11:08:16.000Z</updated>
        <summary type="html"><![CDATA[Yesterday evening in a restaurant, our attentive server frequently asked us things like "Are we ready to order" and "How are we doing?". This use of we is common enough that I didn't notice it. But when they brought us a complimentary bit of sushi with the explanation "Here's some unagi for us", that caught […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[New Library Updates in PyTorch 2.1]]></title>
        <id>https://pytorch.org/blog/new-library-updates/</id>
        <link href="https://pytorch.org/blog/new-library-updates/"/>
        <updated>2023-10-04T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Summary]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch 2.1: automatic dynamic shape compilation, distributed checkpointing]]></title>
        <id>https://pytorch.org/blog/pytorch-2-1/</id>
        <link href="https://pytorch.org/blog/pytorch-2-1/"/>
        <updated>2023-10-04T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to announce the release of PyTorch® 2.1 (release note)! PyTorch 2.1 offers automatic dynamic shape support in torch.compile, torch.distributed.checkpoint for saving/loading distributed training jobs on multiple ranks in parallel, and torch.compile support for the NumPy API.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High performance Llama 2 deployments with AWS Inferentia2 using TorchServe]]></title>
        <id>https://pytorch.org/blog/high-performance-llama/</id>
        <link href="https://pytorch.org/blog/high-performance-llama/"/>
        <updated>2023-10-04T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Recently, Llama 2 was released and has attracted a lot of interest from the machine learning community. Amazon EC2 Inf2 instances, powered by AWS Inferentia2, now support training and inference of Llama 2 models. In this post, we show low-latency and cost-effective inference of Llama-2 models on Amazon EC2 Inf2 instances using the latest AWS Neuron SDK release.  We first introduce how to create, compile and deploy the Llama-2 model and explain the optimization techniques introduced by AWS Neuron SDK to achieve high performance at low cost. We then present our benchmarking results. Lastly, we show how the Llama-2 model can be deployed through Amazon SageMaker using TorchServe on an Inf2 instance.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In-Context Learning Learns Label Relationships but Is Not Conventional
  Learning]]></title>
        <id>http://arxiv.org/abs/2307.12375</id>
        <link href="http://arxiv.org/abs/2307.12375"/>
        <updated>2023-10-04T02:22:27.694Z</updated>
        <summary type="html"><![CDATA[Jannik Kossen, Yarin Gal, Tom Rainforth]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning k-Level Sparse Neural Networks Using a New Generalized Weighted
  Group Sparse Envelope Regularization]]></title>
        <id>http://arxiv.org/abs/2212.12921</id>
        <link href="http://arxiv.org/abs/2212.12921"/>
        <updated>2023-10-04T02:22:27.683Z</updated>
        <summary type="html"><![CDATA[Yehonathan Refael, Iftach Arbel, Wasim Huleihel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transferring Learning Trajectories of Neural Networks]]></title>
        <id>http://arxiv.org/abs/2305.14122</id>
        <link href="http://arxiv.org/abs/2305.14122"/>
        <updated>2023-10-04T02:22:27.565Z</updated>
        <summary type="html"><![CDATA[Daiki Chijiwa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Relax: Setting Solver Parameters Across a Sequence of Linear
  System Instances]]></title>
        <id>http://arxiv.org/abs/2310.02246</id>
        <link href="http://arxiv.org/abs/2310.02246"/>
        <updated>2023-10-04T02:22:27.560Z</updated>
        <summary type="html"><![CDATA[Mikhail Khodak, Edmond Chow, Maria-Florina Balcan, Ameet Talwalkar]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unifying supervised learning and VAEs -- coverage, systematics and
  goodness-of-fit in normalizing-flow based neural network models for
  astro-particle reconstructions]]></title>
        <id>http://arxiv.org/abs/2008.05825</id>
        <link href="http://arxiv.org/abs/2008.05825"/>
        <updated>2023-10-04T02:22:27.476Z</updated>
        <summary type="html"><![CDATA[Thorsten Gl\"usenkamp]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nobels away]]></title>
        <id>http://xianblog.wordpress.com/?p=54157</id>
        <link href="https://xianblog.wordpress.com/2023/10/04/nobels-away/"/>
        <updated>2023-10-03T22:23:55.000Z</updated>
        <summary type="html"><![CDATA[A self-administred poll in Nature about the respondents’ feeling about the prizes, with only 15% thinking it would be preferable to have none. As an absurd concept of singling out one scientist out the flock of top scientists, of comparing chalk and cheese, of idealising “great men” (since winners are predominantly men) with the ensuing […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Higher Criticism for Discriminating Word-Frequency Tables and Testing
  Authorship]]></title>
        <id>http://arxiv.org/abs/1911.01208</id>
        <link href="http://arxiv.org/abs/1911.01208"/>
        <updated>2023-10-03T22:13:31.118Z</updated>
        <summary type="html"><![CDATA[Alon Kipnis]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Good News for Polynomial Root-finding]]></title>
        <id>http://arxiv.org/abs/1805.12042</id>
        <link href="http://arxiv.org/abs/1805.12042"/>
        <updated>2023-10-03T22:13:31.093Z</updated>
        <summary type="html"><![CDATA[Victor Y. Pan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Implicit Regularization and Momentum Algorithms in Nonlinearly
  Parameterized Adaptive Control and Prediction]]></title>
        <id>http://arxiv.org/abs/1912.13154</id>
        <link href="http://arxiv.org/abs/1912.13154"/>
        <updated>2023-10-03T22:13:31.075Z</updated>
        <summary type="html"><![CDATA[Nicholas M. Boffi, Jean-Jacques E. Slotine]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Horizon instability of extremal Reissner-Nordstr\"om black holes to
  charged perturbations]]></title>
        <id>http://arxiv.org/abs/1612.03172</id>
        <link href="http://arxiv.org/abs/1612.03172"/>
        <updated>2023-10-03T22:13:30.788Z</updated>
        <summary type="html"><![CDATA[Peter Zimmerman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Formal Embeddings Between $\mathcal{BSD}$-Models]]></title>
        <id>http://arxiv.org/abs/1708.00089</id>
        <link href="http://arxiv.org/abs/1708.00089"/>
        <updated>2023-10-03T22:13:30.640Z</updated>
        <summary type="html"><![CDATA[Valentin Burcea]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language, topolect, dialect, idiolect]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60820</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60820&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=language-topolect-dialect-idiolect"/>
        <updated>2023-10-03T18:12:52.000Z</updated>
        <summary type="html"><![CDATA[An educated person will have all four levels of speech. The more highly educated they are, the higher up the scale their language capacity will go, though they may not be familiar with some of the argot of the lower levels. Of course, all four levels are language, but that is possible because "language" has […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to Build an Interactive Chat-Generation Model using DialoGPT and PyTorch]]></title>
        <id>https://pytorch.org/blog/interactive-chat-gen-model/</id>
        <link href="https://pytorch.org/blog/interactive-chat-gen-model/"/>
        <updated>2023-10-03T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[The focus on interactive chat-generation (or conversational response-generation) models has greatly increased in the past several months. Conversational response-generation models such as ChatGPT and Google Bard have taken the AI world by storm. The purpose of interactive chat generation is to answer various questions posed by humans, and these AI based models use natural language processing (NLP) to generate conversations almost indistinguishable from those generated by humans.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zero-Shot Recommendations with Pre-Trained Large Language Models for
  Multimodal Nudging]]></title>
        <id>http://arxiv.org/abs/2309.01026</id>
        <link href="http://arxiv.org/abs/2309.01026"/>
        <updated>2023-10-03T03:15:24.414Z</updated>
        <summary type="html"><![CDATA[Rachel M. Harrison, Anton Dereventsov, Anton Bibin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning Meets Sparse Regularization: A Signal Processing
  Perspective]]></title>
        <id>http://arxiv.org/abs/2301.09554</id>
        <link href="http://arxiv.org/abs/2301.09554"/>
        <updated>2023-10-03T03:15:24.376Z</updated>
        <summary type="html"><![CDATA[Rahul Parhi, Robert D. Nowak]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WASA: WAtermark-based Source Attribution for Large Language
  Model-Generated Data]]></title>
        <id>http://arxiv.org/abs/2310.00646</id>
        <link href="http://arxiv.org/abs/2310.00646"/>
        <updated>2023-10-03T03:15:24.362Z</updated>
        <summary type="html"><![CDATA[Jingtan Wang, Xinyang Lu, Zitong Zhao, Zhongxiang Dai, Chuan-Sheng
  Foo, See-Kiong Ng, Bryan Kian Hsiang Low]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Provable Reward-Agnostic Preference-Based Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2305.18505</id>
        <link href="http://arxiv.org/abs/2305.18505"/>
        <updated>2023-10-03T03:15:24.308Z</updated>
        <summary type="html"><![CDATA[Wenhao Zhan, Masatoshi Uehara, Wen Sun, Jason D. Lee]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A review of ensemble learning and data augmentation models for class
  imbalanced problems: combination, implementation and evaluation]]></title>
        <id>http://arxiv.org/abs/2304.02858</id>
        <link href="http://arxiv.org/abs/2304.02858"/>
        <updated>2023-10-03T03:15:24.303Z</updated>
        <summary type="html"><![CDATA[Azal Ahmad Khan, Omkar Chaudhari, Rohitash Chandra]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scaling up learning across many different robot types]]></title>
        <id>https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types</id>
        <link href="https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types"/>
        <updated>2023-10-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are launching a new set of resources for general-purpose robotics learning across different robot types, or embodiments. Together with partners from 34 academic labs we have pooled data from 22 different robot types to create the Open X-Embodiment dataset. We also release RT-1-X, a robotics transformer (RT) model derived from RT-1 and trained on our dataset, that shows skills transfer across many robot embodiments.]]></summary>
        <author>
            <name>DeepMind Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Familial inference]]></title>
        <id>http://xianblog.wordpress.com/?p=54136</id>
        <link href="https://xianblog.wordpress.com/2023/10/03/familial-inference/"/>
        <updated>2023-10-02T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[An ISBA-BNP webinar on Wednesday, 4 October, at 17:00 UTC by my friend Steve McEachern: Familial inference: Tests for hypotheses on a family of centers Many scientific disciplines face a replicability crisis. While these crises have many drivers, we focus on one. Statistical hypotheses are translations of scientific hypotheses into statements about one or more […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mental anguish from having too many English words in Japanese]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60805</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60805&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=mental-anguish-from-having-too-many-english-words-in-japanese"/>
        <updated>2023-10-02T12:47:25.000Z</updated>
        <summary type="html"><![CDATA[One thing I revel in about the English language is the huge number of loanwords it has:  French, Latin, Greek, Native American, Arabic, Persian, Turkish, Kurdish, Sanskrit, Hindi, Urdu, Bengali, Tamil, Russian, German, Spanish, Italian, Irish, Swedish, Dutch, Danish, Norwegian, Finnish, Japanese, Cantonese, Mandarin, Maori, Hebrew, Yiddish, Afrikaans, Zulu, Swahili, and so on and on […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pressure metrics for cusped Hitchin components]]></title>
        <id>http://arxiv.org/abs/2111.07493</id>
        <link href="http://arxiv.org/abs/2111.07493"/>
        <updated>2023-10-02T11:12:19.017Z</updated>
        <summary type="html"><![CDATA[Harrison Bray, Richard Canary, Lien-Yung Kao, Giuseppe Martone]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universality for Lozenge Tiling Local Statistics]]></title>
        <id>http://arxiv.org/abs/1907.09991</id>
        <link href="http://arxiv.org/abs/1907.09991"/>
        <updated>2023-10-02T11:12:19.012Z</updated>
        <summary type="html"><![CDATA[Amol Aggarwal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gromov's Oka principle for equivariant maps]]></title>
        <id>http://arxiv.org/abs/1912.07129</id>
        <link href="http://arxiv.org/abs/1912.07129"/>
        <updated>2023-10-02T11:12:18.987Z</updated>
        <summary type="html"><![CDATA[Frank Kutzschebauch, Finnur Larusson, Gerald W. Schwarz]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tensor products of Bands and Ideals]]></title>
        <id>http://arxiv.org/abs/2207.13796</id>
        <link href="http://arxiv.org/abs/2207.13796"/>
        <updated>2023-10-02T11:12:18.792Z</updated>
        <summary type="html"><![CDATA[Mohamed Amine Ben Amor, Omer Gok, Damla Yaman]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Lessons Learned: How (Not) to Defend Against Property Inference Attacks]]></title>
        <id>http://arxiv.org/abs/2205.08821</id>
        <link href="http://arxiv.org/abs/2205.08821"/>
        <updated>2023-10-02T11:12:18.780Z</updated>
        <summary type="html"><![CDATA[Joshua Stock (1), Jens Wettlaufer, Daniel Demmler (1), Hannes
  Federrath (1) ((1) Universit\"at Hamburg)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google at ICCV 2023]]></title>
        <id>http://blog.research.google/2023/10/google-at-iccv-2023.html</id>
        <link href="http://blog.research.google/2023/10/google-at-iccv-2023.html"/>
        <updated>2023-10-02T07:51:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Shaina Mehta, Program Manager, Google




Google is proud to be a Platinum Sponsor of the International Conference on Computer Vision (ICCV 2023), a premier annual conference, which is being held this week in Paris, France. As a leader in computer vision research, Google has a strong presence at this year’s conference with 60 accepted papers and active involvement in 27 workshops and tutorials. Google is also proud to be a Platinum Sponsor for the LatinX in CV workshop. We look forward to sharing some of our extensive computer vision research and expanding our partnership with the broader research community. 



Attending ICCV 2023? We hope you’ll visit the Google booth to chat with researchers who are actively pursuing the latest innovations in computer vision, and check out som…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing PyTorch Docathon H2 2023]]></title>
        <id>https://pytorch.org/blog/announcing-docathon-h2-2023/</id>
        <link href="https://pytorch.org/blog/announcing-docathon-h2-2023/"/>
        <updated>2023-10-02T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[We are excited to announce that we will be holding a Docathon for PyTorch on November 1, 2023! This event is an opportunity for our community to come together and improve the quality of our documentation.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalized Balancing Weights via Deep Neural Networks]]></title>
        <id>http://arxiv.org/abs/2211.07533</id>
        <link href="http://arxiv.org/abs/2211.07533"/>
        <updated>2023-10-02T03:15:24.494Z</updated>
        <summary type="html"><![CDATA[Yoshiaki Kitazawa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Characteristic Activation Value Analysis for Improved ReLU
  Network Feature Learning]]></title>
        <id>http://arxiv.org/abs/2305.15912</id>
        <link href="http://arxiv.org/abs/2305.15912"/>
        <updated>2023-10-02T03:15:24.452Z</updated>
        <summary type="html"><![CDATA[Wenlin Chen, Hong Ge]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Agnostic Learning with Average Smoothness]]></title>
        <id>http://arxiv.org/abs/2309.17016</id>
        <link href="http://arxiv.org/abs/2309.17016"/>
        <updated>2023-10-02T03:15:24.422Z</updated>
        <summary type="html"><![CDATA[Steve Hanneke, Aryeh Kontorovich, Guy Kornowski]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalization Guarantees of Gradient Descent for Multi-Layer Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.16891</id>
        <link href="http://arxiv.org/abs/2305.16891"/>
        <updated>2023-10-02T03:15:24.253Z</updated>
        <summary type="html"><![CDATA[Puyu Wang, Yunwen Lei, Di Wang, Yiming Ying, Ding-Xuan Zhou]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Water quality prediction using machine learning and neural network
  approaches]]></title>
        <id>http://arxiv.org/abs/2309.16951</id>
        <link href="http://arxiv.org/abs/2309.16951"/>
        <updated>2023-10-02T03:15:24.231Z</updated>
        <summary type="html"><![CDATA[Yinpu Li, Siqi Mao, Yaping Yuan, Ziren Wang, Yixin Kang, Yuanxin Yao]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ELLIS PhD Program]]></title>
        <id>http://xianblog.wordpress.com/?p=54113</id>
        <link href="https://xianblog.wordpress.com/2023/10/02/54113/"/>
        <updated>2023-10-01T22:23:12.000Z</updated>
        <summary type="html"><![CDATA[The ELLIS PhD Program is now accepting applications. ELLIS PhDs are co-supervised by one ELLIS fellow/scholar/unit faculty and one ELLIS fellow/scholar/member, both based in Europe. The ELLIS initiative has the goal to foster and educate the best talent in machine learning and related research areas by pairing outstanding students with leading academic and industrial researchers […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A dangerous degree of accidental intelligence]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60808</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60808&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-dangerous-degree-of-accidental-intelligence"/>
        <updated>2023-10-01T18:59:31.000Z</updated>
        <summary type="html"><![CDATA[Henry Farrell and Cosma Shalizi, "Behold the AI Shoggoth", The Economist 6/21/2023 ("The academics argue that large language models have much older cousins in markets and bureaucracies"): An internet meme keeps on turning up in debates about the large language models (LLMS) that power services such Openai’s ChatGPT and the newest version of Microsoft’s Bing […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[semi-marathon d’Argentan 2023]]></title>
        <id>http://xianblog.wordpress.com/?p=54037</id>
        <link href="https://xianblog.wordpress.com/2023/10/01/semi-marathon-dargentan-2023/"/>
        <updated>2023-09-30T22:23:06.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Share your language]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60800</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60800&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=share-your-language"/>
        <updated>2023-09-30T19:55:43.000Z</updated>
        <summary type="html"><![CDATA[If you can't make up your mind what to do about something, then in French you would say "je suis partagé":  I'm torn or divided over it.  You can't decide what to do about it.  You can't make up your mind whether to be pleased or angry with something.  But the verb "partager" means "to […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Synge's dynamic problem for two isolated point charges. A new method to
  find global solutions for Functional Differential Equations System]]></title>
        <id>http://arxiv.org/abs/2308.11641</id>
        <link href="http://arxiv.org/abs/2308.11641"/>
        <updated>2023-09-30T02:18:51.265Z</updated>
        <summary type="html"><![CDATA[Rodrigo R. Silva, Annibal Figueiredo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[optimal formation for marathon records]]></title>
        <id>http://xianblog.wordpress.com/?p=53860</id>
        <link href="https://xianblog.wordpress.com/2023/09/30/optimal-formation-for-marathon-records/"/>
        <updated>2023-09-29T22:23:58.000Z</updated>
        <summary type="html"><![CDATA[A fascinating experiment run (!) by researchers from Lyon and Torino, testing the impact of different pacer formations on the air drag of a specific runner, and leading to a predicted 4¼mn gain on a marathon for the optimal configuration. Inspired by (and in agreement with) the Nike Breaking2 and INEOS1:59 Challenge attempts. Of course, […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Juridical tautology:  "illegal crime"]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60774</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60774&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=juridical-tautology-illegal-crime"/>
        <updated>2023-09-29T20:12:34.000Z</updated>
        <summary type="html"><![CDATA[The news is flooded with stories about Hui Ka Yan 许家印 (MSM Xǔ Jiāyìn), one of China's wealthiest individuals, Chairman and Party Committee secretary of Evergrande Group, the mega real estate corporation that is currently going belly up, being arrested on suspicion of "illegal crimes".  That expression sounded so strange that I had to find […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Furious sleeping continues]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60778</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60778&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=furious-sleeping-continues"/>
        <updated>2023-09-29T13:31:36.000Z</updated>
        <summary type="html"><![CDATA[Several people have sent me pointers to the linguistically-themed 9/27/2023 NYT crossword puzzle. For some discussion by Sam Corbin, see "Talk, Talk, Talk", NYT 9/26/2023 ("Scott Koenig puts silly thoughts to bed with a clever crossword"), which includes a quotation from the puzzle's author: I first learned about Professor Chomsky as an undergraduate linguistics minor. […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[11/03 1pm-2pm: Stats Seminar]]></title>
        <id>8a17841a8adb7b43018ae00188cd1221</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:15:11.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 11 Mar '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[26/02 1pm-2pm: Stats Seminar]]></title>
        <id>8a1785d88adb7b44018ae000e6e84f4b</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:14:30.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 26 Feb '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[12/02 1pm-2pm: Stats Seminar]]></title>
        <id>8a1785d78adb7884018ae000414f1360</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:13:47.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 12 Feb '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[29/01 1pm-2pm: Statistics Seminar]]></title>
        <id>8a1785d88adb7b44018adfff90924f47</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:13:02.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 29 Jan '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[15/01 1pm-2pm: Stats Seminar]]></title>
        <id>8a1785d78adb7884018adffec409135d</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T08:12:10.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 15 Jan '24

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[04/12 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841a8adb7b43018adfd7774d1148</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:29:14.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 04 Dec '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[20/11 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841b8adb7895018adfd6ce0c4ad1</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:28:31.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 20 Nov '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[06/11 1pm-2pm: Statistics Seminar]]></title>
        <id>8a1785d78adb7884018adfd618211321</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:27:44.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 06 Nov '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[23/10 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841b8adb7895018adfd54cfc4ace</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:26:52.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 23 Oct '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[09/10 1pm-2pm: Statistics Seminar]]></title>
        <id>8a17841b8adb7895018adfd46a884acb</id>
        <link href="https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/statisticsseminars-copy/"/>
        <updated>2023-09-29T07:25:54.000Z</updated>
        <summary type="html"><![CDATA[When:
	
  		13:00
		-
		14:00, Mon, 09 Oct '23

	
Where: Stats Common Room]]></summary>
        <author>
            <name>Statistics</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Selection in Algorithmic Decision-making]]></title>
        <id>http://arxiv.org/abs/2108.12547</id>
        <link href="http://arxiv.org/abs/2108.12547"/>
        <updated>2023-09-29T01:04:29.683Z</updated>
        <summary type="html"><![CDATA[Jin Li, Ye Luo, Xiaowei Zhang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantum Self-Attention Neural Networks for Text Classification]]></title>
        <id>http://arxiv.org/abs/2205.05625</id>
        <link href="http://arxiv.org/abs/2205.05625"/>
        <updated>2023-09-29T01:04:29.678Z</updated>
        <summary type="html"><![CDATA[Guangxi Li, Xuanqiang Zhao, Xin Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Private Stochastic Optimization With Large Worst-Case Lipschitz
  Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to
  Non-Convex Losses]]></title>
        <id>http://arxiv.org/abs/2209.07403</id>
        <link href="http://arxiv.org/abs/2209.07403"/>
        <updated>2023-09-29T01:04:29.450Z</updated>
        <summary type="html"><![CDATA[Andrew Lowy, Meisam Razaviyayn]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HyperBO+: Pre-training a universal prior for Bayesian optimization with
  hierarchical Gaussian processes]]></title>
        <id>http://arxiv.org/abs/2212.10538</id>
        <link href="http://arxiv.org/abs/2212.10538"/>
        <updated>2023-09-29T01:04:29.439Z</updated>
        <summary type="html"><![CDATA[Zhou Fan, Xinran Han, Zi Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Augmentation in the Underparameterized and Overparameterized
  Regimes]]></title>
        <id>http://arxiv.org/abs/2202.09134</id>
        <link href="http://arxiv.org/abs/2202.09134"/>
        <updated>2023-09-29T01:04:29.434Z</updated>
        <summary type="html"><![CDATA[Kevin Han Huang, Peter Orbanz, Morgane Austern]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bertrand’s paradox [re]solved?]]></title>
        <id>http://xianblog.wordpress.com/?p=53824</id>
        <link href="https://xianblog.wordpress.com/2023/09/29/bertrands-paradox-resolved/"/>
        <updated>2023-09-28T22:23:44.000Z</updated>
        <summary type="html"><![CDATA[On the plane back from Vancouver, I read Bertrand’s Paradox Resolution and Its Implications for the Bing–Fisher Problem by Richard A. Chechile [who had pointed out his paper to me] In this paper, Chechile considers the Bayesian connections/sequences of Betrand’s paradox, as he sees it Bertrand’s different solutions/paradox to be “designed to illustrate his dissatisfaction […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DynIBaR: Space-time view synthesis from videos of dynamic scenes]]></title>
        <id>http://blog.research.google/2023/09/dynibar-space-time-view-synthesis-from.html</id>
        <link href="http://blog.research.google/2023/09/dynibar-space-time-view-synthesis-from.html"/>
        <updated>2023-09-28T20:01:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Zhengqi Li and Noah Snavely, Research Scientists, Google Research







A mobile phone’s camera is a powerful tool for capturing everyday moments. However, capturing a dynamic scene using a single camera is fundamentally limited. For instance, if we wanted to adjust the camera motion or timing of a recorded video (e.g., to freeze time while sweeping the camera around to highlight a dramatic moment), we would typically need an expensive Hollywood setup with a synchronized camera rig. Would it be possible to achieve similar effects solely from a video captured using a mobile phone’s camera, without a Hollywood budget?



In “DynIBaR: Neural Dynamic Image-Based Rendering”, a best paper honorable mention at CVPR 2023, we describe a new method that generates photorealistic free-viewp…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Re-weighted gradient descent via distributionally robust optimization]]></title>
        <id>http://blog.research.google/2023/09/re-weighted-gradient-descent-via.html</id>
        <link href="http://blog.research.google/2023/09/re-weighted-gradient-descent-via.html"/>
        <updated>2023-09-28T18:16:00.002Z</updated>
        <summary type="html"><![CDATA[Ramnath Kumar, Pre-Doctoral Researcher, and Arun Sai Suggala, Research Scientist, Google Research





Deep neural networks (DNNs) have become essential for solving a wide range of tasks, from standard supervised learning (image classification using ViT) to meta-learning. The most commonly-used paradigm for learning DNNs is empirical risk minimization (ERM), which aims to identify a network that minimizes the average loss on training data points. Several algorithms, including stochastic gradient descent (SGD), Adam, and Adagrad, have been proposed for solving ERM. However, a drawback of ERM is that it weights all the samples equally, often ignoring the rare and more difficult samples, and focusing on the easier and abundant samples. This leads to suboptimal performance on unseen data, espe…]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[international safe abortion day]]></title>
        <id>http://xianblog.wordpress.com/?p=54140</id>
        <link href="https://xianblog.wordpress.com/2023/09/28/international-safe-abortion-day-2/"/>
        <updated>2023-09-28T10:23:12.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kimchee is Korean]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60759</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60759&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=kimchee-is-korean"/>
        <updated>2023-09-28T10:17:26.000Z</updated>
        <summary type="html"><![CDATA[Not Chinese.  Do you understand? This has long been a cabbage of contention, but make no mistake about it:  fermented kimchee / kimchi  (gimchi 김치 (IPA [kim.tɕʰi]) (lit., "soaked [in their own juices of fermentation] vegetables") is not the same thing as pickled paocai / pao tsai 泡菜 (lit., "soaked [in brine] vegetables"). Kimchee and […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantum-Noise-driven Generative Diffusion Models]]></title>
        <id>http://arxiv.org/abs/2308.12013</id>
        <link href="http://arxiv.org/abs/2308.12013"/>
        <updated>2023-09-28T03:15:19.646Z</updated>
        <summary type="html"><![CDATA[Marco Parigi, Stefano Martina, Filippo Caruso]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural network with optimal neuron activation functions based on
  additive Gaussian process regression]]></title>
        <id>http://arxiv.org/abs/2301.05567</id>
        <link href="http://arxiv.org/abs/2301.05567"/>
        <updated>2023-09-28T03:15:16.432Z</updated>
        <summary type="html"><![CDATA[Sergei Manzhos, Manabu Ihara]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Neural Prompting with Large Language Models]]></title>
        <id>http://arxiv.org/abs/2309.15427</id>
        <link href="http://arxiv.org/abs/2309.15427"/>
        <updated>2023-09-28T03:15:16.311Z</updated>
        <summary type="html"><![CDATA[Yijun Tian, Huan Song, Zichen Wang, Haozhu Wang, Ziqing Hu, Fang Wang,
  Nitesh V. Chawla, Panpan Xu]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Approximation of Zonoids and Uniform Approximation by Shallow
  Neural Networks]]></title>
        <id>http://arxiv.org/abs/2307.15285</id>
        <link href="http://arxiv.org/abs/2307.15285"/>
        <updated>2023-09-28T03:15:15.778Z</updated>
        <summary type="html"><![CDATA[Jonathan W. Siegel]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GeONet: a neural operator for learning the Wasserstein geodesic]]></title>
        <id>http://arxiv.org/abs/2209.14440</id>
        <link href="http://arxiv.org/abs/2209.14440"/>
        <updated>2023-09-28T03:15:15.455Z</updated>
        <summary type="html"><![CDATA[Andrew Gracyk, Xiaohui Chen]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representations having vectors fixed by a Levi subgroup]]></title>
        <id>http://arxiv.org/abs/2002.10928</id>
        <link href="http://arxiv.org/abs/2002.10928"/>
        <updated>2023-09-28T01:04:22.233Z</updated>
        <summary type="html"><![CDATA[Ilia Smilga]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Sparse Decision Trees]]></title>
        <id>http://arxiv.org/abs/1904.12847</id>
        <link href="http://arxiv.org/abs/1904.12847"/>
        <updated>2023-09-28T01:04:22.189Z</updated>
        <summary type="html"><![CDATA[Xiyang Hu, Cynthia Rudin, Margo Seltzer]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding North Atlantic Climate Instabilities and Complex
  Interactions using Data Science]]></title>
        <id>http://arxiv.org/abs/2001.10171</id>
        <link href="http://arxiv.org/abs/2001.10171"/>
        <updated>2023-09-28T01:04:22.153Z</updated>
        <summary type="html"><![CDATA[Alka Yadav, Sourish Das, Anirban Chakraborti]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving the convergence of SGD through adaptive batch sizes]]></title>
        <id>http://arxiv.org/abs/1910.08222</id>
        <link href="http://arxiv.org/abs/1910.08222"/>
        <updated>2023-09-28T01:04:22.146Z</updated>
        <summary type="html"><![CDATA[Scott Sievert, Shrey Shah]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A differential model for B-type Landau-Ginzburg theories]]></title>
        <id>http://arxiv.org/abs/1709.00684</id>
        <link href="http://arxiv.org/abs/1709.00684"/>
        <updated>2023-09-28T01:04:21.912Z</updated>
        <summary type="html"><![CDATA[Elena Mirela Babalic, Dmitry Doryn, Calin Iuliu Lazaroiu, Mehdi
  Tavakol]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ISBA²⁴ [call for contributed talks]]]></title>
        <id>http://xianblog.wordpress.com/?p=54121</id>
        <link href="https://xianblog.wordpress.com/2023/09/28/isba%c2%b2%e2%81%b4-call-for-contributed-talks/"/>
        <updated>2023-09-27T22:24:52.000Z</updated>
        <summary type="html"><![CDATA[Now that the invited sessions have been selected by the scientific committee of ISBA²⁴ (with both sessions in which I am involved, Bayesian data privacy and The future of ISBA conferences, accepted), the call is open for contributed talks, with deadline 17 November. (If  this helps in making a proposal, childcare will be available during […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Reversal Curse]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60766</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60766&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=the-reversal-curse"/>
        <updated>2023-09-27T13:57:15.000Z</updated>
        <summary type="html"><![CDATA[An interesting recent paper — Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans,"The Reversal Curse: LLMs trained on 'A is B' fail to learn 'B is A'", arXiv.org 9/21/2023. The abstract: We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Some snarks are worse than others]]></title>
        <id>http://arxiv.org/abs/2004.14049</id>
        <link href="http://arxiv.org/abs/2004.14049"/>
        <updated>2023-09-27T11:12:35.149Z</updated>
        <summary type="html"><![CDATA[Edita M\'a\v{c}ajov\'a, Giuseppe Mazzuoccolo, Vahan Mkrtchyan, Jean
  Paul Zerafa]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimal Experimental Design for Staggered Rollouts]]></title>
        <id>http://arxiv.org/abs/1911.03764</id>
        <link href="http://arxiv.org/abs/1911.03764"/>
        <updated>2023-09-27T11:12:35.109Z</updated>
        <summary type="html"><![CDATA[Ruoxuan Xiong, Susan Athey, Mohsen Bayati, Guido Imbens]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Computational aspects of orbifold equivalence]]></title>
        <id>http://arxiv.org/abs/1901.09019</id>
        <link href="http://arxiv.org/abs/1901.09019"/>
        <updated>2023-09-27T11:12:35.099Z</updated>
        <summary type="html"><![CDATA[Timo Kluck, Ana Ros Camacho]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The strategy of conflict and cooperation]]></title>
        <id>http://arxiv.org/abs/1808.06750</id>
        <link href="http://arxiv.org/abs/1808.06750"/>
        <updated>2023-09-27T11:12:35.035Z</updated>
        <summary type="html"><![CDATA[Mehmet S. Ismail]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NN2Poly: A polynomial representation for deep feed-forward artificial
  neural networks]]></title>
        <id>http://arxiv.org/abs/2112.11397</id>
        <link href="http://arxiv.org/abs/2112.11397"/>
        <updated>2023-09-27T02:21:28.251Z</updated>
        <summary type="html"><![CDATA[Pablo Morala (1, 2), Jenny Alexandra Cifuentes (3), Rosa E. Lillo
  (1, 2), I\~naki Ucar (1, 2) ((1) uc3m-Santander Big Data Institute,
  Universidad Carlos III de Madrid. Spain., (2) Department of Statistics,
  Universidad Carlos III de Madrid. Spain., (3) ICADE, Department of
  Quantitative Methods, Faculty of Economics, Business Administration,
  Universidad Pontificia Comillas. Spain.)]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring Small Language Models with Prompt-Learning Paradigm for
  Efficient Domain-Specific Text Classification]]></title>
        <id>http://arxiv.org/abs/2309.14779</id>
        <link href="http://arxiv.org/abs/2309.14779"/>
        <updated>2023-09-27T02:21:26.121Z</updated>
        <summary type="html"><![CDATA[Hengyu Luo, Peng Liu, Stefan Esping]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On Excess Risk Convergence Rates of Neural Network Classifiers]]></title>
        <id>http://arxiv.org/abs/2309.15075</id>
        <link href="http://arxiv.org/abs/2309.15075"/>
        <updated>2023-09-27T02:21:25.967Z</updated>
        <summary type="html"><![CDATA[Hyunouk Ko, Namjoon Suh, Xiaoming Huo]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SGD Finds then Tunes Features in Two-Layer Neural Networks with
  near-Optimal Sample Complexity: A Case Study in the XOR problem]]></title>
        <id>http://arxiv.org/abs/2309.15111</id>
        <link href="http://arxiv.org/abs/2309.15111"/>
        <updated>2023-09-27T02:21:25.932Z</updated>
        <summary type="html"><![CDATA[Margalit Glasgow]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[congrats, friends!]]></title>
        <id>http://xianblog.wordpress.com/?p=53984</id>
        <link href="https://xianblog.wordpress.com/2023/09/27/congrats-friends/"/>
        <updated>2023-09-26T22:23:35.000Z</updated>
        <summary type="html"><![CDATA[Congrats to my friends who got academic recognition at JSM last month, among whom Bin Yu for her 2023 COPSS Distinguished Achievement Award and Lectureship, Veronika Rockova for her Emerging Leader Award, Nancy Reid for her David R. Cox Foundations of Statistics Award, Malay Ghosh for his Deming Lecture, Andrew Gelman for his Monroe G. […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Corporeal grammar]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60726</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60726&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=corporeal-grammar"/>
        <updated>2023-09-26T21:03:01.000Z</updated>
        <summary type="html"><![CDATA[Recent article in Scientific American: This Ancient Language Has the Only Grammar Based Entirely on the Human Body An endangered language family suggests that early humans used their bodies as a model for reality By Anvita Abbi on June 1, 2023 From just a small handful of Andaman Islanders, the last speakers of their languages, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Google Research embarks on effort to map a mouse brain]]></title>
        <id>http://blog.research.google/2023/09/google-research-embarks-on-effort-to.html</id>
        <link href="http://blog.research.google/2023/09/google-research-embarks-on-effort-to.html"/>
        <updated>2023-09-26T14:10:00.000Z</updated>
        <summary type="html"><![CDATA[Posted by Michał Januszewski, Research Scientist, Google Research






The human brain is perhaps the most computationally complex machine in existence, consisting of networks of billions of cells. Researchers currently don’t understand the full picture of how glitches in its network machinery contribute to mental illnesses and other diseases, such as dementia. However, the emerging connectomics field, which aims to precisely map the connections between every cell in the brain, could help solve that problem. While maps have only been created for simpler organisms, technological advances for mapping even larger brains can enable us to understand how the human brain works, and how to treat brain diseases.



Today, we're excited to announce that the Connectomics team at Google Research and …]]></summary>
        <author>
            <name>Google AI Blog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A new Indo-European language]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60750</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60750&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-new-indo-european-language"/>
        <updated>2023-09-26T08:47:29.000Z</updated>
        <summary type="html"><![CDATA[Many LL readers are familiar with the archeological site of Boğazköy-Hattusha in north-central Turkey, which was the capital of the Hittite Empire and the place where the Hittite Royal Archives (17th-13th c. BC) were discovered, making it the oldest historically attested Indo-European language (scattered Hittite words in Akkadian documents stretch back to the 20th c. […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Utilizing Expert Features for Contrastive Learning of Time-Series
  Representations]]></title>
        <id>http://arxiv.org/abs/2206.11517</id>
        <link href="http://arxiv.org/abs/2206.11517"/>
        <updated>2023-09-26T02:21:19.953Z</updated>
        <summary type="html"><![CDATA[Manuel Nonnenmacher, Lukas Oldenburg, Ingo Steinwart, David Reeb]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring and Interacting with the Set of Good Sparse Generalized
  Additive Models]]></title>
        <id>http://arxiv.org/abs/2303.16047</id>
        <link href="http://arxiv.org/abs/2303.16047"/>
        <updated>2023-09-26T02:21:19.947Z</updated>
        <summary type="html"><![CDATA[Chudi Zhong, Zhi Chen, Margo Seltzer, Cynthia Rudin]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Benefits of Being Distributional: Small-Loss Bounds for
  Reinforcement Learning]]></title>
        <id>http://arxiv.org/abs/2305.15703</id>
        <link href="http://arxiv.org/abs/2305.15703"/>
        <updated>2023-09-26T02:21:18.545Z</updated>
        <summary type="html"><![CDATA[Kaiwen Wang, Kevin Zhou, Runzhe Wu, Nathan Kallus, Wen Sun]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mode-Aware Continual Learning for Conditional Generative Adversarial
  Networks]]></title>
        <id>http://arxiv.org/abs/2305.11400</id>
        <link href="http://arxiv.org/abs/2305.11400"/>
        <updated>2023-09-26T02:21:18.537Z</updated>
        <summary type="html"><![CDATA[Cat P. Le, Juncheng Dong, Ahmed Aloui, Vahid Tarokh]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[脑洞大开：非线性RNN居然也可以并行计算？]]></title>
        <id>https://kexue.fm/archives/9783</id>
        <link href="https://kexue.fm/archives/9783"/>
        <updated>2023-09-26T02:03:00.000Z</updated>
        <summary type="html"><![CDATA[近年来，线性RNN由于其可并行训练以及常数推理成本等特性，吸引了一定研究人员的关注（例如笔者之前写的《Google新作试图“复活”RNN：RNN能否再次辉煌？》），这让RNN在Transform...]]></summary>
        <author>
            <name>苏剑林</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[course du souffle au Parc de Sceaux [42:06, 10k, 128m⁺, 43/663, 1/19M5M]]]></title>
        <id>http://xianblog.wordpress.com/?p=54100</id>
        <link href="https://xianblog.wordpress.com/2023/09/26/course-du-souffle-au-parc-de-sceaux-4206-10k-128m%e2%81%ba-43-663-1-19m5m/"/>
        <updated>2023-09-25T22:23:01.000Z</updated>
        <summary type="html"><![CDATA[Visit the post for more.]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A bad thing about social media is also good]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60735</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60735&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=a-bad-thing-about-social-media-is-also-good"/>
        <updated>2023-09-25T12:06:12.000Z</updated>
        <summary type="html"><![CDATA[Jill Lepore recently presented an illustrative example of how social media amplifies bad stuff ("The World According to Elon Musk's Grandfather", 9/19/2023): Walter Isaacson’s new biography of Musk […] only glancingly discusses Musk’s grandfather J. N. Haldeman, whom he presents as a risk-taking adventurer and whose politics he dismisses as “quirky.” In fact, Haldeman was […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond]]></title>
        <id>https://pytorch.org/blog/inside-the-matrix/</id>
        <link href="https://pytorch.org/blog/inside-the-matrix/"/>
        <updated>2023-09-25T07:00:00.000Z</updated>
        <summary type="html"><![CDATA[Use 3D to visualize matrix multiplication expressions, attention heads with real weights, and more.]]></summary>
        <author>
            <name>PyTorch Website</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Hybrid Deep Learning-based Approach for Optimal Genotype by
  Environment Selection]]></title>
        <id>http://arxiv.org/abs/2309.13021</id>
        <link href="http://arxiv.org/abs/2309.13021"/>
        <updated>2023-09-25T03:15:26.640Z</updated>
        <summary type="html"><![CDATA[Zahra Khalilzadeh, Motahareh Kashanian, Saeed Khaki, Lizhi Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multimodal Deep Learning for Scientific Imaging Interpretation]]></title>
        <id>http://arxiv.org/abs/2309.12460</id>
        <link href="http://arxiv.org/abs/2309.12460"/>
        <updated>2023-09-25T03:15:25.861Z</updated>
        <summary type="html"><![CDATA[Abdulelah S. Alshehri, Franklin L. Lee, Shihu Wang]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exploring Transfer Learning in Medical Image Segmentation using
  Vision-Language Models]]></title>
        <id>http://arxiv.org/abs/2308.07706</id>
        <link href="http://arxiv.org/abs/2308.07706"/>
        <updated>2023-09-25T03:15:25.530Z</updated>
        <summary type="html"><![CDATA[Kanchan Poudel, Manish Dhakal, Prasiddha Bhandari, Rabin Adhikari,
  Safal Thapaliya, Bishesh Khanal]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantitative Gaussian Approximation of Randomly Initialized Deep Neural
  Networks]]></title>
        <id>http://arxiv.org/abs/2203.07379</id>
        <link href="http://arxiv.org/abs/2203.07379"/>
        <updated>2023-09-25T03:15:25.483Z</updated>
        <summary type="html"><![CDATA[Andrea Basteri, Dario Trevisan]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BayesDLL: Bayesian Deep Learning Library]]></title>
        <id>http://arxiv.org/abs/2309.12928</id>
        <link href="http://arxiv.org/abs/2309.12928"/>
        <updated>2023-09-25T03:15:25.385Z</updated>
        <summary type="html"><![CDATA[Minyoung Kim, Timothy Hospedales]]></summary>
        <author>
            <name>arxivist feed</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exact MCMC with differentially private moves]]></title>
        <id>http://xianblog.wordpress.com/?p=53975</id>
        <link href="https://xianblog.wordpress.com/2023/09/25/exact-mcmc-with-differentially-private-moves/"/>
        <updated>2023-09-24T22:23:27.000Z</updated>
        <summary type="html"><![CDATA[“The algorithm can be made differentially private while remaining exact in the sense that its target distribution is the true posterior distribution conditioned on the private data (…) The main contribution of this paper arises from the simple  observation that the penalty algorithm has a built-in noise in its calculations which is not desirable in […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sweden's renewed emphasis on books and handwriting]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60683</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60683&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=swedens-renewed-emphasis-on-books-and-handwriting"/>
        <updated>2023-09-24T11:41:05.000Z</updated>
        <summary type="html"><![CDATA[Sweden brings more books and handwriting practice back to its tech-heavy schools Charlene Pele, AP (9/10/23) Accompanied by 10 photographs showing young children (3rd grade?) practicing handwriting. As young children went back to school across Sweden last month, many of their teachers were putting a new emphasis on printed books, quiet reading time and handwriting […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bad AI performance]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60690</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60690&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=bad-ai-performance"/>
        <updated>2023-09-24T11:09:34.000Z</updated>
        <summary type="html"><![CDATA[It's clear that text-to-speech programs have gotten better and better over the past 60 years, technical details aside. The best current systems rarely make phrasing or letter-to-sound mistakes, and generally produce speech that sounds pretty natural on a phrase-by-phrase basis. (Though there's a lot of variation in quality, with some shockingly bad systems in common use.) […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian diﬀerential privacy for free?]]></title>
        <id>http://xianblog.wordpress.com/?p=53957</id>
        <link href="https://xianblog.wordpress.com/2023/09/24/bayesian-di%ef%ac%80erential-privacy-for-free/"/>
        <updated>2023-09-23T22:23:06.000Z</updated>
        <summary type="html"><![CDATA[“We are interested in the question of how we can build diﬀerentially-private algorithms within the Bayesian framework. More precisely, we examine when the choice of prior is suﬃcient to guarantee diﬀerential privacy for decisions that are derived from the posterior distribution (…) we show that the Bayesian statistician’s choice of prior distribution ensures a base […]]]></summary>
        <author>
            <name>xi'an</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Motivating the cross-entropy loss]]></title>
        <id>https://parsiad.ca/blog/2023/motivating_the_cross_entropy_loss/</id>
        <link href="https://parsiad.ca/blog/2023/motivating_the_cross_entropy_loss/"/>
        <updated>2023-09-23T20:00:00.000Z</updated>
        <summary type="html"><![CDATA[Introduction]]></summary>
        <author>
            <name>Parsiad Azimzadeh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA["Hurting the feelings of the Chinese people", part 3]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60657</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60657&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=hurting-the-feelings-of-the-chinese-people-part-3"/>
        <updated>2023-09-23T19:08:09.000Z</updated>
        <summary type="html"><![CDATA[Shared by John Rohsenow and David Cahill / Isham Cook: From Arthur Meursault (@emptymeursault) This is a trope with which we're intimately familiar. According to the Chinese government, of all peoples on earth, the Chinese people are unique in this regard, except that now, more and more, they are starting to hurt their own feelings, […]]]></summary>
        <author>
            <name>Victor Mair</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Annals of AI bias]]></title>
        <id>https://languagelog.ldc.upenn.edu/nll/?p=60695</id>
        <link href="https://languagelog.ldc.upenn.edu/nll/?p=60695&amp;utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=annals-of-ai-bias"/>
        <updated>2023-09-23T18:23:18.000Z</updated>
        <summary type="html"><![CDATA[The Large Language Model DistilBert is "a distilled version of BERT: smaller, faster, cheaper and lighter". A trained DistilBert model is available from Hugging Face, and recommended applications include "text classification", with the featured application being "sentiment analysis": And as with many similar applications, it's been noted that this version of "sentiment analysis" has picked […]]]></summary>
        <author>
            <name>Mark Liberman</name>
        </author>
    </entry>
</feed>