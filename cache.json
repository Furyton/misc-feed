{
  "sources": [
    {
      "title": "arxivist feed",
      "feedUrl": "https://arxivist.com/rss.php?rss_id=175ea3663a919f8117ebe029d30ebe6c",
      "siteUrl": "https://www.arxivist.com",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2302.00878",
          "author": null,
          "description": "Ryan Thompson, Amir Dezfouli, Robert Kohn",
          "link": "http://arxiv.org/abs/2302.00878",
          "publishedOn": "2023-05-30T07:13:25.154Z",
          "wordCount": 718,
          "title": "The contextual lasso: Sparse linear models via deep neural networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.03299",
          "author": null,
          "description": "Mingze Wang, Chao Ma",
          "link": "http://arxiv.org/abs/2206.03299",
          "publishedOn": "2023-05-30T07:13:24.424Z",
          "wordCount": 631,
          "title": "Generalization Error Bounds for Deep Neural Networks Trained by SGD",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.18270",
          "author": null,
          "description": "Yatin Dandi, Florent Krzakala, Bruno Loureiro, Luca Pesce, Ludovic\n  Stephan",
          "link": "http://arxiv.org/abs/2305.18270",
          "publishedOn": "2023-05-30T07:13:23.287Z",
          "wordCount": 721,
          "title": "Learning Two-Layer Neural Networks, One (Giant) Step at a Time",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2006.07356",
          "author": null,
          "description": "Hui Jin, Guido Mont\\'ufar",
          "link": "http://arxiv.org/abs/2006.07356",
          "publishedOn": "2023-05-30T07:13:23.096Z",
          "wordCount": 765,
          "title": "Implicit Bias of Gradient Descent for Mean Squared Error Regression with\n  Two-Layer Wide Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.17608",
          "author": null,
          "description": "Ziang Song, Tianle Cai, Jason D. Lee, Weijie J. Su",
          "link": "http://arxiv.org/abs/2305.17608",
          "publishedOn": "2023-05-30T07:13:22.873Z",
          "wordCount": 709,
          "title": "Reward Collapse in Aligning Large Language Models",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.17119",
          "author": null,
          "description": "Shadi Sartipi, Edgar A. Bernal",
          "link": "http://arxiv.org/abs/2305.17119",
          "publishedOn": "2023-05-29T07:14:17.605Z",
          "wordCount": 646,
          "title": "Manifold Regularization for Memory-Efficient Training of Deep Neural\n  Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.17063",
          "author": null,
          "description": "Felix Jimenez, Matthias Katzfuss",
          "link": "http://arxiv.org/abs/2305.17063",
          "publishedOn": "2023-05-29T07:14:17.597Z",
          "wordCount": 599,
          "title": "Vecchia Gaussian Process Ensembles on Internal Representations of Deep\n  Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.17126",
          "author": null,
          "description": "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou",
          "link": "http://arxiv.org/abs/2305.17126",
          "publishedOn": "2023-05-29T07:14:16.379Z",
          "wordCount": 784,
          "title": "Large Language Models as Tool Makers",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.02157",
          "author": null,
          "description": "Blake Bordelon, Cengiz Pehlevan",
          "link": "http://arxiv.org/abs/2210.02157",
          "publishedOn": "2023-05-29T07:14:16.372Z",
          "wordCount": 797,
          "title": "The Influence of Learning Rule on Representation Dynamics in Wide Neural\n  Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.16597",
          "author": null,
          "description": "Neal Lawton, Anoop Kumar, Govind Thattai, Aram Galstyan, Greg Ver\n  Steeg",
          "link": "http://arxiv.org/abs/2305.16597",
          "publishedOn": "2023-05-29T07:14:16.356Z",
          "wordCount": 612,
          "title": "Neural Architecture Search for Parameter-Efficient Fine-tuning of Large\n  Pre-trained Language Models",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2108.13097",
          "author": null,
          "description": "Adam X. Yang, Maxime Robeyns, Edward Milsom, Ben Anson, Nandi Schoots,\n  Laurence Aitchison",
          "link": "http://arxiv.org/abs/2108.13097",
          "publishedOn": "2023-05-26T02:32:49.402Z",
          "wordCount": 786,
          "title": "A theory of representation learning gives a deep generalisation of\n  kernel methods",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.06767",
          "author": null,
          "description": "Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng\n  Zhang, Kashun Shum, Tong Zhang",
          "link": "http://arxiv.org/abs/2304.06767",
          "publishedOn": "2023-05-26T02:32:49.394Z",
          "wordCount": 763,
          "title": "RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15786",
          "author": null,
          "description": "Hilaf Hasson, Danielle C. Maddix, Yuyang Wang, Gaurav Gupta, Youngsuk\n  Park",
          "link": "http://arxiv.org/abs/2305.15786",
          "publishedOn": "2023-05-26T02:32:49.374Z",
          "wordCount": 691,
          "title": "Theoretical Guarantees of Learning Ensembling Strategies with\n  Applications to Time Series Forecasting",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.03067",
          "author": null,
          "description": "Tim Genewein, Gr\\'egoire Del\\'etang, Anian Ruoss, Li Kevin Wenliang,\n  Elliot Catt, Vincent Dutordoir, Jordi Grau-Moya, Laurent Orseau, Marcus\n  Hutter, Joel Veness",
          "link": "http://arxiv.org/abs/2302.03067",
          "publishedOn": "2023-05-26T02:32:49.365Z",
          "wordCount": 632,
          "title": "Memory-Based Meta-Learning on Non-Stationary Distributions",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15598",
          "author": null,
          "description": "Suzanna Parkinson, Greg Ongie, Rebecca Willett",
          "link": "http://arxiv.org/abs/2305.15598",
          "publishedOn": "2023-05-26T02:32:49.357Z",
          "wordCount": 685,
          "title": "Linear Neural Network Layers Promote Learning Single- and Multiple-Index\n  Models",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14961",
          "author": null,
          "description": "Simon Wiegrebe, Philipp Kopper, Raphael Sonabend, Andreas Bender",
          "link": "http://arxiv.org/abs/2305.14961",
          "publishedOn": "2023-05-25T07:13:51.339Z",
          "wordCount": 696,
          "title": "Deep Learning for Survival Analysis: A Review",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14765",
          "author": null,
          "description": "Insung Kong, Dongyoon Yang, Jongjin Lee, Ilsang Ohn, Gyuseung Baek,\n  Yongdai Kim",
          "link": "http://arxiv.org/abs/2305.14765",
          "publishedOn": "2023-05-25T07:13:51.311Z",
          "wordCount": 653,
          "title": "Masked Bayesian Neural Networks : Theoretical Guarantee and its\n  Posterior Inference",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14943",
          "author": null,
          "description": "Louis Sharrock, Lester Mackey, Christopher Nemeth",
          "link": "http://arxiv.org/abs/2305.14943",
          "publishedOn": "2023-05-25T07:13:51.252Z",
          "wordCount": 606,
          "title": "Learning Rate Free Bayesian Inference in Constrained Domains",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15027",
          "author": null,
          "description": "Veit David Wild, Sahra Ghalebikesabi, Dino Sejdinovic, Jeremias\n  Knoblauch",
          "link": "http://arxiv.org/abs/2305.15027",
          "publishedOn": "2023-05-25T07:13:50.477Z",
          "wordCount": 671,
          "title": "A Rigorous Link between Deep Ensembles and (Variational) Bayesian\n  Methods",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15042",
          "author": null,
          "description": "Zaccharie Ramzi, Pierre Ablin, Gabriel Peyr\\'e, Thomas Moreau",
          "link": "http://arxiv.org/abs/2305.15042",
          "publishedOn": "2023-05-25T07:13:50.461Z",
          "wordCount": 665,
          "title": "Test like you Train in Implicit Deep Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14077",
          "author": null,
          "description": "Moritz Haas, David Holzm\\\"uller, Ulrike von Luxburg, Ingo Steinwart",
          "link": "http://arxiv.org/abs/2305.14077",
          "publishedOn": "2023-05-24T07:13:44.399Z",
          "wordCount": 730,
          "title": "Mind the spikes: Benign overfitting of kernels and neural networks in\n  fixed dimension",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14045",
          "author": null,
          "description": "Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye,\n  Jamin Shin, Minjoon Seo",
          "link": "http://arxiv.org/abs/2305.14045",
          "publishedOn": "2023-05-24T07:13:44.392Z",
          "wordCount": 683,
          "title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of\n  Language Models via Chain-of-Thought Fine-Tuning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14196",
          "author": null,
          "description": "Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, Omer\n  Levy",
          "link": "http://arxiv.org/abs/2305.14196",
          "publishedOn": "2023-05-24T07:13:44.382Z",
          "wordCount": 635,
          "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.13588",
          "author": null,
          "description": "Yuka Hashimoto, Masahiro Ikeda, Hachem Kadri",
          "link": "http://arxiv.org/abs/2305.13588",
          "publishedOn": "2023-05-24T07:13:44.376Z",
          "wordCount": 625,
          "title": "Deep Learning with Kernels through RKHM and the Perron-Frobenius\n  Operator",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14122",
          "author": null,
          "description": "Daiki Chijiwa",
          "link": "http://arxiv.org/abs/2305.14122",
          "publishedOn": "2023-05-24T07:13:44.370Z",
          "wordCount": 628,
          "title": "Transferring Learning Trajectories of Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2205.10217",
          "author": null,
          "description": "Simone Bombari, Mohammad Hossein Amani, Marco Mondelli",
          "link": "http://arxiv.org/abs/2205.10217",
          "publishedOn": "2023-05-23T07:13:42.300Z",
          "wordCount": 699,
          "title": "Memorization and Optimization in Deep Neural Networks with Minimum\n  Over-parameterization",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2201.13001",
          "author": null,
          "description": "Jayanta Dey, Haoyin Xu, Ashwin De Silva, Will LeVine, Tyler M. Tomita,\n  Ali Geisa, Tiffany Chu, Jacob Desman, Joshua T. Vogelstein",
          "link": "http://arxiv.org/abs/2201.13001",
          "publishedOn": "2023-05-23T07:13:42.293Z",
          "wordCount": 746,
          "title": "Deep Discriminative to Kernel Generative Networks for Calibrated\n  Inference",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11997",
          "author": null,
          "description": "Faisal Hamman, Erfaun Noorani, Saumitra Mishra, Daniele Magazzeni,\n  Sanghamitra Dutta",
          "link": "http://arxiv.org/abs/2305.11997",
          "publishedOn": "2023-05-23T07:13:42.269Z",
          "wordCount": 737,
          "title": "Robust Counterfactual Explanations for Neural Networks With\n  Probabilistic Guarantees",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11965",
          "author": null,
          "description": "Zi-Hao Qiu, Quanqi Hu, Zhuoning Yuan, Denny Zhou, Lijun Zhang, Tianbao\n  Yang",
          "link": "http://arxiv.org/abs/2305.11965",
          "publishedOn": "2023-05-23T07:13:42.257Z",
          "wordCount": 736,
          "title": "Not All Semantics are Created Equal: Contrastive Self-supervised\n  Learning with Automatic Temperature Individualization",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.05250",
          "author": null,
          "description": "Yaqi Duan, Kaizheng Wang",
          "link": "http://arxiv.org/abs/2202.05250",
          "publishedOn": "2023-05-23T07:13:42.204Z",
          "wordCount": 585,
          "title": "Adaptive and Robust Multi-Task Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11400",
          "author": null,
          "description": "Cat P. Le, Juncheng Dong, Ahmed Aloui, Vahid Tarokh",
          "link": "http://arxiv.org/abs/2305.11400",
          "publishedOn": "2023-05-22T08:19:27.936Z",
          "wordCount": 647,
          "title": "Few-Shot Continual Learning for Conditional Generative Adversarial\n  Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11353",
          "author": null,
          "description": "Tomoharu Iwata, Yoichi Chikahara",
          "link": "http://arxiv.org/abs/2305.11353",
          "publishedOn": "2023-05-22T08:19:27.389Z",
          "wordCount": 639,
          "title": "Meta-learning for heterogeneous treatment effect estimation with\n  closed-form solvers",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11278",
          "author": null,
          "description": "Matthew Dowling, Yuan Zhao, Il Memming Park",
          "link": "http://arxiv.org/abs/2305.11278",
          "publishedOn": "2023-05-22T08:19:27.383Z",
          "wordCount": 650,
          "title": "Real-Time Variational Method for Learning Neural Trajectory and its\n  Dynamics",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.01762",
          "author": null,
          "description": "Mrinank Sharma, Tom Rainforth, Yee Whye Teh, Vincent Fortuin",
          "link": "http://arxiv.org/abs/2304.01762",
          "publishedOn": "2023-05-22T08:19:27.328Z",
          "wordCount": 610,
          "title": "Incorporating Unlabelled Data into Bayesian Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2107.08924",
          "author": null,
          "description": "Ian Osband, Zheng Wen, Seyed Mohammad Asghari, Vikranth Dwaracherla,\n  Morteza Ibrahimi, Xiuyuan Lu, Benjamin Van Roy",
          "link": "http://arxiv.org/abs/2107.08924",
          "publishedOn": "2023-05-19T07:13:19.926Z",
          "wordCount": 706,
          "title": "Epistemic Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.10633",
          "author": null,
          "description": "Alex Damian, Eshaan Nichani, Rong Ge, Jason D. Lee",
          "link": "http://arxiv.org/abs/2305.10633",
          "publishedOn": "2023-05-19T07:13:19.919Z",
          "wordCount": 683,
          "title": "Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample\n  Complexity for Learning Single Index Models",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2002.01368",
          "author": null,
          "description": "Emile R. Engelbrecht, Johan A. du Preez",
          "link": "http://arxiv.org/abs/2002.01368",
          "publishedOn": "2023-05-19T07:13:19.894Z",
          "wordCount": 718,
          "title": "Unified machine learning: Open-set learning with augmented category by\n  exploiting unlabelled data (Open-LACU)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.10438",
          "author": null,
          "description": "David A. Ehrlich, Andreas C. Schneider, Viola Priesemann, Michael\n  Wibral, Abdullah Makkeh",
          "link": "http://arxiv.org/abs/2209.10438",
          "publishedOn": "2023-05-19T07:13:19.888Z",
          "wordCount": 728,
          "title": "A Measure of the Complexity of Neural Representations based on Partial\n  Information Decomposition",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2106.11211",
          "author": null,
          "description": "Maximilian Autenrieth, David A. van Dyk, Roberto Trotta, David C.\n  Stenning",
          "link": "http://arxiv.org/abs/2106.11211",
          "publishedOn": "2023-05-18T07:13:31.695Z",
          "wordCount": 663,
          "title": "Stratified Learning: A General-Purpose Statistical Method for Improved\n  Learning under Covariate Shift",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.09957",
          "author": null,
          "description": "Diego Garc\\'ia-Mart\\'in, Martin Larocca, M. Cerezo",
          "link": "http://arxiv.org/abs/2305.09957",
          "publishedOn": "2023-05-18T07:13:31.666Z",
          "wordCount": 676,
          "title": "Deep quantum neural networks form Gaussian processes",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.10379",
          "author": null,
          "description": "Jorge Medina, Andrew D. White",
          "link": "http://arxiv.org/abs/2305.10379",
          "publishedOn": "2023-05-18T07:13:30.762Z",
          "wordCount": 599,
          "title": "Active Learning in Symbolic Regression Performance with Physical\n  Constraints",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.00564",
          "author": null,
          "description": "Jacob A. Zavatone-Veth, Cengiz Pehlevan",
          "link": "http://arxiv.org/abs/2303.00564",
          "publishedOn": "2023-05-18T07:13:30.755Z",
          "wordCount": 614,
          "title": "Learning curves for deep structured Gaussian feature models",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.07611",
          "author": null,
          "description": "Han Zheng, Zimu Li, Junyu Liu, Sergii Strelchuk, Risi Kondor",
          "link": "http://arxiv.org/abs/2112.07611",
          "publishedOn": "2023-05-17T07:13:38.489Z",
          "wordCount": 775,
          "title": "Speeding up Learning Quantum States through Group Equivariant\n  Convolutional Quantum Ans\\\"atze",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2009.03836",
          "author": null,
          "description": "Mohammed Sharafath Abdul Hameed, Andreas Schwung",
          "link": "http://arxiv.org/abs/2009.03836",
          "publishedOn": "2023-05-17T07:13:38.479Z",
          "wordCount": 841,
          "title": "Graph neural networks-based Scheduler for Production planning problems\n  using Reinforcement Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.03544",
          "author": null,
          "description": "Itai Shapira",
          "link": "http://arxiv.org/abs/2303.03544",
          "publishedOn": "2023-05-17T07:13:38.456Z",
          "wordCount": 645,
          "title": "Expressivity of Shallow and Deep Neural Networks for Polynomial\n  Approximation",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.09557",
          "author": null,
          "description": "Lin Chen, Thomas Fu, Amin Karbasi, Vahab Mirrokni",
          "link": "http://arxiv.org/abs/2305.09557",
          "publishedOn": "2023-05-17T07:13:37.498Z",
          "wordCount": 774,
          "title": "Learning from Aggregated Data: Curated Bags versus Random Bags",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.07733",
          "author": null,
          "description": "Aaron Defazio, Konstantin Mishchenko",
          "link": "http://arxiv.org/abs/2301.07733",
          "publishedOn": "2023-05-17T07:13:37.479Z",
          "wordCount": 613,
          "title": "Learning-Rate-Free Learning by D-Adaptation",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.09574",
          "author": null,
          "description": "Idan Achituve, Gal Chechik, Ethan Fetaya",
          "link": "http://arxiv.org/abs/2302.09574",
          "publishedOn": "2023-05-16T07:14:20.124Z",
          "wordCount": 652,
          "title": "Guided Deep Kernel Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.03068",
          "author": null,
          "description": "Yann Dubois, Tatsunori Hashimoto, Percy Liang",
          "link": "http://arxiv.org/abs/2302.03068",
          "publishedOn": "2023-05-16T07:14:20.117Z",
          "wordCount": 673,
          "title": "Evaluating Self-Supervised Learning via Risk Decomposition",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00608",
          "author": null,
          "description": "Guohao Shen, Yuling Jiao, Yuanyuan Lin, Jian Huang",
          "link": "http://arxiv.org/abs/2305.00608",
          "publishedOn": "2023-05-16T07:14:20.110Z",
          "wordCount": 737,
          "title": "Differentiable Neural Networks with RePU Activation: with Applications\n  to Score Estimation and Isotonic Regression",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.08642",
          "author": null,
          "description": "Adam Spannaus, Heidi A.Hanson, Lynne Penberthy, Georgia Tourassi",
          "link": "http://arxiv.org/abs/2305.08642",
          "publishedOn": "2023-05-16T07:14:20.072Z",
          "wordCount": 710,
          "title": "Topological Interpretability for Deep-Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.07617",
          "author": null,
          "description": "Marianne Defresne, Sophie Barbe, Thomas Schiex",
          "link": "http://arxiv.org/abs/2305.07617",
          "publishedOn": "2023-05-15T07:15:23.838Z",
          "wordCount": 621,
          "title": "Scalable Coupling of Deep Learning with Logical Reasoning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2105.09095",
          "author": null,
          "description": "J\\\"org Martin, Clemens Elster",
          "link": "http://arxiv.org/abs/2105.09095",
          "publishedOn": "2023-05-15T07:15:21.022Z",
          "wordCount": 688,
          "title": "Aleatoric uncertainty for Errors-in-Variables models in deep regression",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2006.03476",
          "author": null,
          "description": "Matja\\v{z} Kukar, Gregor Gun\\v{c}ar, Toma\\v{z} Vovko, Simon Podnar,\n  Peter \\v{C}ernel\\v{c}, Miran Brvar, Mateja Zalaznik, Mateja Notar, Sa\\v{s}o\n  Mo\\v{s}kon, Marko Notar",
          "link": "http://arxiv.org/abs/2006.03476",
          "publishedOn": "2023-05-15T07:15:20.992Z",
          "wordCount": 781,
          "title": "COVID-19 diagnosis by routine blood tests using machine learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06884",
          "author": null,
          "description": "Shubhanshu Shekhar, Ziyu Xu, Zachary C. Lipton, Pierre J. Liang,\n  Aaditya Ramdas",
          "link": "http://arxiv.org/abs/2305.06884",
          "publishedOn": "2023-05-12T07:13:34.006Z",
          "wordCount": 733,
          "title": "Risk-limiting Financial Audits via Weighted Sampling without Replacement",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2108.12515",
          "author": null,
          "description": "Maarten V. de Hoop, Nikola B. Kovachki, Nicholas H. Nelsen, Andrew M.\n  Stuart",
          "link": "http://arxiv.org/abs/2108.12515",
          "publishedOn": "2023-05-12T07:13:33.665Z",
          "wordCount": 721,
          "title": "Convergence Rates for Learning Linear Operators from Noisy Data",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06703",
          "author": null,
          "description": "Vincent Jeanselme, Chang Ho Yoon, Brian Tom, Jessica Barrett",
          "link": "http://arxiv.org/abs/2305.06703",
          "publishedOn": "2023-05-12T07:13:33.622Z",
          "wordCount": 636,
          "title": "Neural Fine-Gray: Monotonic neural networks for competing risks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06648",
          "author": null,
          "description": "Pierre Marion",
          "link": "http://arxiv.org/abs/2305.06648",
          "publishedOn": "2023-05-12T07:13:33.615Z",
          "wordCount": 581,
          "title": "Generalization bounds for neural ordinary differential equations and\n  deep residual networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06986",
          "author": null,
          "description": "Eshaan Nichani, Alex Damian, Jason D. Lee",
          "link": "http://arxiv.org/abs/2305.06986",
          "publishedOn": "2023-05-12T07:13:33.598Z",
          "wordCount": 733,
          "title": "Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural\n  Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.13881",
          "author": null,
          "description": "Adityanarayanan Radhakrishnan, Daniel Beaglehole, Parthe Pandit,\n  Mikhail Belkin",
          "link": "http://arxiv.org/abs/2212.13881",
          "publishedOn": "2023-05-11T07:13:57.402Z",
          "wordCount": 750,
          "title": "Mechanism of feature learning in deep fully connected networks and\n  kernel machines that recursively learn features",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06230",
          "author": null,
          "description": "William Kengne, Modou Wade",
          "link": "http://arxiv.org/abs/2305.06230",
          "publishedOn": "2023-05-11T07:13:57.396Z",
          "wordCount": 635,
          "title": "Penalized deep neural networks estimator with general loss functions\n  under weak dependence",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2204.05044",
          "author": null,
          "description": "Maximilian Springenberg, Annika Frommholz, Markus Wenzel, Eva Weicken,\n  Jackie Ma, Nils Strodthoff",
          "link": "http://arxiv.org/abs/2204.05044",
          "publishedOn": "2023-05-11T07:13:56.982Z",
          "wordCount": 737,
          "title": "From Modern CNNs to Vision Transformers: Assessing the Performance,\n  Robustness, and Classification Strategies of Deep Learning Models in\n  Histopathology",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06082",
          "author": null,
          "description": "Kota Srinivas Reddy, P. N. Karthik, Nikhil Karamchandani and\n  Jayakrishnan Nair",
          "link": "http://arxiv.org/abs/2305.06082",
          "publishedOn": "2023-05-11T07:13:56.946Z",
          "wordCount": 704,
          "title": "Best Arm Identification in Bandits with Limited Precision Sampling",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.07260",
          "author": null,
          "description": "Mohamed Aziz Bhouri, Michael Joly, Robert Yu, Soumalya Sarkar\n , Paris Perdikaris",
          "link": "http://arxiv.org/abs/2302.07260",
          "publishedOn": "2023-05-10T07:13:51.801Z",
          "wordCount": 772,
          "title": "Scalable Bayesian optimization with high-dimensional outputs using\n  randomized prior networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.08146",
          "author": null,
          "description": "Md. Mohi Uddin Khan, Abdullah Bin Shams, Md. Mohsin Sarker Raihan",
          "link": "http://arxiv.org/abs/2202.08146",
          "publishedOn": "2023-05-10T07:13:51.796Z",
          "wordCount": 872,
          "title": "A Prospective Approach for Human-to-Human Interaction Recognition from\n  Wi-Fi Channel Data using Attention Bidirectional Gated Recurrent Neural\n  Network with GUI Application Implementation",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.05642",
          "author": null,
          "description": "Hongrui Chen, Jihao Long, Lei Wu",
          "link": "http://arxiv.org/abs/2305.05642",
          "publishedOn": "2023-05-10T07:13:51.688Z",
          "wordCount": 742,
          "title": "A duality framework for generalization analysis of random feature models\n  and two-layer neural networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.01666",
          "author": null,
          "description": "Guojun Zhang, Saber Malekmohammadi, Xi Chen, Yaoliang Yu",
          "link": "http://arxiv.org/abs/2202.01666",
          "publishedOn": "2023-05-10T07:13:51.665Z",
          "wordCount": 689,
          "title": "Proportional Fairness in Federated Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2108.05660",
          "author": null,
          "description": "Md. Mohsin Sarker Raihan, Md. Mohi Uddin Khan, Laboni Akter and\n  Abdullah Bin Shams",
          "link": "http://arxiv.org/abs/2108.05660",
          "publishedOn": "2023-05-10T07:13:51.474Z",
          "wordCount": 874,
          "title": "Development of a Risk-Free COVID-19 Screening Algorithm from Routine\n  Blood Tests Using Ensemble Machine Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.12578",
          "author": null,
          "description": "Bhargav Ganguly, Vaneet Aggarwal",
          "link": "http://arxiv.org/abs/2211.12578",
          "publishedOn": "2023-05-09T07:13:44.771Z",
          "wordCount": 709,
          "title": "Online Federated Learning via Non-Stationary Detection and Adaptation\n  amidst Concept Drift",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.01848",
          "author": null,
          "description": "Noah Hollmann, Samuel M\\\"uller, Katharina Eggensperger, Frank Hutter",
          "link": "http://arxiv.org/abs/2207.01848",
          "publishedOn": "2023-05-09T07:13:44.764Z",
          "wordCount": 760,
          "title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems\n  in a Second",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.03874",
          "author": null,
          "description": "Yuan Chen, Dongbin Xiu",
          "link": "http://arxiv.org/abs/2305.03874",
          "publishedOn": "2023-05-09T07:13:44.742Z",
          "wordCount": 671,
          "title": "Learning Stochastic Dynamical System via Flow Map Operator",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.11222",
          "author": null,
          "description": "Mikhail Khodak, Kareem Amin, Travis Dick, Sergei Vassilvitskii",
          "link": "http://arxiv.org/abs/2210.11222",
          "publishedOn": "2023-05-09T07:13:44.735Z",
          "wordCount": 684,
          "title": "Learning-Augmented Private Algorithms for Multiple Quantile Release",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.04341",
          "author": null,
          "description": "Sweta Rai, Alexis Hoffman, Soumendra Lahiri, Douglas W. Nychka,\n  Stephan R. Sain, Soutir Bandyopadhyay",
          "link": "http://arxiv.org/abs/2305.04341",
          "publishedOn": "2023-05-09T07:13:44.719Z",
          "wordCount": 674,
          "title": "Fast parameter estimation of Generalized Extreme Value distribution\n  using Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2008.11416",
          "author": null,
          "description": "Xu Chen, Yuangang Pan, Ivor Tsang, Ya Zhang",
          "link": "http://arxiv.org/abs/2008.11416",
          "publishedOn": "2023-05-08T07:14:23.586Z",
          "wordCount": 729,
          "title": "Learning Node Representations against Perturbations",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.03531",
          "author": null,
          "description": "Liang Ding, Tianyang Hu, Jiahang Jiang, Donghao Li, Wenjia Wang, Yuan\n  Yao",
          "link": "http://arxiv.org/abs/2305.03531",
          "publishedOn": "2023-05-08T07:14:23.581Z",
          "wordCount": 726,
          "title": "Random Smoothing Regularization in Kernel Gradient Descent Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2110.13330",
          "author": null,
          "description": "Chandrajit Bajaj, Luke McLennan, Timothy Andeen, Avik Roy",
          "link": "http://arxiv.org/abs/2110.13330",
          "publishedOn": "2023-05-08T07:14:23.576Z",
          "wordCount": 749,
          "title": "Recipes for when Physics Fails: Recovering Robust Learning of Physics\n  Informed Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.03395",
          "author": null,
          "description": "Lars Skaaret-Lund, Geir Storvik, Aliaksandr Hubin",
          "link": "http://arxiv.org/abs/2305.03395",
          "publishedOn": "2023-05-08T07:14:23.361Z",
          "wordCount": 780,
          "title": "Sparsifying Bayesian neural networks with latent binary variables and\n  normalizing flows",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/hep-ph/9503364",
          "author": null,
          "description": "Masato Jimbo, Tadashi Kon, Minami-Tateya collaboration",
          "link": "http://arxiv.org/abs/hep-ph/9503364",
          "publishedOn": "2023-05-07T07:13:04.429Z",
          "wordCount": 550,
          "title": "The automatic computation for SUSY processes",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.02657",
          "author": null,
          "description": "Yicheng Li, Zixiong Yu, Guhan Chen, Qian Lin",
          "link": "http://arxiv.org/abs/2305.02657",
          "publishedOn": "2023-05-05T07:13:30.015Z",
          "wordCount": 621,
          "title": "Statistical Optimality of Deep Wide Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2104.09371",
          "author": null,
          "description": "Aniruddha Rajendra Rao, Matthew Reimherr",
          "link": "http://arxiv.org/abs/2104.09371",
          "publishedOn": "2023-05-05T07:13:30.009Z",
          "wordCount": 666,
          "title": "Non-linear Functional Modeling using Neural Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1909.12098",
          "author": null,
          "description": "Seyedsaman Emami, Gonzalo Mart\\'inez-Mu\\~noz",
          "link": "http://arxiv.org/abs/1909.12098",
          "publishedOn": "2023-05-05T07:13:30.002Z",
          "wordCount": 799,
          "title": "Sequential Training of Neural Networks with Gradient Boosting",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.02573",
          "author": null,
          "description": "Ziheng Cheng, Junzi Zhang, Akshay Agrawal, Stephen Boyd",
          "link": "http://arxiv.org/abs/2305.02573",
          "publishedOn": "2023-05-05T07:13:29.977Z",
          "wordCount": 736,
          "title": "Joint Graph Learning and Model Fitting in Laplacian Regularized\n  Stratified Models",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.02499",
          "author": null,
          "description": "Shujian Zhang, Chengyue Gong, Lemeng Wu, Xingchao Liu, Mingyuan Zhou",
          "link": "http://arxiv.org/abs/2305.02499",
          "publishedOn": "2023-05-05T07:13:29.971Z",
          "wordCount": 688,
          "title": "AutoML-GPT: Automatic Machine Learning with GPT",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.08893",
          "author": null,
          "description": "Davide Cacciarelli, Murat Kulahci",
          "link": "http://arxiv.org/abs/2302.08893",
          "publishedOn": "2023-05-04T07:14:32.958Z",
          "wordCount": 741,
          "title": "A survey on online active learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.01807",
          "author": null,
          "description": "Saurabh Sihag, Gonzalo Mateos, Corey T. McMillan, Alejandro Ribeiro",
          "link": "http://arxiv.org/abs/2305.01807",
          "publishedOn": "2023-05-04T07:14:32.172Z",
          "wordCount": 791,
          "title": "Transferablility of coVariance Neural Networks and Application to\n  Interpretable Brain Age Prediction using Anatomical Features",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.01773",
          "author": null,
          "description": "Andreas Look, Melih Kandemir, Barbara Rakitsch, Jan Peters",
          "link": "http://arxiv.org/abs/2305.01773",
          "publishedOn": "2023-05-04T07:14:31.666Z",
          "wordCount": 753,
          "title": "Cheap and Deterministic Inference for Deep State-Space Models of\n  Interacting Dynamical Systems",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.02865",
          "author": null,
          "description": "Michael Kirchhof, Enkelejda Kasneci, Seong Joon Oh",
          "link": "http://arxiv.org/abs/2302.02865",
          "publishedOn": "2023-05-04T07:14:31.419Z",
          "wordCount": 688,
          "title": "Probabilistic Contrastive Learning Recovers the Correct Aleatoric\n  Uncertainty of Ambiguous Inputs",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.02009",
          "author": null,
          "description": "Marco Scutari",
          "link": "http://arxiv.org/abs/2305.02009",
          "publishedOn": "2023-05-04T07:14:31.413Z",
          "wordCount": 697,
          "title": "fairml: A Statistician's Take on Fair Machine Learning Modelling",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.01143",
          "author": null,
          "description": "Yuxin Dong, Tieliang Gong, Hong Chen, Chen Li",
          "link": "http://arxiv.org/abs/2305.01143",
          "publishedOn": "2023-05-03T07:15:02.721Z",
          "wordCount": 697,
          "title": "Understanding the Generalization Ability of Deep Learning Algorithms: A\n  Kernelized Renyi's Entropy Perspective",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2107.08649",
          "author": null,
          "description": "Dong-Young Lim, Ariel Neufeld, Sotirios Sabanis, Ying Zhang",
          "link": "http://arxiv.org/abs/2107.08649",
          "publishedOn": "2023-05-03T07:15:02.715Z",
          "wordCount": 776,
          "title": "Non-asymptotic estimates for TUSLA algorithm for non-convex learning\n  with applications to neural networks with ReLU activation function",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.08201",
          "author": null,
          "description": "Michail Spitieris, Ingelin Steinsland",
          "link": "http://arxiv.org/abs/2206.08201",
          "publishedOn": "2023-05-03T07:15:01.356Z",
          "wordCount": 724,
          "title": "Learning Physics between Digital Twins with Low-Fidelity Models and\n  Physics-Informed Gaussian Processes",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.15764",
          "author": null,
          "description": "Noam Levi, Itay M. Bloch, Marat Freytsis, Tomer Volansky",
          "link": "http://arxiv.org/abs/2210.15764",
          "publishedOn": "2023-05-03T07:15:01.340Z",
          "wordCount": 682,
          "title": "Noise Injection Node Regularization for Robust Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.13599",
          "author": null,
          "description": "Noam Levi, Itay Bloch, Marat Freytsis, Tomer Volansky",
          "link": "http://arxiv.org/abs/2210.13599",
          "publishedOn": "2023-05-03T07:15:01.333Z",
          "wordCount": 640,
          "title": "Noise Injection as a Probe of Deep Learning Dynamics",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00054",
          "author": null,
          "description": "Hoang Anh Just, Feiyang Kang, Jiachen T. Wang, Yi Zeng, Myeongseob Ko,\n  Ming Jin, Ruoxi Jia",
          "link": "http://arxiv.org/abs/2305.00054",
          "publishedOn": "2023-05-02T07:13:48.931Z",
          "wordCount": 795,
          "title": "LAVA: Data Valuation without Pre-Specified Learning Algorithms",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00350",
          "author": null,
          "description": "Korawat Tanwisuth, Shujian Zhang, Huangjie Zheng, Pengcheng He,\n  Mingyuan Zhou",
          "link": "http://arxiv.org/abs/2305.00350",
          "publishedOn": "2023-05-02T07:13:48.900Z",
          "wordCount": 642,
          "title": "POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained\n  models",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.09894",
          "author": null,
          "description": "Kerem Ozfatura, Emre Ozfatura, Alptekin Kupcu, Deniz Gunduz",
          "link": "http://arxiv.org/abs/2208.09894",
          "publishedOn": "2023-05-02T07:13:48.895Z",
          "wordCount": 767,
          "title": "Byzantines can also Learn from History: Fall of Centered Clipping in\n  Federated Learning",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00934",
          "author": null,
          "description": "Aliaksandr Hubin, Geir Storvik",
          "link": "http://arxiv.org/abs/2305.00934",
          "publishedOn": "2023-05-02T07:13:48.877Z",
          "wordCount": 677,
          "title": "Variational Inference for Bayesian Neural Networks under Model and\n  Parameter Uncertainty",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14774",
          "author": null,
          "description": "Carlos Sebasti\\'an, Carlos E. Gonz\\'alez-Guill\\'en",
          "link": "http://arxiv.org/abs/2304.14774",
          "publishedOn": "2023-05-01T07:14:17.709Z",
          "wordCount": 715,
          "title": "A feature selection method based on Shapley values robust to concept\n  shift in regression",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.15261",
          "author": null,
          "description": "Yubei Chen, Zeyu Yun, Yi Ma, Bruno Olshausen, Yann LeCun",
          "link": "http://arxiv.org/abs/2209.15261",
          "publishedOn": "2023-05-01T07:14:17.666Z",
          "wordCount": 707,
          "title": "Minimalistic Unsupervised Learning with the Sparse Manifold Transform",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1903.02140",
          "author": null,
          "description": "Hui Jiang",
          "link": "http://arxiv.org/abs/1903.02140",
          "publishedOn": "2023-05-01T07:14:17.661Z",
          "wordCount": 692,
          "title": "Why Learning of Large-Scale Neural Networks Behaves Like Convex\n  Optimization",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14994",
          "author": null,
          "description": "Marc Finzi, Andres Potapczynski, Matthew Choptuik, Andrew Gordon\n  Wilson",
          "link": "http://arxiv.org/abs/2304.14994",
          "publishedOn": "2023-05-01T07:14:17.647Z",
          "wordCount": 732,
          "title": "A Stable and Scalable Method for Solving Initial Value PDEs with Neural\n  Networks",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.17312",
          "author": null,
          "description": "Junghwan Lee, Tingnan Gong, Xiuyuan Cheng, Yao Xie",
          "link": "http://arxiv.org/abs/2210.17312",
          "publishedOn": "2023-05-01T07:14:17.642Z",
          "wordCount": 609,
          "title": "Training Neural Networks for Sequential Change-point Detection",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "Off the convex path",
      "feedUrl": "http://www.offconvex.org/feed.xml",
      "siteUrl": "http://offconvex.github.io/",
      "articles": []
    },
    {
      "title": "Free Mind",
      "feedUrl": "https://freemind.pluskid.org/rss.xml",
      "siteUrl": "http://freemind.pluskid.org",
      "articles": []
    },
    {
      "title": "Combinatorics and more",
      "feedUrl": "https://gilkalai.wordpress.com/feed/",
      "siteUrl": "https://gilkalai.wordpress.com",
      "articles": [
        {
          "id": "http://gilkalai.wordpress.com/?p=23932",
          "author": "Gil Kalai",
          "description": "(Click to enlarge.) Plan for this post: Prologue: “Can we sleep soundly at night?” Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel … Continue reading →",
          "link": "https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/",
          "publishedOn": "2023-05-30T05:38:33.000Z",
          "wordCount": 4660,
          "title": "Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.",
          "imageUrl": "https://gilkalai.files.wordpress.com/2023/05/cern22.jpg"
        },
        {
          "id": "http://gilkalai.wordpress.com/?p=24359",
          "author": "Gil Kalai",
          "description": "Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice’s task is to choose, at a certain time of her choice, some number (smaller than the number of unseen … Continue reading →",
          "link": "https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/",
          "publishedOn": "2023-05-25T08:33:58.000Z",
          "wordCount": 3098,
          "title": "Test your intuition 52: Can you predict the ratios of ones?",
          "imageUrl": "https://s0.wp.com/i/blank.jpg"
        },
        {
          "id": "http://gilkalai.wordpress.com/?p=24235",
          "author": "Gil Kalai",
          "description": "LLM is the acronym for “large language model” like GPT-3, ChatGPT, GPT-4 etc. Amnon Shashua gave an enlightening clear lecture about the repeated recent breakthroughs for LLM’s and where we stand. Here is the You-Tube link for the lecture (in … Continue reading →",
          "link": "https://gilkalai.wordpress.com/2023/05/11/amnon-shashuas-lecture-at-reichman-university-a-deep-dive-into-llms-and-their-future-impact/",
          "publishedOn": "2023-05-11T05:31:20.000Z",
          "wordCount": 3251,
          "title": "Amnon Shashua’s lecture at Reichman University: A Deep Dive into LLMs and their Future Impact.",
          "imageUrl": "https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg"
        },
        {
          "id": "http://gilkalai.wordpress.com/?p=24215",
          "author": "Gil Kalai",
          "description": "Plan for next weeks blogging There are various things to blog about and let me give a quick preview for the plan for the next few posts. The purpose of this post is to give an impression about the hectic … Continue reading →",
          "link": "https://gilkalai.wordpress.com/2023/05/08/mathematics-mainly-combinatorics-related-matters-a-lot-of-activity/",
          "publishedOn": "2023-05-08T06:50:10.000Z",
          "wordCount": 4517,
          "title": "Mathematics (mainly combinatorics) related matters: A lot of activity.",
          "imageUrl": "https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg"
        }
      ]
    },
    {
      "title": "Parsiad Azimzadeh",
      "feedUrl": "http://parsiad.ca/feed.xml",
      "siteUrl": "https://parsiad.ca/",
      "articles": [
        {
          "id": "https://parsiad.ca/blog/2023/the_geometric_mean_rate_of_return/",
          "author": null,
          "description": "Consider a horizon of disjoint periods labelled $1$ through $N$. On the entire horizon, an asset with a rate of return $r_n$ on the $n$-th period has a geometric mean rate of return of \\begin{equation} \\overline{r} = \\left( \\prod_{n = 1}^N \\left(1 + r_n\\right) \\right)^{1 / N} - 1. \\end{equation} Note in particular that \\begin{equation} \\left(1 + \\overline{r}\\right)^N = \\prod_{n = 1}^N \\left(1 + r_n\\right). \\end{equation} In other words, a hypothetical asset whose rate of return is equal to $\\overline{r}$ on all $N$ periods yields the same return (over the horizon) as the original asset.",
          "link": "https://parsiad.ca/blog/2023/the_geometric_mean_rate_of_return/",
          "publishedOn": "2023-05-02T20:00:00.000Z",
          "wordCount": 241,
          "title": "The geometric mean rate of return",
          "imageUrl": null
        },
        {
          "id": "https://parsiad.ca/blog/2023/uncorrelated_coordinates_in_pca/",
          "author": null,
          "description": "Let $X$ be an $N\\times p$ real matrix. Let $D$ be a real diagonal matrix, $w$ be a vector of nonnegative weights that sum to one, and \\begin{equation} Y=\\left(X-\\frac{1}{N}ee^{\\intercal}X\\right)D^{-1}. \\end{equation} $Y$ is a demeaned and rescaled version of $X$.",
          "link": "https://parsiad.ca/blog/2023/uncorrelated_coordinates_in_pca/",
          "publishedOn": "2023-05-02T20:00:00.000Z",
          "wordCount": 306,
          "title": "Uncorrelated coordinates in PCA",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Windows On Theory",
      "feedUrl": "https://windowsontheory.org/feed/",
      "siteUrl": "https://windowsontheory.org",
      "articles": [
        {
          "id": "http://windowsontheory.org/?p=8615",
          "author": "Boaz Barak",
          "description": "[See my post with Edelman on AI takeover and Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.]  One challenge for considering the implications of “artificial intelligence,” especially of the “general” variety, is that we don’t have a consensus definition of intelligence. The Oxford Companion … Continue reading GPT as an “Intelligence Forklift.”",
          "link": "https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/",
          "publishedOn": "2023-05-19T21:16:17.000Z",
          "wordCount": 3773,
          "title": "GPT as an “Intelligence Forklift.”",
          "imageUrl": "https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/cfee2d12a17cf70d8bfdc038070a679c423c7061ed67439f.png"
        }
      ]
    },
    {
      "title": "UCSD Machine Learning Group",
      "feedUrl": "https://ucsdml.github.io//feed.xml",
      "siteUrl": "https://ucsdml.github.io//",
      "articles": []
    },
    {
      "title": "科学空间|Scientific Spaces",
      "feedUrl": "https://kexue.fm/feed/",
      "siteUrl": "https://kexue.fm/",
      "articles": [
        {
          "id": "https://kexue.fm/archives/9617",
          "author": "苏剑林",
          "description": "在LLM时代还玩朴素贝叶斯（Naive Bayes）？这可能是许多读者在看到标题后的首个想法。确实如此，当古老的朴素贝叶斯与前沿的LLM相遇时，产生了令人惊讶的效果——我们可以直接提升现有LLM...",
          "link": "https://kexue.fm/archives/9617",
          "publishedOn": "2023-05-23T02:45:00.000Z",
          "wordCount": 1593,
          "title": "NBCE：使用朴素贝叶斯拓展LLM的Context处理长度",
          "imageUrl": null
        },
        {
          "id": "https://kexue.fm/archives/9607",
          "author": "苏剑林",
          "description": "尺度定律（Scaling Law），指的是模型能力与模型尺度之间的渐近关系。具体来说，模型能力我们可以简单理解为模型的损失函数，模型尺度可以指模型参数量、训练数据量、训练步数等，所谓尺度定律，就...",
          "link": "https://kexue.fm/archives/9607",
          "publishedOn": "2023-05-18T12:55:00.000Z",
          "wordCount": 1491,
          "title": "基于量子化假设推导模型的尺度定律（Scaling Law）",
          "imageUrl": null
        },
        {
          "id": "https://kexue.fm/archives/9603",
          "author": "苏剑林",
          "description": "说到Transformer无法处理超长序列的原因，大家的第一反应通常都是Self Attention的二次复杂度。但事实上，即便忽略算力限制，常规的Transformer也无法处理超长序列，因为...",
          "link": "https://kexue.fm/archives/9603",
          "publishedOn": "2023-05-12T09:11:00.000Z",
          "wordCount": 1503,
          "title": "Transformer升级之路：9、一种全局长度外推的新思路",
          "imageUrl": null
        },
        {
          "id": "https://kexue.fm/archives/9595",
          "author": "苏剑林",
          "description": "在机器学习中，我们经常会谈到稀疏性，比如我们经常说注意力矩阵通常是很稀疏的。然而，不知道大家发现没有，我们似乎从没有给出过度量稀疏程度的标准方法。也就是说，以往我们关于稀疏性的讨论，仅仅是直观层...",
          "link": "https://kexue.fm/archives/9595",
          "publishedOn": "2023-05-05T03:19:00.000Z",
          "wordCount": 1635,
          "title": "如何度量数据的稀疏程度？",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Decent Descent",
      "feedUrl": "https://decentdescent.org/feed.xml",
      "siteUrl": "https://decentdescent.org/",
      "articles": []
    },
    {
      "title": "Harvard ML Foundations",
      "feedUrl": "https://mlfoundations.org/index.xml",
      "siteUrl": "https://mlfoundations.org/",
      "articles": [
        {
          "id": "https://mlfoundations.org/talk/lecun/",
          "author": null,
          "description": "How could machines learn as efficiently as humans and animals? How could machines learn how the world works and acquire common sense? How could machines learn to reason and plan? Current AI architectures, such as Auto-Regressive Large Language Models fall short.  I will propose a modular cognitive architecture that may constitute a path towards answering these questions.  The centerpiece of the architecture is a predictive world model that allows the system to predict the consequences of its actions and to plan a sequence of actions that optimize a set of objectives. The world model employs a Hierarchical Joint Embedding Predictive Architecture (H-JEPA) trained with self-supervised learning. The JEPA learns abstract representations of the percepts that are simultaneously maximally informative and maximally predictable. The corresponding working paper is available here - [A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id=BZ5a1r-kVsf)",
          "link": "https://mlfoundations.org/talk/lecun/",
          "publishedOn": "2023-05-23T14:00:00.000Z",
          "wordCount": 204,
          "title": "Yann LeCun - Towards Machines that can Learn, Reason, and Plan.",
          "imageUrl": "https://mlfoundations.org/img/icon-192.png"
        },
        {
          "id": "https://mlfoundations.org/talk/lilicrap/",
          "author": null,
          "description": "Large language models are capable of an incredible array of tasks. Language models are pre-trained on large amounts of text data from the internet. Then they are fine-tuned on instruction following and further improved by optimizing human preferences. The resulting models are imperfect but are nevertheless able to hold conversations, solve problems, and use tools. How quickly will these models continue to improve? There are a variety of opinions. The answer to this question is also important because language models are poised to make significant changes to the way we live and work. Some researchers think we’ve hit a plateau in performance and that progress will stall without a breakthrough. Others predict the arrival of general intelligence within a couple of years.Putting aside the question of AGI, I will argue that rapid progress in model capabilities will continue without the need for a breakthrough. I will draw connections between language model research and the past decade of work in deep reinforcement learning, especially the Go & Starcraft projects.\nThese projects followed a similar methodology - models were pre-trained using data collected from game databases. Then they were improved iteratively with reinforcement learning. Viewed from the vantage point of model-based reinforcement learning, optimization of language models is in its infancy. Put simply, there are clear experiments which are likely to create much better models. Why haven’t these experiments been run already? Since performant language models are large and reward is derived from human preferences, experiments require extensive coordination of people and compute. Given economic incentives, we can expect researchers to overcome these hurdles. There is therefore good reason to believe that language model capabilities will continue to improve rapidly. This motivates increased investment in AI safety research, policy, and governance.",
          "link": "https://mlfoundations.org/talk/lilicrap/",
          "publishedOn": "2023-05-19T14:00:00.000Z",
          "wordCount": 359,
          "title": "Timothy Lillicrap - Model-based reinforcement learning and the future of language models",
          "imageUrl": "https://mlfoundations.org/img/icon-192.png"
        },
        {
          "id": "https://mlfoundations.org/talk/choi/",
          "author": null,
          "description": "Scale appears to be the winning recipe in today's leaderboards. And yet, extreme-scale neural models are (un)surprisingly brittle and make errors that are often nonsensical and even counterintuitive. In this talk, I will argue for the importance of knowledge, especially commonsense knowledge, as well as inference-time reasoning algorithms, and demonstrate how smaller models developed in academia can still have an edge over larger industry-scale models, if powered with knowledge and/or reasoning algorithms.",
          "link": "https://mlfoundations.org/talk/choi/",
          "publishedOn": "2023-05-12T14:15:00.000Z",
          "wordCount": 142,
          "title": "Yejin Choi - Common Sense: the Dark Matter of Language and Intelligence",
          "imageUrl": "https://mlfoundations.org/img/icon-192.png"
        }
      ]
    },
    {
      "title": "Statistics » Event Diary",
      "feedUrl": "https://warwick.ac.uk/sitebuilder2/api/rss/news.rss?page=/fac/sci/statistics/event_diary/&tag=CRiSM%20seminars&rss=true&view=upcoming",
      "siteUrl": "https://warwick.ac.uk/fac/sci/statistics/event_diary/",
      "articles": [
        {
          "id": "8a17841b87bcdaa00187eaa431674bef",
          "author": "Statistics",
          "description": "When:\r\n\t\r\n  \t\t11:00\r\n\t\t-\r\n\t\t12:00, Wed, 10 May '23\r\n\r\n\t\nWhere: MB0.07",
          "link": "https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9",
          "publishedOn": "2023-05-05T06:40:41.000Z",
          "wordCount": 355,
          "title": "10/05 11am-12pm: CRiSM Seminar",
          "imageUrl": null
        },
        {
          "id": "8a17841b87bcdaa00187eaa431674bf0",
          "author": "Statistics",
          "description": "When:\r\n\t\r\n  \t\t11:00\r\n\t\t-\r\n\t\t12:00, Wed, 24 May '23\r\n\r\n\t\nWhere: MB0.07",
          "link": "https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9",
          "publishedOn": "2023-05-05T06:40:41.000Z",
          "wordCount": 355,
          "title": "24/05 11am-12pm: CRiSM Seminar",
          "imageUrl": null
        },
        {
          "id": "8a17841b87bcdaa00187eaa431674bf1",
          "author": "Statistics",
          "description": "When:\r\n\t\r\n  \t\t11:00\r\n\t\t-\r\n\t\t12:00, Wed, 07 Jun '23\r\n\r\n\t\nWhere: MB0.07",
          "link": "https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9",
          "publishedOn": "2023-05-05T06:40:41.000Z",
          "wordCount": 355,
          "title": "07/06 11am-12pm: CRiSM Seminar",
          "imageUrl": null
        },
        {
          "id": "8a17841b87bcdaa00187eaa431674bf2",
          "author": "Statistics",
          "description": "When:\r\n\t\r\n  \t\t11:00\r\n\t\t-\r\n\t\t12:00, Wed, 21 Jun '23\r\n\r\n\t\nWhere: MB0.07",
          "link": "https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem=8a17841b835b10a4018360b5677a44f9",
          "publishedOn": "2023-05-05T06:40:41.000Z",
          "wordCount": 355,
          "title": "21/06 11am-12pm: CRiSM Seminar",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "arg min blog",
      "feedUrl": "https://www.argmin.net/feed.xml",
      "siteUrl": "http://benjamin-recht.github.io/",
      "articles": []
    },
    {
      "title": "Python⇒Speed",
      "feedUrl": "https://pythonspeed.com/atom.xml",
      "siteUrl": "https://pythonspeed.com/atom.xml",
      "articles": [
        {
          "id": "https://pythonspeed.com/articles/best-file-format-for-pandas/",
          "author": null,
          "description": "Before you can process your data with Pandas, you need to load it (from disk or remote storage).\nThere are plenty of data formats supported by Pandas, from CSV, to JSON, to Parquet, and many others as well.\nWhich should you use?\nYou don’t want loading the data to be slow, or use lots of memory: that’s pure overhead.\nIdeally you’d want a file format that’s fast, efficient, small, and broadly supported.\nYou also want to make sure the loaded data has all the right types: numeric types, datetimes, and so on.\nSome data formats do a better job at this than others.\nWhile there is no one true answer that works for everyone, this article will try to help you narrow down the field and make an informed decision.\nRead more...",
          "link": "https://pythonspeed.com/articles/best-file-format-for-pandas/",
          "publishedOn": "2023-05-24T00:00:00.000Z",
          "wordCount": 1898,
          "title": "Choosing a good file format for Pandas",
          "imageUrl": "https://pythonspeed.com/assets/titles/best-file-format-for-pandas.png"
        },
        {
          "id": "https://pythonspeed.com/articles/externally-managed-environment-pep-668/",
          "author": null,
          "description": "You’re on a new version of Linux, you try a pip install, and it errors out, talking about “externally managed environments” and “PEP 668”.\nWhat’s going on?\nHow do you solve this?\nLet’s see:\nWhat the problem looks like, and what causes it.\nThe places you are likely to encounter it.\nA variety of solutions, depending on your use case.\nRead more...",
          "link": "https://pythonspeed.com/articles/externally-managed-environment-pep-668/",
          "publishedOn": "2023-05-05T00:00:00.000Z",
          "wordCount": 1785,
          "title": "\"Externally managed environments\": when PEP 668 breaks pip",
          "imageUrl": "https://pythonspeed.com/assets/titles/externally-managed-environment-pep-668.png"
        }
      ]
    },
    {
      "title": "统计之都",
      "feedUrl": "https://cosx.org/index.xml",
      "siteUrl": "https://cosx.org/",
      "articles": []
    },
    {
      "title": "Sander Dieleman",
      "feedUrl": "https://benanne.github.io/feed",
      "siteUrl": "https://sander.ai/",
      "articles": []
    },
    {
      "title": "Jeremy Jordan",
      "feedUrl": "https://www.jeremyjordan.me/rss/",
      "siteUrl": "https://www.jeremyjordan.me/",
      "articles": [
        {
          "id": "64489047578bbf003dccd8e8",
          "author": "Jeremy Jordan",
          "description": "The attention mechanism allows us to merge a variable-length sequence of vectors into a fixed-size context vector. What if we could use this mechanism to entirely replace recurrence for sequential modeling? This blog post covers the Transformer architecture which explores such an approach.",
          "link": "https://www.jeremyjordan.me/transformer-architecture/",
          "publishedOn": "2023-05-06T18:17:57.000Z",
          "wordCount": 3943,
          "title": "Understanding the Transformer architecture for neural networks",
          "imageUrl": "https://www.jeremyjordan.me/content/images/2022/01/trolltunga.png"
        }
      ]
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "http://jalammar.github.io/feed",
      "siteUrl": "http://jalammar.github.io/",
      "articles": [
        {
          "id": "http://jalammar.github.io/generative-ai-and-ai-product-moats/",
          "author": null,
          "description": "Here are eight observations I’ve shared recently on the Cohere blog and videos that go over them.: Article: What’s the big deal with Generative AI? Is it the future or the present? Article: AI is Eating The World",
          "link": "http://jalammar.github.io/generative-ai-and-ai-product-moats/",
          "publishedOn": "2023-05-09T00:00:00.000Z",
          "wordCount": 213,
          "title": "Generative AI and AI Product Moats",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Lil'Log",
      "feedUrl": "https://lilianweng.github.io/index.xml",
      "siteUrl": "https://lilianweng.github.io/",
      "articles": []
    },
    {
      "title": "Amit Chaudhary",
      "feedUrl": "https://amitness.com/feed",
      "siteUrl": "https://amitness.com/",
      "articles": []
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": [
        {
          "id": "http://bair.berkeley.edu/blog/2023/05/23/lmd/",
          "author": null,
          "description": "TL;DR: Text Prompt -> LLM -> Intermediate Representation (such as an image layout) -> Stable Diffusion -> Image.\nRecent advancements in text-to-image generation with diffusion models have yielded remarkable results synthesizing highly realistic and diverse images. However, despite their impressive capabilities, diffusion models, such as Stable Diffusion, often struggle to accurately follow the prompts when spatial or common sense reasoning is required.\nThe following figure lists four scenarios in which Stable Diffusion falls short in generating images that accurately correspond to the given prompts, namely negation, numeracy, and attribute assignment, spatial relationships. In contrast, our method, LLM-grounded Diffusion (LMD), delivers much better prompt understanding in text-to-image gen…",
          "link": "http://bair.berkeley.edu/blog/2023/05/23/lmd/",
          "publishedOn": "2023-05-23T15:00:00.000Z",
          "wordCount": 803,
          "title": "GPT-4 + Stable-Diffusion = ?: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/lmd/main.jpg"
        }
      ]
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss/",
      "siteUrl": "https://www.inference.vc/",
      "articles": [
        {
          "id": "64724f2336605b0001f5e7fa",
          "author": "Ferenc Huszar",
          "description": "Last week in Cambridge was Hinton bonanza. He visited the university town where he was once an undergraduate in experimental psychology, and gave a series of back-to-back talks, Q&A sessions, interviews, dinners, etc. He was stopped on the street by random passers-by who recognised him from the lecture,",
          "link": "https://www.inference.vc/mortal-computation-hintons/",
          "publishedOn": "2023-05-30T13:48:52.000Z",
          "wordCount": 2347,
          "title": "Mortal Komputation: On Hinton's argument for superhuman AI.",
          "imageUrl": "https://www.inference.vc/content/images/2023/05/hqdefault-1.jpg"
        }
      ]
    },
    {
      "title": "Eric Jang",
      "feedUrl": "https://blog.evjang.com/feeds/posts/default",
      "siteUrl": "https://blog.evjang.com/",
      "articles": []
    },
    {
      "title": "DeepMind Blog",
      "feedUrl": "https://deepmind.com/blog/feed/basic/",
      "siteUrl": "https://www.deepmind.com",
      "articles": [
        {
          "id": "https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks",
          "author": null,
          "description": "AI researchers already use a range of evaluation benchmarks to identify unwanted behaviours in AI systems, such as AI systems making misleading statements, biased decisions, or repeating copyrighted content. Now, as the AI community builds and deploys increasingly powerful AI, we must expand the evaluation portfolio to include the possibility of extreme risks from general-purpose AI models that have strong skills in manipulation, deception, cyber-offense, or other dangerous capabilities.",
          "link": "https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks",
          "publishedOn": "2023-05-25T00:00:00.000Z",
          "wordCount": 1475,
          "title": "An early warning system for novel AI risks",
          "imageUrl": "https://assets-global.website-files.com/621e749a546b7592125f38ed/646f6e9992ceb1a002f3c316_16x9-min.jpg"
        }
      ]
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "scikit-learn Blog",
      "feedUrl": "https://blog.scikit-learn.org/feed",
      "siteUrl": "https://blog.scikit-learn.org/",
      "articles": []
    },
    {
      "title": "Machine Learning (Theory)",
      "feedUrl": "http://feeds2.feedburner.com/MachineLearningtheory",
      "siteUrl": "https://hunch.net",
      "articles": []
    },
    {
      "title": "Causal Analysis in Theory and Practice",
      "feedUrl": "http://causality.cs.ucla.edu/blog/index.php/feed/",
      "siteUrl": "http://causality.cs.ucla.edu/blog",
      "articles": []
    },
    {
      "title": "YongYuan's homepage",
      "feedUrl": "https://yongyuan.name/blog/feed.xml",
      "siteUrl": "https://yongyuan.name",
      "articles": []
    },
    {
      "title": "Andrej Karpathy blog",
      "feedUrl": "https://karpathy.github.io/feed.xml",
      "siteUrl": "http://karpathy.github.io/",
      "articles": []
    },
    {
      "title": "colah's blog",
      "feedUrl": "http://colah.github.io/rss",
      "siteUrl": "http://colah.github.io/",
      "articles": []
    },
    {
      "title": "PyTorch Website",
      "feedUrl": "https://pytorch.org/feed",
      "siteUrl": "https://pytorch.org/",
      "articles": [
        {
          "id": "https://pytorch.org/blog/out-of-the-box-acceleration/",
          "author": null,
          "description": "As part of PyTorch 2.0 release, an accelerated implementation of the attention mechanism as part of the “Better Transformer” project (and known in PyTorch as Accelerated Transformers) has been added natively into PyTorch as torch.nn.functional.scaled_dot_product_attention. This implementation leverages fused kernels from FlashAttention and Memory-efficient attention, and supports both training and inference.",
          "link": "https://pytorch.org/blog/out-of-the-box-acceleration/",
          "publishedOn": "2023-05-22T07:00:00.000Z",
          "wordCount": 2191,
          "title": "Out of the box acceleration and memory savings of 🤗 decoder models with PyTorch 2.0",
          "imageUrl": "https://pytorch.org/assets/images/pytorch-logo.png"
        },
        {
          "id": "https://pytorch.org/blog/pytorch-conference-2023/",
          "author": null,
          "description": "<div type=\"html\"/>",
          "link": "https://pytorch.org/blog/pytorch-conference-2023/",
          "publishedOn": "2023-05-16T07:00:00.000Z",
          "wordCount": 889,
          "title": "PyTorch Conference 2023: Join us in San Francisco October 16-17",
          "imageUrl": "https://pytorch.org/assets/images/pytorch-logo.png"
        },
        {
          "id": "https://pytorch.org/blog/language-identification/",
          "author": null,
          "description": "Language Identification is the process of identifying the primary language from multiple audio input samples. In natural language processing (NLP), language identification is an important problem and a challenging issue. There are many language-related tasks such as entering text on your phone, finding news articles you enjoy, or discovering answers to questions that you may have. All these tasks are powered by NLP models. To decide which model to invoke at a particular point in time, we must perform language identification.",
          "link": "https://pytorch.org/blog/language-identification/",
          "publishedOn": "2023-05-12T07:00:00.000Z",
          "wordCount": 2343,
          "title": "Language Identification: Building an End-to-End AI Solution using PyTorch",
          "imageUrl": "https://pytorch.org/assets/images/pytorch-logo.png"
        },
        {
          "id": "https://pytorch.org/blog/announcing-docathon/",
          "author": null,
          "description": "<div type=\"html\"/>",
          "link": "https://pytorch.org/blog/announcing-docathon/",
          "publishedOn": "2023-05-03T07:00:00.000Z",
          "wordCount": 874,
          "title": "Announcing PyTorch Docathon 2023",
          "imageUrl": "https://pytorch.org/assets/images/pytorch-logo.png"
        },
        {
          "id": "https://pytorch.org/blog/accelerated-image-seg/",
          "author": null,
          "description": "Using Intel® Extension for PyTorch to Boost Image Processing Performance",
          "link": "https://pytorch.org/blog/accelerated-image-seg/",
          "publishedOn": "2023-05-02T07:00:00.000Z",
          "wordCount": 2305,
          "title": "Accelerated Image Segmentation using PyTorch",
          "imageUrl": "https://pytorch.org/assets/images/pytorch-logo.png"
        }
      ]
    },
    {
      "title": "Guillaume Genthial blog",
      "feedUrl": "https://guillaumegenthial.github.io/feed",
      "siteUrl": "https://guillaumegenthial.github.io/",
      "articles": []
    },
    {
      "title": "Math ∩ Programming",
      "feedUrl": "https://jeremykun.com/feed/",
      "siteUrl": "https://jeremykun.com",
      "articles": []
    },
    {
      "title": "Jonty Sinai",
      "feedUrl": "https://jontysinai.github.io/feed",
      "siteUrl": "https://jontysinai.github.io/",
      "articles": []
    },
    {
      "title": "The AI Blog",
      "feedUrl": "https://blogs.microsoft.com/ai/feed/",
      "siteUrl": "https://blogs.microsoft.com/ai/",
      "articles": []
    },
    {
      "title": "arg min blog",
      "feedUrl": "https://www.argmin.net/feed.xml",
      "siteUrl": "http://benjamin-recht.github.io/",
      "articles": []
    },
    {
      "title": "Combinatorics and more",
      "feedUrl": "https://gilkalai.wordpress.com/feed/",
      "siteUrl": "https://gilkalai.wordpress.com",
      "articles": [
        {
          "id": "http://gilkalai.wordpress.com/?p=23932",
          "author": "Gil Kalai",
          "description": "(Click to enlarge.) Plan for this post: Prologue: “Can we sleep soundly at night?” Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel … Continue reading →",
          "link": "https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/",
          "publishedOn": "2023-05-30T05:38:33.000Z",
          "wordCount": 4660,
          "title": "Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.",
          "imageUrl": "https://gilkalai.files.wordpress.com/2023/05/cern22.jpg"
        },
        {
          "id": "http://gilkalai.wordpress.com/?p=24359",
          "author": "Gil Kalai",
          "description": "Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice’s task is to choose, at a certain time of her choice, some number (smaller than the number of unseen … Continue reading →",
          "link": "https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/",
          "publishedOn": "2023-05-25T08:33:58.000Z",
          "wordCount": 3098,
          "title": "Test your intuition 52: Can you predict the ratios of ones?",
          "imageUrl": "https://s0.wp.com/i/blank.jpg"
        },
        {
          "id": "http://gilkalai.wordpress.com/?p=24235",
          "author": "Gil Kalai",
          "description": "LLM is the acronym for “large language model” like GPT-3, ChatGPT, GPT-4 etc. Amnon Shashua gave an enlightening clear lecture about the repeated recent breakthroughs for LLM’s and where we stand. Here is the You-Tube link for the lecture (in … Continue reading →",
          "link": "https://gilkalai.wordpress.com/2023/05/11/amnon-shashuas-lecture-at-reichman-university-a-deep-dive-into-llms-and-their-future-impact/",
          "publishedOn": "2023-05-11T05:31:20.000Z",
          "wordCount": 3251,
          "title": "Amnon Shashua’s lecture at Reichman University: A Deep Dive into LLMs and their Future Impact.",
          "imageUrl": "https://gilkalai.files.wordpress.com/2023/05/founders_roei-shor-photography-ai21-labs-.jpg"
        },
        {
          "id": "http://gilkalai.wordpress.com/?p=24215",
          "author": "Gil Kalai",
          "description": "Plan for next weeks blogging There are various things to blog about and let me give a quick preview for the plan for the next few posts. The purpose of this post is to give an impression about the hectic … Continue reading →",
          "link": "https://gilkalai.wordpress.com/2023/05/08/mathematics-mainly-combinatorics-related-matters-a-lot-of-activity/",
          "publishedOn": "2023-05-08T06:50:10.000Z",
          "wordCount": 4517,
          "title": "Mathematics (mainly combinatorics) related matters: A lot of activity.",
          "imageUrl": "https://gilkalai.files.wordpress.com/2023/05/avinoam.jpg"
        }
      ]
    },
    {
      "title": "Skywind Inside",
      "feedUrl": "https://www.skywind.me/blog/feed",
      "siteUrl": "https://www.skywind.me/blog",
      "articles": [
        {
          "id": "https://www.skywind.me/blog/?p=2719",
          "author": "skywind",
          "description": "最近时间线上看到不少人在论战，做互联网的人觉得游戏服务端发展很慢，而互联网技术日新月异，觉得似乎互联网技术领先了游戏后端技术十年，这个结论显然是武断的，互联网就是发展到今天，就是任意一台互联网的服务器拿出来，其复杂度也远远比不上游戏服务器，即便各种 C/C++ 开发的互联网基建项目。 同时没有意识到游戏玩家之间交互性的复杂性与实时性是大部分互联网项目无法比较的。话分两头说，看到一些做游戏后端的同学觉得互联网更简单，电商之类的更是 CRUD 的增删改查，比起游戏服务器落后十年不止。 我觉得游戏服务端的同学实属没必要和这个互联网的人一般见识，不管不顾的也跟着说什么游戏服务端比互联网先进十年什么的，这是另一个极端了，一些情况也需要正视： 1）游戏服务端足够复杂，但是发展太慢，祖传代码修修补补跑个十多年的不要太多。能用固然是好事，但没有新观念的引入，导致可用性和开发效率一直没有太多提升。 2）各自闭门造车，没有形成行业标准与合力，这个项目的代码，很难在另一个项目共享，相互之间缺少支持和协同。 3）互联网后端随便拎出一个服务来（包括各种 C/C++ 基建）大概率都没有游戏服务端复杂，但最近十年日新月异，形成了很强的互相组合互相增强的态势。 我上面指的是互联网基建项目，不是互联网 CRUD，实话实说，游戏服务器的确很复杂很难，可能 ARPG 里砍一刀这种小事情，想砍的有手感，做互联网的也不一定能理解背后的复杂度有多少。但互联网近十年的发展，让其整体可用性，效能，开发效率，都上了很多个台阶，不应一味忽视。 如果继续觉得游戏服务端领先互联网十年可以直接右转了，开放心态的话我也可以多聊一些（点击下方 more 阅读更多）： 举个例子，音视频领域的基建，并不比游戏服务端简单： 1）一路高清视频 720-1080p 的，差不多每秒钟 2MB/s 的数据量，同时在线 100w 的，整个网络每秒钟至少有 2T/s 的数据量在跑着，不但不分服，而且玩家遍布世界每个角落，还要不卡不掉不延迟，这个数据量比起游戏的消息要大好几个数量级吧？在把这 2T/s 数据安排明白妥当的同时，还得保证延迟不能超过 500ms，超过就没法玩了。 2）一个房间的人数少的是 2-4 人，多的上千人，遍布 4-5 个国家，你一屏幕打开，可以同时看到 50 个人的视频，虽然是小窗口，但是你拉住任意小窗口，快速拉大到全屏，看不到明显的清晰度梯度切换带来的抖动，如何实现呢？ 3）全球上百个机房协同工作，组成一张很大的网络，一会这个机房出问题，一会那里线路阻塞了，能做到动态自如的切换，让用户几乎感觉不到，也不容易吧？ 4）更新无需停机，停服，即便一个 1000 人的房间后面的服务器更新，可能你都感觉不出来，视频的房间也算是有状态的，这种平滑的切换，不算简单吧？ 5）弱网情况下，开着车接着视频，不停切换基站，60% 的丢包情况下，虽然会卡一些，但如果要保证基础可用，也还是有点技术含量的吧。 ６）服务端跑视频编码器，即便有现成开源的也需要自己花大力气二次开发，编码器方面的积累，你不搞个四五年，你入不了手吧？这方面的知识日新月异，每年都有新标准，更新比游戏快多了。 ７）后端图象增强，允许带宽不足用户发送比较差的视频，增强成比较清晰的视频，这个 AI 增强技术，比 DLSS 1/2 复杂好几个台阶。 8）即便不是实时通信，点播，看着简单，也有很多挑战的地方，比如你客户端看短视频，不停的手指往上滑，连续划十个，不卡，秒出，丝滑切换，光这一点数据量有多大？客户端该怎么管理资源？服务端从接入服务，调度服务，到 CDN 和传输协议，要做多少项优化呢？ […]\nThe post 互联网技术比游戏后端技术领先十年吗？ appeared first on Skywind Inside.",
          "link": "https://www.skywind.me/blog/archives/2719",
          "publishedOn": "2023-05-19T17:14:00.000Z",
          "wordCount": 1688,
          "title": "互联网技术比游戏后端技术领先十年吗？",
          "imageUrl": "https://skywind3000.github.io/images/blog/2023/lcevc.jpg"
        }
      ]
    },
    {
      "title": "Xi'an's Og",
      "feedUrl": "https://xianblog.wordpress.com/feed/",
      "siteUrl": "https://xianblog.wordpress.com",
      "articles": [
        {
          "id": "http://xianblog.wordpress.com/?p=53111",
          "author": "xi'an",
          "description": "In a recent arXival, Metodiev et al. (including my friend Adrian Raftery, who is spending the academic year in Paris) proposed a new version of reciprocal importance sampling, expanding the proposal we made with Darren Wraith (2009) of using a Uniform over an HPD region. It is called THAMES, hence the picture (of London, not […]",
          "link": "https://xianblog.wordpress.com/2023/05/30/reciprocal-importance-sampling/",
          "publishedOn": "2023-05-29T22:23:39.000Z",
          "wordCount": 2002,
          "title": "reciprocal importance sampling",
          "imageUrl": "https://xianblog.files.wordpress.com/2012/01/dscn1366.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53104",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/29/model-based-clustering-classification-and-density-estimation-using-mclust-in-r-not-a-book-review/",
          "publishedOn": "2023-05-28T22:23:16.000Z",
          "wordCount": 1734,
          "title": "Model-Based Clustering, Classification, and Density Estimation Using mclust in R [not a book review]",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/temp-5.png"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53091",
          "author": "xi'an",
          "description": "“The nested sampling algorithm solves otherwise challenging, high-dimensional integrals by evolving a collection of live points through parameter space. The algorithm was immediately adopted in cosmology because it partially overcomes three of the major difficulties in Markov chain Monte Carlo, the algorithm traditionally used for Bayesian computation. Nested sampling simultaneously returns results for model comparison […]",
          "link": "https://xianblog.wordpress.com/2023/05/28/natural-nested-sampling/",
          "publishedOn": "2023-05-27T22:23:11.000Z",
          "wordCount": 2040,
          "title": "Natural nested sampling",
          "imageUrl": "https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43586-022-00121-x/MediaObjects/43586_2022_121_Fig2_HTML.png"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52378",
          "author": "xi'an",
          "description": "A few months ago, I had to write a thesis evaluation of Rémi Leluc’s PhD, which contained several novel Monte Carlo proposals on control variates and importance techniques. For instance, Leluc et al. (Statistics and Computing, 2021) revisits the concept of control variables by adding a perspective of control variable selection using LASSO. This prior […]",
          "link": "https://xianblog.wordpress.com/2023/05/27/on-control-variates/",
          "publishedOn": "2023-05-26T22:23:58.000Z",
          "wordCount": 2158,
          "title": "on control variates",
          "imageUrl": "https://nips.cc/media/PosterPDFs/NeurIPS%202022/72007983849f4fcb0ad565439834756b.png"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53085",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/26/ems-2023-warsaw/",
          "publishedOn": "2023-05-25T22:23:13.000Z",
          "wordCount": 1728,
          "title": "EMS 2023, Warsaw",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/ems23.png"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53075",
          "author": "xi'an",
          "description": "This week, I am taking part in the Stochastic Numerics and Statistical Learning workshop, in KAUST, which should prove an interesting experience!",
          "link": "https://xianblog.wordpress.com/2023/05/25/stochastic-numerics-and-statistical-learning/",
          "publishedOn": "2023-05-24T22:23:33.000Z",
          "wordCount": 1664,
          "title": "Stochastic Numerics and Statistical Learning",
          "imageUrl": "https://cemse.kaust.edu.sa/sites/default/files/styles/max_fullhd_scale/public/2023-01/Stochastic%20Numerics%20Workshop%202022%20LED%20Signage%20Screens-01.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53022",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/24/art-brut-90/",
          "publishedOn": "2023-05-23T22:23:05.000Z",
          "wordCount": 1703,
          "title": "art brut",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/1683538746341-e1683549130187.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53038",
          "author": "xi'an",
          "description": "A form of Bernoulli factory with limited energy from The Riddler: being given the choice of 0<p<1, what is the minimal number n of throws such that the outcomes of n iid B(p) draws can be partitioned into six groups of equal probability? Running a brute force R code [in the train to Cambridge] and […]",
          "link": "https://xianblog.wordpress.com/2023/05/23/bernoulli-factory-on-a-budget/",
          "publishedOn": "2023-05-22T22:23:22.000Z",
          "wordCount": 1798,
          "title": "Bernoulli factory on a budget",
          "imageUrl": "https://xianblog.files.wordpress.com/2009/07/danish_bill-e1445288109123.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52979",
          "author": "xi'an",
          "description": "The Lonely Planet blog has a list of prohibitions on tourists’ activities when visiting some Italian cities. Like Venice, Rome or Milan (below). Most of which is sort of obvious, like not walking around shirtless or barefoot away from beaches, feed the pigeons (although our kids did when visiting Venice for the first time!), hold […]",
          "link": "https://xianblog.wordpress.com/2023/05/22/italy-no-nos/",
          "publishedOn": "2023-05-21T22:23:12.000Z",
          "wordCount": 1858,
          "title": "Italy no-no’s",
          "imageUrl": "https://xianblog.files.wordpress.com/2012/10/dsc_2982.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53034",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/21/foxhuntshire/",
          "publishedOn": "2023-05-20T22:23:42.000Z",
          "wordCount": 1648,
          "title": "foxhuntshire",
          "imageUrl": "https://static01.nyt.com/images/2023/02/11/multimedia/11uk-foxhunt--gbtv/11uk-foxhunt--gbtv-superJumbo.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52447",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/20/chateau-balac-haut-medoc/",
          "publishedOn": "2023-05-20T18:20:23.000Z",
          "wordCount": 1708,
          "title": "Château Balac [Haut-Médoc]",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/03/1677843445855-e1677844190281.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53019",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/19/french-coast/",
          "publishedOn": "2023-05-18T22:23:56.000Z",
          "wordCount": 1702,
          "title": "French coast",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/1683538746363-e1683548921528.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53069",
          "author": "xi'an",
          "description": "Following my earlier post on the terrible performances of ChatGPT for a grasshopping riddle, Bob Carpenter sent me his interaction with GPT4, using the same entry. Here is the python code outcome he obtained. The code is running  and the answer is correct. BC: Thanks. Can you write a python program to simulate the final […]",
          "link": "https://xianblog.wordpress.com/2023/05/18/grasshoppers-for-pythons/",
          "publishedOn": "2023-05-17T22:23:17.000Z",
          "wordCount": 2118,
          "title": "grasshoppers for pythons",
          "imageUrl": "https://xianblog.files.wordpress.com/2020/09/vallouise103-e1598802275394.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53043",
          "author": "xi'an",
          "description": "At Sylvia Richardson’s career celebration last Friday, I gave a talk on How many components in a mixture? which was most relevant given Sylvia’s contributions to mixture inference over the years, including her highly influential 1997 Read Paper with Peter Green. The other talks highlighted the many facets of Sylvia to the field and the […]",
          "link": "https://xianblog.wordpress.com/2023/05/17/53043/",
          "publishedOn": "2023-05-16T22:23:17.000Z",
          "wordCount": 1856,
          "title": "Festschift for Sylvia",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/1683965654838-1-e1683966278231.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53063",
          "author": "xi'an",
          "description": "Following my earlier post on the terrible performances of ChatGPT for a grasshopping riddle, Bob Carpenter sent me his interaction with GPT4, using the same entry. Here is the outcome he obtained. The answer is correct, but the reasoning is wrong. GPT4: This is a classic problem of infinite series and expected values in probability […]",
          "link": "https://xianblog.wordpress.com/2023/05/16/more-grasshope/",
          "publishedOn": "2023-05-15T22:23:34.000Z",
          "wordCount": 2056,
          "title": "more [grass]hope",
          "imageUrl": "https://xianblog.files.wordpress.com/2020/09/vallouise103-e1598802275394.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52858",
          "author": "xi'an",
          "description": "While I rarely enter company sweepstakes and lotteries (and correlatively never win!), I answered a contest from my credit card company around the 2022 Beijing Winter Olympics, and won the prize of having a Chinese dinner cooked at home by a chef, news that I first treated as a spam for being so improbable. The […]",
          "link": "https://xianblog.wordpress.com/2023/05/15/chez-guy/",
          "publishedOn": "2023-05-14T22:23:37.000Z",
          "wordCount": 1871,
          "title": "Chez Guy**(*)",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/1683018488094-e1683021548789.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52986",
          "author": "xi'an",
          "description": "Checking the R coding abilities of ChatGPT, I entered the latest Riddler puzzle that asks for the expected value of the stationary distribution of a slowing-down random walk over the real line when the N-th jump from x is to x±2-N. Which is ½ since the limiting distribution is uniform over (-1,1). The first proposed […]",
          "link": "https://xianblog.wordpress.com/2023/05/14/grass-hopping-on-the-wrong-fgpt/",
          "publishedOn": "2023-05-13T22:23:23.000Z",
          "wordCount": 1843,
          "title": "grass hopping on the wrong fgpt",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/temp-4.png"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52971",
          "author": "xi'an",
          "description": "Since the solution to the previous riddle from The Riddler on the maximum of  different terms in the composed operation a∅b∅c∅d∅e∅f depending on the bracketing ordering and the meaning of each ∅ among one of the six elementary operations got posted today as 974,860, I got back to my R code to understand why it […]",
          "link": "https://xianblog.wordpress.com/2023/05/13/operation-precisely-impossible/",
          "publishedOn": "2023-05-12T22:23:30.000Z",
          "wordCount": 1886,
          "title": "operation precisely impossible",
          "imageUrl": "https://xianblog.files.wordpress.com/2012/01/pict0448-e1326730756979.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=53001",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/12/cirm-luminy-1995/",
          "publishedOn": "2023-05-11T22:23:15.000Z",
          "wordCount": 1718,
          "title": "CIRM, Luminy, 1995",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/1683535668660-e1683539064900.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52956",
          "author": "xi'an",
          "description": "In a 2009 JCGS paper, Peter Lenk proposed a bias correction of the harmonic mean estimator, which is somewhat surprising given that the estimator usually has no variance and hence that its consistency is purely formal, since no speed of convergence can be taken for granted. In particular, the conjugate Normal model serving as a […]",
          "link": "https://xianblog.wordpress.com/2023/05/11/back-to-a-correction-of-the-harmonic-mean-estimator/",
          "publishedOn": "2023-05-10T22:23:13.000Z",
          "wordCount": 1808,
          "title": "back to a correction of the harmonic mean estimator",
          "imageUrl": "https://secure.gravatar.com/blavatar/c1152fd99c26a547613cfba76091fd4f?s=200&ts=1683760515"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52944",
          "author": "xi'an",
          "description": "A rather intriguing question on X validated, namely a simulation approach to sampling a bivariate distribution fully specified by one conditional p(x|y) and the symmetric conditional expectation IE[Y|X=x]. The book Conditional Specification of Statistical Models, by Arnold, Castillo and Sarabia, as referenced by and in the question, contains (§7.7) illustrations of such cases. As for […]",
          "link": "https://xianblog.wordpress.com/2023/05/10/mean-simulations/",
          "publishedOn": "2023-05-09T22:23:48.000Z",
          "wordCount": 1858,
          "title": "mean simulations",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/temp-1.png"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52998",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/09/europe-day/",
          "publishedOn": "2023-05-08T22:23:52.000Z",
          "wordCount": 1641,
          "title": "Europe Day",
          "imageUrl": "https://www.europarl.europa.eu/europe-day/assets/img/europe-day-2023-campaign-image-program_en.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52870",
          "author": "xi'an",
          "description": "“I believe neither in luck nor in destiny, I trust only the science of probabilities. I have studied mathematical statistics, combinatorial analysis, mass functions, and random variables, and they never have held any surprise for me.” Over the past weeks, I read  both second and third volumes of The Mirror Visitor series, by Christelle Dabos, […]",
          "link": "https://xianblog.wordpress.com/2023/05/08/52870/",
          "publishedOn": "2023-05-07T22:23:35.000Z",
          "wordCount": 2023,
          "title": "book reviews",
          "imageUrl": "https://static.fnac-static.com/multimedia/Images/FR/NR/f6/4c/a7/10964214/1520-1/tsp20200130155126/La-Pae-miroir-3.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52915",
          "author": "xi'an",
          "description": "Taking advantage of the 01 May break and a relatively low density of people in Paris, we went to the Musée du Quai Branly to see a soon to close exhibit on kimonos, with many pieces loaned from Japanese collections, through an exhibit designed by the Victoria and Albert Museum in London. The collection is […]",
          "link": "https://xianblog.wordpress.com/2023/05/07/kimono-exhibition/",
          "publishedOn": "2023-05-06T22:23:58.000Z",
          "wordCount": 1852,
          "title": "Kimono exhibition",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/04/2023-04-30_00-55-06-e1682881970127.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52904",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/06/napaljarri-wanu-jukurrpa/",
          "publishedOn": "2023-05-05T22:23:30.000Z",
          "wordCount": 1729,
          "title": "Napaljarri-wanu Jukurrpa",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/04/2023-04-29_23-50-43.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52894",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/05/baltos-genome/",
          "publishedOn": "2023-05-04T22:23:19.000Z",
          "wordCount": 1652,
          "title": "Balto’s genome",
          "imageUrl": "https://static.scientificamerican.com/sciam/assets/Image/2023/Balto_graphic_d.jpg"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52879",
          "author": "xi'an",
          "description": "“…many well-known learning-algorithms, such as those used in optimization, deep learning, and machine learning in general, can now be derived directly following the above scheme using a single algorithm” The One World ABC webinar today was delivered by Emtiyaz Khan (RIKEN), about the Bayesian Learning Rule, following Khan and Rue 2021 arXival on Bayesian learning. […]",
          "link": "https://xianblog.wordpress.com/2023/05/04/bayesian-learning/",
          "publishedOn": "2023-05-04T16:01:52.000Z",
          "wordCount": 1904,
          "title": "Bayesian learning",
          "imageUrl": "https://secure.gravatar.com/blavatar/c1152fd99c26a547613cfba76091fd4f?s=200&ts=1683217755"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52923",
          "author": "xi'an",
          "description": "Visit the post for more.",
          "link": "https://xianblog.wordpress.com/2023/05/03/aixcuse-me/",
          "publishedOn": "2023-05-02T22:23:29.000Z",
          "wordCount": 1713,
          "title": "AIxcuse me?!",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/05/temp.png"
        },
        {
          "id": "http://xianblog.wordpress.com/?p=52802",
          "author": "xi'an",
          "description": "Read Brent Weeks’ The Way of Shadows, a rather traditional tale of an orphan boy learning assassin’s skills from a master, within a crime guild organisation tolerated by a feudal structure itself ruled by a below-par king, with the usual dilemma between dedication to the (gory and amoral) job and love+friendship+loyalty constraints. Both collide when […]",
          "link": "https://xianblog.wordpress.com/2023/05/02/a-journal-of-the-plague-sword-and-famine-year-5/",
          "publishedOn": "2023-05-01T22:23:18.000Z",
          "wordCount": 2063,
          "title": "a journal of the plague, sword, and famine year",
          "imageUrl": "https://xianblog.files.wordpress.com/2023/04/1681369890881-e1681370290799.jpg"
        }
      ]
    },
    {
      "title": "Windows On Theory",
      "feedUrl": "https://windowsontheory.org/feed/",
      "siteUrl": "https://windowsontheory.org",
      "articles": [
        {
          "id": "http://windowsontheory.org/?p=8615",
          "author": "Boaz Barak",
          "description": "[See my post with Edelman on AI takeover and Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.]  One challenge for considering the implications of “artificial intelligence,” especially of the “general” variety, is that we don’t have a consensus definition of intelligence. The Oxford Companion … Continue reading GPT as an “Intelligence Forklift.”",
          "link": "https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/",
          "publishedOn": "2023-05-19T21:16:17.000Z",
          "wordCount": 3773,
          "title": "GPT as an “Intelligence Forklift.”",
          "imageUrl": "https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/cfee2d12a17cf70d8bfdc038070a679c423c7061ed67439f.png"
        }
      ]
    },
    {
      "title": "Machine Learning (Theory)",
      "feedUrl": "https://hunch.net/?feed=rss2",
      "siteUrl": "https://hunch.net",
      "articles": []
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://ai.googleblog.com/",
      "articles": [
        {
          "id": "http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html",
          "author": null,
          "description": "Posted by Julian Eisenschlos, Research Software Engineer, Google Research\n\n\n\n\n\nVisual language is the form of communication that relies on pictorial symbols outside of text to convey information. It is ubiquitous in our digital life in the form of iconography, infographics, tables, plots, and charts, extending to the real world in street signs, comic books, food labels, etc. For that reason, having computers better understand this type of media can help with scientific communication and discovery, accessibility, and data transparency.\n \n\nWhile computer vision models have made tremendous progress using learning-based solutions since the advent of ImageNet, the focus has been on natural images, where all sorts of tasks, such as classification, visual question answering (VQA), captioning, det…",
          "link": "http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html",
          "publishedOn": "2023-05-26T19:08:00.002Z",
          "wordCount": 27907,
          "title": "Foundation models for reasoning on charts",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifdjDjOARh4hb7ejkosuWwJDb1xEhPVkFiJQpa9Go1uhkRMy58esTSN9DXgWN5N74ZS5P4dyvG6FnZ_F-EzxNl0FcwFycDqEBOvabOoudTXbEXxSohAUbjvKYu_GKu3XNCumZLxBpzeUbjIZ1pgXtXZofVrBdR19g2dGBZ1gIYOCr6h9wYPQY-sXdhbQ/w1200-h630-p-k-no-nu/MatCha.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html",
          "author": null,
          "description": "Posted by Ken Caluwaerts and Atil Iscen, Research Scientists, Google\n\n\n\n\n\nCreating robots that exhibit robust and dynamic locomotion capabilities, similar to animals or humans, has been a long-standing goal in the robotics community. In addition to completing tasks quickly and efficiently, agility allows legged robots to move through complex environments that are otherwise difficult to traverse. Researchers at Google have been pursuing agility for multiple years and across various form factors. Yet, while researchers have enabled robots to hike or jump over some obstacles, there is still no generally accepted benchmark that comprehensively measures robot agility or mobility. In contrast, benchmarks are driving forces behind the development of machine learning, such as ImageNet for computer…",
          "link": "http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html",
          "publishedOn": "2023-05-26T16:58:00.000Z",
          "wordCount": 27724,
          "title": "Barkour: Benchmarking animal-level agility with quadruped robots",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrBp7HZPrMFbbwb27gWZsRozP9LIfcn-Jc-MRqipA7Wi93OOwcpuYFDA_wJVepiwlAHT8cbtKn_IatNGhbX0qBHodjCWrluPI9_56aGOsScLWhGkvQ9jNaQUwU1uZNgg0U4-dWFwVyK3aCZPl5Z6frQimBaIZuyZHnQBY-KOUHmdOJNpkDCW1I8Fl6Bw/w1200-h630-p-k-no-nu/barkour%20hero.gif"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html",
          "author": null,
          "description": "Posted by Vincent Cohen-Addad and  Alessandro Epasto, Research Scientists, Google Research, Graph Mining team\n\n\n\n\nClustering is a central problem in unsupervised machine learning (ML) with many applications across domains in both industry and academic research more broadly. At its core, clustering consists of the following problem: given a set of data elements, the goal is to partition the data elements into groups such that similar objects are in the same group, while dissimilar objects are in different groups. This problem has been studied in math, computer science, operations research and statistics for more than 60 years in its myriad variants. Two common forms of clustering are metric clustering, in which the elements are points in a metric space, like in the k-means problem, and grap…",
          "link": "http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html",
          "publishedOn": "2023-05-25T23:09:00.003Z",
          "wordCount": 27754,
          "title": "Differentially private clustering for large-scale datasets",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjG6jKdvoUMqPI-WRS9KnK6Clj8W-uXfR_Pd3BfLIeSQGMb7sJtp1dTNlITKnF5CTtw4c-JtRIi9r_ySKXmKLeIGBTeLozFnQWQhp6aiXMHVctZjqQfcl2LGDywb3SktCtPwQV9OgAJZ9PyMsAOxeUxxjdRzTf3CIApROfx6hSFBv7NItHKjB8LbFgiTQ/w1200-h630-p-k-no-nu/COVID.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/google-research-at-io-2023.html",
          "author": null,
          "description": "Posted by James Manyika, SVP Google Research and Technology & Society, and Jeff Dean, Chief Scientist, Google DeepMind and Google Research\n\n\n\n\nWednesday, May 10th was an exciting day for the Google Research community as we watched the results of months and years of our foundational and applied work get announced on the Google I/O stage. With the quick pace of announcements on stage, it can be difficult to convey the substantial effort and unique innovations that underlie the technologies we presented. So today, we’re excited to reveal more about the research efforts behind some of the many exciting announcements at this year's I/O. \n\n\n \n\nPaLM 2 \nPaLM 2, is built on advances in compute-optimal scaling, scaled instruction-fine tuning and improved dataset mixture. By fine-tuning and instructi…",
          "link": "http://ai.googleblog.com/2023/05/google-research-at-io-2023.html",
          "publishedOn": "2023-05-25T17:03:00.003Z",
          "wordCount": 28008,
          "title": "Google Research at I/O 2023",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUde5cQAPm8frw1OO3Ub-QIx91GGpY3crqacseMxvbkJ55GMmjma-dqjEmxg8XtAJpSEYvyVWsFagmNVLzugwLWJiQ6OHPm0c1yDgIgXzTHRRF4NpoOJRl5p75u3O11uYuOmPNJW97Xyciox0OJni48f3MrMGmAPqVudm9mtsUUtGaCvt9vIQrc6h3NA/w1200-h630-p-k-no-nu/GoogleIO.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html",
          "author": null,
          "description": "Posted by Alexander Frömmgen, Staff Software Engineer, and Lera Kharatyan, Senior Software Engineer, Core Systems & Experiences\n\n\n  \n\nCode-change reviews are a critical part of the software development process at scale, taking a significant amount of the code authors’ and the code reviewers’ time. As part of this process, the reviewer inspects the proposed code and asks the author for code changes through comments written in natural language. At Google, we see millions of reviewer comments per year, and authors require an average of ~60 minutes active shepherding time between sending changes for review and finally submitting the change. In our measurements, the required active work time that the code author must do to address reviewer comments grows almost linearly with the number of comme…",
          "link": "http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html",
          "publishedOn": "2023-05-23T17:51:00.003Z",
          "wordCount": 27806,
          "title": "Resolving code review comments with ML",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoK3FH1StJnuqrj0gTExqLUxNkVfwRVmiG9tbCNUDV2I5295yqrPlw0L4hRHJmsruvZBIa_FqAFvJfwW7VU4XvxDU4ZweaW6ehENeU7-BLJaLVGPPtn-25cme5qTUldd11YigkAj6Ks9Tif6J3MePey_Gn3cAp3nQf9LMmVy4Eg3yF0qyBZPUKfYJYLw/w1200-h630-p-k-no-nu/comments2code.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/making-ml-models-differentially-private.html",
          "author": null,
          "description": "Posted by Natalia Ponomareva and Alex Kurakin, Staff Software Engineers, Google Research\n\n\n\n\n\n\nLarge machine learning (ML) models are ubiquitous in modern applications: from spam filters to recommender systems and virtual assistants. These models achieve remarkable performance partially due to the abundance of available training data. However, these data can sometimes contain private information, including personal identifiable information, copyright material, etc. Therefore, protecting the privacy of the training data is critical to practical, applied ML.  \n\n\n\nDifferential Privacy (DP) is one of the most widely accepted technologies that allows reasoning about data anonymization in a formal way. In the context of an ML model, DP can guarantee that each individual user's contribution will …",
          "link": "http://ai.googleblog.com/2023/05/making-ml-models-differentially-private.html",
          "publishedOn": "2023-05-19T16:59:00.002Z",
          "wordCount": 28028,
          "title": "Making ML models differentially private: Best practices and open challenges",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhqMCb-nNfoCncADD29b0YyxB4wN8bOhRph7pJBGzKyYc1bvdZ10VC3RkyUCJBopmvukjXJnZiJyiZ5ZIPyIW66ZfrYmBoJFrxx35T8OrL_HmNr4YIKzBS5y6Ej24f1Mjsu-IqH5ECyzPBRKDRtoGgQhoKoOpILElqHDIGsn9SiI-7x58qc_nbtQ1JZ1A/w1200-h630-p-k-no-nu/DPfy%20hero.gif"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html",
          "author": null,
          "description": "Posted by AJ Piergiovanni and Anelia Angelova, Research Scientists, Google\n\n\n\n\n\n\n\n\nVideo understanding is a challenging problem that requires reasoning about both spatial information (e.g., for objects in a scene, including their locations and relations) and temporal information for activities or events shown in a video. There are many video understanding applications and tasks, such as understanding the semantic content of web videos and robot perception. However, current works, such as ViViT and TimeSFormer, densely process the video and require significant compute, especially as model size plus video length and resolution increase. \n\n\n\nIn “Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video Learning”, to be presented at CVPR 2023, we introduce a simple technique that tur…",
          "link": "http://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html",
          "publishedOn": "2023-05-18T21:08:00.000Z",
          "wordCount": 27729,
          "title": "Sparse video tubes for joint video and image vision transformers",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg5vGQDyw66Z4hevP1JdKXnn8OCKudaDk2bacIPBkxtSYH1BgyNqXhK2QXOr-ANdX6MfoZp-jzVsETmH6kgy_Tvnii7ylDJEA-u5pJXareZRDyIBsRqguw2-AcDejtp3HXImtSLXKs_wUfMf8plDnpWzk1KGCgmm0U_j31qGh3rU4Cyv58HTpiocpyZiA/w1200-h630-p-k-no-nu/TubeViT%20hero.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html",
          "author": null,
          "description": "Posted by Lucas Dixon and Michael Terry, co-leads, PAIR, Google Research\n\n\n\n\nPAIR (People + AI Research) first launched in 2017 with the belief that “AI can go much further — and be more useful to all of us — if we build systems with people in mind at the start of the process.” We continue to focus on making AI more understandable, interpretable, fun, and usable by more people around the world. It’s a mission that is particularly timely given the emergence of generative AI and chatbots.\n\n\n\nToday, PAIR is part of the Responsible AI and Human-Centered Technology team within Google Research, and our work spans this larger research space: We advance foundational research on human-AI interaction (HAI) and machine learning (ML); we publish educational materials, including the PAIR Guidebook and …",
          "link": "http://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html",
          "publishedOn": "2023-05-18T17:12:00.003Z",
          "wordCount": 27915,
          "title": "Responsible AI at Google Research: PAIR",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDUj2YMMcVzCHuAQ9TYS3IkauQbh9Tti-nZl6LZOMwwieYdyJM7DHShetIblRhW0hvTaPvDmK2f0SDu9XcLCVg0780I3GnYU0FrA27s0-MiQXQ5xPUCGqTSx-7KNJLwrlczkco2Ql5KzMeVHNXBl2oeaN0gMCPi7A2Bpc6eDpzjwZIHoNMiWLfQqL2vQ/w1200-h630-p-k-no-nu/image3.gif"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/using-reinforcement-learning-for.html",
          "author": null,
          "description": "Posted by Deborah Cohen, Staff Research Scientist, and Craig Boutilier, Principal Scientist, Google Research\n\n\n\n\nAs virtual assistants become ubiquitous, users increasingly interact with them to learn about new topics or obtain recommendations and expect them to deliver capabilities beyond narrow dialogues of one or two turns. Dynamic planning, namely the capability to look ahead and replan based on the flow of the conversation, is an essential ingredient for the making of engaging conversations with the deeper, open-ended interactions that users expect.\n \n\nWhile large language models (LLMs) are now beating state-of-the-art approaches in many natural language processing benchmarks, they are typically trained to output the next best response, rather than planning ahead, which is required fo…",
          "link": "http://ai.googleblog.com/2023/05/using-reinforcement-learning-for.html",
          "publishedOn": "2023-05-16T19:22:00.001Z",
          "wordCount": 28006,
          "title": "Using reinforcement learning for dynamic planning in open-ended conversations",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1pRX6ly5Tgckfk47u8_KxBasWJhuFoQ4SzbSmiK3SrQOKn8jXr3RHvb32lGlBksKl3-wXCwU8UnEhRp6YztIREY874N4i1289xQKHlO64QZqD9tQBiBQHMW-S5B4u5mSaBw6lgbuTEVplIrBfaOIcX-7-YG6D0lGzSOMN7r9umjZwMoE_1t1gcsEOZA/w1200-h630-p-k-no-nu/rlxtalk.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html",
          "author": null,
          "description": "Posted by Jerry Wei, Student Researcher, and Denny Zhou, Principal Scientist, Google Research\n\n\n\n\nThere have recently been tremendous advances in language models, partly because they can perform tasks with strong performance via in-context learning (ICL), a process whereby models are prompted with a few examples of input-label pairs before performing the task on an unseen evaluation example. In general, models’ success at in-context learning is enabled by:\n \n\n\nTheir use of semantic prior knowledge from pre-training to predict labels while following the format of in-context examples (e.g., seeing examples of movie reviews with “positive sentiment” and “negative sentiment” as labels and performing sentiment analysis using prior knowledge).\n\n\nLearning the input-label mappings in context from …",
          "link": "http://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html",
          "publishedOn": "2023-05-15T20:59:00.000Z",
          "wordCount": 27646,
          "title": "Larger language models do in-context learning differently",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQS0-Pkd_JiN7brkU6zV0-FEisuUcnKs0I56t37HVYKMgKStmwNgLREYn5CfURvW-lMvKbHU4cEV9elAu9qe4-M_FvveTlvBQHezbksTlH3YfOAk4TyJiXYiGBW_95RGKIW-JyjAQiC0Zd4VIjZrCSIm1PEBqrIAqbiEklluNunTOMhX_7CU9Degbwqg/w1200-h630-p-k-no-nu/SULICL.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/consensus-and-subjectivity-of-skin-tone_15.html",
          "author": null,
          "description": "Posted by Candice Schumann, Software Engineer, and Gbolahan O. Olanubi, User Experience Researcher, Google Research\n\n\n\n\nSkin tone is an observable characteristic that is subjective, perceived differently by individuals (e.g., depending on their location or culture) and thus is complicated to annotate. That said, the ability to reliably and accurately annotate skin tone is highly important in computer vision. This became apparent in 2018, when the Gender Shades study highlighted that computer vision systems struggled to detect people with darker skin tones, and performed particularly poorly for women with darker skin tones. The study highlights the importance for computer researchers and practitioners to evaluate their technologies across the full range of skin tones and at intersections of…",
          "link": "http://ai.googleblog.com/2023/05/consensus-and-subjectivity-of-skin-tone_15.html",
          "publishedOn": "2023-05-15T17:16:00.003Z",
          "wordCount": 27925,
          "title": "Consensus and subjectivity of skin tone annotation for ML fairness",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgZx6lCt5n99GkA_Q8Jd3S0msBQNxZpoFWH9Jc2vwcnyxLUhWn-s8f7zn2u5YRNrCbdGki6sRB9pcJ-n_0dGgqD47BM72DVy3zCykkRgJjP1zohvB9l7KPgetFJiLebxm9EvtWBAjRM59eAUbVUPfmuUWAeKc6ljtiMOfiAnOttUBtkYNcXm2HieMod2Q/w1200-h630-p-k-no-nu/MST-E.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/f-vlm-open-vocabulary-object-detection.html",
          "author": null,
          "description": "Posted by Weicheng Kuo and Anelia Angelova, Research Scientists, Google Research\n\n\n\n\n\n\nDetection is a fundamental vision task that aims to localize and recognize objects in an image. However, the data collection process of manually annotating bounding boxes or instance masks is tedious and costly, which limits the modern detection vocabulary size to roughly 1,000 object classes. This is orders of magnitude smaller than the vocabulary people use to describe the visual world and leaves out many categories. Recent vision and language models (VLMs), such as CLIP, have demonstrated improved open-vocabulary visual recognition capabilities through learning from Internet-scale image-text pairs. These VLMs are applied to zero-shot classification using frozen model weights without the need for fine-…",
          "link": "http://ai.googleblog.com/2023/05/f-vlm-open-vocabulary-object-detection.html",
          "publishedOn": "2023-05-12T20:56:00.000Z",
          "wordCount": 27868,
          "title": "F-VLM: Open-vocabulary object detection upon frozen vision and language models",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjd5HnIvLfcA1rgwAR8Jg3M9p1kkVhDC74oaHdUuRS5MPXqyWYoZURIj6Ibllzk2GKfFMNzB-fKxI3J0NNxyLZimLcGEC6GBzX7FG3pUGC-vRECHDaCXkorH0BL9kIBsOO4EAa3tF3HE3eH0QdzKOLwQQYI_NiToJBmBatxTVNOmYctagvi1ml2YLbgtA/w1200-h630-p-k-no-nu/F-VLM%20hero.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html",
          "author": null,
          "description": "Posted by Bryan Wang, Student Researcher, and Yang Li, Research Scientist, Google Research\n\n\n\n\n\nIntelligent assistants on mobile devices have significantly advanced language-based interactions for performing simple daily tasks, such as setting a timer or turning on a flashlight. Despite the progress, these assistants still face limitations in supporting conversational interactions in mobile user interfaces (UIs), where many user tasks are performed. For example, they cannot answer a user's question about specific information displayed on a screen. An agent would need to have a computational understanding of graphical user interfaces (GUIs) to achieve such capabilities. \n\n\n\nPrior research has investigated several important technical building blocks to enable conversational interaction with …",
          "link": "http://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html",
          "publishedOn": "2023-05-12T17:03:00.003Z",
          "wordCount": 28101,
          "title": "Enabling conversational interaction on mobile with LLMs",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBtmVasIEAQHIKlt2az_MQbF13URtJ9LYTtcACwT54elVT1Jr-l-o7MvsHntd4HnN3bxO-rniQdlt3pM1ty7SOpMhXaEsrD0Y8azCU-zAhs3xHR1OE2hsYs_PMysluHt7QItT2klQyU5xGEKIg8JaMNwGsGRGc1axpXBMWUL1KGLqWtSm2bDGDw4B0Pg/w1200-h630-p-k-no-nu/LLM4Mobile%20hero.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/building-better-pangenomes-to-improve.html",
          "author": null,
          "description": "Posted by Andrew Carroll, Product Lead, and Kishwar Shafin, Research Scientist, Genomics\n\n\n\n\n\n\nFor decades, researchers worked together to assemble a complete copy of the molecular instructions for a human — a map of the human genome. The first draft was finished in 2000, but with several missing pieces.  Even when a complete reference genome was achieved in 2022, their work was not finished. A single reference genome can’t incorporate known genetic variations, such as the variants for the gene determining whether a person has a blood type A, B, AB or O. Furthermore, the reference genome didn’t represent the vast diversity of human ancestries, making it less useful for detecting disease or finding cures for people from some backgrounds than others. For the past three years, we have been pa…",
          "link": "http://ai.googleblog.com/2023/05/building-better-pangenomes-to-improve.html",
          "publishedOn": "2023-05-10T15:03:00.002Z",
          "wordCount": 27886,
          "title": "Building better pangenomes to improve the equity of genomics",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgDfvV8C3uALQpVcvYLeqdbLBXoX0ZvSQC76l4SVp4xHq7xGKRDRLuxKYKsZzc5e3gVPp2yyhO4R4YgoXNQreJH4RYSQNlIy7cG57e0bviTgMKeEtubq0kt7q4Ei2uF4fjgqo9qjiT8kXjo9LamEZ4iWHkq6bV80Vu0LYFQ1dTwJCnzSdfpoeZfZuVZzw/w1200-h630-p-k-no-nu/image4.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/mammut-simple-vision-encoder-text.html",
          "author": null,
          "description": "Posted by AJ Piergiovanni and Anelia Angelova, Research Scientists, Google Research\n\n\n\n\nVision-language foundational models are built on the premise of a single pre-training followed by subsequent adaptation to multiple downstream tasks. Two main and disjoint training scenarios are popular: a CLIP-style contrastive learning and next-token prediction. Contrastive learning trains the model to predict if image-text pairs correctly match, effectively building visual and text representations for the corresponding image and text inputs, whereas next-token prediction predicts the most likely next text token in a sequence, thus learning to generate text, according to the required task. Contrastive learning enables image-text and text-image retrieval tasks, such as finding the image that best match…",
          "link": "http://ai.googleblog.com/2023/05/mammut-simple-vision-encoder-text.html",
          "publishedOn": "2023-05-04T21:59:00.004Z",
          "wordCount": 27734,
          "title": "MaMMUT: A simple vision-encoder text-decoder architecture for multimodal tasks",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh53KlJZUXTHEd1ZhRav_9Hwl-MzCVTzans8VhEzushmfeKHUBfNDKTIPpVEbrDhtxlZWeBgLYsIsi6krB_GefP0SrNX-92H3eunTcCwjAH_t2KBW8wVMzZlvYbiltJM5xMFhy9Euclq7q33HgKgdvmsoXnOIbL-RkGMDeHn_ocy2puVKIqfkJ05REmuA/w1200-h630-p-k-no-nu/MAMMUT.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/05/indoorsim-to-outdoorreal-learning-to.html",
          "author": null,
          "description": "Posted by Joanne Truong, Student Researcher, and Wenhao Yu, Research Scientist, Robotics at Google\n\n\n\n\n\nTeaching mobile robots to navigate in complex outdoor environments is critical to real-world applications, such as delivery or search and rescue. However, this is also a challenging problem as the robot needs to perceive its surroundings, and then explore to identify feasible paths towards the goal. Another common challenge is that the robot needs to overcome uneven terrains, such as stairs, curbs, or rockbed on a trail, while avoiding obstacles and pedestrians. In our prior work, we investigated the second challenge by teaching a quadruped robot to tackle challenging uneven obstacles and various outdoor terrains. \n\n\n\nIn “IndoorSim-to-OutdoorReal: Learning to Navigate Outdoors without an…",
          "link": "http://ai.googleblog.com/2023/05/indoorsim-to-outdoorreal-learning-to.html",
          "publishedOn": "2023-05-03T17:22:00.000Z",
          "wordCount": 27868,
          "title": "IndoorSim-to-OutdoorReal: Learning to navigate outdoors without any outdoor experience",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhmX_nD3A8PWm8-BTB-ACmoSoiFt16URvxjvqYmkYFTTDdB8ykipmO9QH3mUTi5fWgoPe3A-LEfG4McZfZPmxj2WxI_g2TMr5qTDxYXjgqgGDd_CBBcjyWJIpAE_pHlFWtxvmkHM68E3TeodFyF_YvLC1Gtw1cGQaERfhIcq1jelMX-73KtlyqXzJ1D8g/w1200-h630-p-k-no-nu/IndoorSim-to-OutdoorReal%20hero.jpeg"
        }
      ]
    },
    {
      "title": "我爱自然语言处理",
      "feedUrl": "https://www.52nlp.cn/feed",
      "siteUrl": "https://www.52nlp.cn",
      "articles": []
    },
    {
      "title": "Language Log",
      "feedUrl": "https://languagelog.ldc.upenn.edu/nll/?feed=rss2",
      "siteUrl": "https://languagelog.ldc.upenn.edu/nll",
      "articles": [
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58816",
          "author": "Mark Liberman",
          "description": "Adam Taylor, Anastacia Galouchka & Heidi Levine, \"Ukrainians fighting outside Bakhmut see Russian mercenaries withdrawing\", Washington Post 5/282023: “The Wagner guys have left and the [regular Russians] have come in,” said a 26-year-old commander who asked to be identified by his call sign, Chichen. He used an anti-Russian ethnic slur to refer to the troops […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58816&utm_source=rss&utm_medium=rss&utm_campaign=vatnik-ethnic-or-political-slur",
          "publishedOn": "2023-05-28T13:31:58.000Z",
          "wordCount": 2529,
          "title": "\"Vatnik\" — ethnic or political slur?",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58803",
          "author": "Victor Mair",
          "description": "Taken at a restaurant in Hangzhou: The big Chinese characters say: Cant. gai1zai2 beng2  MSM  jīzǎi bǐng 鸡仔饼 \"phoenix cookie\" This is a type of chewy biscuit made with lard, originating in Guangzhou / Canton.  (source)  Its original name was Cant. siu2fung6 beng2  MSM xiǎofèng bǐng 小鳳餅 (\"little phoenix cake\"). Here are some recipes for \"phoenix cookies\".  I noticed plenty of fat and sesame, peanuts, […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58803&utm_source=rss&utm_medium=rss&utm_campaign=chickee-cakes",
          "publishedOn": "2023-05-28T03:27:05.000Z",
          "wordCount": 2565,
          "title": "Chickee cakes",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58791",
          "author": "Victor Mair",
          "description": "From Medievalists.net: \"By God’s Bones: Medieval Swear Words\" What were bad words in the Middle Ages? Cursing or swearing in medieval England was really different from today’s world. May, 2023 The post begins: Some historians have looked into the topic, such as Melissa Mohr, the author of Holy Sh*t: A Brief History of Swearing. In her […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58791&utm_source=rss&utm_medium=rss&utm_campaign=insults-oaths-and-curses-in-the-middle-ages",
          "publishedOn": "2023-05-26T12:37:34.000Z",
          "wordCount": 2717,
          "title": "Insults, oaths, and curses in the Middle Ages",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58795",
          "author": "Mark Liberman",
          "description": "Along with half a million other people, I logged onto Twitter at the designated hour to hear Elon Musk help Ron DeSantis announce his run for U.S. President. After about half an hour of  noises, silences, and puzzling graphics, I gave up — too early to catch the restart on a different account. This event […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58795&utm_source=rss&utm_medium=rss&utm_campaign=failure-to-launch",
          "publishedOn": "2023-05-25T12:19:56.000Z",
          "wordCount": 2206,
          "title": "\"Failure to Launch\"?",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58775",
          "author": "Victor Mair",
          "description": "From the website for Royal China Group, a famous Chinese restaurant group in London: The problem begins at the beginning:  jingcui 精粹 does not mean \"master\"; it means \"essence\". The entire text reads as follows: Zhōngguó yǐnshí wénhuà bódàjīngshēn,Huángcháo nǔlì bùxiè yánshǒu zhèngzōng chuántǒng Yuècài de fēnggé,bìng zài wèijué de lǐngyù zhōng xúnqiú túpò,zhǎngwò gùzhōng jīngcuì […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58775&utm_source=rss&utm_medium=rss&utm_campaign=master-the-essence-of-solid",
          "publishedOn": "2023-05-25T08:48:28.000Z",
          "wordCount": 2166,
          "title": "\"Master the essence of solid\"",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58786",
          "author": "Victor Mair",
          "description": "Methodologically, the following communication from Elizabeth J. W. Barber is too important to be left buried in a comment to this post:  \"ChatGPT does cuneiform studies\" (5/21/23) As I showed in my 1974 book, Archaeological Decipherment, there is a mathematical algorithm showing how much text one needs to PROVABLY accomplish a decipherment for what sort […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58786&utm_source=rss&utm_medium=rss&utm_campaign=decipherment-of-linear-a",
          "publishedOn": "2023-05-24T11:14:27.000Z",
          "wordCount": 2185,
          "title": "Decipherment of Linear A",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58781",
          "author": "Victor Mair",
          "description": "Is it really so? Uncannily and independently, Apollo Wu* sent me the following note before I made this post: Hànzì bùrú pīnyīn de guānjiàn lǐngyù shì páixù, jiǎnsuǒ hé réngōng zhìnéng. Fùzá, fánsuǒ, nán xué nán yòng shì wǒmen mùqián miànlín de kùnnán. Hànzì de luàn, biāozhìzhe Zhōngguó wénhuà de luàn! 汉字 比不上 字母文字 的 […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58781&utm_source=rss&utm_medium=rss&utm_campaign=chinese-characters-and-the-messiness-of-chinese-culture",
          "publishedOn": "2023-05-23T10:57:23.000Z",
          "wordCount": 2356,
          "title": "Chinese characters and the messiness of Chinese culture",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58778",
          "author": "Victor Mair",
          "description": "Plus Indic, plus Arabic, Korean, Vietnamese, Hokkien (Taiwanese), Hakka, and Fuzhou (Eastern Min). For an exciting read / ride, be sure to follow the whole thread, travelling through time and space. 零 originally didn't mean 'zero,' but 'small rain, drizzle.' Makes it easy to learn: Rain 雨 above, pronunciation 令 below (ok, tone is different). […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58778&utm_source=rss&utm_medium=rss&utm_campaign=learning-sinitic-and-sinoglyphic-zero",
          "publishedOn": "2023-05-22T12:00:04.000Z",
          "wordCount": 2005,
          "title": "Learning sinitic and sinoglyphic \"zero\"",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58767",
          "author": "Mark Liberman",
          "description": "I recently stumbled on this 5/10/2023 Medium article by David Brock, \"A Backup of Historical Proportions\" — which reminded me of the Xerox Palo Alto Research Center (\"PARC\") and the Xerox Alto. Those were the people and the machine that invented interactive GUIs on bit-mapped displays, the computer mouse, and so on — though it […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58767&utm_source=rss&utm_medium=rss&utm_campaign=hack-of-the-year-1980",
          "publishedOn": "2023-05-21T15:00:41.000Z",
          "wordCount": 2449,
          "title": "Hack of the year: 1980",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58745",
          "author": "Victor Mair",
          "description": "We have seen ChatGPT tell stories (and variants of the stories it tells), fancify Coleridge's famous poem on Xanadu, pose a serious challenge to the Great Firewall of China, mimic VHM, write Haiku, and perform all manner of amazing feats.  In a forthcoming post, we will witness its efforts to translate Chinese poetry.  Today, we […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58745&utm_source=rss&utm_medium=rss&utm_campaign=chatgpt-does-cuneiform-studies",
          "publishedOn": "2023-05-21T10:32:21.000Z",
          "wordCount": 3268,
          "title": "ChatGPT does cuneiform studies",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58752",
          "author": "Mark Liberman",
          "description": "Today's Tank McNamara: Of course the joke in this strip is the seven fingers on Tank's right hand, and the eight fingers on his left hand. A quick web search for {ai comic generator} turns out lots of options. As far as I can tell, these are all systems for creating images, not image sequences […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58752&utm_source=rss&utm_medium=rss&utm_campaign=ai-comic-strip-creation",
          "publishedOn": "2023-05-20T15:02:30.000Z",
          "wordCount": 2016,
          "title": "AI comic strip creation?",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58734",
          "author": "Victor Mair",
          "description": "As we have pointed out countless times on Language Log, if one wishes to learn a Sinitic language, one can concentrate on the characters (writing system), one can rely exclusively on romanization or other phoneticization, or one can devise various means for combining the two approaches.  Here is a clever, fun method for learning Cantonese […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58734&utm_source=rss&utm_medium=rss&utm_campaign=romanisation-gives-clarity",
          "publishedOn": "2023-05-20T04:48:59.000Z",
          "wordCount": 2362,
          "title": "\"Romanisation 'gives clarity'\"",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58720",
          "author": "Victor Mair",
          "description": "Since about the 90s, pho has been popping up all over the place.  It has been especially conspicuous after the turn of the millennium, and I think it adapted well to the pandemic as a quick and ready kind of street food.  I've often wondered whether it had anything to do with French \"fire\" or […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58720&utm_source=rss&utm_medium=rss&utm_campaign=pho",
          "publishedOn": "2023-05-17T13:34:32.000Z",
          "wordCount": 2899,
          "title": "Phở",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58724",
          "author": "Mark Liberman",
          "description": "In Maria Bartiromo's recent interview with James Comer (R-KY), there's an interesting speech error — \"quid pro crow\" for \"quid pro quo\": This being Language Log rather than Making Fun Of Politicians Log, I'm going to start by assuming that this was a slip of the tongue rather than an inadequate command of legal Latin […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58724&utm_source=rss&utm_medium=rss&utm_campaign=quid-pro-crow",
          "publishedOn": "2023-05-16T13:42:43.000Z",
          "wordCount": 2103,
          "title": "\"Quid pro crow\"",
          "enclosure": {
            "url": "https://languagelog.ldc.upenn.edu/myl/ComerQuidProCrowX1a.wav",
            "length": "64316",
            "type": "audio/wav"
          },
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58702",
          "author": "Victor Mair",
          "description": "Topolects matter: Taiwanese buys anti-CCP book, gets scam call from Chinese propagandist: Caller posing as Eslite Bookstore’s ‘marketing department’ tells consumer book content inappropriate By Stephanie Chiang, Taiwan News, Staff Reporter (5/14/23) Before delving into the substance of this report, I should mention that Eslite is a huge, and hugely influential, bookstore in Taiwan. AntC, […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58702&utm_source=rss&utm_medium=rss&utm_campaign=ccp-scamming-with-a-taiwanese-like-accent",
          "publishedOn": "2023-05-16T11:40:37.000Z",
          "wordCount": 2131,
          "title": "CCP scamming with a Taiwanese-like accent",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58706",
          "author": "Mark Liberman",
          "description": "The future of news? 🚨 BREAKING!!! Just when we thought we'd defeated the #CensorshipIndustrialComplex and @TuckerCarlson rose again on @Twitter, @elonmusk appoints #LindaYaccarino as new #TwitterCEO. Can an Executive Chair from the #WEF lead the revolution?#BreakingNews #EdisonThrustwell #WTF pic.twitter.com/uHt7NjCiO6 — Edison Thrustwell (@EdisonGPT) May 12, 2023 That's the first \"Edison Thrustwell\" tweet that I saw. […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58706&utm_source=rss&utm_medium=rss&utm_campaign=ai-anchorman-edisongpt",
          "publishedOn": "2023-05-15T11:52:37.000Z",
          "wordCount": 2133,
          "title": "AI Anchorman \"@EdisonGPT\"",
          "enclosure": {
            "url": "https://languagelog.ldc.upenn.edu/myl/EdisonThrustwell1.wav",
            "length": "77926",
            "type": "audio/wav"
          },
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58687",
          "author": "Victor Mair",
          "description": "Animal communication is not a favorite topic here at Language Log, but according to the following account, one project concerning it seems serious and is being conducted by credible scientists.  Although their claims for its ultimate significance may be inflated, I believe the research they are undertaking is worth considering, especially after hearing the clicks […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58687&utm_source=rss&utm_medium=rss&utm_campaign=sperm-whale-talk",
          "publishedOn": "2023-05-15T09:04:22.000Z",
          "wordCount": 2516,
          "title": "Sperm whale talk",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58691",
          "author": "Mark Liberman",
          "description": "Among the entries in the  2023 Eurovision Song Contest,  there's one of particular linguistic and political interest — from Croatia, Let 3's Mama ŠČ!: [The video of the song's final Eurovision performance is blocked (at least for now) in the U.S. …] The Croatian lyrics and an English translation are available on genius.com, and the […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58691&utm_source=rss&utm_medium=rss&utm_campaign=mama-sc",
          "publishedOn": "2023-05-14T13:37:33.000Z",
          "wordCount": 2522,
          "title": "\"Mama ŠČ!\"",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58671",
          "author": "Victor Mair",
          "description": "Sign on the campus of Zhōngguó kēxué jìshù dàxué 中国科学技术大学 (University of Science and Technology of China) telling people how to park: tíng hǎo chēliàng de hánglièshì 停好车辆的行列式* (\"park your vehicles well according to rows and columns\")*matrix determinant zuò hǎo xiūyǎng de wéijīfēn 做好修养的微积分* (\"cultivate yourself well to gradually accumulate points [i.e., merit]\")*calculus Parking according to one's profession. Selected […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58671&utm_source=rss&utm_medium=rss&utm_campaign=mathematical-parking",
          "publishedOn": "2023-05-14T03:36:45.000Z",
          "wordCount": 1921,
          "title": "Mathematical parking",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58680",
          "author": "Victor Mair",
          "description": "I'm in Ames, home of Iowa State University.  The next town down the road is Nevada.  What?  Yes, but it's /nəˈveɪdə/ nə-VAY-də, not /nɪˈvædə/ nih-VAD-ə; Spanish: [neˈβaða], and the locals I've met know the difference.  The same thing holds for Madrid, which is on the other side of Ames; it is /ˈmædrɪd/, not /məˈdrɪd/ mə-DRID, Spanish: [maˈðɾið]. […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58680&utm_source=rss&utm_medium=rss&utm_campaign=iowa-town-names",
          "publishedOn": "2023-05-13T14:04:03.000Z",
          "wordCount": 1933,
          "title": "Iowa town names",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58677",
          "author": "Victor Mair",
          "description": "From Nancy Friedman: I'm writing about \"zen\" in brand names and corporate lingo, having been amused by an email from Medium (where I'm a contributing writer) touting the platform's updates as \"Project Zen\"–a name chosen \"because that's our goal: a zen-like reading experience.\"   I'm not sure I know what a \"zen-like reading experience\" is […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58677&utm_source=rss&utm_medium=rss&utm_campaign=zen-again",
          "publishedOn": "2023-05-13T11:31:10.000Z",
          "wordCount": 2232,
          "title": "Zen again",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58650",
          "author": "Victor Mair",
          "description": "Last weekend, I was in Omaha for the annual Berkshire-Hathaway Shareholders Meeting.  Not that I am a shareholder of Berkshire-Hathaway, but simply because I was curious to see two nonagenarian financial wizards hold forth in front of 20,000 enthusiastic fans for a whole day.  I wasn't disappointed, though I must confess that I didn't understand […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58650&utm_source=rss&utm_medium=rss&utm_campaign=tucky",
          "publishedOn": "2023-05-12T10:15:06.000Z",
          "wordCount": 2490,
          "title": "-tucky",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58647",
          "author": "Victor Mair",
          "description": "[This is a guest post by Scott Mauldin] I recently visited Marrakesh and was fascinated by the signs that I submit in the attached photographs. Ostensibly these were originally a kind of business sign that artisans and professionals could hang on their businesses or homes to advertise their profession, but they have evolved into something […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58647&utm_source=rss&utm_medium=rss&utm_campaign=signs-of-the-phonetics-of-moroccan-french",
          "publishedOn": "2023-05-11T02:36:36.000Z",
          "wordCount": 2066,
          "title": "Signs of the phonetics of Moroccan French",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58636",
          "author": "Victor Mair",
          "description": "Sign in Hong Kong: fàng gǒu hòu qǐng lìjí qīnglǐ 放狗後請立即清理 \"Please clean up immediately after letting your dog out\" This is a case where the English and the Chinese both make sense, and the one is a rough approximation of the other, but the English is not an exact translation of the Chinese. Selected […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58636&utm_source=rss&utm_medium=rss&utm_campaign=clean-up-after-your-dog",
          "publishedOn": "2023-05-11T02:26:48.000Z",
          "wordCount": 1918,
          "title": "Clean Up After Your Dog",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58652",
          "author": "Mark Liberman",
          "description": "A recent Dinosaur Comic features a passionate investigation into alleged philosophical plagiarism: The mouseover title: \"For my next thought experiment, suppose a man, a super man, gets turned into energy and is widely considered to be the same man, but then one day splits into two energy guys: one red and one blue. WHICH IS […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58652&utm_source=rss&utm_medium=rss&utm_campaign=retraction-watch-swamp-man-thing",
          "publishedOn": "2023-05-10T23:33:21.000Z",
          "wordCount": 3546,
          "title": "Retraction Watch: Swamp Man Thing",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58630",
          "author": "Victor Mair",
          "description": "Sign on the elevator doors of a Taipei department store: Here's the writing on the sign (romanized transcriptions and parenthetical English translations have been added by me [VHM]): One Boy Atmosphere / Function Jīnéng  qīng lǚ xié xìliè機能 輕旅鞋系列(\"Function    light travel slippers series\") 2F Shèngdà kāimù盛大開幕(\"Grand Opening\") New Opening Dàiyánrén GEmma Wú Yìngjié 代言人 GEmma 吳映潔(\"Spokesperson […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58630&utm_source=rss&utm_medium=rss&utm_campaign=crappy-metaphor-slippers-that-make-you-feel-like-youre-stepping-on-shit",
          "publishedOn": "2023-05-08T02:41:46.000Z",
          "wordCount": 2726,
          "title": "Crappy metaphor:  slippers that make you feel like you're stepping on shit",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58633",
          "author": "Victor Mair",
          "description": "The hotel where I'm staying in Morgantown, West Virginia kindly gave me a complimentary rectangular packet of freshmint toothpaste.  At the top right corner of the packet, there was a dotted, diagonal line with the words \"TEAR HERE\" printed above it.  Alas, no matter how hard I tried, I could not tear it open. Then […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58633&utm_source=rss&utm_medium=rss&utm_campaign=tear-here",
          "publishedOn": "2023-05-07T10:49:38.000Z",
          "wordCount": 2179,
          "title": "TEAR here",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58624",
          "author": "Victor Mair",
          "description": "Here I am in the middle of Missouri, Macon, to be exact (not precisely the geographical center, but not very far from it either, and certainly not near the edges of the state), and I still don't know the origins of this authentic Doggyism:  \"Move out of Missouri!\" As I explained in \"How to pronounce […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58624&utm_source=rss&utm_medium=rss&utm_campaign=move-out-of-missouri",
          "publishedOn": "2023-05-06T10:20:45.000Z",
          "wordCount": 2326,
          "title": "\"Move out of Missouri\"",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58621",
          "author": "Victor Mair",
          "description": "From 9 Chickweed Lane (4/28/23): (source) Question from Francois Lang, who sent this in:   \"Don't agonized screams have semantic or pragmatic content?\" Selected readings \"More 'screaming and spluttering' from Matthew Engel\" (7/21/11) \"The emerging science of gendered yelling\" (9/5/06)",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58621&utm_source=rss&utm_medium=rss&utm_campaign=i-dont-think-it-exactly-qualifies-as-language",
          "publishedOn": "2023-05-05T04:20:11.000Z",
          "wordCount": 1894,
          "title": "\"I don't think it exactly qualifies as language\"",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58615",
          "author": "Victor Mair",
          "description": "A couple of days ago, I was having a conversation with one of my former students at a tea/coffee shop (that's what I call 'em because I don't drink coffee very often, almost never). We were talking about a controversy in Mongolian historiography.  It was a question of whether it is ever suitable to use […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58615&utm_source=rss&utm_medium=rss&utm_campaign=shribe-in-mongolian-historiography",
          "publishedOn": "2023-05-04T03:58:50.000Z",
          "wordCount": 2242,
          "title": "\"Shribe\" in Mongolian historiography",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58604",
          "author": "Victor Mair",
          "description": "And no dabbling either (see \"Selected readings\"). Qǐng wù xī shuǐ 請勿嬉水 \"Please don't play in the water\" The anonymous contributor who took this photograph in Hong Kong and sent it to me remarked:  \"I believe it is correct English though.\" You will also see signs that translate xī shuǐ 嬉水 (\"play in the water\") as (\"frolicking\") […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58604&utm_source=rss&utm_medium=rss&utm_campaign=no-paddling",
          "publishedOn": "2023-05-03T03:45:38.000Z",
          "wordCount": 1966,
          "title": "No paddling",
          "imageUrl": null
        },
        {
          "id": "https://languagelog.ldc.upenn.edu/nll/?p=58613",
          "author": "Mark Liberman",
          "description": "Frazz for 4/25/2023: Let's not forget Plato's argument against the use of written language in education (From Phaedrus, in the voice of Socrates quoting Thamus): SOCRATES: At the Egyptian city of Naucratis, there was a famous old god, whose name was Theuth; the bird which is called the Ibis is sacred to him, and he […]",
          "link": "https://languagelog.ldc.upenn.edu/nll/?p=58613&utm_source=rss&utm_medium=rss&utm_campaign=llms-in-education-the-historical-view",
          "publishedOn": "2023-05-01T11:37:42.000Z",
          "wordCount": 2533,
          "title": "LLMs in education: the historical view",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Data Mining: Text Mining, Visualization and Social Media",
      "feedUrl": "https://datamining.typepad.com/data_mining/rss.xml",
      "siteUrl": "https://datamining.typepad.com/data_mining/",
      "articles": []
    },
    {
      "title": "A Butterfly Valley",
      "feedUrl": "https://zeyuan.wordpress.com/feed/",
      "siteUrl": "https://zeyuan.wordpress.com",
      "articles": []
    }
  ],
  "cliVersion": "1.15.1"
}