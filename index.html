<!DOCTYPE html>
<html lang="en">

  <head>
    <title>osmos::feed</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="osmos::feed" href="feed.atom" />
    <link href="index.css?v1.14.4" rel="stylesheet" />
    <!-- %before-head-end.html% -->
  </head>

  <body>
    <!-- %after-body-begin.html% -->
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-10 datetime="2023-06-10T12:51:43.000Z">2023-06-10</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-10 datetime="2023-06-10T12:51:43.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59074"
                        open
                      >
                        <summary class="article-expander__title">&quot;The beautiful mind paper boxes&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59074&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;the-beautiful-mind-paper-boxes">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>The most recent Trump indictment reproduces this exchange of text messages (p. 11) : Trump Employee 2: We can definitely make it work if we move his papers into the lake room? Trump Employee 1: There is still a little room in the shower where his other stuff is. Is it only his papers he […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59071"
                        open
                      >
                        <summary class="article-expander__title">InternLM</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59071&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;internlm">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>As I am about to deliver a keynote address to an international conference on Chinese language pedagogy, I receive news of this new LLM that knocks my socks off: InternLM is a multilingual large language model jointly developed by Shanghai AI Lab and SenseTime (with equal contribution), in collaboration with the Chinese University of Hong […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59030"
                        open
                      >
                        <summary class="article-expander__title">ChatGPT does Emily Dickinson writing a recipe for Pad Thai (and haiku too)</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59030&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;chatgpt-does-emily-dickinson-writing-a-recipe-for-pad-thai-and-haiku-too">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>From Scott D. Seligman via Facebook:   ChatGPT is really creeping me out. I asked it for a recipe for Pad Thai in the form of an Emily Dickinson poem. I&#x27;m no poetry maven, but the damned thing seems to have the ability to turn a phrase, at least some of the time. Below is […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-09 datetime="2023-06-09T22:23:10.000Z">2023-06-09</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-09 datetime="2023-06-09T22:23:10.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53183"
                        open
                      >
                        <summary class="article-expander__title">statistical modeling with R [book review]</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/10/statistical-modeling-with-r-book-review/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://global.oup.com/academic/covers/pdp/9780192859013" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Statistical Modeling with R (A dual frequentist and Bayesian approach for life scientists) is a recent book written by Pablo Inchausti, from Uruguay. In a highly personal and congenial style (witness the preface), with references to (fiction) books that enticed me to buy them. The book was sent to me by the JASA book editor […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html"
                        open
                      >
                        <summary class="article-expander__title">Imagen Editor and EditBench: Advancing and evaluating text-guided image inpainting</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/06/imagen-editor-and-editbench-advancing.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCOhgOtXQGmv1getpW3oHgD-4dCvqg9Q_Srs4qnD-FtydmHFb6XEesvUNGkf1eXRemuok7hb58ikl8tSw4xoNSwDd_YZkrdxVgj-6Fb5AeM6DkRB32URqFjpdzLYZaOtjjHcOqXzDmh7KdshdtaNtU1cVgv69UbvwW-v4-yu6h0-XDBe7vyo6PB23dyg/w1200-h630-p-k-no-nu/Imagen%20Editor%20&amp;%20EditBench%20hero.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Su Wang and Ceslee Montgormery, Research Engineers, Google Research





In the last few years, text-to-image generation research has seen an explosion of breakthroughs (notably, Imagen, Parti, DALL-E 2, etc.) that have naturally permeated into related topics. In particular, text-guided image editing (TGIE) is a practical task that involves editing generated and photographed visuals rather than completely redoing them. Quick, automated, and controllable editing is a convenient solution when recreating visuals would be time-consuming or infeasible (e.g., tweaking objects in vacation photos or perfecting fine-grained details on a cute pup generated from scratch). Further, TGIE represents a substantial opportunity to improve training of foundational models themselves. Multimodal mod…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59056"
                        open
                      >
                        <summary class="article-expander__title">Self-owning peeve of the week: Compersion</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59056&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;self-owning-peeve-of-the-week-compersion">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Email from Florent Moncomble [links added]: A few months ago, the distinguished member of the Académie française Alain Finkielkraut was featured in a video where he deplored the loss of “a word which used to exist in the [French] language and disappeared from it”, ie. “compersion”. Apparently, little does he know that “compersion” was actually coined […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.04933"
                        open
                      >
                        <summary class="article-expander__title">InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural
  Language Understanding</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04933">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Junda Wu, Tong Yu, Rui Wang, Zhao Song, Ruiyi Zhang, Handong Zhao,
  Chaochao Lu, Shuai Li, Ricardo Henao</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.04746"
                        open
                      >
                        <summary class="article-expander__title">Using Large Language Model Annotations for Valid Downstream Statistical
  Inference in Social Science: Design-Based Semi-Supervised Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04746">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Naoki Egami, Musashi Jacobs-Harukawa, Brandon M. Stewart, Hanying Wei</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2112.14233"
                        open
                      >
                        <summary class="article-expander__title">Multitask Learning and Bandits via Robust Statistics</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.14233">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Kan Xu, Hamsa Bastani</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2303.04288"
                        open
                      >
                        <summary class="article-expander__title">Polynomial Time and Private Learning of Unbounded Gaussian Mixture
  Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.04288">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Jamil Arbas, Hassan Ashtiani, Christopher Liaw</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2301.09554"
                        open
                      >
                        <summary class="article-expander__title">Deep Learning Meets Sparse Regularization: A Signal Processing
  Perspective</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.09554">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Rahul Parhi, Robert D. Nowak</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"
                        open
                      >
                        <summary class="article-expander__title">The asymptotics of r(4,t)</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://gilkalai.files.wordpress.com/2023/06/erdos-prize-r4t.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/"
                        open
                      >
                        <summary class="article-expander__title">The asymptotics of r(4,t)</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/06/09/the-asymptotics-of-r4t/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://gilkalai.files.wordpress.com/2023/06/erdos-prize-r4t.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Originally posted on Points And Lines: 
Jacques Verstraete and I posted a preprint on the arXiv today on the off-diagonal Ramsey number . In short, we show that , which is just a factor shy from the upper bound proved…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-08 datetime="2023-06-08T22:23:02.000Z">2023-06-08</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-08 datetime="2023-06-08T22:23:02.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53208"
                        open
                      >
                        <summary class="article-expander__title">de-MCM’d</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/09/de-mcmd/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/06/temp-2.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This morning I received a message from the MCM 23 conference organisers that my registration [submitted two months ago] was declined for lack of room! I wonder why the organisers did not opt for broadcasting in a second amphitheater, as was done for ISBA in Edinburgh. Unfortunately, we have attained the maximal capacity of the […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"
                        open
                      >
                        <summary class="article-expander__title">Determining Ramsey numbers using finite geometry</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://gilkalai.files.wordpress.com/2023/06/screenshot-2023-06-08-at-13.18.39.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Originally posted on Anurag&#x27;s Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/"
                        open
                      >
                        <summary class="article-expander__title">Determining Ramsey numbers using finite geometry</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/06/08/determining-ramsey-numbers-using-finite-geometry/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://gilkalai.files.wordpress.com/2023/06/screenshot-2023-06-08-at-13.18.39.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Originally posted on Anurag&#x27;s Math Blog: 
Sam Mattheus and Jacques Verstraete have posted a preprint today where they solve the classic open problem of determining the asymptotics of the Ramsey number . They show that which is just a…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59014"
                        open
                      >
                        <summary class="article-expander__title">Transliterations aplenty</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59014&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;transliterations-aplenty">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>From Simon Cartoon: Here&#x27;s something I just saw at a local bakery in Berkeley, CA. Simon explains: We have English, Spanish, and then French in the last position, no issues there. 3rd position is Mandarin Chinese via pinyin: Who is this for? What is the population of people uncomfortable reading in English, but comfortable reading […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59026"
                        open
                      >
                        <summary class="article-expander__title">What is the logical form of that?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59026&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;what-is-the-logical-form-of-that">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>This post wanders down a series of rabbit holes, from a couple of dead economists, to a dead philosopher, to a dead Supreme Court justice. It all started with Eric Rahim&#x27;s obituary in the Guardian, which links to the British Academy&#x27;s obituary for Piero Sraffa, which includes this passage: He also formed a close friendship […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59024"
                        open
                      >
                        <summary class="article-expander__title">Greco-Sinitic ψάμμος / ʃˠa  mɑk̚ (&quot;desert&quot;)</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59024&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;greco-sinitic-%25cf%2588%25ce%25ac%25ce%25bc%25ce%25bc%25ce%25bf%25cf%2582-%25ca%2583%25cb%25a0a-mak%25cc%259a-desert">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>[This is a guest post by Chau Wu] The psammo- component of the winning word in this year&#x27;s Scripps National Spelling Bee, psammophile, is of interest to me because it is a good example of European-Sinitic lexical correspondence. The Ancient Greek word psámmos (ψάμμος) means ‘sand’.  When used together with a definite article (ἡ ψάμμος), […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >inFERENCe</button>
                  <a class="source-heading__link" href="https://www.inference.vc/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="6481b5876965110001df8c10"
                        open
                      >
                        <summary class="article-expander__title">We may finally crack Maths. But should we?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://www.inference.vc/we-may-finally-crack-maths-but-should-we/">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Automating mathematical theorem proving has been a long standing goal of artificial intelligence and indeed computer science. It&#x27;s one of the areas I became very interested in recently. This is because I feel we may have the ingredients needed to make very, very significant progress:

a structured search</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2203.07475"
                        open
                      >
                        <summary class="article-expander__title">Invariance in Policy Optimisation and Partial Identifiability in Reward
  Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2203.07475">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Joar Skalse, Matthew Farrugia-Roberts, Stuart Russell, Alessandro
  Abate, Adam Gleave</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.04637"
                        open
                      >
                        <summary class="article-expander__title">Transformers as Statisticians: Provable In-Context Learning with
  In-Context Algorithm Selection</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04637">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.04539"
                        open
                      >
                        <summary class="article-expander__title">Multimodal Learning Without Labeled Multimodal Data: Guarantees and
  Applications</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.04539">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Paul Pu Liang, Chun Kai Ling, Yun Cheng, Alex Obolenskiy, Yudong Liu,
  Rohan Pandey, Alex Wilf, Louis-Philippe Morency, Ruslan Salakhutdinov</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2212.02457"
                        open
                      >
                        <summary class="article-expander__title">Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics,
  Directional Convergence, and Equilibria</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2212.02457">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Tengyuan Liang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.03962"
                        open
                      >
                        <summary class="article-expander__title">PILLAR: How to make semi-private learning more effective</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.03962">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Francesco Pinto, Yaxi Hu, Fanny Yang, Amartya Sanyal</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >我爱自然语言处理</button>
                  <a class="source-heading__link" href="https://www.52nlp.cn">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://www.52nlp.cn/?p&#x3D;13474"
                        open
                      >
                        <summary class="article-expander__title">2023世界人工智能大会“AI生成与垂直大语言模型”论坛重磅来袭！</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://www.52nlp.cn/2023%e4%b8%96%e7%95%8c%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%a4%a7%e4%bc%9aai%e7%94%9f%e6%88%90%e4%b8%8e%e5%9e%82%e7%9b%b4%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e8%ae%ba">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>当前AI生成与大语言模型的指数级发展，为相关产业链带来新的发展引擎，也为AI落地应用带来新的想象空间。2023 […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >科学空间|Scientific Spaces</button>
                  <a class="source-heading__link" href="https://kexue.fm/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://kexue.fm/archives/9648"
                        open
                      >
                        <summary class="article-expander__title">Naive Bayes is all you need ?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://kexue.fm/archives/9648">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>很抱歉，起了这么个具有标题党特征的题目。在写完《NBCE：使用朴素贝叶斯扩展LLM的Context处理长度》之后，笔者就觉得朴素贝叶斯（Naive Bayes）跟Attention机制有很多相同...</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-07 datetime="2023-06-07T22:23:28.000Z">2023-06-07</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-07 datetime="2023-06-07T22:23:28.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53161"
                        open
                      >
                        <summary class="article-expander__title">uniform spacings</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/08/uniform-spacings/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/spacingz.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>A riddle on uniform spacings!, namely when considering eight iid Uniform (0,1) variates as visiting times and three further iid Uniform (0,1) variates as server availability times, with unit service time, the question being the probability a server is available for a ninth visiting time, T⁹. Which can be decomposed into four cases: at least […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html"
                        open
                      >
                        <summary class="article-expander__title">Evaluating speech synthesis in many languages with SQuId</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/06/evaluating-speech-synthesis-in-many.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheQlvvXBg5s0pU2XQwb7gxDhd_sNEHcE2EifW94vv-gYgpKF8V8BG5hKqw91qF5IzbZFnp2vZr1Am0OIQLAl29XK-MAh3XpOP05CzqCSLy1arpJ5gC4mJ4OMs0CGxc0iE4I9Rn5xcZaLFitBEK0lFQF1yURehcGbPYBsnKmpqE21VQHKovgAz76av4pg/w1200-h630-p-k-no-nu/SQuId%20hero.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Thibault Sellam, Research Scientist, Google





Previously, we presented the 1,000 languages initiative and the Universal Speech Model with the goal of making speech and language technologies available to billions of users around the world. Part of this commitment involves developing high-quality speech synthesis technologies, which build upon projects such as VDTTS and AudioLM, for users that speak many different languages.






listening tests, during which dozens of annotators listen to the utterances one after the other to determine how natural they sound. While humans are still unbeaten at detecting whether a piece of text sounds natural, this process can be impractical — especially in the early stages of research projects, when engineers need rapid feedback to test and re…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;92
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2302.08215"
                        open
                      >
                        <summary class="article-expander__title">Aligning Language Models with Preferences through f-divergence
  Minimization</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.08215">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Dongyoung Go, Tomasz Korbak, Germ\&#x27;an Kruszewski, Jos Rozen, Nahyeon
  Ryu, Marc Dymetman</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2004.13612"
                        open
                      >
                        <summary class="article-expander__title">Denise: Deep Robust Principal Component Analysis for Positive
  Semidefinite Matrices</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13612">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen,
  Josef Teichmann</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/1901.09036"
                        open
                      >
                        <summary class="article-expander__title">Orthogonal Statistical Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.09036">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Dylan J. Foster, Vasilis Syrgkanis</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.03406"
                        open
                      >
                        <summary class="article-expander__title">Deep neural networks architectures from the perspective of manifold
  learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.03406">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>German Magai</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >PyTorch Website</button>
                  <a class="source-heading__link" href="https://pytorch.org/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://pytorch.org/blog/join-pytorch/"
                        open
                      >
                        <summary class="article-expander__title">Join the PyTorch Foundation: Membership Now Open</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://pytorch.org/blog/join-pytorch/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://pytorch.org/assets/images/pytorch-logo.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In September 2022, we welcomed PyTorch to the Linux Foundation from Meta, which formed the PyTorch Foundation with founding members AMD, Amazon Web Services (AWS), Google, Meta, Microsoft, and NVIDIA.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59005"
                        open
                      >
                        <summary class="article-expander__title">Unknown language #15</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;59005&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;unknown-language-15">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Yuan (? dynasty (1271-1368) jade seal in the Bristol Museum: Know what language this is, or even what it says? Yes? Please get back to me. No? Please retweet it until somebody does. (But be aware, it&#x27;s stumped some quite clever people who&#x27;ve already been asked, so it isn&#x27;t obvious) Also, advance apologies if it […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Python⇒Speed</button>
                  <a class="source-heading__link" href="https://pythonspeed.com/atom.xml">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://pythonspeed.com/articles/speeding-up-numba/"
                        open
                      >
                        <summary class="article-expander__title">Understanding CPUs can help speed up Numba and NumPy code</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://pythonspeed.com/articles/speeding-up-numba/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://pythonspeed.com/assets/titles/speeding-up-numba.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>When you need to speed up your NumPy processing—or just reduce your memory usage—the Numba just-in-time compiler is a great tool.
It lets you write Python code that gets compiled at runtime to machine code, allowing you to get the kind of speed improvements you’d get from languages like C, Fortran, or Rust.
Or at least, that’s the theory.
In practice, your initial Numba code may be no faster than the NumPy equivalent.
But you can do better, once you have a better understanding of how CPUs work.
And this knowledge will help you more broadly with any compiled language.
In this article we’ll:
Consider a simple image-processing problem.
Try, and initially fail, to speed it up with Numba.
We’ll review just a little bit how modern CPUs are so fast, and the limits of compilers.
Based on our new understanding, we’ll then show how we can tweak our code to run 25× faster than our original version.
Read more...</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >DeepMind Blog</button>
                  <a class="source-heading__link" href="https://www.deepmind.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools"
                        open
                      >
                        <summary class="article-expander__title">Optimising computer systems with more generalised AI tools</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://www.deepmind.com/blog/optimising-computer-systems-with-more-generalised-ai-tools">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://assets-global.website-files.com/621e749a546b7592125f38ed/64807bf25294d9863578ef5a_DM_Hero1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Based on reinforcement learning, our AI models AlphaZero and MuZero have achieved superhuman performance winning games. Now, they’re expanding their capabilities to help optimise resources in data centres and advance video compression – and most recently, our specialised version of AlphaZero, called AlphaDev, discovered new algorithms that are already accelerating the software applications at the foundations of our digital society.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms"
                        open
                      >
                        <summary class="article-expander__title">AlphaDev discovers faster sorting algorithms</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://assets-global.website-files.com/621e749a546b7592125f38ed/64807d68d425bdd22cc43233_Copy%20of%20alphadev_01_06_crops_crop5_0114%20(1).png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In our paper published today in Nature, we introduce AlphaDev, an artificial intelligence (AI) system that uses reinforcement learning to discover enhanced computer science algorithms – surpassing those honed by scientists and engineers over decades.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-06 datetime="2023-06-06T22:23:40.000Z">2023-06-06</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-06 datetime="2023-06-06T22:23:40.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53202"
                        open
                      >
                        <summary class="article-expander__title">stack overflow on strike</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/07/stack-overflow-on-strike/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/06/temp-1.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58949"
                        open
                      >
                        <summary class="article-expander__title">Sinitic exclamations in English speech</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58949&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;sinitic-exclamations-in-english-speech">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Listen to Malaysian comedian Nigel Ng (aka &quot;Uncle Roger&quot;), who has had his Weibo and bilibili social media accounts banned due to &quot;violation of relevant regulations&quot;: The ban comes one day after Ng uploaded this clip to various social media platforms. pic.twitter.com/8Wwf2aTrfZ — Aaron Busch (@tripperhead) May 19, 2023 Under the subject line &quot;Uncle Roger […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58977"
                        open
                      >
                        <summary class="article-expander__title">LLMs as coders?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58977&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;llms-as-coders">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>I&#x27;ve recently seen many articles like this one, &quot;You probably don&#x27;t need to learn to code anymore&quot; (Medium 6/5/2023), arguing that Large Language Models will make human programming (and human programmers) unnecessary. These arguments puzzle me, because my experience with LLMs suggests that they can&#x27;t be relied on even for very simple programming tasks. After […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;12
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58917"
                        open
                      >
                        <summary class="article-expander__title">Sinitic semiliteracy</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58917&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;sinitic-semiliteracy">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>From a story on CNN on &quot;begpackers&quot; in Asia: The photo is captioned, &quot;Professor Stephen Pratt posed as a begpacker to do fieldwork in Hong Kong.&quot; The sign says: qǐng bāngzhù wǒ zài quán shìjiè lǚxíng 請幫助我在全世界旅行 &quot;Please help me travel around the world&quot; Despite the fractured grammar (the zài 在* is especially egregious), all the […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58888"
                        open
                      >
                        <summary class="article-expander__title">Annals of biang</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58888&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;annals-of-biang">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Shop sign in Budapest: Don&#x27;t be cowed by the quixotic orthography.  The noodles are delicious, and you can get them right here in Philadelphia, and many other cities around the world. Selected readings &quot;Biangbiang: authentic Xi&#x27;an grub in the heart of Philadelphia&#x27;s University City&quot; (6/9/22) &quot;A Chinese character that is harder to write than &#x27;biang&#x27;&quot; […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html"
                        open
                      >
                        <summary class="article-expander__title">Visual captions: Using large language models to augment video conferences with dynamic visuals</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/06/visual-captions-using-large-language.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiuQA-vtXoNbaUU05FVACHS1vMdvtOxK5pcusTeWW2dkG9OpPiKHLtRuCbtNlAMX4TyRYYNNO0NMhCPTDsGDkVzs2FJvITsOknz8GcO4hJ7Eds57YVXdFtQW3fEzNxiLq0MQC2G3GW0ESfVqOBogCsbIDc1YfQpIgKsJm0idXET58ia266bNjb63HHuDw/w1200-h630-p-k-no-nu/VisualCaptions.gif" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Ruofei Du, Research Scientist, and Alex Olwal, Senior Staff Research Scientist, Google Augmented Reality




Recent advances in video conferencing have significantly improved remote video communication through features like live captioning and noise cancellation. However, there are various situations where dynamic visual augmentation would be useful to better convey complex and nuanced information. For example, when discussing what to order at a Japanese restaurant, your friends could share visuals that would help you feel more confident about ordering the “Sukiyaki”. Or when talking about your recent family trip to San Francisco, you may want to show a photo from your personal album.




In “Visual Captions: Augmenting Verbal Communication With On-the-fly Visuals”, presented at …</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2106.02770"
                        open
                      >
                        <summary class="article-expander__title">Deep Bayesian Active Learning for Accelerating Stochastic Simulation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02770">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Dongxia Wu, Ruijia Niu, Matteo Chinazzi, Alessandro Vespignani, Yi-An
  Ma, Rose Yu</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2301.11990"
                        open
                      >
                        <summary class="article-expander__title">Alignment with human representations supports robust few-shot learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.11990">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Ilia Sucholutsky, Thomas L. Griffiths</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.02533"
                        open
                      >
                        <summary class="article-expander__title">On Emergence of Clean-Priority Learning in Early Stopped Neural Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.02533">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Chaoyue Liu, Amirhesam Abedsoltan, Mikhail Belkin</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.03065"
                        open
                      >
                        <summary class="article-expander__title">LibAUC: A Deep Learning Library for X-Risk Optimization</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.03065">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Zhuoning Yuan, Dixian Zhu, Zi-Hao Qiu, Gang Li, Xuanhui Wang, Tianbao
  Yang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.02235"
                        open
                      >
                        <summary class="article-expander__title">Learning Linear Causal Representations from Interventions under General
  Nonlinear Mixing</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.02235">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Simon Buchholz, Goutham Rajendran, Elan Rosenfeld, Bryon Aragam,
  Bernhard Sch\&quot;olkopf, Pradeep Ravikumar</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-05 datetime="2023-06-05T22:23:56.000Z">2023-06-05</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-05 datetime="2023-06-05T22:23:56.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53194"
                        open
                      >
                        <summary class="article-expander__title">remembering May 35th</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/06/remembering-may-35th/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://hkprotesting.files.wordpress.com/2020/07/e3808a5e69c8835e697a5e5ba9ae5ad90e78988e3808b.jpeg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Windows On Theory</button>
                  <a class="source-heading__link" href="https://windowsontheory.org">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://windowsontheory.org/?p&#x3D;8630"
                        open
                      >
                        <summary class="article-expander__title">The (local) unit of intelligence is FLOPs</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/e5d88d991fc175c7676c6ada658142cd44b9887c69c15521.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>[Crossposting again on Lesswrong and Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it’s hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure … Continue reading The (local) unit of intelligence is FLOPs</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Windows On Theory</button>
                  <a class="source-heading__link" href="https://windowsontheory.org">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://windowsontheory.org/?p&#x3D;8630"
                        open
                      >
                        <summary class="article-expander__title">The (local) unit of intelligence is FLOPs</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://windowsontheory.org/2023/06/05/the-local-unit-of-intelligence-is-flops/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/e5d88d991fc175c7676c6ada658142cd44b9887c69c15521.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>[Crossposting again on Lesswrong and Windowsontheory, with the hope I am not overstaying my welcome in LW.] Wealth can be measured by dollars. This is not a perfect measurement: it’s hard to account for purchasing power and circumstances when comparing people across varying countries or time periods. However, within a particular place and time, one can measure … Continue reading The (local) unit of intelligence is FLOPs</span>
                                &ensp;<span class="article-reading-time">(&hairsp;15
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58960"
                        open
                      >
                        <summary class="article-expander__title">Bilingual road signs</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58960&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;bilingual-road-signs">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>…in New Zealand. Phil Pennington, &quot;Analysis: National opposed bilingual road signs, so what does the evidence say?&quot;, RNZ 62/2023: Analysis – Bilingual road signs send a signal – that the country values te reo Māori. But going bilingual was confusing and National would not support it, National&#x27;s Simeon Brown told voters in blue-ribbon Tauranga recently. […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.14076"
                        open
                      >
                        <summary class="article-expander__title">Towards Understanding the Dynamics of Gaussian-Stein Variational
  Gradient Descent</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14076">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Tianle Liu, Promit Ghosal, Krishnakumar Balasubramanian, Natesh S.
  Pillai</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.01212"
                        open
                      >
                        <summary class="article-expander__title">Linked Deep Gaussian Process Emulation for Model Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01212">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Deyu Ming, Daniel Williamson</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.05248"
                        open
                      >
                        <summary class="article-expander__title">Towards Understanding Generalization of Macro-AUC in Multi-label
  Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.05248">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Guoqiang Wu, Chongxuan Li, Yilong Yin</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2209.12778"
                        open
                      >
                        <summary class="article-expander__title">Developing A Visual-Interactive Interface for Electronic Health Record
  Labeling: An Explainable Machine Learning Approach</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.12778">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Donlapark Ponnoprat, Parichart Pattarapanitchai, Phimphaka Taninpong,
  Suthep Suantai, Natthanaphop Isaradech, Thiraphat Tanphiriyakun</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.01613"
                        open
                      >
                        <summary class="article-expander__title">Hyperparameter Learning under Data Poisoning: Analysis of the Influence
  of Regularization via Multiobjective Bilevel Optimization</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.01613">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Javier Carnerero-Cano, Luis Mu\~noz-Gonz\&#x27;alez, Phillippa Spencer,
  Emil C. Lupu</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-04 datetime="2023-06-04T22:23:59.000Z">2023-06-04</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-04 datetime="2023-06-04T22:23:59.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53177"
                        open
                      >
                        <summary class="article-expander__title">fusing simulation with data science [18-19 July 2023]</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/05/fusing-simulation-with-data-science-18-19-july-2023/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2013/05/img_5108.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In collaboration with the Met Office, my friend and Warwick colleague Rito Dutta is co-organising a two-day workshop in Warwick in July on the use of statistics and machine learning tools in weather prediction. Attendance is free, but registration needed for tea breaks.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58924"
                        open
                      >
                        <summary class="article-expander__title">Greater China Co-Prosperity Sushi and Ramen Kitchen</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58924&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;greater-china-co-prosperity-sushi-and-ramen-kitchen">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Shouldn’t that be Zhonghua Pan-Asian Kitchen Ramen Wok Premium Sushi? pic.twitter.com/tTUaWidjL3 — James Millward 米華健 (@JimMillward) June 4, 2023 The small characters at the top of the sign say: Hànzú Yàzhōu chúfáng 汉族亚洲厨房 &quot;Han ethnicity Asian kitchen&quot; The wording in large Hànyǔ Pīnyīn (&quot;Sinitic spelling&quot;) is HANZU, the roman letter transcription of the first two […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58846"
                        open
                      >
                        <summary class="article-expander__title">Revelation:  Scythians and Shang</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58846&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;revelation-scythians-and-shang">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>I was stunned when I read the following article in the South China Morning Post, both because it was published in Hong Kong, which is now completely under the censorial control of the People&#x27;s Republic of China (PRC) / Chinese Communist Party (CCP), and because it raises some disturbing political issues and troubling linguistic problems. […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;18
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58832"
                        open
                      >
                        <summary class="article-expander__title">Annals of inventive pinyin: rua</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58832&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;annals-of-inventive-pinyin-rua">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>This exercise video shows a woman repeating the syllable &quot;rua&quot; to describe a move that she makes: Problem is that there&#x27;s no Sinoglyph (hànzì 漢字 / 汉字) for writing that in Modern Standard Mandarin (MSM), although some might claim that it can be written with this character, ruó 挼 (&quot;rub; knead; massage&quot;). According to this table, &quot;rua&quot; is not a […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58927"
                        open
                      >
                        <summary class="article-expander__title">The rise (and fall?) of shiesties</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58927&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;the-rise-and-fall-of-shiesties">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Last month I learned a new word, shiesty — which rhymes with feisty, as if it were written &quot;sheisty&quot; — because shiesties have been banned on the local transit system (&quot;SEPTA&quot;): Your browser does not support the audio element. Keith, I&#x27;m sure if you walked around Philadelphia, live in Philadelphia, work in Philadelphia, you&#x27;ve seen […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19299"
                        open
                      >
                        <summary class="article-expander__title">The Role Of Social Media On Selected Businesses In Nigeria In The Era Of
  Covid-19 Pandemic</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19299">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Cajetan Ihemebiri, Elochukwu Ukwandu, Lizzy Ofusori, Comfort
  Olebara</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19822"
                        open
                      >
                        <summary class="article-expander__title">Near-Atomic Scale Perspective on the Oxidation of Ti$_3$C$_2$T$_x$
  MXenes: Insights from Atom Probe Tomography</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19822">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Mathias Kr\&quot;amer, Bar Favelukis, Ayman A. El-Zoka, Maxim Sokol, Brian
  A. Rosen, Noam Eliaz, Se-Ho Kim, Baptiste Gault</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19297"
                        open
                      >
                        <summary class="article-expander__title">Visual Exploratory Data Analysis of the Covid-19 Pandemic in Nigeria:
  Two Years after the Outbreak</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19297">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Ugochukwu Orji, Modesta Ezema, Elochukwu Ukwandu, Chikaodili
  Ugwuishiwu, Ezugwu Obianuju, Malachi Egbugha</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19544"
                        open
                      >
                        <summary class="article-expander__title">To what extent can control policies influence the epidemic spreading? --
  A data-driven analysis based on the first wave of COVID-19</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19544">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Dongyan Zhang, Wanqi Wen, Wuyue Yang, Liangrong Peng, Changjingn
  Zhuge, Liu Hong</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-03 datetime="2023-06-03T22:23:04.000Z">2023-06-03</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-03 datetime="2023-06-03T22:23:04.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53153"
                        open
                      >
                        <summary class="article-expander__title">The Beacon [jatp]</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/04/the-beacon-jatp/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/kaust.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58921"
                        open
                      >
                        <summary class="article-expander__title">Dog bites man:  Indian wins spelling bee</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58921&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;dog-bites-man-indian-wins-spelling-bee">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>New old news: &quot;Dev Shah wins 2023 Scripps National Spelling Bee by correctly spelling &#x27;psammophile&#x27;&quot;Chris BumbacaUSA TODAY (6/1/23) Another year, same story: The 2023 Scripps National Spelling Bee ended the old-fashioned way. Two competitors left on the stage. No spell-off required. Dev Shah, an eighth-grader from Largo, Florida, spelled &quot;psammophile&quot; correctly to win the 95th […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58876"
                        open
                      >
                        <summary class="article-expander__title">Pronouncing &quot;DeSantis&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58876&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;pronouncing-desantis">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>The question of how to pronounce Ron DeSantis&#x27; last name — and the observation that the candidate, his wife, and his campaign have made different choices at different times — is among the more trivial bits of political flotsam recently washing up on the shores of social and political media. In fact the issue has […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58874"
                        open
                      >
                        <summary class="article-expander__title">Sinological formatting</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58874&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;sinological-formatting">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>I recently received this book: Sūn Sīmiǎo, Sabine Wilms.  Healing Virtue-Power: Medical Ethics and the Doctor&#x27;s Dao.  Whidbey Island WA:  Happy Goat Productions, 2022. ISBN:  978-1-7321571-9-4 website As soon as I started to leaf through the volume, I was struck by its unusual format and usages:  every Chinese character is accompanied by Hanyu Pinyin phonetic […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.13249"
                        open
                      >
                        <summary class="article-expander__title">Tsunami and megathrust earthquake disaster prevention warnings:
  Real-time monitoring of the genesis processes with Physical Wavelets</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13249">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Fumihide Takeda</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2110.06211"
                        open
                      >
                        <summary class="article-expander__title">Diagonalization of Polynomial-Time Deterministic Turing Machines Via
  Nondeterministic Turing Machine</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2110.06211">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Tianrong Lin</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-02 datetime="2023-06-02T22:23:48.000Z">2023-06-02</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-02 datetime="2023-06-02T22:23:48.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53169"
                        open
                      >
                        <summary class="article-expander__title">van Dantzig seminar</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/03/van-dantzig-seminar/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/06/temp.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58869"
                        open
                      >
                        <summary class="article-expander__title">Just &lt; Not the same as it was</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58869&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;just-not-the-same-as-it-was">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>I listened to this Harry Styles song dozens of times on the radio, and every time I heard him sing &quot;You know it&#x27;s just the same as it was&quot; over and over: It was only after watching the video and reading the subtitles that I realized he was saying &quot;You know it&#x27;s not the same […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58855"
                        open
                      >
                        <summary class="article-expander__title">Austronesian languages of Taiwan</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58855&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;austronesian-languages-of-taiwan">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Handbook of Formosan Languages (Online): The Indigenous Languages of Taiwan Editors: Paul Jen-kuei Li, Academia SinicaElizabeth Zeitoun, Academia SinicaRik De Busser, National Taiwan Cheng-Chi University Leiden:  Brill, 2023 Outright Purchase: € 2249 / US dollars 2495Subscription: € 350 / US dollars 390 A print version is forthcoming (September 2023 ; 3 vols, ~ 2200 pp.) […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58857"
                        open
                      >
                        <summary class="article-expander__title">Historical speech styles</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58857&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;historical-speech-styles">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>A recent Dinosaur Comics strip features T-Rex imitating (a certain kind of) speech style from the 1940s: Mouseover title: &quot;to t-rex&#x27;s mind, and mine as well, all of the past takes place around the 1930s. well sure! and why not?&quot; The next strip: Mouseover title: &quot;you want a gender-neutral way to address a room, well here […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html"
                        open
                      >
                        <summary class="article-expander__title">AVFormer: Injecting vision into frozen speech models for zero-shot AV-ASR</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/06/avformer-injecting-vision-into-frozen.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgEpnVot9nisUn-B5GierK8WfqI_mhVwKmJ1mjj_FOdOr2_74gIwvwSJgobi8K_a1uq9n5B3pO4Zi5-mXoE0mzOw32WW-ny6kBThTgHIv3wtQVrpjdMdhMYCSqustzlN7ArP3y2jSqEy_2rlz_zXfsfp05Z3svQ7bu8rYJAN6V1ellHjbL-SJOHraUHEQ/w1200-h630-p-k-no-nu/AVFormer.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Arsha Nagrani and Paul Hongsuck Seo, Research Scientists, Google Research






Automatic speech recognition (ASR) is a well-established technology that is widely adopted for various applications such as conference calls, streamed video transcription and voice commands. While the challenges for this technology are centered around noisy audio inputs, the visual stream in multimodal videos (e.g., TV, online edited videos) can provide strong cues for improving the robustness of ASR systems — this is called audiovisual ASR (AV-ASR).
 

Although lip motion can provide strong signals for speech recognition and is the most common area of focus for AV-ASR, the mouth is often not directly visible in videos in the wild (e.g., due to egocentric viewpoints, face coverings, and low resolution…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;92
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.00145"
                        open
                      >
                        <summary class="article-expander__title">On the Expressive Power of Neural Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00145">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Jan Holstermann</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2306.00342"
                        open
                      >
                        <summary class="article-expander__title">Combining Explicit and Implicit Regularization for Efficient Learning in
  Deep Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2306.00342">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Dan Zhao</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2210.13512"
                        open
                      >
                        <summary class="article-expander__title">Provably Learning Diverse Features in Multi-View Data with Midpoint
  Mixup</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.13512">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Muthu Chidambaram, Xiang Wang, Chenwei Wu, Rong Ge</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.15408"
                        open
                      >
                        <summary class="article-expander__title">Towards Revealing the Mystery behind Chain of Thought: a Theoretical
  Perspective</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15408">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He, Liwei Wang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2205.10457"
                        open
                      >
                        <summary class="article-expander__title">Robust Sensible Adversarial Learning of Deep Neural Networks for Image
  Classification</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10457">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Jungeum Kim, Xiao Wang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-06-01 datetime="2023-06-01T22:23:10.000Z">2023-06-01</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-06-01 datetime="2023-06-01T22:23:10.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53139"
                        open
                      >
                        <summary class="article-expander__title">Galton and Watson voluntarily skipping some generations</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/02/galton-and-watson-voluntarily-skipping-some-generations/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/06/gw.gif" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>A riddle on a form of a Galton-Watson process, starting from a single unit, where no one dies but rather, at each of 100 generations, Dog either opts for a Uniform number υ of additional units or increments a counter γ by this number υ, its goal being to optimise γ. The solution proposed by […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58807"
                        open
                      >
                        <summary class="article-expander__title">Know your relatives in Chinese</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58807&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;know-your-relatives-in-chinese">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Randy Alexander reports that during a guitar lesson, he asked his student: Māmā de dìdi de nǚér shì biǎomèi ma？ 妈妈的弟弟的女儿是表妹吗？ &quot;Is your mother&#x27;s younger brother&#x27;s daughter your younger maternal female cousin?&quot; The student replied: wǒyě bútài qīngchǔ děngyíxià 我也不太清楚等一下 &quot;I don&#x27;t quite know either, wait a minute.&quot; Here&#x27;s a screen shot of the student&#x27;s […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58835"
                        open
                      >
                        <summary class="article-expander__title">Multilingual TV series</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58835&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;multilingual-tv-series">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Coby Lubliner called my attention to the Belgian Netflix series &quot;Rough Diamonds.&quot; It takes place in Antwerp, so the default language is Dutch (Flemish), but the characters move into Yiddish, English and French with the greatest of ease. The subtitles don&#x27;t indicate the language spoken in any one scene, except that when [Yiddish] appears what is […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58838"
                        open
                      >
                        <summary class="article-expander__title">&quot;Wordectomy&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58838&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;wordectomy">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>The medical news site MedPage Today has recently added a daily game page, &quot;Wordectomy&quot;, in which a medically-relevant Wikipedia article is presented with all letters blanked out except for punctuation and (some) function words, e.g. The instructions: Welcome to Wordectomy — a word game from MedPage Today where you try to determine what medical condition is […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html"
                        open
                      >
                        <summary class="article-expander__title">Retrieval-augmented visual-language pre-training</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/06/retrieval-augmented-visual-language-pre.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrAmMW5q9tM1RpbnrDdMiw-kXeP1kkCNH0Vj_ZmqxTxoT45GYgBjIKXBZ2eF7_mtQ-ijE7h5g-O69tcbfmEoqifjP6ssE12hsRzIE-fl64ZdaFBL0f0Ruu-Ix3R-dy1jhBibQXoxZCpF0CVsdLWwK1aS-JJGu2wcPdyZkPMeRQFP-AqZq5nYUq0KTOAQ/w1200-h630-p-k-no-nu/REVEAL%20hero.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Ziniu Hu, Student Researcher, and Alireza Fathi, Research Scientist, Google Research, Perception Team





Large-scale models, such as T5, GPT-3, PaLM, Flamingo and PaLI, have demonstrated the ability to store substantial amounts of knowledge when scaled to tens of billions of parameters and trained on large text and image datasets. These models achieve state-of-the-art results on downstream tasks, such as image captioning, visual question answering and open vocabulary recognition. Despite such achievements, these models require a massive volume of data for training and end up with a tremendous number of parameters (billions in many cases), resulting in significant computational requirements. Moreover, the data used to train these models can become outdated, requiring re-training…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19535"
                        open
                      >
                        <summary class="article-expander__title">Low-rank extended Kalman filtering for online learning of neural
  networks from streaming data</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19535">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Peter Chang, Gerardo Dur\&#x60;an-Mart\&#x27;in, Alexander Y Shestopaloff, Matt
  Jones, Kevin Murphy</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19588"
                        open
                      >
                        <summary class="article-expander__title">Active causal structure learning with advice</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19588">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Davin Choo, Themis Gouleakis, Arnab Bhattacharyya</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19640"
                        open
                      >
                        <summary class="article-expander__title">Optimal Estimates for Pairwise Learning with Deep ReLU Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19640">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Junyu Zhou, Shuo Huang, Han Feng, Ding-Xuan Zhou</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19420"
                        open
                      >
                        <summary class="article-expander__title">What and How does In-Context Learning Learn? Bayesian Model Averaging,
  Parameterization, and Generalization</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19420">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Yufeng Zhang, Fengzhuo Zhang, Zhuoran Yang, Zhaoran Wang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19440"
                        open
                      >
                        <summary class="article-expander__title">Machine learning with tree tensor networks, CP rank constraints, and
  tensor dropout</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19440">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Hao Chen, Thomas Barthel</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-31 datetime="2023-05-31T22:23:44.000Z">2023-05-31</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-31 datetime="2023-05-31T22:23:44.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53126"
                        open
                      >
                        <summary class="article-expander__title">the alpinist [film review]</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/06/01/the-alpinist-film-review/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2018/08/squamish22.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Watched (with supplementary oxygen) The Alpinist in the plane to Jeddah. It is a documentary (made by the same filmmakers who filmed the Dawn Wall) about the amazing Canadian alpinist Marc-André Leclerc, who died in 2018 on the Mendenhall Glacier, Alaska, in an avalanche, after achieving extraordinary complex solo climbs as eg on Mount Robbson, […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/?p&#x3D;24142"
                        open
                      >
                        <summary class="article-expander__title">Questions and Concerns About Google’s Quantum Supremacy Claim</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.  Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical … Continue reading →</span>
                                &ensp;<span class="article-reading-time">(&hairsp;18
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/?p&#x3D;24142"
                        open
                      >
                        <summary class="article-expander__title">Questions and Concerns About Google’s Quantum Supremacy Claim</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/05/31/questions-and-concerns-about-googles-quantum-supremacy-claim/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://gilkalai.files.wordpress.com/2023/05/table3-krs.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Yosi Rinott, Tomer Shoham, and I wrote our third paper regarding our statistical study of the Google 2019 supremacy experiment.  Our paper presents statistical analysis that may shed light on the quality and reliability of the data and the statistical … Continue reading →</span>
                                &ensp;<span class="article-reading-time">(&hairsp;18
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/large-sequence-models-for-software.html"
                        open
                      >
                        <summary class="article-expander__title">Large sequence models for software development activities</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/large-sequence-models-for-software.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj8_SbpjaNoBFB_ymmlPa_9YTKL4tOAPfWFHajgnphxoPc3dTXyORaOPk1kN1TP8gVgdjiyPtqGfEYmVCyYIIBdd2ICEIROmNVMCbJmcmT0wLoRWow8djNms5ejc-pfk2Bx_79P7FCnN5PGAQqnXq8YWkn5sX_oLwP0NSoq3IvaV9WyiYhYk1wYK8cTEg/w1200-h630-p-k-no-nu/DIDACT-Hero.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Petros Maniatis and Daniel Tarlow, Research Scientists, Google




Software isn’t created in one dramatic step. It improves bit by bit, one little step at a time — editing, running unit tests, fixing build errors, addressing code reviews, editing some more, appeasing linters, and fixing more errors — until finally it becomes good enough to merge into a code repository. Software engineering isn’t an isolated process, but a dialogue among human developers, code reviewers, bug reporters, software architects and tools, such as compilers, unit tests, linters and static analyzers. 




Today we describe DIDACT (​​Dynamic Integrated Developer ACTivity), which is a methodology for training large machine learning (ML) models for software development. The novelty of DIDACT is that it uses …</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >科学空间|Scientific Spaces</button>
                  <a class="source-heading__link" href="https://kexue.fm/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://kexue.fm/archives/9632"
                        open
                      >
                        <summary class="article-expander__title">关于NBCE方法的一些补充说明和分析</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://kexue.fm/archives/9632">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>上周在《NBCE：使用朴素贝叶斯扩展LLM的Context处理长度》中，我们介绍了一种基于朴素贝叶斯来扩展LLM的Context长度的方案NBCE（Naive Bayes-based Conte...</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/1905.09195"
                        open
                      >
                        <summary class="article-expander__title">On the minimax optimality and superiority of deep neural network
  learning over sparse parameter spaces</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.09195">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Satoshi Hayakawa, Taiji Suzuki</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.18806"
                        open
                      >
                        <summary class="article-expander__title">Prediction Error-based Classification for Class-Incremental Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18806">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Micha{\l} Zaj\k{a}c, Tinne Tuytelaars, Gido M. van de Ven</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2303.12147"
                        open
                      >
                        <summary class="article-expander__title">Universal Approximation Property of Hamiltonian Deep Neural Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.12147">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Muhammad Zakwan, Massimiliano d&#x27;Angelo, Giancarlo Ferrari-Trecate</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.18404"
                        open
                      >
                        <summary class="article-expander__title">Conformal Prediction with Large Language Models for Multi-Choice
  Question Answering</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18404">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Bhawesh Kumar, Charlie Lu, Gauri Gupta, Anil Palepu, David Bellamy,
  Ramesh Raskar, Andrew Beam</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.19187"
                        open
                      >
                        <summary class="article-expander__title">Generating with Confidence: Uncertainty Quantification for Black-box
  Large Language Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.19187">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Zhen Lin, Shubhendu Trivedi, Jimeng Sun</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-30 datetime="2023-05-30T22:23:27.000Z">2023-05-30</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-30 datetime="2023-05-30T22:23:27.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53120"
                        open
                      >
                        <summary class="article-expander__title">optimal importance sampling</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/31/optimal-importance-sampling/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2013/09/img_1743-e1378378499746.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In Stein Π-Importance Sampling, Congye Wang et al. (mostly from Newcastle, UK) build an MCMC scheme with invariant distribution Π targeting a distribution P, showing that the optimal solution (in terms of a discrepancy) differs from P when the chain is Stein-sampled, e..g. via kernel discrepancies. In terms of densities, the solution is the correction […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >inFERENCe</button>
                  <a class="source-heading__link" href="https://www.inference.vc/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="64724f2336605b0001f5e7fa"
                        open
                      >
                        <summary class="article-expander__title">Mortal Komputation: On Hinton&#x27;s argument for superhuman AI.</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://www.inference.vc/mortal-computation-hintons/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://www.inference.vc/content/images/2023/05/hqdefault-1.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Last week in Cambridge was Hinton bonanza. He visited the university town where he was once an undergraduate in experimental psychology, and gave a series of back-to-back talks, Q&amp;A sessions, interviews, dinners, etc. He was stopped on the street by random passers-by who recognised him from the lecture,</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2302.00878"
                        open
                      >
                        <summary class="article-expander__title">The contextual lasso: Sparse linear models via deep neural networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.00878">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Ryan Thompson, Amir Dezfouli, Robert Kohn</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2206.03299"
                        open
                      >
                        <summary class="article-expander__title">Generalization Error Bounds for Deep Neural Networks Trained by SGD</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2206.03299">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Mingze Wang, Chao Ma</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.18270"
                        open
                      >
                        <summary class="article-expander__title">Learning Two-Layer Neural Networks, One (Giant) Step at a Time</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.18270">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Yatin Dandi, Florent Krzakala, Bruno Loureiro, Luca Pesce, Ludovic
  Stephan</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2006.07356"
                        open
                      >
                        <summary class="article-expander__title">Implicit Bias of Gradient Descent for Mean Squared Error Regression with
  Two-Layer Wide Neural Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07356">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Hui Jin, Guido Mont\&#x27;ufar</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.17608"
                        open
                      >
                        <summary class="article-expander__title">Reward Collapse in Aligning Large Language Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17608">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Ziang Song, Tianle Cai, Jason D. Lee, Weijie J. Su</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/?p&#x3D;23932"
                        open
                      >
                        <summary class="article-expander__title">Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://gilkalai.files.wordpress.com/2023/05/cern22.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>(Click to enlarge.) Plan for this post: Prologue: “Can we sleep soundly at night?” Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel … Continue reading →</span>
                                &ensp;<span class="article-reading-time">(&hairsp;16
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/?p&#x3D;23932"
                        open
                      >
                        <summary class="article-expander__title">Physics Related News: Israel Joining CERN, Pugwash and Global Zero, The Replication Crisis, and MAX the Damon.</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/05/30/physics-related-news-israel-joining-cern-pugwash-and-global-zero-the-replication-crisis-and-max-the-damon/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://gilkalai.files.wordpress.com/2023/05/cern22.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>(Click to enlarge.) Plan for this post: Prologue: “Can we sleep soundly at night?” Meeting Ephraim Halevi (former head of the Israeli Mossad) in 2007. Israel and CERN, an evening in honor of Eliezer Rabinovici: The story of how Israel … Continue reading →</span>
                                &ensp;<span class="article-reading-time">(&hairsp;16
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-29 datetime="2023-05-29T22:23:39.000Z">2023-05-29</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-29 datetime="2023-05-29T22:23:39.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53111"
                        open
                      >
                        <summary class="article-expander__title">reciprocal importance sampling</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/30/reciprocal-importance-sampling/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2012/01/dscn1366.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>In a recent arXival, Metodiev et al. (including my friend Adrian Raftery, who is spending the academic year in Paris) proposed a new version of reciprocal importance sampling, expanding the proposal we made with Darren Wraith (2009) of using a Uniform over an HPD region. It is called THAMES, hence the picture (of London, not […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.17119"
                        open
                      >
                        <summary class="article-expander__title">Manifold Regularization for Memory-Efficient Training of Deep Neural
  Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17119">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Shadi Sartipi, Edgar A. Bernal</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.17063"
                        open
                      >
                        <summary class="article-expander__title">Vecchia Gaussian Process Ensembles on Internal Representations of Deep
  Neural Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17063">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Felix Jimenez, Matthias Katzfuss</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.17126"
                        open
                      >
                        <summary class="article-expander__title">Large Language Models as Tool Makers</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.17126">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2210.02157"
                        open
                      >
                        <summary class="article-expander__title">The Influence of Learning Rule on Representation Dynamics in Wide Neural
  Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2210.02157">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Blake Bordelon, Cengiz Pehlevan</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.16597"
                        open
                      >
                        <summary class="article-expander__title">Neural Architecture Search for Parameter-Efficient Fine-tuning of Large
  Pre-trained Language Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.16597">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Neal Lawton, Anoop Kumar, Govind Thattai, Aram Galstyan, Greg Ver
  Steeg</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-28 datetime="2023-05-28T22:23:16.000Z">2023-05-28</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-28 datetime="2023-05-28T22:23:16.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53104"
                        open
                      >
                        <summary class="article-expander__title">Model-Based Clustering, Classification, and Density Estimation Using mclust in R [not a book review]</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/29/model-based-clustering-classification-and-density-estimation-using-mclust-in-r-not-a-book-review/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/temp-5.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58816"
                        open
                      >
                        <summary class="article-expander__title">&quot;Vatnik&quot; — ethnic or political slur?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58816&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;vatnik-ethnic-or-political-slur">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Adam Taylor, Anastacia Galouchka &amp; Heidi Levine, &quot;Ukrainians fighting outside Bakhmut see Russian mercenaries withdrawing&quot;, Washington Post 5/282023: “The Wagner guys have left and the [regular Russians] have come in,” said a 26-year-old commander who asked to be identified by his call sign, Chichen. He used an anti-Russian ethnic slur to refer to the troops […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58803"
                        open
                      >
                        <summary class="article-expander__title">Chickee cakes</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58803&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;chickee-cakes">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Taken at a restaurant in Hangzhou: The big Chinese characters say: Cant. gai1zai2 beng2  MSM  jīzǎi bǐng 鸡仔饼 &quot;phoenix cookie&quot; This is a type of chewy biscuit made with lard, originating in Guangzhou / Canton.  (source)  Its original name was Cant. siu2fung6 beng2  MSM xiǎofèng bǐng 小鳳餅 (&quot;little phoenix cake&quot;). Here are some recipes for &quot;phoenix cookies&quot;.  I noticed plenty of fat and sesame, peanuts, […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-27 datetime="2023-05-27T22:23:11.000Z">2023-05-27</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-27 datetime="2023-05-27T22:23:11.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53091"
                        open
                      >
                        <summary class="article-expander__title">Natural nested sampling</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/28/natural-nested-sampling/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43586-022-00121-x/MediaObjects/43586_2022_121_Fig2_HTML.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>“The nested sampling algorithm solves otherwise challenging, high-dimensional integrals by evolving a collection of live points through parameter space. The algorithm was immediately adopted in cosmology because it partially overcomes three of the major difficulties in Markov chain Monte Carlo, the algorithm traditionally used for Bayesian computation. Nested sampling simultaneously returns results for model comparison […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-26 datetime="2023-05-26T22:23:58.000Z">2023-05-26</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-26 datetime="2023-05-26T22:23:58.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;52378"
                        open
                      >
                        <summary class="article-expander__title">on control variates</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/27/on-control-variates/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://nips.cc/media/PosterPDFs/NeurIPS%202022/72007983849f4fcb0ad565439834756b.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>A few months ago, I had to write a thesis evaluation of Rémi Leluc’s PhD, which contained several novel Monte Carlo proposals on control variates and importance techniques. For instance, Leluc et al. (Statistics and Computing, 2021) revisits the concept of control variables by adding a perspective of control variable selection using LASSO. This prior […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html"
                        open
                      >
                        <summary class="article-expander__title">Foundation models for reasoning on charts</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEifdjDjOARh4hb7ejkosuWwJDb1xEhPVkFiJQpa9Go1uhkRMy58esTSN9DXgWN5N74ZS5P4dyvG6FnZ_F-EzxNl0FcwFycDqEBOvabOoudTXbEXxSohAUbjvKYu_GKu3XNCumZLxBpzeUbjIZ1pgXtXZofVrBdR19g2dGBZ1gIYOCr6h9wYPQY-sXdhbQ/w1200-h630-p-k-no-nu/MatCha.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Julian Eisenschlos, Research Software Engineer, Google Research





Visual language is the form of communication that relies on pictorial symbols outside of text to convey information. It is ubiquitous in our digital life in the form of iconography, infographics, tables, plots, and charts, extending to the real world in street signs, comic books, food labels, etc. For that reason, having computers better understand this type of media can help with scientific communication and discovery, accessibility, and data transparency.
 

While computer vision models have made tremendous progress using learning-based solutions since the advent of ImageNet, the focus has been on natural images, where all sorts of tasks, such as classification, visual question answering (VQA), captioning, det…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html"
                        open
                      >
                        <summary class="article-expander__title">Barkour: Benchmarking animal-level agility with quadruped robots</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/barkour-benchmarking-animal-level.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrBp7HZPrMFbbwb27gWZsRozP9LIfcn-Jc-MRqipA7Wi93OOwcpuYFDA_wJVepiwlAHT8cbtKn_IatNGhbX0qBHodjCWrluPI9_56aGOsScLWhGkvQ9jNaQUwU1uZNgg0U4-dWFwVyK3aCZPl5Z6frQimBaIZuyZHnQBY-KOUHmdOJNpkDCW1I8Fl6Bw/w1200-h630-p-k-no-nu/barkour%20hero.gif" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Ken Caluwaerts and Atil Iscen, Research Scientists, Google





Creating robots that exhibit robust and dynamic locomotion capabilities, similar to animals or humans, has been a long-standing goal in the robotics community. In addition to completing tasks quickly and efficiently, agility allows legged robots to move through complex environments that are otherwise difficult to traverse. Researchers at Google have been pursuing agility for multiple years and across various form factors. Yet, while researchers have enabled robots to hike or jump over some obstacles, there is still no generally accepted benchmark that comprehensively measures robot agility or mobility. In contrast, benchmarks are driving forces behind the development of machine learning, such as ImageNet for computer…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;92
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58791"
                        open
                      >
                        <summary class="article-expander__title">Insults, oaths, and curses in the Middle Ages</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58791&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;insults-oaths-and-curses-in-the-middle-ages">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>From Medievalists.net: &quot;By God’s Bones: Medieval Swear Words&quot; What were bad words in the Middle Ages? Cursing or swearing in medieval England was really different from today’s world. May, 2023 The post begins: Some historians have looked into the topic, such as Melissa Mohr, the author of Holy Sh*t: A Brief History of Swearing. In her […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;9
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2108.13097"
                        open
                      >
                        <summary class="article-expander__title">A theory of representation learning gives a deep generalisation of
  kernel methods</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13097">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Adam X. Yang, Maxime Robeyns, Edward Milsom, Ben Anson, Nandi Schoots,
  Laurence Aitchison</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2304.06767"
                        open
                      >
                        <summary class="article-expander__title">RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.06767">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng
  Zhang, Kashun Shum, Tong Zhang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.15786"
                        open
                      >
                        <summary class="article-expander__title">Theoretical Guarantees of Learning Ensembling Strategies with
  Applications to Time Series Forecasting</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15786">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Hilaf Hasson, Danielle C. Maddix, Yuyang Wang, Gaurav Gupta, Youngsuk
  Park</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2302.03067"
                        open
                      >
                        <summary class="article-expander__title">Memory-Based Meta-Learning on Non-Stationary Distributions</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03067">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Tim Genewein, Gr\&#x27;egoire Del\&#x27;etang, Anian Ruoss, Li Kevin Wenliang,
  Elliot Catt, Vincent Dutordoir, Jordi Grau-Moya, Laurent Orseau, Marcus
  Hutter, Joel Veness</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.15598"
                        open
                      >
                        <summary class="article-expander__title">Linear Neural Network Layers Promote Learning Single- and Multiple-Index
  Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15598">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Suzanna Parkinson, Greg Ongie, Rebecca Willett</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-25 datetime="2023-05-25T23:09:00.003Z">2023-05-25</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-25 datetime="2023-05-25T23:09:00.003Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html"
                        open
                      >
                        <summary class="article-expander__title">Differentially private clustering for large-scale datasets</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/differentially-private-clustering-for.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjG6jKdvoUMqPI-WRS9KnK6Clj8W-uXfR_Pd3BfLIeSQGMb7sJtp1dTNlITKnF5CTtw4c-JtRIi9r_ySKXmKLeIGBTeLozFnQWQhp6aiXMHVctZjqQfcl2LGDywb3SktCtPwQV9OgAJZ9PyMsAOxeUxxjdRzTf3CIApROfx6hSFBv7NItHKjB8LbFgiTQ/w1200-h630-p-k-no-nu/COVID.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Vincent Cohen-Addad and  Alessandro Epasto, Research Scientists, Google Research, Graph Mining team




Clustering is a central problem in unsupervised machine learning (ML) with many applications across domains in both industry and academic research more broadly. At its core, clustering consists of the following problem: given a set of data elements, the goal is to partition the data elements into groups such that similar objects are in the same group, while dissimilar objects are in different groups. This problem has been studied in math, computer science, operations research and statistics for more than 60 years in its myriad variants. Two common forms of clustering are metric clustering, in which the elements are points in a metric space, like in the k-means problem, and grap…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/google-research-at-io-2023.html"
                        open
                      >
                        <summary class="article-expander__title">Google Research at I/O 2023</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/google-research-at-io-2023.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjUde5cQAPm8frw1OO3Ub-QIx91GGpY3crqacseMxvbkJ55GMmjma-dqjEmxg8XtAJpSEYvyVWsFagmNVLzugwLWJiQ6OHPm0c1yDgIgXzTHRRF4NpoOJRl5p75u3O11uYuOmPNJW97Xyciox0OJni48f3MrMGmAPqVudm9mtsUUtGaCvt9vIQrc6h3NA/w1200-h630-p-k-no-nu/GoogleIO.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by James Manyika, SVP Google Research and Technology &amp; Society, and Jeff Dean, Chief Scientist, Google DeepMind and Google Research




Wednesday, May 10th was an exciting day for the Google Research community as we watched the results of months and years of our foundational and applied work get announced on the Google I/O stage. With the quick pace of announcements on stage, it can be difficult to convey the substantial effort and unique innovations that underlie the technologies we presented. So today, we’re excited to reveal more about the research efforts behind some of the many exciting announcements at this year&#x27;s I/O. 


 

PaLM 2 
PaLM 2, is built on advances in compute-optimal scaling, scaled instruction-fine tuning and improved dataset mixture. By fine-tuning and instructi…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53085"
                        open
                      >
                        <summary class="article-expander__title">EMS 2023, Warsaw</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/26/ems-2023-warsaw/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/ems23.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58795"
                        open
                      >
                        <summary class="article-expander__title">&quot;Failure to Launch&quot;?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58795&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;failure-to-launch">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Along with half a million other people, I logged onto Twitter at the designated hour to hear Elon Musk help Ron DeSantis announce his run for U.S. President. After about half an hour of  noises, silences, and puzzling graphics, I gave up — too early to catch the restart on a different account. This event […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58775"
                        open
                      >
                        <summary class="article-expander__title">&quot;Master the essence of solid&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58775&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;master-the-essence-of-solid">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>From the website for Royal China Group, a famous Chinese restaurant group in London: The problem begins at the beginning:  jingcui 精粹 does not mean &quot;master&quot;; it means &quot;essence&quot;. The entire text reads as follows: Zhōngguó yǐnshí wénhuà bódàjīngshēn,Huángcháo nǔlì bùxiè yánshǒu zhèngzōng chuántǒng Yuècài de fēnggé,bìng zài wèijué de lǐngyù zhōng xúnqiú túpò,zhǎngwò gùzhōng jīngcuì […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/?p&#x3D;24359"
                        open
                      >
                        <summary class="article-expander__title">Test your intuition 52: Can you predict the ratios of ones?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice’s task is to choose, at a certain time of her choice, some number (smaller than the number of unseen … Continue reading →</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Combinatorics and more</button>
                  <a class="source-heading__link" href="https://gilkalai.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://gilkalai.wordpress.com/?p&#x3D;24359"
                        open
                      >
                        <summary class="article-expander__title">Test your intuition 52: Can you predict the ratios of ones?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://gilkalai.wordpress.com/2023/05/25/test-your-intuition-52-can-you-predict-the-ratios-of-ones/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://s0.wp.com/i/blank.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Bob choses a sequences of zeroes and ones of length . The bits are presented to Alice one by one. Alice’s task is to choose, at a certain time of her choice, some number (smaller than the number of unseen … Continue reading →</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.14961"
                        open
                      >
                        <summary class="article-expander__title">Deep Learning for Survival Analysis: A Review</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14961">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Simon Wiegrebe, Philipp Kopper, Raphael Sonabend, Andreas Bender</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.14765"
                        open
                      >
                        <summary class="article-expander__title">Masked Bayesian Neural Networks : Theoretical Guarantee and its
  Posterior Inference</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14765">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Insung Kong, Dongyoon Yang, Jongjin Lee, Ilsang Ohn, Gyuseung Baek,
  Yongdai Kim</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.14943"
                        open
                      >
                        <summary class="article-expander__title">Learning Rate Free Bayesian Inference in Constrained Domains</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14943">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Louis Sharrock, Lester Mackey, Christopher Nemeth</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.15027"
                        open
                      >
                        <summary class="article-expander__title">A Rigorous Link between Deep Ensembles and (Variational) Bayesian
  Methods</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15027">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Veit David Wild, Sahra Ghalebikesabi, Dino Sejdinovic, Jeremias
  Knoblauch</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.15042"
                        open
                      >
                        <summary class="article-expander__title">Test like you Train in Implicit Deep Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.15042">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Zaccharie Ramzi, Pierre Ablin, Gabriel Peyr\&#x27;e, Thomas Moreau</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >DeepMind Blog</button>
                  <a class="source-heading__link" href="https://www.deepmind.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks"
                        open
                      >
                        <summary class="article-expander__title">An early warning system for novel AI risks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://assets-global.website-files.com/621e749a546b7592125f38ed/646f6e9992ceb1a002f3c316_16x9-min.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>AI researchers already use a range of evaluation benchmarks to identify unwanted behaviours in AI systems, such as AI systems making misleading statements, biased decisions, or repeating copyrighted content. Now, as the AI community builds and deploys increasingly powerful AI, we must expand the evaluation portfolio to include the possibility of extreme risks from general-purpose AI models that have strong skills in manipulation, deception, cyber-offense, or other dangerous capabilities.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-24 datetime="2023-05-24T22:23:33.000Z">2023-05-24</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-24 datetime="2023-05-24T22:23:33.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53075"
                        open
                      >
                        <summary class="article-expander__title">Stochastic Numerics and Statistical Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/25/stochastic-numerics-and-statistical-learning/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://cemse.kaust.edu.sa/sites/default/files/styles/max_fullhd_scale/public/2023-01/Stochastic%20Numerics%20Workshop%202022%20LED%20Signage%20Screens-01.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>This week, I am taking part in the Stochastic Numerics and Statistical Learning workshop, in KAUST, which should prove an interesting experience!</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58786"
                        open
                      >
                        <summary class="article-expander__title">Decipherment of Linear A</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58786&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;decipherment-of-linear-a">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Methodologically, the following communication from Elizabeth J. W. Barber is too important to be left buried in a comment to this post:  &quot;ChatGPT does cuneiform studies&quot; (5/21/23) As I showed in my 1974 book, Archaeological Decipherment, there is a mathematical algorithm showing how much text one needs to PROVABLY accomplish a decipherment for what sort […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.14077"
                        open
                      >
                        <summary class="article-expander__title">Mind the spikes: Benign overfitting of kernels and neural networks in
  fixed dimension</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14077">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Moritz Haas, David Holzm\&quot;uller, Ulrike von Luxburg, Ingo Steinwart</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.14045"
                        open
                      >
                        <summary class="article-expander__title">The CoT Collection: Improving Zero-shot and Few-shot Learning of
  Language Models via Chain-of-Thought Fine-Tuning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14045">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye,
  Jamin Shin, Minjoon Seo</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.14196"
                        open
                      >
                        <summary class="article-expander__title">ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14196">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, Omer
  Levy</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.13588"
                        open
                      >
                        <summary class="article-expander__title">Deep Learning with Kernels through RKHM and the Perron-Frobenius
  Operator</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.13588">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Yuka Hashimoto, Masahiro Ikeda, Hachem Kadri</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.14122"
                        open
                      >
                        <summary class="article-expander__title">Transferring Learning Trajectories of Neural Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.14122">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Daiki Chijiwa</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Python⇒Speed</button>
                  <a class="source-heading__link" href="https://pythonspeed.com/atom.xml">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://pythonspeed.com/articles/best-file-format-for-pandas/"
                        open
                      >
                        <summary class="article-expander__title">Choosing a good file format for Pandas</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://pythonspeed.com/articles/best-file-format-for-pandas/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://pythonspeed.com/assets/titles/best-file-format-for-pandas.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Before you can process your data with Pandas, you need to load it (from disk or remote storage).
There are plenty of data formats supported by Pandas, from CSV, to JSON, to Parquet, and many others as well.
Which should you use?
You don’t want loading the data to be slow, or use lots of memory: that’s pure overhead.
Ideally you’d want a file format that’s fast, efficient, small, and broadly supported.
You also want to make sure the loaded data has all the right types: numeric types, datetimes, and so on.
Some data formats do a better job at this than others.
While there is no one true answer that works for everyone, this article will try to help you narrow down the field and make an informed decision.
Read more...</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-23 datetime="2023-05-23T22:23:05.000Z">2023-05-23</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-23 datetime="2023-05-23T22:23:05.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53022"
                        open
                      >
                        <summary class="article-expander__title">art brut</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/24/art-brut-90/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/1683538746341-e1683549130187.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html"
                        open
                      >
                        <summary class="article-expander__title">Resolving code review comments with ML</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/resolving-code-review-comments-with-ml.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjoK3FH1StJnuqrj0gTExqLUxNkVfwRVmiG9tbCNUDV2I5295yqrPlw0L4hRHJmsruvZBIa_FqAFvJfwW7VU4XvxDU4ZweaW6ehENeU7-BLJaLVGPPtn-25cme5qTUldd11YigkAj6Ks9Tif6J3MePey_Gn3cAp3nQf9LMmVy4Eg3yF0qyBZPUKfYJYLw/w1200-h630-p-k-no-nu/comments2code.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Alexander Frömmgen, Staff Software Engineer, and Lera Kharatyan, Senior Software Engineer, Core Systems &amp; Experiences


  

Code-change reviews are a critical part of the software development process at scale, taking a significant amount of the code authors’ and the code reviewers’ time. As part of this process, the reviewer inspects the proposed code and asks the author for code changes through comments written in natural language. At Google, we see millions of reviewer comments per year, and authors require an average of ~60 minutes active shepherding time between sending changes for review and finally submitting the change. In our measurements, the required active work time that the code author must do to address reviewer comments grows almost linearly with the number of comme…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >The Berkeley Artificial Intelligence Research Blog</button>
                  <a class="source-heading__link" href="http://bair.berkeley.edu/blog/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://bair.berkeley.edu/blog/2023/05/23/lmd/"
                        open
                      >
                        <summary class="article-expander__title">GPT-4 + Stable-Diffusion &#x3D; ?: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://bair.berkeley.edu/blog/2023/05/23/lmd/">
                          <div class="article-summary-box-inner media-object">
                              <img src="http://bair.berkeley.edu/blog/assets/lmd/main.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>TL;DR: Text Prompt -&gt; LLM -&gt; Intermediate Representation (such as an image layout) -&gt; Stable Diffusion -&gt; Image.
Recent advancements in text-to-image generation with diffusion models have yielded remarkable results synthesizing highly realistic and diverse images. However, despite their impressive capabilities, diffusion models, such as Stable Diffusion, often struggle to accurately follow the prompts when spatial or common sense reasoning is required.
The following figure lists four scenarios in which Stable Diffusion falls short in generating images that accurately correspond to the given prompts, namely negation, numeracy, and attribute assignment, spatial relationships. In contrast, our method, LLM-grounded Diffusion (LMD), delivers much better prompt understanding in text-to-image gen…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Harvard ML Foundations</button>
                  <a class="source-heading__link" href="https://mlfoundations.org/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://mlfoundations.org/talk/lecun/"
                        open
                      >
                        <summary class="article-expander__title">Yann LeCun - Towards Machines that can Learn, Reason, and Plan.</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://mlfoundations.org/talk/lecun/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://mlfoundations.org/img/icon-192.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>How could machines learn as efficiently as humans and animals? How could machines learn how the world works and acquire common sense? How could machines learn to reason and plan? Current AI architectures, such as Auto-Regressive Large Language Models fall short.  I will propose a modular cognitive architecture that may constitute a path towards answering these questions.  The centerpiece of the architecture is a predictive world model that allows the system to predict the consequences of its actions and to plan a sequence of actions that optimize a set of objectives. The world model employs a Hierarchical Joint Embedding Predictive Architecture (H-JEPA) trained with self-supervised learning. The JEPA learns abstract representations of the percepts that are simultaneously maximally informative and maximally predictable. The corresponding working paper is available here - [A Path Towards Autonomous Machine Intelligence](https://openreview.net/forum?id&#x3D;BZ5a1r-kVsf)</span>
                                &ensp;<span class="article-reading-time">(&hairsp;1
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58781"
                        open
                      >
                        <summary class="article-expander__title">Chinese characters and the messiness of Chinese culture</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58781&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;chinese-characters-and-the-messiness-of-chinese-culture">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Is it really so? Uncannily and independently, Apollo Wu* sent me the following note before I made this post: Hànzì bùrú pīnyīn de guānjiàn lǐngyù shì páixù, jiǎnsuǒ hé réngōng zhìnéng. Fùzá, fánsuǒ, nán xué nán yòng shì wǒmen mùqián miànlín de kùnnán. Hànzì de luàn, biāozhìzhe Zhōngguó wénhuà de luàn! 汉字 比不上 字母文字 的 […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2205.10217"
                        open
                      >
                        <summary class="article-expander__title">Memorization and Optimization in Deep Neural Networks with Minimum
  Over-parameterization</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2205.10217">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Simone Bombari, Mohammad Hossein Amani, Marco Mondelli</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2201.13001"
                        open
                      >
                        <summary class="article-expander__title">Deep Discriminative to Kernel Generative Networks for Calibrated
  Inference</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2201.13001">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Jayanta Dey, Haoyin Xu, Ashwin De Silva, Will LeVine, Tyler M. Tomita,
  Ali Geisa, Tiffany Chu, Jacob Desman, Joshua T. Vogelstein</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.11997"
                        open
                      >
                        <summary class="article-expander__title">Robust Counterfactual Explanations for Neural Networks With
  Probabilistic Guarantees</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11997">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Faisal Hamman, Erfaun Noorani, Saumitra Mishra, Daniele Magazzeni,
  Sanghamitra Dutta</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.11965"
                        open
                      >
                        <summary class="article-expander__title">Not All Semantics are Created Equal: Contrastive Self-supervised
  Learning with Automatic Temperature Individualization</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11965">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Zi-Hao Qiu, Quanqi Hu, Zhuoning Yuan, Denny Zhou, Lijun Zhang, Tianbao
  Yang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2202.05250"
                        open
                      >
                        <summary class="article-expander__title">Adaptive and Robust Multi-Task Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2202.05250">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Yaqi Duan, Kaizheng Wang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >科学空间|Scientific Spaces</button>
                  <a class="source-heading__link" href="https://kexue.fm/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://kexue.fm/archives/9617"
                        open
                      >
                        <summary class="article-expander__title">NBCE：使用朴素贝叶斯拓展LLM的Context处理长度</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://kexue.fm/archives/9617">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>在LLM时代还玩朴素贝叶斯（Naive Bayes）？这可能是许多读者在看到标题后的首个想法。确实如此，当古老的朴素贝叶斯与前沿的LLM相遇时，产生了令人惊讶的效果——我们可以直接提升现有LLM...</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-22 datetime="2023-05-22T22:23:22.000Z">2023-05-22</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-22 datetime="2023-05-22T22:23:22.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53038"
                        open
                      >
                        <summary class="article-expander__title">Bernoulli factory on a budget</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/23/bernoulli-factory-on-a-budget/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2009/07/danish_bill-e1445288109123.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>A form of Bernoulli factory with limited energy from The Riddler: being given the choice of 0&lt;p&lt;1, what is the minimal number n of throws such that the outcomes of n iid B(p) draws can be partitioned into six groups of equal probability? Running a brute force R code [in the train to Cambridge] and […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58778"
                        open
                      >
                        <summary class="article-expander__title">Learning sinitic and sinoglyphic &quot;zero&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58778&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;learning-sinitic-and-sinoglyphic-zero">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Plus Indic, plus Arabic, Korean, Vietnamese, Hokkien (Taiwanese), Hakka, and Fuzhou (Eastern Min). For an exciting read / ride, be sure to follow the whole thread, travelling through time and space. 零 originally didn&#x27;t mean &#x27;zero,&#x27; but &#x27;small rain, drizzle.&#x27; Makes it easy to learn: Rain 雨 above, pronunciation 令 below (ok, tone is different). […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.11400"
                        open
                      >
                        <summary class="article-expander__title">Few-Shot Continual Learning for Conditional Generative Adversarial
  Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11400">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Cat P. Le, Juncheng Dong, Ahmed Aloui, Vahid Tarokh</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.11353"
                        open
                      >
                        <summary class="article-expander__title">Meta-learning for heterogeneous treatment effect estimation with
  closed-form solvers</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11353">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Tomoharu Iwata, Yoichi Chikahara</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.11278"
                        open
                      >
                        <summary class="article-expander__title">Real-Time Variational Method for Learning Neural Trajectory and its
  Dynamics</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.11278">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Matthew Dowling, Yuan Zhao, Il Memming Park</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2304.01762"
                        open
                      >
                        <summary class="article-expander__title">Incorporating Unlabelled Data into Bayesian Neural Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2304.01762">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Mrinank Sharma, Tom Rainforth, Yee Whye Teh, Vincent Fortuin</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >PyTorch Website</button>
                  <a class="source-heading__link" href="https://pytorch.org/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://pytorch.org/blog/out-of-the-box-acceleration/"
                        open
                      >
                        <summary class="article-expander__title">Out of the box acceleration and memory savings of 🤗 decoder models with PyTorch 2.0</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://pytorch.org/blog/out-of-the-box-acceleration/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://pytorch.org/assets/images/pytorch-logo.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>As part of PyTorch 2.0 release, an accelerated implementation of the attention mechanism as part of the “Better Transformer” project (and known in PyTorch as Accelerated Transformers) has been added natively into PyTorch as torch.nn.functional.scaled_dot_product_attention. This implementation leverages fused kernels from FlashAttention and Memory-efficient attention, and supports both training and inference.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-21 datetime="2023-05-21T22:23:12.000Z">2023-05-21</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-21 datetime="2023-05-21T22:23:12.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;52979"
                        open
                      >
                        <summary class="article-expander__title">Italy no-no’s</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/22/italy-no-nos/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2012/10/dsc_2982.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>The Lonely Planet blog has a list of prohibitions on tourists’ activities when visiting some Italian cities. Like Venice, Rome or Milan (below). Most of which is sort of obvious, like not walking around shirtless or barefoot away from beaches, feed the pigeons (although our kids did when visiting Venice for the first time!), hold […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58767"
                        open
                      >
                        <summary class="article-expander__title">Hack of the year: 1980</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58767&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;hack-of-the-year-1980">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>I recently stumbled on this 5/10/2023 Medium article by David Brock, &quot;A Backup of Historical Proportions&quot; — which reminded me of the Xerox Palo Alto Research Center (&quot;PARC&quot;) and the Xerox Alto. Those were the people and the machine that invented interactive GUIs on bit-mapped displays, the computer mouse, and so on — though it […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58745"
                        open
                      >
                        <summary class="article-expander__title">ChatGPT does cuneiform studies</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58745&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;chatgpt-does-cuneiform-studies">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>We have seen ChatGPT tell stories (and variants of the stories it tells), fancify Coleridge&#x27;s famous poem on Xanadu, pose a serious challenge to the Great Firewall of China, mimic VHM, write Haiku, and perform all manner of amazing feats.  In a forthcoming post, we will witness its efforts to translate Chinese poetry.  Today, we […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;11
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-20 datetime="2023-05-20T22:23:42.000Z">2023-05-20</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-20 datetime="2023-05-20T22:23:42.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53034"
                        open
                      >
                        <summary class="article-expander__title">foxhuntshire</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/21/foxhuntshire/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static01.nyt.com/images/2023/02/11/multimedia/11uk-foxhunt--gbtv/11uk-foxhunt--gbtv-superJumbo.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;52447"
                        open
                      >
                        <summary class="article-expander__title">Château Balac [Haut-Médoc]</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/20/chateau-balac-haut-medoc/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/03/1677843445855-e1677844190281.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58752"
                        open
                      >
                        <summary class="article-expander__title">AI comic strip creation?</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58752&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;ai-comic-strip-creation">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Today&#x27;s Tank McNamara: Of course the joke in this strip is the seven fingers on Tank&#x27;s right hand, and the eight fingers on his left hand. A quick web search for {ai comic generator} turns out lots of options. As far as I can tell, these are all systems for creating images, not image sequences […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58734"
                        open
                      >
                        <summary class="article-expander__title">&quot;Romanisation &#x27;gives clarity&#x27;&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58734&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;romanisation-gives-clarity">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>As we have pointed out countless times on Language Log, if one wishes to learn a Sinitic language, one can concentrate on the characters (writing system), one can rely exclusively on romanization or other phoneticization, or one can devise various means for combining the two approaches.  Here is a clever, fun method for learning Cantonese […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-19 datetime="2023-05-19T21:16:17.000Z">2023-05-19</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-19 datetime="2023-05-19T21:16:17.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Windows On Theory</button>
                  <a class="source-heading__link" href="https://windowsontheory.org">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://windowsontheory.org/?p&#x3D;8615"
                        open
                      >
                        <summary class="article-expander__title">GPT as an “Intelligence Forklift.”</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/cfee2d12a17cf70d8bfdc038070a679c423c7061ed67439f.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>[See my post with Edelman on AI takeover and Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.]  One challenge for considering the implications of “artificial intelligence,” especially of the “general” variety, is that we don’t have a consensus definition of intelligence. The Oxford Companion … Continue reading GPT as an “Intelligence Forklift.”</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Windows On Theory</button>
                  <a class="source-heading__link" href="https://windowsontheory.org">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://windowsontheory.org/?p&#x3D;8615"
                        open
                      >
                        <summary class="article-expander__title">GPT as an “Intelligence Forklift.”</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://windowsontheory.org/2023/05/19/gpt-as-an-intelligence-forklift/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/cfee2d12a17cf70d8bfdc038070a679c423c7061ed67439f.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>[See my post with Edelman on AI takeover and Aaronson on AI scenarios. This is a rough, with various fine print, caveats, and other discussions missing. Cross-posted on Windows on Theory.]  One challenge for considering the implications of “artificial intelligence,” especially of the “general” variety, is that we don’t have a consensus definition of intelligence. The Oxford Companion … Continue reading GPT as an “Intelligence Forklift.”</span>
                                &ensp;<span class="article-reading-time">(&hairsp;13
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Skywind Inside</button>
                  <a class="source-heading__link" href="https://www.skywind.me/blog">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://www.skywind.me/blog/?p&#x3D;2719"
                        open
                      >
                        <summary class="article-expander__title">互联网技术比游戏后端技术领先十年吗？</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://www.skywind.me/blog/archives/2719">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://skywind3000.github.io/images/blog/2023/lcevc.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>最近时间线上看到不少人在论战，做互联网的人觉得游戏服务端发展很慢，而互联网技术日新月异，觉得似乎互联网技术领先了游戏后端技术十年，这个结论显然是武断的，互联网就是发展到今天，就是任意一台互联网的服务器拿出来，其复杂度也远远比不上游戏服务器，即便各种 C/C++ 开发的互联网基建项目。 同时没有意识到游戏玩家之间交互性的复杂性与实时性是大部分互联网项目无法比较的。话分两头说，看到一些做游戏后端的同学觉得互联网更简单，电商之类的更是 CRUD 的增删改查，比起游戏服务器落后十年不止。 我觉得游戏服务端的同学实属没必要和这个互联网的人一般见识，不管不顾的也跟着说什么游戏服务端比互联网先进十年什么的，这是另一个极端了，一些情况也需要正视： 1）游戏服务端足够复杂，但是发展太慢，祖传代码修修补补跑个十多年的不要太多。能用固然是好事，但没有新观念的引入，导致可用性和开发效率一直没有太多提升。 2）各自闭门造车，没有形成行业标准与合力，这个项目的代码，很难在另一个项目共享，相互之间缺少支持和协同。 3）互联网后端随便拎出一个服务来（包括各种 C/C++ 基建）大概率都没有游戏服务端复杂，但最近十年日新月异，形成了很强的互相组合互相增强的态势。 我上面指的是互联网基建项目，不是互联网 CRUD，实话实说，游戏服务器的确很复杂很难，可能 ARPG 里砍一刀这种小事情，想砍的有手感，做互联网的也不一定能理解背后的复杂度有多少。但互联网近十年的发展，让其整体可用性，效能，开发效率，都上了很多个台阶，不应一味忽视。 如果继续觉得游戏服务端领先互联网十年可以直接右转了，开放心态的话我也可以多聊一些（点击下方 more 阅读更多）： 举个例子，音视频领域的基建，并不比游戏服务端简单： 1）一路高清视频 720-1080p 的，差不多每秒钟 2MB/s 的数据量，同时在线 100w 的，整个网络每秒钟至少有 2T/s 的数据量在跑着，不但不分服，而且玩家遍布世界每个角落，还要不卡不掉不延迟，这个数据量比起游戏的消息要大好几个数量级吧？在把这 2T/s 数据安排明白妥当的同时，还得保证延迟不能超过 500ms，超过就没法玩了。 2）一个房间的人数少的是 2-4 人，多的上千人，遍布 4-5 个国家，你一屏幕打开，可以同时看到 50 个人的视频，虽然是小窗口，但是你拉住任意小窗口，快速拉大到全屏，看不到明显的清晰度梯度切换带来的抖动，如何实现呢？ 3）全球上百个机房协同工作，组成一张很大的网络，一会这个机房出问题，一会那里线路阻塞了，能做到动态自如的切换，让用户几乎感觉不到，也不容易吧？ 4）更新无需停机，停服，即便一个 1000 人的房间后面的服务器更新，可能你都感觉不出来，视频的房间也算是有状态的，这种平滑的切换，不算简单吧？ 5）弱网情况下，开着车接着视频，不停切换基站，60% 的丢包情况下，虽然会卡一些，但如果要保证基础可用，也还是有点技术含量的吧。 ６）服务端跑视频编码器，即便有现成开源的也需要自己花大力气二次开发，编码器方面的积累，你不搞个四五年，你入不了手吧？这方面的知识日新月异，每年都有新标准，更新比游戏快多了。 ７）后端图象增强，允许带宽不足用户发送比较差的视频，增强成比较清晰的视频，这个 AI 增强技术，比 DLSS 1/2 复杂好几个台阶。 8）即便不是实时通信，点播，看着简单，也有很多挑战的地方，比如你客户端看短视频，不停的手指往上滑，连续划十个，不卡，秒出，丝滑切换，光这一点数据量有多大？客户端该怎么管理资源？服务端从接入服务，调度服务，到 CDN 和传输协议，要做多少项优化呢？ […]
The post 互联网技术比游戏后端技术领先十年吗？ appeared first on Skywind Inside.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/making-ml-models-differentially-private.html"
                        open
                      >
                        <summary class="article-expander__title">Making ML models differentially private: Best practices and open challenges</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/making-ml-models-differentially-private.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhqMCb-nNfoCncADD29b0YyxB4wN8bOhRph7pJBGzKyYc1bvdZ10VC3RkyUCJBopmvukjXJnZiJyiZ5ZIPyIW66ZfrYmBoJFrxx35T8OrL_HmNr4YIKzBS5y6Ej24f1Mjsu-IqH5ECyzPBRKDRtoGgQhoKoOpILElqHDIGsn9SiI-7x58qc_nbtQ1JZ1A/w1200-h630-p-k-no-nu/DPfy%20hero.gif" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Natalia Ponomareva and Alex Kurakin, Staff Software Engineers, Google Research






Large machine learning (ML) models are ubiquitous in modern applications: from spam filters to recommender systems and virtual assistants. These models achieve remarkable performance partially due to the abundance of available training data. However, these data can sometimes contain private information, including personal identifiable information, copyright material, etc. Therefore, protecting the privacy of the training data is critical to practical, applied ML.  



Differential Privacy (DP) is one of the most widely accepted technologies that allows reasoning about data anonymization in a formal way. In the context of an ML model, DP can guarantee that each individual user&#x27;s contribution will …</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Harvard ML Foundations</button>
                  <a class="source-heading__link" href="https://mlfoundations.org/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://mlfoundations.org/talk/lilicrap/"
                        open
                      >
                        <summary class="article-expander__title">Timothy Lillicrap - Model-based reinforcement learning and the future of language models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://mlfoundations.org/talk/lilicrap/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://mlfoundations.org/img/icon-192.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Large language models are capable of an incredible array of tasks. Language models are pre-trained on large amounts of text data from the internet. Then they are fine-tuned on instruction following and further improved by optimizing human preferences. The resulting models are imperfect but are nevertheless able to hold conversations, solve problems, and use tools. How quickly will these models continue to improve? There are a variety of opinions. The answer to this question is also important because language models are poised to make significant changes to the way we live and work. Some researchers think we’ve hit a plateau in performance and that progress will stall without a breakthrough. Others predict the arrival of general intelligence within a couple of years.Putting aside the question of AGI, I will argue that rapid progress in model capabilities will continue without the need for a breakthrough. I will draw connections between language model research and the past decade of work in deep reinforcement learning, especially the Go &amp; Starcraft projects.
These projects followed a similar methodology - models were pre-trained using data collected from game databases. Then they were improved iteratively with reinforcement learning. Viewed from the vantage point of model-based reinforcement learning, optimization of language models is in its infancy. Put simply, there are clear experiments which are likely to create much better models. Why haven’t these experiments been run already? Since performant language models are large and reward is derived from human preferences, experiments require extensive coordination of people and compute. Given economic incentives, we can expect researchers to overcome these hurdles. There is therefore good reason to believe that language model capabilities will continue to improve rapidly. This motivates increased investment in AI safety research, policy, and governance.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;1
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2107.08924"
                        open
                      >
                        <summary class="article-expander__title">Epistemic Neural Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08924">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Ian Osband, Zheng Wen, Seyed Mohammad Asghari, Vikranth Dwaracherla,
  Morteza Ibrahimi, Xiuyuan Lu, Benjamin Van Roy</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.10633"
                        open
                      >
                        <summary class="article-expander__title">Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample
  Complexity for Learning Single Index Models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10633">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Alex Damian, Eshaan Nichani, Rong Ge, Jason D. Lee</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2002.01368"
                        open
                      >
                        <summary class="article-expander__title">Unified machine learning: Open-set learning with augmented category by
  exploiting unlabelled data (Open-LACU)</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.01368">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Emile R. Engelbrecht, Johan A. du Preez</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2209.10438"
                        open
                      >
                        <summary class="article-expander__title">A Measure of the Complexity of Neural Representations based on Partial
  Information Decomposition</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2209.10438">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>David A. Ehrlich, Andreas C. Schneider, Viola Priesemann, Michael
  Wibral, Abdullah Makkeh</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-18 datetime="2023-05-18T22:23:56.000Z">2023-05-18</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-18 datetime="2023-05-18T22:23:56.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53019"
                        open
                      >
                        <summary class="article-expander__title">French coast</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/19/french-coast/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/1683538746363-e1683548921528.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Visit the post for more.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html"
                        open
                      >
                        <summary class="article-expander__title">Sparse video tubes for joint video and image vision transformers</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/sparse-video-tubes-for-joint-video-and.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg5vGQDyw66Z4hevP1JdKXnn8OCKudaDk2bacIPBkxtSYH1BgyNqXhK2QXOr-ANdX6MfoZp-jzVsETmH6kgy_Tvnii7ylDJEA-u5pJXareZRDyIBsRqguw2-AcDejtp3HXImtSLXKs_wUfMf8plDnpWzk1KGCgmm0U_j31qGh3rU4Cyv58HTpiocpyZiA/w1200-h630-p-k-no-nu/TubeViT%20hero.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by AJ Piergiovanni and Anelia Angelova, Research Scientists, Google








Video understanding is a challenging problem that requires reasoning about both spatial information (e.g., for objects in a scene, including their locations and relations) and temporal information for activities or events shown in a video. There are many video understanding applications and tasks, such as understanding the semantic content of web videos and robot perception. However, current works, such as ViViT and TimeSFormer, densely process the video and require significant compute, especially as model size plus video length and resolution increase. 



In “Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video Learning”, to be presented at CVPR 2023, we introduce a simple technique that tur…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;92
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html"
                        open
                      >
                        <summary class="article-expander__title">Responsible AI at Google Research: PAIR</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/responsible-ai-at-google-research-pair.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDUj2YMMcVzCHuAQ9TYS3IkauQbh9Tti-nZl6LZOMwwieYdyJM7DHShetIblRhW0hvTaPvDmK2f0SDu9XcLCVg0780I3GnYU0FrA27s0-MiQXQ5xPUCGqTSx-7KNJLwrlczkco2Ql5KzMeVHNXBl2oeaN0gMCPi7A2Bpc6eDpzjwZIHoNMiWLfQqL2vQ/w1200-h630-p-k-no-nu/image3.gif" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Lucas Dixon and Michael Terry, co-leads, PAIR, Google Research




PAIR (People + AI Research) first launched in 2017 with the belief that “AI can go much further — and be more useful to all of us — if we build systems with people in mind at the start of the process.” We continue to focus on making AI more understandable, interpretable, fun, and usable by more people around the world. It’s a mission that is particularly timely given the emergence of generative AI and chatbots.



Today, PAIR is part of the Responsible AI and Human-Centered Technology team within Google Research, and our work spans this larger research space: We advance foundational research on human-AI interaction (HAI) and machine learning (ML); we publish educational materials, including the PAIR Guidebook and …</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >科学空间|Scientific Spaces</button>
                  <a class="source-heading__link" href="https://kexue.fm/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://kexue.fm/archives/9607"
                        open
                      >
                        <summary class="article-expander__title">基于量子化假设推导模型的尺度定律（Scaling Law）</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://kexue.fm/archives/9607">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>尺度定律（Scaling Law），指的是模型能力与模型尺度之间的渐近关系。具体来说，模型能力我们可以简单理解为模型的损失函数，模型尺度可以指模型参数量、训练数据量、训练步数等，所谓尺度定律，就...</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2106.11211"
                        open
                      >
                        <summary class="article-expander__title">Stratified Learning: A General-Purpose Statistical Method for Improved
  Learning under Covariate Shift</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11211">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Maximilian Autenrieth, David A. van Dyk, Roberto Trotta, David C.
  Stenning</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.09957"
                        open
                      >
                        <summary class="article-expander__title">Deep quantum neural networks form Gaussian processes</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09957">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Diego Garc\&#x27;ia-Mart\&#x27;in, Martin Larocca, M. Cerezo</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.10379"
                        open
                      >
                        <summary class="article-expander__title">Active Learning in Symbolic Regression Performance with Physical
  Constraints</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.10379">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Jorge Medina, Andrew D. White</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2303.00564"
                        open
                      >
                        <summary class="article-expander__title">Learning curves for deep structured Gaussian feature models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.00564">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Jacob A. Zavatone-Veth, Cengiz Pehlevan</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-17 datetime="2023-05-17T22:23:17.000Z">2023-05-17</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-17 datetime="2023-05-17T22:23:17.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53069"
                        open
                      >
                        <summary class="article-expander__title">grasshoppers for pythons</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/18/grasshoppers-for-pythons/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2020/09/vallouise103-e1598802275394.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Following my earlier post on the terrible performances of ChatGPT for a grasshopping riddle, Bob Carpenter sent me his interaction with GPT4, using the same entry. Here is the python code outcome he obtained. The code is running  and the answer is correct. BC: Thanks. Can you write a python program to simulate the final […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58720"
                        open
                      >
                        <summary class="article-expander__title">Phở</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58720&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;pho">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Since about the 90s, pho has been popping up all over the place.  It has been especially conspicuous after the turn of the millennium, and I think it adapted well to the pandemic as a quick and ready kind of street food.  I&#x27;ve often wondered whether it had anything to do with French &quot;fire&quot; or […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;10
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2112.07611"
                        open
                      >
                        <summary class="article-expander__title">Speeding up Learning Quantum States through Group Equivariant
  Convolutional Quantum Ans\&quot;atze</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2112.07611">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Han Zheng, Zimu Li, Junyu Liu, Sergii Strelchuk, Risi Kondor</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2009.03836"
                        open
                      >
                        <summary class="article-expander__title">Graph neural networks-based Scheduler for Production planning problems
  using Reinforcement Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.03836">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Mohammed Sharafath Abdul Hameed, Andreas Schwung</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2303.03544"
                        open
                      >
                        <summary class="article-expander__title">Expressivity of Shallow and Deep Neural Networks for Polynomial
  Approximation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2303.03544">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Itai Shapira</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.09557"
                        open
                      >
                        <summary class="article-expander__title">Learning from Aggregated Data: Curated Bags versus Random Bags</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.09557">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Lin Chen, Thomas Fu, Amin Karbasi, Vahab Mirrokni</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2301.07733"
                        open
                      >
                        <summary class="article-expander__title">Learning-Rate-Free Learning by D-Adaptation</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2301.07733">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Aaron Defazio, Konstantin Mishchenko</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-16 datetime="2023-05-16T22:23:17.000Z">2023-05-16</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-16 datetime="2023-05-16T22:23:17.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53043"
                        open
                      >
                        <summary class="article-expander__title">Festschift for Sylvia</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/17/53043/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/1683965654838-1-e1683966278231.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>At Sylvia Richardson’s career celebration last Friday, I gave a talk on How many components in a mixture? which was most relevant given Sylvia’s contributions to mixture inference over the years, including her highly influential 1997 Read Paper with Peter Green. The other talks highlighted the many facets of Sylvia to the field and the […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/using-reinforcement-learning-for.html"
                        open
                      >
                        <summary class="article-expander__title">Using reinforcement learning for dynamic planning in open-ended conversations</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/using-reinforcement-learning-for.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1pRX6ly5Tgckfk47u8_KxBasWJhuFoQ4SzbSmiK3SrQOKn8jXr3RHvb32lGlBksKl3-wXCwU8UnEhRp6YztIREY874N4i1289xQKHlO64QZqD9tQBiBQHMW-S5B4u5mSaBw6lgbuTEVplIrBfaOIcX-7-YG6D0lGzSOMN7r9umjZwMoE_1t1gcsEOZA/w1200-h630-p-k-no-nu/rlxtalk.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Deborah Cohen, Staff Research Scientist, and Craig Boutilier, Principal Scientist, Google Research




As virtual assistants become ubiquitous, users increasingly interact with them to learn about new topics or obtain recommendations and expect them to deliver capabilities beyond narrow dialogues of one or two turns. Dynamic planning, namely the capability to look ahead and replan based on the flow of the conversation, is an essential ingredient for the making of engaging conversations with the deeper, open-ended interactions that users expect.
 

While large language models (LLMs) are now beating state-of-the-art approaches in many natural language processing benchmarks, they are typically trained to output the next best response, rather than planning ahead, which is required fo…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58724"
                        open
                      >
                        <summary class="article-expander__title">&quot;Quid pro crow&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58724&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;quid-pro-crow">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>In Maria Bartiromo&#x27;s recent interview with James Comer (R-KY), there&#x27;s an interesting speech error — &quot;quid pro crow&quot; for &quot;quid pro quo&quot;: This being Language Log rather than Making Fun Of Politicians Log, I&#x27;m going to start by assuming that this was a slip of the tongue rather than an inadequate command of legal Latin […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58702"
                        open
                      >
                        <summary class="article-expander__title">CCP scamming with a Taiwanese-like accent</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58702&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;ccp-scamming-with-a-taiwanese-like-accent">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Topolects matter: Taiwanese buys anti-CCP book, gets scam call from Chinese propagandist: Caller posing as Eslite Bookstore’s ‘marketing department’ tells consumer book content inappropriate By Stephanie Chiang, Taiwan News, Staff Reporter (5/14/23) Before delving into the substance of this report, I should mention that Eslite is a huge, and hugely influential, bookstore in Taiwan. AntC, […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2302.09574"
                        open
                      >
                        <summary class="article-expander__title">Guided Deep Kernel Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.09574">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Idan Achituve, Gal Chechik, Ethan Fetaya</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2302.03068"
                        open
                      >
                        <summary class="article-expander__title">Evaluating Self-Supervised Learning via Risk Decomposition</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2302.03068">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Yann Dubois, Tatsunori Hashimoto, Percy Liang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.00608"
                        open
                      >
                        <summary class="article-expander__title">Differentiable Neural Networks with RePU Activation: with Applications
  to Score Estimation and Isotonic Regression</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.00608">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Guohao Shen, Yuling Jiao, Yuanyuan Lin, Jian Huang</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.08642"
                        open
                      >
                        <summary class="article-expander__title">Topological Interpretability for Deep-Learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.08642">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Adam Spannaus, Heidi A.Hanson, Lynne Penberthy, Georgia Tourassi</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >PyTorch Website</button>
                  <a class="source-heading__link" href="https://pytorch.org/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://pytorch.org/blog/pytorch-conference-2023/"
                        open
                      >
                        <summary class="article-expander__title">PyTorch Conference 2023: Join us in San Francisco October 16-17</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://pytorch.org/blog/pytorch-conference-2023/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://pytorch.org/assets/images/pytorch-logo.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>No content preview</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-15 datetime="2023-05-15T22:23:34.000Z">2023-05-15</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-15 datetime="2023-05-15T22:23:34.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;53063"
                        open
                      >
                        <summary class="article-expander__title">more [grass]hope</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/16/more-grasshope/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2020/09/vallouise103-e1598802275394.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Following my earlier post on the terrible performances of ChatGPT for a grasshopping riddle, Bob Carpenter sent me his interaction with GPT4, using the same entry. Here is the outcome he obtained. The answer is correct, but the reasoning is wrong. GPT4: This is a classic problem of infinite series and expected values in probability […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html"
                        open
                      >
                        <summary class="article-expander__title">Larger language models do in-context learning differently</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQS0-Pkd_JiN7brkU6zV0-FEisuUcnKs0I56t37HVYKMgKStmwNgLREYn5CfURvW-lMvKbHU4cEV9elAu9qe4-M_FvveTlvBQHezbksTlH3YfOAk4TyJiXYiGBW_95RGKIW-JyjAQiC0Zd4VIjZrCSIm1PEBqrIAqbiEklluNunTOMhX_7CU9Degbwqg/w1200-h630-p-k-no-nu/SULICL.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Jerry Wei, Student Researcher, and Denny Zhou, Principal Scientist, Google Research




There have recently been tremendous advances in language models, partly because they can perform tasks with strong performance via in-context learning (ICL), a process whereby models are prompted with a few examples of input-label pairs before performing the task on an unseen evaluation example. In general, models’ success at in-context learning is enabled by:
 


Their use of semantic prior knowledge from pre-training to predict labels while following the format of in-context examples (e.g., seeing examples of movie reviews with “positive sentiment” and “negative sentiment” as labels and performing sentiment analysis using prior knowledge).


Learning the input-label mappings in context from …</span>
                                &ensp;<span class="article-reading-time">(&hairsp;92
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/consensus-and-subjectivity-of-skin-tone_15.html"
                        open
                      >
                        <summary class="article-expander__title">Consensus and subjectivity of skin tone annotation for ML fairness</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/consensus-and-subjectivity-of-skin-tone_15.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgZx6lCt5n99GkA_Q8Jd3S0msBQNxZpoFWH9Jc2vwcnyxLUhWn-s8f7zn2u5YRNrCbdGki6sRB9pcJ-n_0dGgqD47BM72DVy3zCykkRgJjP1zohvB9l7KPgetFJiLebxm9EvtWBAjRM59eAUbVUPfmuUWAeKc6ljtiMOfiAnOttUBtkYNcXm2HieMod2Q/w1200-h630-p-k-no-nu/MST-E.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Candice Schumann, Software Engineer, and Gbolahan O. Olanubi, User Experience Researcher, Google Research




Skin tone is an observable characteristic that is subjective, perceived differently by individuals (e.g., depending on their location or culture) and thus is complicated to annotate. That said, the ability to reliably and accurately annotate skin tone is highly important in computer vision. This became apparent in 2018, when the Gender Shades study highlighted that computer vision systems struggled to detect people with darker skin tones, and performed particularly poorly for women with darker skin tones. The study highlights the importance for computer researchers and practitioners to evaluate their technologies across the full range of skin tones and at intersections of…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58706"
                        open
                      >
                        <summary class="article-expander__title">AI Anchorman &quot;@EdisonGPT&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58706&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;ai-anchorman-edisongpt">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>The future of news? 🚨 BREAKING!!! Just when we thought we&#x27;d defeated the #CensorshipIndustrialComplex and @TuckerCarlson rose again on @Twitter, @elonmusk appoints #LindaYaccarino as new #TwitterCEO. Can an Executive Chair from the #WEF lead the revolution?#BreakingNews #EdisonThrustwell #WTF pic.twitter.com/uHt7NjCiO6 — Edison Thrustwell (@EdisonGPT) May 12, 2023 That&#x27;s the first &quot;Edison Thrustwell&quot; tweet that I saw. […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58687"
                        open
                      >
                        <summary class="article-expander__title">Sperm whale talk</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58687&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;sperm-whale-talk">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Animal communication is not a favorite topic here at Language Log, but according to the following account, one project concerning it seems serious and is being conducted by credible scientists.  Although their claims for its ultimate significance may be inflated, I believe the research they are undertaking is worth considering, especially after hearing the clicks […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.07617"
                        open
                      >
                        <summary class="article-expander__title">Scalable Coupling of Deep Learning with Logical Reasoning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.07617">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Marianne Defresne, Sophie Barbe, Thomas Schiex</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2105.09095"
                        open
                      >
                        <summary class="article-expander__title">Aleatoric uncertainty for Errors-in-Variables models in deep regression</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09095">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>J\&quot;org Martin, Clemens Elster</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2006.03476"
                        open
                      >
                        <summary class="article-expander__title">COVID-19 diagnosis by routine blood tests using machine learning</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03476">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Matja\v{z} Kukar, Gregor Gun\v{c}ar, Toma\v{z} Vovko, Simon Podnar,
  Peter \v{C}ernel\v{c}, Miran Brvar, Mateja Zalaznik, Mateja Notar, Sa\v{s}o
  Mo\v{s}kon, Marko Notar</span>
                                &ensp;<span class="article-reading-time">(&hairsp;3
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-14 datetime="2023-05-14T22:23:37.000Z">2023-05-14</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-14 datetime="2023-05-14T22:23:37.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;52858"
                        open
                      >
                        <summary class="article-expander__title">Chez Guy**(*)</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/15/chez-guy/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/1683018488094-e1683021548789.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>While I rarely enter company sweepstakes and lotteries (and correlatively never win!), I answered a contest from my credit card company around the 2022 Beijing Winter Olympics, and won the prize of having a Chinese dinner cooked at home by a chef, news that I first treated as a spam for being so improbable. The […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58691"
                        open
                      >
                        <summary class="article-expander__title">&quot;Mama ŠČ!&quot;</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58691&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;mama-sc">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Among the entries in the  2023 Eurovision Song Contest,  there&#x27;s one of particular linguistic and political interest — from Croatia, Let 3&#x27;s Mama ŠČ!: [The video of the song&#x27;s final Eurovision performance is blocked (at least for now) in the U.S. …] The Croatian lyrics and an English translation are available on genius.com, and the […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58671"
                        open
                      >
                        <summary class="article-expander__title">Mathematical parking</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58671&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;mathematical-parking">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Sign on the campus of Zhōngguó kēxué jìshù dàxué 中国科学技术大学 (University of Science and Technology of China) telling people how to park: tíng hǎo chēliàng de hánglièshì 停好车辆的行列式* (&quot;park your vehicles well according to rows and columns&quot;)*matrix determinant zuò hǎo xiūyǎng de wéijīfēn 做好修养的微积分* (&quot;cultivate yourself well to gradually accumulate points [i.e., merit]&quot;)*calculus Parking according to one&#x27;s profession. Selected […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-13 datetime="2023-05-13T22:23:23.000Z">2023-05-13</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-13 datetime="2023-05-13T22:23:23.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;52986"
                        open
                      >
                        <summary class="article-expander__title">grass hopping on the wrong fgpt</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/14/grass-hopping-on-the-wrong-fgpt/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2023/05/temp-4.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Checking the R coding abilities of ChatGPT, I entered the latest Riddler puzzle that asks for the expected value of the stationary distribution of a slowing-down random walk over the real line when the N-th jump from x is to x±2-N. Which is ½ since the limiting distribution is uniform over (-1,1). The first proposed […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58680"
                        open
                      >
                        <summary class="article-expander__title">Iowa town names</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58680&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;iowa-town-names">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>I&#x27;m in Ames, home of Iowa State University.  The next town down the road is Nevada.  What?  Yes, but it&#x27;s /nəˈveɪdə/ nə-VAY-də, not /nɪˈvædə/ nih-VAD-ə; Spanish: [neˈβaða], and the locals I&#x27;ve met know the difference.  The same thing holds for Madrid, which is on the other side of Ames; it is /ˈmædrɪd/, not /məˈdrɪd/ mə-DRID, Spanish: [maˈðɾið]. […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58677"
                        open
                      >
                        <summary class="article-expander__title">Zen again</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58677&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;zen-again">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>From Nancy Friedman: I&#x27;m writing about &quot;zen&quot; in brand names and corporate lingo, having been amused by an email from Medium (where I&#x27;m a contributing writer) touting the platform&#x27;s updates as &quot;Project Zen&quot;–a name chosen &quot;because that&#x27;s our goal: a zen-like reading experience.&quot;   I&#x27;m not sure I know what a &quot;zen-like reading experience&quot; is […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;7
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>
      <section class="daily-content js-toggle-accordions-scope">
        <h2 class="daily-heading">
          <button
            class="daily-heading-toggle"
            data-action="toggle-accordions"
            title="Click to toggle the day, Ctrl + click to toggle all."
          >
            <time class="daily-heading-toggle__weekday js-offset-weekday" data-offset-date=2023-05-12 datetime="2023-05-12T22:23:30.000Z">2023-05-12</time>
            <time class="daily-heading-toggle__date js-offset-date" data-offset-date=2023-05-12 datetime="2023-05-12T22:23:30.000Z"></time>
          </button>
        </h2>
        <ul class="sources card">
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Xi&#x27;an&#x27;s Og</button>
                  <a class="source-heading__link" href="https://xianblog.wordpress.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://xianblog.wordpress.com/?p&#x3D;52971"
                        open
                      >
                        <summary class="article-expander__title">operation precisely impossible</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://xianblog.wordpress.com/2023/05/13/operation-precisely-impossible/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://xianblog.files.wordpress.com/2012/01/pict0448-e1326730756979.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Since the solution to the previous riddle from The Riddler on the maximum of  different terms in the composed operation a∅b∅c∅d∅e∅f depending on the bracketing ordering and the meaning of each ∅ among one of the six elementary operations got posted today as 974,860, I got back to my R code to understand why it […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;6
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Google AI Blog</button>
                  <a class="source-heading__link" href="http://ai.googleblog.com/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/f-vlm-open-vocabulary-object-detection.html"
                        open
                      >
                        <summary class="article-expander__title">F-VLM: Open-vocabulary object detection upon frozen vision and language models</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/f-vlm-open-vocabulary-object-detection.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjd5HnIvLfcA1rgwAR8Jg3M9p1kkVhDC74oaHdUuRS5MPXqyWYoZURIj6Ibllzk2GKfFMNzB-fKxI3J0NNxyLZimLcGEC6GBzX7FG3pUGC-vRECHDaCXkorH0BL9kIBsOO4EAa3tF3HE3eH0QdzKOLwQQYI_NiToJBmBatxTVNOmYctagvi1ml2YLbgtA/w1200-h630-p-k-no-nu/F-VLM%20hero.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Weicheng Kuo and Anelia Angelova, Research Scientists, Google Research






Detection is a fundamental vision task that aims to localize and recognize objects in an image. However, the data collection process of manually annotating bounding boxes or instance masks is tedious and costly, which limits the modern detection vocabulary size to roughly 1,000 object classes. This is orders of magnitude smaller than the vocabulary people use to describe the visual world and leaves out many categories. Recent vision and language models (VLMs), such as CLIP, have demonstrated improved open-vocabulary visual recognition capabilities through learning from Internet-scale image-text pairs. These VLMs are applied to zero-shot classification using frozen model weights without the need for fine-…</span>
                                &ensp;<span class="article-reading-time">(&hairsp;93
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html"
                        open
                      >
                        <summary class="article-expander__title">Enabling conversational interaction on mobile with LLMs</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiBtmVasIEAQHIKlt2az_MQbF13URtJ9LYTtcACwT54elVT1Jr-l-o7MvsHntd4HnN3bxO-rniQdlt3pM1ty7SOpMhXaEsrD0Y8azCU-zAhs3xHR1OE2hsYs_PMysluHt7QItT2klQyU5xGEKIg8JaMNwGsGRGc1axpXBMWUL1KGLqWtSm2bDGDw4B0Pg/w1200-h630-p-k-no-nu/LLM4Mobile%20hero.jpg" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Posted by Bryan Wang, Student Researcher, and Yang Li, Research Scientist, Google Research





Intelligent assistants on mobile devices have significantly advanced language-based interactions for performing simple daily tasks, such as setting a timer or turning on a flashlight. Despite the progress, these assistants still face limitations in supporting conversational interactions in mobile user interfaces (UIs), where many user tasks are performed. For example, they cannot answer a user&#x27;s question about specific information displayed on a screen. An agent would need to have a computational understanding of graphical user interfaces (GUIs) to achieve such capabilities. 



Prior research has investigated several important technical building blocks to enable conversational interaction with …</span>
                                &ensp;<span class="article-reading-time">(&hairsp;94
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Harvard ML Foundations</button>
                  <a class="source-heading__link" href="https://mlfoundations.org/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://mlfoundations.org/talk/choi/"
                        open
                      >
                        <summary class="article-expander__title">Yejin Choi - Common Sense: the Dark Matter of Language and Intelligence</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://mlfoundations.org/talk/choi/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://mlfoundations.org/img/icon-192.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Scale appears to be the winning recipe in today&#x27;s leaderboards. And yet, extreme-scale neural models are (un)surprisingly brittle and make errors that are often nonsensical and even counterintuitive. In this talk, I will argue for the importance of knowledge, especially commonsense knowledge, as well as inference-time reasoning algorithms, and demonstrate how smaller models developed in academia can still have an edge over larger industry-scale models, if powered with knowledge and/or reasoning algorithms.</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Language Log</button>
                  <a class="source-heading__link" href="https://languagelog.ldc.upenn.edu/nll">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58650"
                        open
                      >
                        <summary class="article-expander__title">-tucky</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://languagelog.ldc.upenn.edu/nll/?p&#x3D;58650&amp;utm_source&#x3D;rss&amp;utm_medium&#x3D;rss&amp;utm_campaign&#x3D;tucky">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>Last weekend, I was in Omaha for the annual Berkshire-Hathaway Shareholders Meeting.  Not that I am a shareholder of Berkshire-Hathaway, but simply because I was curious to see two nonagenarian financial wizards hold forth in front of 20,000 enthusiastic fans for a whole day.  I wasn&#x27;t disappointed, though I must confess that I didn&#x27;t understand […]</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >科学空间|Scientific Spaces</button>
                  <a class="source-heading__link" href="https://kexue.fm/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://kexue.fm/archives/9603"
                        open
                      >
                        <summary class="article-expander__title">Transformer升级之路：9、一种全局长度外推的新思路</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://kexue.fm/archives/9603">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>说到Transformer无法处理超长序列的原因，大家的第一反应通常都是Self Attention的二次复杂度。但事实上，即便忽略算力限制，常规的Transformer也无法处理超长序列，因为...</span>
                                &ensp;<span class="article-reading-time">(&hairsp;5
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >Statistics » Event Diary</button>
                  <a class="source-heading__link" href="https://warwick.ac.uk/fac/sci/statistics/event_diary/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="8a1785d7880083fb01880ee837704378"
                        open
                      >
                        <summary class="article-expander__title">07/06 1pm-2pm: CRiSM Seminar</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem&#x3D;8a17841b835b10a4018360b5677a44f9">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>When:
	
  		13:00
		-
		14:00, Wed, 07 Jun &#x27;23

	
Where: MB0.07</span>
                                &ensp;<span class="article-reading-time">(&hairsp;1
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="8a1785d7880083fb01880ee837704379"
                        open
                      >
                        <summary class="article-expander__title">21/06 1pm-2pm: CRiSM Seminar</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://warwick.ac.uk/fac/sci/statistics/event_diary/?calendarItem&#x3D;8a17841b835b10a4018360b5677a44f9">
                          <div class="article-summary-box-inner media-object">
                            <span class="media-object__text">
                              <span>When:
	
  		13:00
		-
		14:00, Wed, 21 Jun &#x27;23

	
Where: MB0.07</span>
                                &ensp;<span class="article-reading-time">(&hairsp;1
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >arxivist feed</button>
                  <a class="source-heading__link" href="https://www.arxivist.com">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.06884"
                        open
                      >
                        <summary class="article-expander__title">Risk-limiting Financial Audits via Weighted Sampling without Replacement</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06884">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Shubhanshu Shekhar, Ziyu Xu, Zachary C. Lipton, Pierre J. Liang,
  Aaditya Ramdas</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2108.12515"
                        open
                      >
                        <summary class="article-expander__title">Convergence Rates for Learning Linear Operators from Noisy Data</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12515">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Maarten V. de Hoop, Nikola B. Kovachki, Nicholas H. Nelsen, Andrew M.
  Stuart</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.06703"
                        open
                      >
                        <summary class="article-expander__title">Neural Fine-Gray: Monotonic neural networks for competing risks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06703">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Vincent Jeanselme, Chang Ho Yoon, Brian Tom, Jessica Barrett</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.06648"
                        open
                      >
                        <summary class="article-expander__title">Generalization bounds for neural ordinary differential equations and
  deep residual networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06648">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Pierre Marion</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="http://arxiv.org/abs/2305.06986"
                        open
                      >
                        <summary class="article-expander__title">Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural
  Networks</summary>
                        <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2305.06986">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Eshaan Nichani, Alex Damian, Jason D. Lee</span>
                                &ensp;<span class="article-reading-time">(&hairsp;2
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
            <li class="card__section">
              <section class="js-toggle-accordions-scope">
                <h3 class="source-heading">
                  <button
                    class="source-heading__name"
                    data-action="toggle-accordions"
                    title="Click to toggle the source, Ctrl + click to toggle all."
                  >PyTorch Website</button>
                  <a class="source-heading__link" href="https://pytorch.org/">Open</a>
                </h3>
                <section class="articles-per-source">
                    <article>
                      <details
                        class="article-expander"
                        data-action="toggle-native-accordion"
                        data-accordion-key="https://pytorch.org/blog/language-identification/"
                        open
                      >
                        <summary class="article-expander__title">Language Identification: Building an End-to-End AI Solution using PyTorch</summary>
                        <a class="article-summary-link article-summary-box-outer" href="https://pytorch.org/blog/language-identification/">
                          <div class="article-summary-box-inner media-object">
                              <img src="https://pytorch.org/assets/images/pytorch-logo.png" loading="lazy" class="media-object__media article-image" />
                            <span class="media-object__text">
                              <span>Language Identification is the process of identifying the primary language from multiple audio input samples. In natural language processing (NLP), language identification is an important problem and a challenging issue. There are many language-related tasks such as entering text on your phone, finding news articles you enjoy, or discovering answers to questions that you may have. All these tasks are powered by NLP models. To decide which model to invoke at a particular point in time, we must perform language identification.</span>
                                &ensp;<span class="article-reading-time">(&hairsp;8
                                  min&hairsp;)</span>
                            </span>
                          </div>
                        </a>
                      </details>
                    </article>
                </section>
              </section>
            </li>
        </ul>
      </section>

    <footer>
      <a class="footer-link" href="https://github.com/Furyton/misc-feed/actions/runs/5230166152">
        <time id="build-timestamp" datetime="2023-06-10T13:16:19.196Z">2023-06-10T13:16:19.196Z</time>
      </a>
      <a class="footer-link" href="https://github.com/osmoscraft/osmosfeed">osmosfeed 1.15.1</a>
    </footer>
    <script src="index.js?v1.14.4"></script>
    <!-- %before-body-end.html% -->
  </body>

</html>